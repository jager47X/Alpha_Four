2025-01-16 05:01:24,698 - INFO - Policy network initialized.
2025-01-16 05:01:24,729 - INFO - Target network initialized.
2025-01-16 05:01:24,729 - INFO - Optimizer initialized.
2025-01-16 05:01:24,729 - INFO - Replay buffer initialized.
2025-01-16 05:01:24,791 - INFO - Checkpoint file path: Connect4_Agent_Model.pth verified.
2025-01-16 05:01:24,791 - INFO - Loaded policy network state_dict.
2025-01-16 05:01:24,791 - INFO - Loaded optimizer state_dict.
2025-01-16 05:01:24,791 - INFO - Loaded start episode: 1100
2025-01-16 05:01:24,791 - INFO - TOTAL_EPISODES adjusted to 98900 after subtracting 1100.
2025-01-16 05:01:24,791 - INFO - Current Epsilon adjusted to 0.9901487995715225.
2025-01-16 05:01:24,791 - INFO - Episode 1101/98900: Winner=2, Reward=2.55, EPSILON=0.990, (W=0,D=0,L=0)
2025-01-16 05:01:25,073 - INFO - Episode 1102/98900: Winner=2, Reward=-37.20, EPSILON=0.990, (W=1,D=0,L=0)
2025-01-16 05:01:25,307 - INFO - Episode 1103/98900: Winner=2, Reward=-9.60, EPSILON=0.990, (W=1,D=0,L=0)
2025-01-16 05:01:25,323 - DEBUG - Q-vals = [0.05728441 0.73519266 0.00738672 0.02657611 0.03809975 0.11895774
 0.01650251], best_act=1, best_val=0.735
2025-01-16 05:01:25,323 - DEBUG - Low Q-value (0.735), using MCTS.
2025-01-16 05:01:25,323 - INFO - Running MCTS with 54 simulations using 6 processes.
2025-01-16 05:01:28,463 - DEBUG - Aggregated action counts: {0: 4, 1: 2}
2025-01-16 05:01:28,463 - DEBUG - Chose best action 0
2025-01-16 05:01:28,698 - INFO - Episode 1104/98900: Winner=2, Reward=43.45, EPSILON=0.990, (W=1,D=0,L=0)
2025-01-16 05:01:28,995 - INFO - Episode 1105/98900: Winner=2, Reward=-18.70, EPSILON=0.990, (W=2,D=0,L=0)
2025-01-16 05:01:29,229 - INFO - Episode 1106/98900: Winner=2, Reward=19.85, EPSILON=0.990, (W=2,D=0,L=0)
2025-01-16 05:01:29,495 - INFO - Episode 1107/98900: Winner=2, Reward=-4.10, EPSILON=0.990, (W=3,D=0,L=0)
2025-01-16 05:01:29,667 - DEBUG - Q-vals = [0.2749898  0.1841962  0.05316687 0.09689867 0.07205314 0.07747
 0.24122535], best_act=0, best_val=0.275
2025-01-16 05:01:29,667 - DEBUG - Low Q-value (0.275), using MCTS.
2025-01-16 05:01:29,667 - INFO - Running MCTS with 54 simulations using 6 processes.
2025-01-16 05:01:32,495 - DEBUG - Aggregated action counts: {2: 1, 3: 3, 0: 1, 4: 1}
2025-01-16 05:01:32,495 - DEBUG - Chose best action 3
2025-01-16 05:01:32,635 - INFO - Episode 1108/98900: Winner=2, Reward=10.15, EPSILON=0.990, (W=3,D=0,L=0)
2025-01-16 05:01:32,791 - INFO - Episode 1109/98900: Winner=2, Reward=14.10, EPSILON=0.990, (W=3,D=0,L=0)
2025-01-16 05:01:32,963 - INFO - Episode 1110/98900: Winner=2, Reward=-20.80, EPSILON=0.990, (W=4,D=0,L=0)
2025-01-16 05:01:33,276 - INFO - Episode 1111/98900: Winner=2, Reward=-32.85, EPSILON=0.990, (W=5,D=0,L=0)
2025-01-16 05:01:33,620 - INFO - Episode 1112/98900: Winner=2, Reward=-42.85, EPSILON=0.990, (W=5,D=0,L=0)
2025-01-16 05:01:33,713 - INFO - Episode 1113/98900: Winner=2, Reward=-10.45, EPSILON=0.990, (W=6,D=0,L=0)
2025-01-16 05:01:33,729 - DEBUG - Q-vals = [0.0659906  0.33564678 0.08913242 0.03584026 0.33597147 0.06452781
 0.07289074], best_act=4, best_val=0.336
2025-01-16 05:01:33,729 - DEBUG - Low Q-value (0.336), using MCTS.
2025-01-16 05:01:33,729 - INFO - Running MCTS with 54 simulations using 6 processes.
2025-01-16 05:01:36,432 - DEBUG - Aggregated action counts: {2: 3, 0: 3}
2025-01-16 05:01:36,432 - DEBUG - Chose best action 2
2025-01-16 05:01:36,525 - INFO - Episode 1114/98900: Winner=2, Reward=-0.75, EPSILON=0.990, (W=6,D=0,L=0)
2025-01-16 05:01:36,697 - INFO - Episode 1115/98900: Winner=2, Reward=-16.10, EPSILON=0.990, (W=7,D=0,L=0)
2025-01-16 05:01:36,853 - INFO - Episode 1116/98900: Winner=2, Reward=8.15, EPSILON=0.990, (W=7,D=0,L=0)
2025-01-16 05:01:37,056 - INFO - Episode 1117/98900: Winner=2, Reward=-14.80, EPSILON=0.990, (W=8,D=0,L=0)
2025-01-16 05:01:37,353 - INFO - Episode 1118/98900: Winner=2, Reward=-52.60, EPSILON=0.990, (W=9,D=0,L=0)
2025-01-16 05:01:37,619 - INFO - Episode 1119/98900: Winner=2, Reward=-16.85, EPSILON=0.990, (W=10,D=0,L=0)
2025-01-16 05:01:37,853 - INFO - Episode 1120/98900: Winner=2, Reward=-15.25, EPSILON=0.990, (W=11,D=0,L=0)
2025-01-16 05:01:37,947 - DEBUG - Q-vals = [0.15326443 0.12223624 0.21438502 0.10016058 0.22466843 0.07466393
 0.11062136], best_act=4, best_val=0.225
2025-01-16 05:01:37,947 - DEBUG - Low Q-value (0.225), using MCTS.
2025-01-16 05:01:37,947 - INFO - Running MCTS with 54 simulations using 6 processes.
2025-01-16 05:01:40,768 - DEBUG - Aggregated action counts: {0: 5, 3: 1}
2025-01-16 05:01:40,768 - DEBUG - Chose best action 0
2025-01-16 05:01:40,956 - INFO - Episode 1121/98900: Winner=2, Reward=0.55, EPSILON=0.990, (W=11,D=0,L=0)
2025-01-16 05:01:41,143 - INFO - Episode 1122/98900: Winner=2, Reward=-10.75, EPSILON=0.990, (W=12,D=0,L=0)
2025-01-16 05:01:41,456 - INFO - Episode 1123/98900: Winner=2, Reward=24.75, EPSILON=0.990, (W=12,D=0,L=0)
2025-01-16 05:01:41,753 - INFO - Episode 1124/98900: Winner=2, Reward=-12.90, EPSILON=0.990, (W=13,D=0,L=0)
2025-01-16 05:01:41,893 - INFO - Episode 1125/98900: Winner=2, Reward=9.10, EPSILON=0.990, (W=13,D=0,L=0)
2025-01-16 05:01:42,081 - INFO - Episode 1126/98900: Winner=2, Reward=-4.75, EPSILON=0.990, (W=13,D=0,L=0)
2025-01-16 05:01:42,347 - INFO - Episode 1127/98900: Winner=2, Reward=7.55, EPSILON=0.990, (W=13,D=0,L=0)
2025-01-16 05:01:42,597 - INFO - Episode 1128/98900: Winner=2, Reward=-4.05, EPSILON=0.990, (W=13,D=0,L=0)
2025-01-16 05:01:42,862 - DEBUG - Q-vals = [0.19284436 0.02529318 0.05641742 0.04291094 0.30002835 0.01500832
 0.36749735], best_act=6, best_val=0.367
2025-01-16 05:01:42,862 - DEBUG - Low Q-value (0.367), using MCTS.
2025-01-16 05:01:42,878 - INFO - Episode 1129/98900: Winner=2, Reward=-3.30, EPSILON=0.990, (W=14,D=0,L=0)
2025-01-16 05:01:42,940 - DEBUG - Q-vals = [0.27746466 0.10374318 0.22637044 0.04510957 0.16042791 0.04385268
 0.14303161], best_act=0, best_val=0.277
2025-01-16 05:01:42,940 - DEBUG - Low Q-value (0.277), using MCTS.
2025-01-16 05:01:42,940 - INFO - Running MCTS with 55 simulations using 6 processes.
2025-01-16 05:01:45,868 - DEBUG - Aggregated action counts: {6: 1, 2: 3, 1: 1, 5: 1, 0: 1}
2025-01-16 05:01:45,868 - DEBUG - Chose best action 2
2025-01-16 05:01:46,102 - INFO - Episode 1130/98900: Winner=2, Reward=-53.10, EPSILON=0.990, (W=15,D=0,L=0)
2025-01-16 05:01:46,305 - INFO - Episode 1131/98900: Winner=2, Reward=-13.45, EPSILON=0.990, (W=16,D=0,L=0)
2025-01-16 05:01:46,508 - INFO - Episode 1132/98900: Winner=2, Reward=-10.10, EPSILON=0.990, (W=17,D=0,L=0)
2025-01-16 05:01:46,665 - INFO - Episode 1133/98900: Winner=2, Reward=1.00, EPSILON=0.990, (W=17,D=0,L=0)
2025-01-16 05:01:46,899 - INFO - Episode 1134/98900: Winner=2, Reward=-3.55, EPSILON=0.990, (W=17,D=0,L=0)
2025-01-16 05:01:47,071 - INFO - Episode 1135/98900: Winner=2, Reward=1.30, EPSILON=0.990, (W=17,D=0,L=0)
2025-01-16 05:01:47,383 - INFO - Episode 1136/98900: Winner=2, Reward=-23.60, EPSILON=0.990, (W=17,D=0,L=0)
2025-01-16 05:01:47,477 - INFO - Episode 1137/98900: Winner=2, Reward=2.10, EPSILON=0.990, (W=17,D=0,L=0)
2025-01-16 05:01:47,696 - INFO - Episode 1138/98900: Winner=2, Reward=7.70, EPSILON=0.990, (W=17,D=0,L=0)
2025-01-16 05:01:47,805 - INFO - Episode 1139/98900: Winner=2, Reward=-10.40, EPSILON=0.990, (W=18,D=0,L=0)
2025-01-16 05:01:48,055 - INFO - Episode 1140/98900: Winner=2, Reward=-7.75, EPSILON=0.990, (W=19,D=0,L=0)
2025-01-16 05:01:48,211 - INFO - Episode 1141/98900: Winner=2, Reward=28.70, EPSILON=0.990, (W=19,D=0,L=0)
2025-01-16 05:01:48,446 - INFO - Episode 1142/98900: Winner=2, Reward=16.25, EPSILON=0.990, (W=19,D=0,L=0)
2025-01-16 05:01:48,727 - INFO - Episode 1143/98900: Winner=2, Reward=-27.25, EPSILON=0.990, (W=20,D=0,L=0)
2025-01-16 05:01:49,024 - INFO - Episode 1144/98900: Winner=2, Reward=-34.85, EPSILON=0.990, (W=20,D=0,L=0)
2025-01-16 05:01:49,305 - INFO - Episode 1145/98900: Winner=2, Reward=-33.60, EPSILON=0.990, (W=21,D=0,L=0)
2025-01-16 05:01:49,539 - INFO - Episode 1146/98900: Winner=2, Reward=-28.85, EPSILON=0.990, (W=21,D=0,L=0)
2025-01-16 05:01:49,805 - INFO - Episode 1147/98900: Winner=2, Reward=-1.25, EPSILON=0.990, (W=22,D=0,L=0)
2025-01-16 05:01:50,165 - INFO - Episode 1148/98900: Winner=2, Reward=-45.10, EPSILON=0.990, (W=23,D=0,L=0)
2025-01-16 05:01:50,368 - INFO - Episode 1149/98900: Winner=2, Reward=-11.50, EPSILON=0.990, (W=24,D=0,L=0)
2025-01-16 05:01:50,700 - INFO - Episode 1150/98900: Winner=2, Reward=-2.95, EPSILON=0.990, (W=24,D=0,L=0)
2025-01-16 05:01:51,009 - INFO - Episode 1151/98900: Winner=2, Reward=-0.45, EPSILON=0.990, (W=24,D=0,L=0)
2025-01-16 05:01:51,410 - INFO - Episode 1152/98900: Winner=2, Reward=-82.65, EPSILON=0.990, (W=25,D=0,L=0)
2025-01-16 05:01:51,610 - INFO - Episode 1153/98900: Winner=2, Reward=-11.95, EPSILON=0.990, (W=26,D=0,L=0)
2025-01-16 05:01:51,777 - INFO - Episode 1154/98900: Winner=2, Reward=22.85, EPSILON=0.990, (W=26,D=0,L=0)
2025-01-16 05:01:51,992 - INFO - Episode 1155/98900: Winner=2, Reward=6.10, EPSILON=0.990, (W=26,D=0,L=0)
2025-01-16 05:01:52,075 - DEBUG - Q-vals = [0.429841   0.10139398 0.16535786 0.07169373 0.06989451 0.04611213
 0.11570677], best_act=0, best_val=0.430
2025-01-16 05:01:52,075 - DEBUG - Low Q-value (0.430), using MCTS.
2025-01-16 05:01:52,075 - INFO - Running MCTS with 56 simulations using 6 processes.
2025-01-16 05:01:54,771 - DEBUG - Aggregated action counts: {0: 4, 2: 1, 1: 1, 6: 1}
2025-01-16 05:01:54,771 - DEBUG - Chose best action 0
2025-01-16 05:01:55,021 - INFO - Episode 1156/98900: Winner=2, Reward=-30.25, EPSILON=0.990, (W=27,D=0,L=0)
2025-01-16 05:01:55,287 - INFO - Episode 1157/98900: Winner=2, Reward=0.40, EPSILON=0.990, (W=27,D=0,L=0)
2025-01-16 05:01:55,349 - DEBUG - Q-vals = [0.11664407 0.10795546 0.08356008 0.03438001 0.35525915 0.11031852
 0.1918827 ], best_act=4, best_val=0.355
2025-01-16 05:01:55,349 - DEBUG - Low Q-value (0.355), using MCTS.
2025-01-16 05:01:55,349 - INFO - Running MCTS with 56 simulations using 6 processes.
2025-01-16 05:01:57,989 - DEBUG - Aggregated action counts: {0: 2, 4: 1, 2: 2, 3: 2}
2025-01-16 05:01:57,989 - DEBUG - Chose best action 0
2025-01-16 05:01:58,005 - INFO - Episode 1158/98900: Winner=2, Reward=5.95, EPSILON=0.990, (W=27,D=0,L=0)
2025-01-16 05:01:58,333 - INFO - Episode 1159/98900: Winner=2, Reward=-45.60, EPSILON=0.990, (W=28,D=0,L=0)
2025-01-16 05:01:58,505 - DEBUG - Q-vals = [0.21957147 0.07305787 0.1612704  0.09554999 0.12350596 0.09301901
 0.23402539], best_act=6, best_val=0.234
2025-01-16 05:01:58,505 - DEBUG - Low Q-value (0.234), using MCTS.
2025-01-16 05:01:58,505 - INFO - Running MCTS with 56 simulations using 6 processes.
2025-01-16 05:02:01,113 - DEBUG - Aggregated action counts: {1: 3, 0: 3, 3: 1}
2025-01-16 05:02:01,113 - DEBUG - Chose best action 1
2025-01-16 05:02:01,145 - INFO - Episode 1160/98900: Winner=2, Reward=11.25, EPSILON=0.990, (W=28,D=0,L=0)
2025-01-16 05:02:01,332 - INFO - Episode 1161/98900: Winner=2, Reward=-7.85, EPSILON=0.990, (W=29,D=0,L=0)
2025-01-16 05:02:01,660 - INFO - Episode 1162/98900: Winner=2, Reward=-34.45, EPSILON=0.990, (W=30,D=0,L=0)
2025-01-16 05:02:01,847 - INFO - Episode 1163/98900: Winner=2, Reward=-10.55, EPSILON=0.990, (W=31,D=0,L=0)
2025-01-16 05:02:01,957 - INFO - Episode 1164/98900: Winner=2, Reward=-12.40, EPSILON=0.990, (W=32,D=0,L=0)
2025-01-16 05:02:02,222 - INFO - Episode 1165/98900: Winner=2, Reward=-13.70, EPSILON=0.990, (W=33,D=0,L=0)
2025-01-16 05:02:02,347 - INFO - Episode 1166/98900: Winner=2, Reward=0.25, EPSILON=0.990, (W=33,D=0,L=0)
2025-01-16 05:02:02,566 - INFO - Episode 1167/98900: Winner=2, Reward=-2.40, EPSILON=0.990, (W=34,D=0,L=0)
2025-01-16 05:02:02,722 - INFO - Episode 1168/98900: Winner=2, Reward=-1.75, EPSILON=0.990, (W=34,D=0,L=0)
2025-01-16 05:02:02,816 - DEBUG - Q-vals = [0.23331444 0.06783576 0.16300392 0.07054871 0.19441205 0.03118838
 0.23969676], best_act=6, best_val=0.240
2025-01-16 05:02:02,816 - DEBUG - Low Q-value (0.240), using MCTS.
2025-01-16 05:02:02,832 - INFO - Running MCTS with 56 simulations using 6 processes.
2025-01-16 05:02:05,425 - DEBUG - Aggregated action counts: {1: 2, 4: 1, 0: 4}
2025-01-16 05:02:05,425 - DEBUG - Chose best action 0
2025-01-16 05:02:05,628 - INFO - Episode 1169/98900: Winner=2, Reward=23.15, EPSILON=0.990, (W=35,D=0,L=0)
2025-01-16 05:02:05,925 - INFO - Episode 1170/98900: Winner=2, Reward=-36.00, EPSILON=0.990, (W=35,D=0,L=0)
2025-01-16 05:02:06,237 - INFO - Episode 1171/98900: Winner=2, Reward=-1.20, EPSILON=0.990, (W=35,D=0,L=0)
2025-01-16 05:02:06,409 - INFO - Episode 1172/98900: Winner=2, Reward=-0.95, EPSILON=0.990, (W=36,D=0,L=0)
2025-01-16 05:02:06,644 - INFO - Episode 1173/98900: Winner=2, Reward=25.10, EPSILON=0.989, (W=36,D=0,L=0)
2025-01-16 05:02:07,003 - DEBUG - Q-vals = [0.30481917 0.13770325 0.21379878 0.13724786 0.09729732 0.0209465
 0.08818708], best_act=0, best_val=0.305
2025-01-16 05:02:07,003 - DEBUG - Low Q-value (0.305), using MCTS.
2025-01-16 05:02:07,019 - INFO - Running MCTS with 56 simulations using 6 processes.
2025-01-16 05:02:09,627 - DEBUG - Aggregated action counts: {5: 5, 4: 1, 0: 1}
2025-01-16 05:02:09,627 - DEBUG - Chose best action 5
2025-01-16 05:02:09,721 - INFO - Episode 1174/98900: Winner=-1, Reward=-73.00, EPSILON=0.989, (W=36,D=1,L=0)
2025-01-16 05:02:09,971 - INFO - Episode 1175/98900: Winner=2, Reward=-21.30, EPSILON=0.989, (W=37,D=1,L=0)
2025-01-16 05:02:10,237 - INFO - Episode 1176/98900: Winner=2, Reward=-7.75, EPSILON=0.989, (W=37,D=1,L=0)
2025-01-16 05:02:10,377 - INFO - Episode 1177/98900: Winner=2, Reward=-4.45, EPSILON=0.989, (W=37,D=1,L=0)
2025-01-16 05:02:10,549 - INFO - Episode 1178/98900: Winner=2, Reward=15.25, EPSILON=0.989, (W=37,D=1,L=0)
2025-01-16 05:02:10,705 - INFO - Episode 1179/98900: Winner=2, Reward=-10.85, EPSILON=0.989, (W=38,D=1,L=0)
2025-01-16 05:02:10,924 - INFO - Episode 1180/98900: Winner=2, Reward=-22.10, EPSILON=0.989, (W=39,D=1,L=0)
2025-01-16 05:02:11,018 - INFO - Episode 1181/98900: Winner=2, Reward=7.20, EPSILON=0.989, (W=39,D=1,L=0)
2025-01-16 05:02:11,236 - INFO - Episode 1182/98900: Winner=2, Reward=27.15, EPSILON=0.989, (W=39,D=1,L=0)
2025-01-16 05:02:11,596 - DEBUG - Q-vals = [0.1610357  0.06440888 0.353354   0.15883422 0.19596076 0.01642623
 0.04998022], best_act=0, best_val=0.161
2025-01-16 05:02:11,596 - DEBUG - Low Q-value (0.161), using MCTS.
2025-01-16 05:02:11,596 - INFO - Episode 1183/98900: Winner=2, Reward=-35.35, EPSILON=0.989, (W=40,D=1,L=0)
2025-01-16 05:02:11,767 - DEBUG - Q-vals = [0.19497448 0.06609362 0.15783122 0.02093735 0.05204932 0.16004167
 0.34807235], best_act=6, best_val=0.348
2025-01-16 05:02:11,767 - DEBUG - Low Q-value (0.348), using MCTS.
2025-01-16 05:02:11,767 - INFO - Running MCTS with 57 simulations using 6 processes.
2025-01-16 05:02:14,486 - DEBUG - Aggregated action counts: {2: 4, 0: 2, 5: 1}
2025-01-16 05:02:14,486 - DEBUG - Chose best action 2
2025-01-16 05:02:14,517 - INFO - Episode 1184/98900: Winner=2, Reward=-10.65, EPSILON=0.989, (W=41,D=1,L=0)
2025-01-16 05:02:14,798 - INFO - Episode 1185/98900: Winner=2, Reward=-21.35, EPSILON=0.989, (W=42,D=1,L=0)
2025-01-16 05:02:14,986 - INFO - Episode 1186/98900: Winner=2, Reward=1.20, EPSILON=0.989, (W=42,D=1,L=0)
2025-01-16 05:02:15,267 - INFO - Episode 1187/98900: Winner=2, Reward=2.05, EPSILON=0.989, (W=43,D=1,L=0)
2025-01-16 05:02:15,392 - INFO - Episode 1188/98900: Winner=2, Reward=-9.30, EPSILON=0.989, (W=44,D=1,L=0)
2025-01-16 05:02:15,486 - INFO - Episode 1189/98900: Winner=2, Reward=-2.15, EPSILON=0.989, (W=44,D=1,L=0)
2025-01-16 05:02:15,548 - DEBUG - Q-vals = [0.17713608 0.15433678 0.09633137 0.12010328 0.17209876 0.10770015
 0.17229348], best_act=0, best_val=0.177
2025-01-16 05:02:15,548 - DEBUG - Low Q-value (0.177), using MCTS.
2025-01-16 05:02:15,548 - INFO - Running MCTS with 57 simulations using 6 processes.
2025-01-16 05:02:18,626 - DEBUG - Aggregated action counts: {2: 2, 6: 1, 0: 3, 1: 1}
2025-01-16 05:02:18,626 - DEBUG - Chose best action 0
2025-01-16 05:02:19,000 - INFO - Episode 1190/98900: Winner=2, Reward=2.65, EPSILON=0.989, (W=44,D=1,L=0)
2025-01-16 05:02:19,219 - INFO - Episode 1191/98900: Winner=2, Reward=3.65, EPSILON=0.989, (W=44,D=1,L=0)
2025-01-16 05:02:19,532 - INFO - Episode 1192/98900: Winner=2, Reward=-12.15, EPSILON=0.989, (W=45,D=1,L=0)
2025-01-16 05:02:19,829 - INFO - Episode 1193/98900: Winner=2, Reward=-41.00, EPSILON=0.989, (W=46,D=1,L=0)
2025-01-16 05:02:20,032 - INFO - Episode 1194/98900: Winner=2, Reward=13.30, EPSILON=0.989, (W=46,D=1,L=0)
2025-01-16 05:02:20,360 - INFO - Episode 1195/98900: Winner=2, Reward=-23.05, EPSILON=0.989, (W=47,D=1,L=0)
2025-01-16 05:02:20,485 - INFO - Episode 1196/98900: Winner=2, Reward=22.80, EPSILON=0.989, (W=47,D=1,L=0)
2025-01-16 05:02:20,672 - INFO - Episode 1197/98900: Winner=2, Reward=-7.80, EPSILON=0.989, (W=48,D=1,L=0)
2025-01-16 05:02:20,907 - INFO - Episode 1198/98900: Winner=2, Reward=27.50, EPSILON=0.989, (W=48,D=1,L=0)
2025-01-16 05:02:21,172 - INFO - Episode 1199/98900: Winner=2, Reward=-7.60, EPSILON=0.989, (W=48,D=1,L=0)
2025-01-16 05:02:21,453 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1200.
2025-01-16 05:02:21,453 - INFO - Models saved at episode 1200
2025-01-16 05:02:21,453 - INFO - Target networks updated
2025-01-16 05:02:21,516 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1200.
2025-01-16 05:02:21,516 - INFO - Episode 1200/98900: Winner=2, Reward=-44.10, EPSILON=0.989, (W=49,D=1,L=0)
2025-01-16 05:02:21,672 - INFO - Episode 1201/98900: Winner=2, Reward=-3.20, EPSILON=0.989, (W=49,D=1,L=0)
2025-01-16 05:02:21,780 - INFO - Episode 1202/98900: Winner=2, Reward=23.75, EPSILON=0.989, (W=49,D=1,L=0)
2025-01-16 05:02:21,968 - INFO - Episode 1203/98900: Winner=2, Reward=-11.65, EPSILON=0.989, (W=50,D=1,L=0)
2025-01-16 05:02:22,140 - INFO - Episode 1204/98900: Winner=2, Reward=1.80, EPSILON=0.989, (W=50,D=1,L=0)
2025-01-16 05:02:22,343 - INFO - Episode 1205/98900: Winner=2, Reward=-0.55, EPSILON=0.989, (W=50,D=1,L=0)
2025-01-16 05:02:22,546 - INFO - Episode 1206/98900: Winner=2, Reward=1.75, EPSILON=0.989, (W=50,D=1,L=0)
2025-01-16 05:02:22,763 - INFO - Episode 1207/98900: Winner=2, Reward=-2.95, EPSILON=0.989, (W=51,D=1,L=0)
2025-01-16 05:02:23,060 - INFO - Episode 1208/98900: Winner=2, Reward=6.25, EPSILON=0.989, (W=51,D=1,L=0)
2025-01-16 05:02:23,396 - INFO - Episode 1209/98900: Winner=2, Reward=-52.80, EPSILON=0.989, (W=52,D=1,L=0)
2025-01-16 05:02:23,591 - INFO - Episode 1210/98900: Winner=2, Reward=-15.85, EPSILON=0.989, (W=53,D=1,L=0)
2025-01-16 05:02:23,857 - INFO - Episode 1211/98900: Winner=2, Reward=-14.00, EPSILON=0.989, (W=53,D=1,L=0)
2025-01-16 05:02:23,962 - DEBUG - Q-vals = [0.23977423 0.05559604 0.385575   0.13550486 0.12211668 0.01649346
 0.04493976], best_act=2, best_val=0.386
2025-01-16 05:02:23,963 - DEBUG - Low Q-value (0.386), using MCTS.
2025-01-16 05:02:23,963 - INFO - Running MCTS with 58 simulations using 6 processes.
2025-01-16 05:02:26,853 - DEBUG - Aggregated action counts: {3: 1, 0: 4, 1: 1, 4: 1}
2025-01-16 05:02:26,853 - DEBUG - Chose best action 0
2025-01-16 05:02:26,884 - INFO - Episode 1212/98900: Winner=2, Reward=15.20, EPSILON=0.989, (W=53,D=1,L=0)
2025-01-16 05:02:26,962 - DEBUG - Q-vals = [0.20122275 0.09853932 0.25553575 0.12156254 0.11536123 0.09266015
 0.11511826], best_act=2, best_val=0.256
2025-01-16 05:02:26,962 - DEBUG - Low Q-value (0.256), using MCTS.
2025-01-16 05:02:26,962 - INFO - Running MCTS with 58 simulations using 6 processes.
2025-01-16 05:02:29,618 - DEBUG - Aggregated action counts: {0: 4, 1: 1, 3: 2}
2025-01-16 05:02:29,633 - DEBUG - Chose best action 0
2025-01-16 05:02:29,743 - INFO - Episode 1213/98900: Winner=2, Reward=-9.75, EPSILON=0.989, (W=54,D=1,L=0)
2025-01-16 05:02:29,836 - INFO - Episode 1214/98900: Winner=2, Reward=0.00, EPSILON=0.989, (W=54,D=1,L=0)
2025-01-16 05:02:30,024 - DEBUG - Q-vals = [0.16872752 0.08320549 0.17912945 0.10594053 0.20893736 0.11043431
 0.14362536], best_act=4, best_val=0.209
2025-01-16 05:02:30,024 - DEBUG - Low Q-value (0.209), using MCTS.
2025-01-16 05:02:30,024 - INFO - Episode 1215/98900: Winner=2, Reward=-6.60, EPSILON=0.989, (W=55,D=1,L=0)
2025-01-16 05:02:30,243 - INFO - Episode 1216/98900: Winner=2, Reward=2.65, EPSILON=0.989, (W=55,D=1,L=0)
2025-01-16 05:02:30,414 - INFO - Episode 1217/98900: Winner=2, Reward=-14.55, EPSILON=0.989, (W=55,D=1,L=0)
2025-01-16 05:02:30,539 - INFO - Episode 1218/98900: Winner=2, Reward=-1.10, EPSILON=0.989, (W=55,D=1,L=0)
2025-01-16 05:02:30,805 - INFO - Episode 1219/98900: Winner=2, Reward=1.10, EPSILON=0.989, (W=55,D=1,L=0)
2025-01-16 05:02:30,914 - INFO - Episode 1220/98900: Winner=2, Reward=2.30, EPSILON=0.989, (W=55,D=1,L=0)
2025-01-16 05:02:31,102 - INFO - Episode 1221/98900: Winner=2, Reward=0.25, EPSILON=0.989, (W=55,D=1,L=0)
2025-01-16 05:02:31,383 - INFO - Episode 1222/98900: Winner=2, Reward=0.65, EPSILON=0.989, (W=55,D=1,L=0)
2025-01-16 05:02:31,664 - INFO - Episode 1223/98900: Winner=2, Reward=-5.40, EPSILON=0.989, (W=56,D=1,L=0)
2025-01-16 05:02:31,883 - INFO - Episode 1224/98900: Winner=2, Reward=-7.95, EPSILON=0.989, (W=57,D=1,L=0)
2025-01-16 05:02:32,133 - INFO - Episode 1225/98900: Winner=2, Reward=-13.65, EPSILON=0.989, (W=57,D=1,L=0)
2025-01-16 05:02:32,289 - INFO - Episode 1226/98900: Winner=2, Reward=4.60, EPSILON=0.989, (W=57,D=1,L=0)
2025-01-16 05:02:32,367 - INFO - Episode 1227/98900: Winner=2, Reward=1.25, EPSILON=0.989, (W=57,D=1,L=0)
2025-01-16 05:02:32,820 - INFO - Episode 1228/98900: Winner=2, Reward=-53.45, EPSILON=0.989, (W=57,D=1,L=0)
2025-01-16 05:02:33,070 - INFO - Episode 1229/98900: Winner=2, Reward=-27.20, EPSILON=0.989, (W=58,D=1,L=0)
2025-01-16 05:02:33,382 - INFO - Episode 1230/98900: Winner=2, Reward=-54.85, EPSILON=0.989, (W=59,D=1,L=0)
2025-01-16 05:02:33,632 - INFO - Episode 1231/98900: Winner=2, Reward=21.80, EPSILON=0.989, (W=59,D=1,L=0)
2025-01-16 05:02:33,867 - INFO - Episode 1232/98900: Winner=2, Reward=-9.10, EPSILON=0.989, (W=60,D=1,L=0)
2025-01-16 05:02:33,992 - INFO - Episode 1233/98900: Winner=2, Reward=9.75, EPSILON=0.989, (W=60,D=1,L=0)
2025-01-16 05:02:34,288 - INFO - Episode 1234/98900: Winner=2, Reward=-1.95, EPSILON=0.989, (W=60,D=1,L=0)
2025-01-16 05:02:34,445 - INFO - Episode 1235/98900: Winner=2, Reward=2.90, EPSILON=0.989, (W=60,D=1,L=0)
2025-01-16 05:02:34,632 - INFO - Episode 1236/98900: Winner=2, Reward=19.05, EPSILON=0.989, (W=60,D=1,L=0)
2025-01-16 05:02:34,835 - INFO - Episode 1237/98900: Winner=2, Reward=-2.85, EPSILON=0.989, (W=60,D=1,L=0)
2025-01-16 05:02:35,210 - INFO - Episode 1238/98900: Winner=2, Reward=-52.50, EPSILON=0.989, (W=60,D=1,L=0)
2025-01-16 05:02:35,429 - INFO - Episode 1239/98900: Winner=2, Reward=-9.70, EPSILON=0.989, (W=60,D=1,L=0)
2025-01-16 05:02:35,772 - INFO - Episode 1240/98900: Winner=2, Reward=-66.70, EPSILON=0.989, (W=60,D=1,L=0)
2025-01-16 05:02:35,944 - INFO - Episode 1241/98900: Winner=2, Reward=-15.10, EPSILON=0.989, (W=61,D=1,L=0)
2025-01-16 05:02:36,054 - INFO - Episode 1242/98900: Winner=2, Reward=-5.55, EPSILON=0.989, (W=61,D=1,L=0)
2025-01-16 05:02:36,241 - INFO - Episode 1243/98900: Winner=2, Reward=0.05, EPSILON=0.989, (W=61,D=1,L=0)
2025-01-16 05:02:36,600 - INFO - Episode 1244/98900: Winner=2, Reward=-34.15, EPSILON=0.989, (W=62,D=1,L=0)
2025-01-16 05:02:36,835 - INFO - Episode 1245/98900: Winner=2, Reward=-9.55, EPSILON=0.989, (W=62,D=1,L=0)
2025-01-16 05:02:36,975 - INFO - Episode 1246/98900: Winner=2, Reward=0.15, EPSILON=0.989, (W=62,D=1,L=0)
2025-01-16 05:02:37,178 - INFO - Episode 1247/98900: Winner=2, Reward=-17.35, EPSILON=0.989, (W=63,D=1,L=0)
2025-01-16 05:02:37,475 - INFO - Episode 1248/98900: Winner=2, Reward=-15.25, EPSILON=0.989, (W=64,D=1,L=0)
2025-01-16 05:02:37,553 - INFO - Episode 1249/98900: Winner=2, Reward=-2.10, EPSILON=0.989, (W=64,D=1,L=0)
2025-01-16 05:02:37,616 - DEBUG - Q-vals = [0.11615609 0.10558241 0.14725994 0.1672919  0.13193998 0.21260738
 0.11916228], best_act=5, best_val=0.213
2025-01-16 05:02:37,616 - DEBUG - Low Q-value (0.213), using MCTS.
2025-01-16 05:02:37,616 - INFO - Running MCTS with 60 simulations using 6 processes.
2025-01-16 05:02:40,434 - DEBUG - Aggregated action counts: {1: 3, 0: 3}
2025-01-16 05:02:40,434 - DEBUG - Chose best action 1
2025-01-16 05:02:40,640 - INFO - Episode 1250/98900: Winner=2, Reward=-37.85, EPSILON=0.989, (W=65,D=1,L=0)
2025-01-16 05:02:40,862 - INFO - Episode 1251/98900: Winner=2, Reward=20.85, EPSILON=0.989, (W=65,D=1,L=0)
2025-01-16 05:02:41,007 - INFO - Episode 1252/98900: Winner=2, Reward=-1.75, EPSILON=0.989, (W=66,D=1,L=0)
2025-01-16 05:02:41,248 - INFO - Episode 1253/98900: Winner=2, Reward=-13.15, EPSILON=0.989, (W=66,D=1,L=0)
2025-01-16 05:02:41,498 - INFO - Episode 1254/98900: Winner=2, Reward=9.25, EPSILON=0.989, (W=67,D=1,L=0)
2025-01-16 05:02:41,874 - INFO - Episode 1255/98900: Winner=2, Reward=-54.15, EPSILON=0.989, (W=67,D=1,L=0)
2025-01-16 05:02:42,015 - INFO - Episode 1256/98900: Winner=2, Reward=11.35, EPSILON=0.989, (W=67,D=1,L=0)
2025-01-16 05:02:42,172 - INFO - Episode 1257/98900: Winner=2, Reward=-2.40, EPSILON=0.989, (W=67,D=1,L=0)
2025-01-16 05:02:42,453 - INFO - Episode 1258/98900: Winner=2, Reward=-40.15, EPSILON=0.989, (W=68,D=1,L=0)
2025-01-16 05:02:42,599 - INFO - Episode 1259/98900: Winner=2, Reward=7.75, EPSILON=0.989, (W=68,D=1,L=0)
2025-01-16 05:02:42,741 - INFO - Episode 1260/98900: Winner=2, Reward=-9.15, EPSILON=0.989, (W=69,D=1,L=0)
2025-01-16 05:02:43,030 - INFO - Episode 1261/98900: Winner=2, Reward=-44.85, EPSILON=0.989, (W=70,D=1,L=0)
2025-01-16 05:02:43,309 - INFO - Episode 1262/98900: Winner=2, Reward=3.15, EPSILON=0.989, (W=70,D=1,L=0)
2025-01-16 05:02:43,356 - DEBUG - Q-vals = [0.12416296 0.12835982 0.1539314  0.16609387 0.13417773 0.16306816
 0.13020612], best_act=3, best_val=0.166
2025-01-16 05:02:43,356 - DEBUG - Low Q-value (0.166), using MCTS.
2025-01-16 05:02:43,356 - INFO - Running MCTS with 60 simulations using 6 processes.
2025-01-16 05:02:46,030 - DEBUG - Aggregated action counts: {0: 4, 6: 1, 1: 1}
2025-01-16 05:02:46,030 - DEBUG - Chose best action 0
2025-01-16 05:02:46,174 - INFO - Episode 1263/98900: Winner=2, Reward=-6.95, EPSILON=0.989, (W=71,D=1,L=0)
2025-01-16 05:02:46,403 - INFO - Episode 1264/98900: Winner=2, Reward=-16.45, EPSILON=0.989, (W=72,D=1,L=0)
2025-01-16 05:02:46,609 - INFO - Episode 1265/98900: Winner=2, Reward=-32.05, EPSILON=0.989, (W=73,D=1,L=0)
2025-01-16 05:02:46,814 - INFO - Episode 1266/98900: Winner=2, Reward=5.35, EPSILON=0.989, (W=73,D=1,L=0)
2025-01-16 05:02:46,957 - INFO - Episode 1267/98900: Winner=2, Reward=-13.65, EPSILON=0.989, (W=74,D=1,L=0)
2025-01-16 05:02:47,062 - INFO - Episode 1268/98900: Winner=2, Reward=0.55, EPSILON=0.989, (W=74,D=1,L=0)
2025-01-16 05:02:47,297 - INFO - Episode 1269/98900: Winner=2, Reward=-13.10, EPSILON=0.989, (W=75,D=1,L=0)
2025-01-16 05:02:47,415 - DEBUG - Q-vals = [0.26910633 0.15385297 0.14375666 0.09218664 0.11107185 0.08988912
 0.14013648], best_act=0, best_val=0.269
2025-01-16 05:02:47,415 - DEBUG - Low Q-value (0.269), using MCTS.
2025-01-16 05:02:47,431 - INFO - Episode 1270/98900: Winner=2, Reward=-8.25, EPSILON=0.989, (W=76,D=1,L=0)
2025-01-16 05:02:47,594 - DEBUG - Q-vals = [0.09713669 0.04837724 0.19630344 0.13555346 0.17190637 0.12096517
 0.22975765], best_act=6, best_val=0.230
2025-01-16 05:02:47,594 - DEBUG - Low Q-value (0.230), using MCTS.
2025-01-16 05:02:47,594 - INFO - Running MCTS with 60 simulations using 6 processes.
2025-01-16 05:02:50,348 - DEBUG - Aggregated action counts: {0: 3, 1: 2, 4: 1}
2025-01-16 05:02:50,348 - DEBUG - Chose best action 0
2025-01-16 05:02:50,469 - INFO - Episode 1271/98900: Winner=2, Reward=9.45, EPSILON=0.989, (W=76,D=1,L=0)
2025-01-16 05:02:50,567 - INFO - Episode 1272/98900: Winner=2, Reward=2.25, EPSILON=0.989, (W=76,D=1,L=0)
2025-01-16 05:02:50,751 - INFO - Episode 1273/98900: Winner=2, Reward=-16.45, EPSILON=0.989, (W=77,D=1,L=0)
2025-01-16 05:02:51,078 - INFO - Episode 1274/98900: Winner=2, Reward=16.25, EPSILON=0.989, (W=77,D=1,L=0)
2025-01-16 05:02:51,456 - INFO - Episode 1275/98900: Winner=2, Reward=-40.55, EPSILON=0.989, (W=78,D=1,L=0)
2025-01-16 05:02:51,731 - INFO - Episode 1276/98900: Winner=2, Reward=-15.05, EPSILON=0.989, (W=78,D=1,L=0)
2025-01-16 05:02:51,951 - INFO - Episode 1277/98900: Winner=2, Reward=-15.75, EPSILON=0.989, (W=79,D=1,L=0)
2025-01-16 05:02:52,106 - INFO - Episode 1278/98900: Winner=2, Reward=24.60, EPSILON=0.989, (W=79,D=1,L=0)
2025-01-16 05:02:52,122 - DEBUG - Q-vals = [0.14244299 0.13678947 0.16747448 0.12931201 0.13057967 0.15853924
 0.13486208], best_act=2, best_val=0.167
2025-01-16 05:02:52,122 - DEBUG - Low Q-value (0.167), using MCTS.
2025-01-16 05:02:52,122 - INFO - Running MCTS with 61 simulations using 6 processes.
2025-01-16 05:02:55,065 - DEBUG - Aggregated action counts: {4: 1, 2: 1, 0: 1, 1: 2, 3: 2}
2025-01-16 05:02:55,065 - DEBUG - Chose best action 1
2025-01-16 05:02:55,206 - INFO - Episode 1279/98900: Winner=2, Reward=5.60, EPSILON=0.989, (W=79,D=1,L=0)
2025-01-16 05:02:55,612 - INFO - Episode 1280/98900: Winner=2, Reward=-40.35, EPSILON=0.989, (W=79,D=1,L=0)
2025-01-16 05:02:55,862 - INFO - Episode 1281/98900: Winner=2, Reward=-9.65, EPSILON=0.989, (W=79,D=1,L=0)
2025-01-16 05:02:55,987 - INFO - Episode 1282/98900: Winner=2, Reward=-1.80, EPSILON=0.989, (W=79,D=1,L=0)
2025-01-16 05:02:56,130 - INFO - Episode 1283/98900: Winner=2, Reward=-10.90, EPSILON=0.989, (W=80,D=1,L=0)
2025-01-16 05:02:56,373 - INFO - Episode 1284/98900: Winner=2, Reward=5.85, EPSILON=0.989, (W=80,D=1,L=0)
2025-01-16 05:02:56,705 - INFO - Episode 1285/98900: Winner=2, Reward=-16.85, EPSILON=0.989, (W=81,D=1,L=0)
2025-01-16 05:02:56,869 - INFO - Episode 1286/98900: Winner=2, Reward=4.75, EPSILON=0.988, (W=81,D=1,L=0)
2025-01-16 05:02:57,046 - INFO - Episode 1287/98900: Winner=2, Reward=3.45, EPSILON=0.988, (W=82,D=1,L=0)
2025-01-16 05:02:57,135 - INFO - Episode 1288/98900: Winner=2, Reward=-0.10, EPSILON=0.988, (W=82,D=1,L=0)
2025-01-16 05:02:57,498 - INFO - Episode 1289/98900: Winner=2, Reward=-41.55, EPSILON=0.988, (W=83,D=1,L=0)
2025-01-16 05:02:57,763 - INFO - Episode 1290/98900: Winner=2, Reward=-24.60, EPSILON=0.988, (W=84,D=1,L=0)
2025-01-16 05:02:57,982 - INFO - Episode 1291/98900: Winner=2, Reward=3.05, EPSILON=0.988, (W=84,D=1,L=0)
2025-01-16 05:02:58,201 - INFO - Episode 1292/98900: Winner=2, Reward=14.45, EPSILON=0.988, (W=84,D=1,L=0)
2025-01-16 05:02:58,451 - INFO - Episode 1293/98900: Winner=2, Reward=-6.25, EPSILON=0.988, (W=84,D=1,L=0)
2025-01-16 05:02:58,529 - INFO - Episode 1294/98900: Winner=2, Reward=-6.45, EPSILON=0.988, (W=85,D=1,L=0)
2025-01-16 05:02:58,638 - DEBUG - Q-vals = [0.13431334 0.06683978 0.17738679 0.21719629 0.21574397 0.13583335
 0.05268646], best_act=3, best_val=0.217
2025-01-16 05:02:58,638 - DEBUG - Low Q-value (0.217), using MCTS.
2025-01-16 05:02:58,638 - INFO - Running MCTS with 61 simulations using 6 processes.
2025-01-16 05:03:01,433 - DEBUG - Aggregated action counts: {1: 4, 0: 2, 3: 1}
2025-01-16 05:03:01,433 - DEBUG - Chose best action 1
2025-01-16 05:03:01,612 - INFO - Episode 1295/98900: Winner=2, Reward=5.45, EPSILON=0.988, (W=85,D=1,L=0)
2025-01-16 05:03:01,796 - INFO - Episode 1296/98900: Winner=2, Reward=-9.20, EPSILON=0.988, (W=86,D=1,L=0)
2025-01-16 05:03:02,067 - INFO - Episode 1297/98900: Winner=2, Reward=1.15, EPSILON=0.988, (W=86,D=1,L=0)
2025-01-16 05:03:02,392 - INFO - Episode 1298/98900: Winner=2, Reward=-16.05, EPSILON=0.988, (W=86,D=1,L=0)
2025-01-16 05:03:02,700 - INFO - Episode 1299/98900: Winner=2, Reward=-44.55, EPSILON=0.988, (W=87,D=1,L=0)
2025-01-16 05:03:03,005 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1300.
2025-01-16 05:03:03,006 - INFO - Models saved at episode 1300
2025-01-16 05:03:03,007 - INFO - Target networks updated
2025-01-16 05:03:03,051 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1300.
2025-01-16 05:03:03,051 - INFO - Episode 1300/98900: Winner=2, Reward=-16.05, EPSILON=0.988, (W=87,D=1,L=0)
2025-01-16 05:03:03,325 - INFO - Episode 1301/98900: Winner=2, Reward=-5.85, EPSILON=0.988, (W=88,D=1,L=0)
2025-01-16 05:03:03,407 - DEBUG - Q-vals = [0.16727923 0.14065479 0.11861746 0.16658194 0.09894536 0.14139824
 0.16652298], best_act=0, best_val=0.167
2025-01-16 05:03:03,407 - DEBUG - Low Q-value (0.167), using MCTS.
2025-01-16 05:03:03,407 - INFO - Running MCTS with 62 simulations using 6 processes.
2025-01-16 05:03:06,418 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 05:03:06,418 - DEBUG - Chose best action 0
2025-01-16 05:03:06,687 - INFO - Episode 1302/98900: Winner=2, Reward=-16.35, EPSILON=0.988, (W=89,D=1,L=0)
2025-01-16 05:03:07,002 - INFO - Episode 1303/98900: Winner=2, Reward=0.45, EPSILON=0.988, (W=89,D=1,L=0)
2025-01-16 05:03:07,128 - INFO - Episode 1304/98900: Winner=2, Reward=-14.35, EPSILON=0.988, (W=90,D=1,L=0)
2025-01-16 05:03:07,409 - INFO - Episode 1305/98900: Winner=2, Reward=-12.40, EPSILON=0.988, (W=91,D=1,L=0)
2025-01-16 05:03:07,763 - INFO - Episode 1306/98900: Winner=2, Reward=-67.45, EPSILON=0.988, (W=92,D=1,L=0)
2025-01-16 05:03:07,951 - INFO - Episode 1307/98900: Winner=2, Reward=8.95, EPSILON=0.988, (W=92,D=1,L=0)
2025-01-16 05:03:08,157 - DEBUG - Q-vals = [0.3917455  0.05680913 0.0217552  0.042716   0.01172396 0.01243794
 0.4628123 ], best_act=6, best_val=0.463
2025-01-16 05:03:08,157 - DEBUG - Low Q-value (0.463), using MCTS.
2025-01-16 05:03:08,173 - INFO - Episode 1308/98900: Winner=2, Reward=-18.75, EPSILON=0.988, (W=93,D=1,L=0)
2025-01-16 05:03:08,533 - INFO - Episode 1309/98900: Winner=2, Reward=-49.80, EPSILON=0.988, (W=93,D=1,L=0)
2025-01-16 05:03:08,853 - INFO - Episode 1310/98900: Winner=2, Reward=-32.15, EPSILON=0.988, (W=93,D=1,L=0)
2025-01-16 05:03:08,949 - DEBUG - Q-vals = [0.21873172 0.15552287 0.1355723  0.09013061 0.16153368 0.10025205
 0.13825679], best_act=0, best_val=0.219
2025-01-16 05:03:08,949 - DEBUG - Low Q-value (0.219), using MCTS.
2025-01-16 05:03:08,949 - INFO - Running MCTS with 62 simulations using 6 processes.
2025-01-16 05:03:11,934 - DEBUG - Aggregated action counts: {6: 1, 5: 1, 0: 3, 1: 1, 2: 1}
2025-01-16 05:03:11,935 - DEBUG - Chose best action 0
2025-01-16 05:03:11,989 - INFO - Episode 1311/98900: Winner=2, Reward=-11.40, EPSILON=0.988, (W=94,D=1,L=0)
2025-01-16 05:03:12,053 - INFO - Episode 1312/98900: Winner=2, Reward=8.25, EPSILON=0.988, (W=94,D=1,L=0)
2025-01-16 05:03:12,299 - INFO - Episode 1313/98900: Winner=2, Reward=-12.75, EPSILON=0.988, (W=95,D=1,L=0)
2025-01-16 05:03:12,476 - DEBUG - Q-vals = [0.10663049 0.2074006  0.04007417 0.17174166 0.1590656  0.12884015
 0.18624724], best_act=1, best_val=0.207
2025-01-16 05:03:12,476 - DEBUG - Low Q-value (0.207), using MCTS.
2025-01-16 05:03:12,478 - INFO - Running MCTS with 62 simulations using 6 processes.
2025-01-16 05:03:15,668 - DEBUG - Aggregated action counts: {2: 1, 0: 4, 4: 2}
2025-01-16 05:03:15,668 - DEBUG - Chose best action 0
2025-01-16 05:03:15,668 - INFO - Episode 1314/98900: Winner=2, Reward=1.25, EPSILON=0.988, (W=95,D=1,L=0)
2025-01-16 05:03:15,889 - DEBUG - Q-vals = [0.08775961 0.09328914 0.0421368  0.02149155 0.07057525 0.13702837
 0.54771924], best_act=6, best_val=0.548
2025-01-16 05:03:15,889 - DEBUG - Low Q-value (0.548), using MCTS.
2025-01-16 05:03:15,889 - INFO - Running MCTS with 62 simulations using 6 processes.
2025-01-16 05:03:18,769 - DEBUG - Aggregated action counts: {1: 1, 0: 2, 2: 2, 4: 1, 3: 1}
2025-01-16 05:03:18,769 - DEBUG - Chose best action 0
2025-01-16 05:03:18,850 - INFO - Episode 1315/98900: Winner=2, Reward=-18.15, EPSILON=0.988, (W=96,D=1,L=0)
2025-01-16 05:03:19,116 - INFO - Episode 1316/98900: Winner=2, Reward=-7.55, EPSILON=0.988, (W=97,D=1,L=0)
2025-01-16 05:03:19,397 - INFO - Episode 1317/98900: Winner=2, Reward=-13.15, EPSILON=0.988, (W=97,D=1,L=0)
2025-01-16 05:03:19,752 - INFO - Episode 1318/98900: Winner=2, Reward=-24.65, EPSILON=0.988, (W=98,D=1,L=0)
2025-01-16 05:03:19,883 - INFO - Episode 1319/98900: Winner=2, Reward=-10.05, EPSILON=0.988, (W=99,D=1,L=0)
2025-01-16 05:03:20,180 - INFO - Episode 1320/98900: Winner=2, Reward=-5.85, EPSILON=0.988, (W=99,D=1,L=0)
2025-01-16 05:03:20,461 - INFO - Episode 1321/98900: Winner=2, Reward=-18.35, EPSILON=0.988, (W=100,D=1,L=0)
2025-01-16 05:03:20,570 - INFO - Episode 1322/98900: Winner=2, Reward=9.40, EPSILON=0.988, (W=100,D=1,L=0)
2025-01-16 05:03:20,867 - INFO - Episode 1323/98900: Winner=2, Reward=-0.35, EPSILON=0.988, (W=100,D=1,L=0)
2025-01-16 05:03:21,116 - INFO - Episode 1324/98900: Winner=2, Reward=4.95, EPSILON=0.988, (W=101,D=1,L=0)
2025-01-16 05:03:21,403 - INFO - Episode 1325/98900: Winner=2, Reward=-22.45, EPSILON=0.988, (W=101,D=1,L=0)
2025-01-16 05:03:21,657 - INFO - Episode 1326/98900: Winner=2, Reward=-7.05, EPSILON=0.988, (W=101,D=1,L=0)
2025-01-16 05:03:21,791 - INFO - Episode 1327/98900: Winner=2, Reward=13.95, EPSILON=0.988, (W=101,D=1,L=0)
2025-01-16 05:03:21,964 - INFO - Episode 1328/98900: Winner=2, Reward=-15.60, EPSILON=0.988, (W=102,D=1,L=0)
2025-01-16 05:03:22,135 - INFO - Episode 1329/98900: Winner=2, Reward=-9.65, EPSILON=0.988, (W=103,D=1,L=0)
2025-01-16 05:03:22,226 - INFO - Episode 1330/98900: Winner=2, Reward=-2.15, EPSILON=0.988, (W=103,D=1,L=0)
2025-01-16 05:03:22,589 - INFO - Episode 1331/98900: Winner=2, Reward=-48.15, EPSILON=0.988, (W=104,D=1,L=0)
2025-01-16 05:03:22,810 - INFO - Episode 1332/98900: Winner=2, Reward=-18.15, EPSILON=0.988, (W=105,D=1,L=0)
2025-01-16 05:03:23,041 - INFO - Episode 1333/98900: Winner=2, Reward=24.50, EPSILON=0.988, (W=105,D=1,L=0)
2025-01-16 05:03:23,213 - INFO - Episode 1334/98900: Winner=2, Reward=-2.50, EPSILON=0.988, (W=106,D=1,L=0)
2025-01-16 05:03:23,556 - INFO - Episode 1335/98900: Winner=2, Reward=-31.50, EPSILON=0.988, (W=107,D=1,L=0)
2025-01-16 05:03:23,796 - INFO - Episode 1336/98900: Winner=2, Reward=-11.60, EPSILON=0.988, (W=108,D=1,L=0)
2025-01-16 05:03:24,140 - INFO - Episode 1337/98900: Winner=2, Reward=-48.85, EPSILON=0.988, (W=109,D=1,L=0)
2025-01-16 05:03:24,312 - INFO - Episode 1338/98900: Winner=2, Reward=-10.85, EPSILON=0.988, (W=110,D=1,L=0)
2025-01-16 05:03:24,457 - INFO - Episode 1339/98900: Winner=2, Reward=6.95, EPSILON=0.988, (W=110,D=1,L=0)
2025-01-16 05:03:24,619 - INFO - Episode 1340/98900: Winner=2, Reward=20.20, EPSILON=0.988, (W=110,D=1,L=0)
2025-01-16 05:03:24,666 - DEBUG - Q-vals = [0.12718485 0.12632407 0.11975586 0.14978704 0.1773804  0.15402852
 0.14553925], best_act=4, best_val=0.177
2025-01-16 05:03:24,666 - DEBUG - Low Q-value (0.177), using MCTS.
2025-01-16 05:03:24,666 - INFO - Running MCTS with 63 simulations using 6 processes.
2025-01-16 05:03:27,604 - DEBUG - Aggregated action counts: {0: 5, 1: 1, 3: 1}
2025-01-16 05:03:27,604 - DEBUG - Chose best action 0
2025-01-16 05:03:27,639 - DEBUG - Q-vals = [0.0172468  0.02836505 0.02869913 0.03082803 0.03153478 0.7521723
 0.11115395], best_act=5, best_val=0.752
2025-01-16 05:03:27,639 - DEBUG - Low Q-value (0.752), using MCTS.
2025-01-16 05:03:27,640 - INFO - Running MCTS with 63 simulations using 6 processes.
2025-01-16 05:03:30,570 - DEBUG - Aggregated action counts: {1: 2, 0: 4, 2: 1}
2025-01-16 05:03:30,570 - DEBUG - Chose best action 0
2025-01-16 05:03:30,749 - INFO - Episode 1341/98900: Winner=2, Reward=-13.60, EPSILON=0.988, (W=110,D=1,L=0)
2025-01-16 05:03:31,046 - INFO - Episode 1342/98900: Winner=2, Reward=-13.60, EPSILON=0.988, (W=110,D=1,L=0)
2025-01-16 05:03:31,252 - INFO - Episode 1343/98900: Winner=2, Reward=-5.25, EPSILON=0.988, (W=110,D=1,L=0)
2025-01-16 05:03:31,460 - INFO - Episode 1344/98900: Winner=2, Reward=-25.85, EPSILON=0.988, (W=110,D=1,L=0)
2025-01-16 05:03:31,814 - INFO - Episode 1345/98900: Winner=2, Reward=-47.90, EPSILON=0.988, (W=111,D=1,L=0)
2025-01-16 05:03:32,051 - INFO - Episode 1346/98900: Winner=2, Reward=0.85, EPSILON=0.988, (W=111,D=1,L=0)
2025-01-16 05:03:32,218 - INFO - Episode 1347/98900: Winner=2, Reward=5.40, EPSILON=0.988, (W=111,D=1,L=0)
2025-01-16 05:03:32,316 - INFO - Episode 1348/98900: Winner=2, Reward=7.70, EPSILON=0.988, (W=111,D=1,L=0)
2025-01-16 05:03:32,480 - INFO - Episode 1349/98900: Winner=2, Reward=-8.70, EPSILON=0.988, (W=112,D=1,L=0)
2025-01-16 05:03:32,663 - INFO - Episode 1350/98900: Winner=2, Reward=6.35, EPSILON=0.988, (W=112,D=1,L=0)
2025-01-16 05:03:33,060 - INFO - Episode 1351/98900: Winner=2, Reward=-13.55, EPSILON=0.988, (W=112,D=1,L=0)
2025-01-16 05:03:33,349 - INFO - Episode 1352/98900: Winner=2, Reward=-30.15, EPSILON=0.988, (W=112,D=1,L=0)
2025-01-16 05:03:33,531 - INFO - Episode 1353/98900: Winner=2, Reward=11.05, EPSILON=0.988, (W=112,D=1,L=0)
2025-01-16 05:03:33,646 - INFO - Episode 1354/98900: Winner=2, Reward=0.50, EPSILON=0.988, (W=112,D=1,L=0)
2025-01-16 05:03:33,746 - DEBUG - Q-vals = [0.18758515 0.16129927 0.08935983 0.12768313 0.14556292 0.11404112
 0.17446864], best_act=0, best_val=0.188
2025-01-16 05:03:33,747 - DEBUG - Low Q-value (0.188), using MCTS.
2025-01-16 05:03:33,747 - INFO - Running MCTS with 64 simulations using 6 processes.
2025-01-16 05:03:36,675 - DEBUG - Aggregated action counts: {2: 1, 1: 3, 3: 2, 0: 1}
2025-01-16 05:03:36,675 - DEBUG - Chose best action 1
2025-01-16 05:03:36,751 - INFO - Episode 1355/98900: Winner=2, Reward=-0.55, EPSILON=0.988, (W=112,D=1,L=0)
2025-01-16 05:03:36,820 - INFO - Episode 1356/98900: Winner=2, Reward=0.45, EPSILON=0.988, (W=112,D=1,L=0)
2025-01-16 05:03:37,102 - INFO - Episode 1357/98900: Winner=2, Reward=-2.70, EPSILON=0.988, (W=112,D=1,L=0)
2025-01-16 05:03:37,300 - INFO - Episode 1358/98900: Winner=2, Reward=-10.80, EPSILON=0.988, (W=113,D=1,L=0)
2025-01-16 05:03:37,594 - INFO - Episode 1359/98900: Winner=2, Reward=-24.05, EPSILON=0.988, (W=114,D=1,L=0)
2025-01-16 05:03:37,974 - INFO - Episode 1360/98900: Winner=2, Reward=-37.35, EPSILON=0.988, (W=114,D=1,L=0)
2025-01-16 05:03:38,268 - INFO - Episode 1361/98900: Winner=2, Reward=-41.75, EPSILON=0.988, (W=114,D=1,L=0)
2025-01-16 05:03:38,471 - INFO - Episode 1362/98900: Winner=2, Reward=-8.25, EPSILON=0.988, (W=114,D=1,L=0)
2025-01-16 05:03:38,672 - INFO - Episode 1363/98900: Winner=2, Reward=9.00, EPSILON=0.988, (W=114,D=1,L=0)
2025-01-16 05:03:39,042 - INFO - Episode 1364/98900: Winner=2, Reward=-25.45, EPSILON=0.988, (W=114,D=1,L=0)
2025-01-16 05:03:39,224 - INFO - Episode 1365/98900: Winner=2, Reward=15.25, EPSILON=0.988, (W=114,D=1,L=0)
2025-01-16 05:03:39,463 - INFO - Episode 1366/98900: Winner=2, Reward=-0.15, EPSILON=0.988, (W=114,D=1,L=0)
2025-01-16 05:03:39,596 - INFO - Episode 1367/98900: Winner=2, Reward=2.95, EPSILON=0.988, (W=114,D=1,L=0)
2025-01-16 05:03:39,752 - INFO - Episode 1368/98900: Winner=2, Reward=-10.80, EPSILON=0.988, (W=115,D=1,L=0)
2025-01-16 05:03:40,091 - INFO - Episode 1369/98900: Winner=2, Reward=-38.25, EPSILON=0.988, (W=116,D=1,L=0)
2025-01-16 05:03:40,106 - DEBUG - Q-vals = [0.10547301 0.13646315 0.10772125 0.18352735 0.17564537 0.14723152
 0.14393835], best_act=3, best_val=0.184
2025-01-16 05:03:40,106 - DEBUG - Low Q-value (0.184), using MCTS.
2025-01-16 05:03:40,106 - INFO - Running MCTS with 64 simulations using 6 processes.
2025-01-16 05:03:43,298 - DEBUG - Aggregated action counts: {2: 3, 0: 3, 1: 1}
2025-01-16 05:03:43,298 - DEBUG - Chose best action 2
2025-01-16 05:03:43,640 - INFO - Episode 1370/98900: Winner=2, Reward=-57.10, EPSILON=0.988, (W=117,D=1,L=0)
2025-01-16 05:03:43,893 - INFO - Episode 1371/98900: Winner=2, Reward=-0.65, EPSILON=0.988, (W=117,D=1,L=0)
2025-01-16 05:03:44,125 - INFO - Episode 1372/98900: Winner=2, Reward=-15.90, EPSILON=0.988, (W=118,D=1,L=0)
2025-01-16 05:03:44,342 - INFO - Episode 1373/98900: Winner=2, Reward=-10.35, EPSILON=0.988, (W=119,D=1,L=0)
2025-01-16 05:03:44,507 - INFO - Episode 1374/98900: Winner=2, Reward=-2.90, EPSILON=0.988, (W=119,D=1,L=0)
2025-01-16 05:03:44,895 - INFO - Episode 1375/98900: Winner=2, Reward=-58.95, EPSILON=0.988, (W=120,D=1,L=0)
2025-01-16 05:03:45,051 - INFO - Episode 1376/98900: Winner=2, Reward=-16.30, EPSILON=0.988, (W=121,D=1,L=0)
2025-01-16 05:03:45,178 - INFO - Episode 1377/98900: Winner=2, Reward=11.85, EPSILON=0.988, (W=121,D=1,L=0)
2025-01-16 05:03:45,523 - INFO - Episode 1378/98900: Winner=2, Reward=-9.40, EPSILON=0.988, (W=121,D=1,L=0)
2025-01-16 05:03:45,806 - INFO - Episode 1379/98900: Winner=2, Reward=-14.45, EPSILON=0.988, (W=121,D=1,L=0)
2025-01-16 05:03:46,061 - INFO - Episode 1380/98900: Winner=2, Reward=-22.05, EPSILON=0.988, (W=122,D=1,L=0)
2025-01-16 05:03:46,360 - INFO - Episode 1381/98900: Winner=2, Reward=-11.30, EPSILON=0.988, (W=123,D=1,L=0)
2025-01-16 05:03:46,570 - INFO - Episode 1382/98900: Winner=2, Reward=7.85, EPSILON=0.988, (W=123,D=1,L=0)
2025-01-16 05:03:46,751 - INFO - Episode 1383/98900: Winner=2, Reward=-13.80, EPSILON=0.988, (W=124,D=1,L=0)
2025-01-16 05:03:46,978 - INFO - Episode 1384/98900: Winner=2, Reward=-4.05, EPSILON=0.988, (W=124,D=1,L=0)
2025-01-16 05:03:47,169 - INFO - Episode 1385/98900: Winner=2, Reward=12.75, EPSILON=0.988, (W=125,D=1,L=0)
2025-01-16 05:03:47,433 - INFO - Episode 1386/98900: Winner=2, Reward=-32.60, EPSILON=0.988, (W=125,D=1,L=0)
2025-01-16 05:03:47,612 - INFO - Episode 1387/98900: Winner=2, Reward=9.05, EPSILON=0.988, (W=125,D=1,L=0)
2025-01-16 05:03:47,838 - INFO - Episode 1388/98900: Winner=2, Reward=-9.90, EPSILON=0.988, (W=126,D=1,L=0)
2025-01-16 05:03:48,061 - INFO - Episode 1389/98900: Winner=2, Reward=-5.85, EPSILON=0.988, (W=126,D=1,L=0)
2025-01-16 05:03:48,153 - INFO - Episode 1390/98900: Winner=2, Reward=5.95, EPSILON=0.988, (W=126,D=1,L=0)
2025-01-16 05:03:48,393 - INFO - Episode 1391/98900: Winner=2, Reward=-33.15, EPSILON=0.988, (W=127,D=1,L=0)
2025-01-16 05:03:48,568 - INFO - Episode 1392/98900: Winner=2, Reward=-9.80, EPSILON=0.988, (W=128,D=1,L=0)
2025-01-16 05:03:48,749 - INFO - Episode 1393/98900: Winner=2, Reward=1.50, EPSILON=0.988, (W=129,D=1,L=0)
2025-01-16 05:03:49,123 - INFO - Episode 1394/98900: Winner=2, Reward=-80.85, EPSILON=0.988, (W=130,D=1,L=0)
2025-01-16 05:03:49,271 - INFO - Episode 1395/98900: Winner=2, Reward=-11.95, EPSILON=0.988, (W=131,D=1,L=0)
2025-01-16 05:03:49,673 - INFO - Episode 1396/98900: Winner=2, Reward=-57.30, EPSILON=0.988, (W=131,D=1,L=0)
2025-01-16 05:03:49,853 - INFO - Episode 1397/98900: Winner=2, Reward=-20.45, EPSILON=0.988, (W=132,D=1,L=0)
2025-01-16 05:03:49,940 - INFO - Episode 1398/98900: Winner=2, Reward=8.30, EPSILON=0.987, (W=132,D=1,L=0)
2025-01-16 05:03:50,151 - INFO - Episode 1399/98900: Winner=2, Reward=3.95, EPSILON=0.987, (W=132,D=1,L=0)
2025-01-16 05:03:50,558 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1400.
2025-01-16 05:03:50,558 - INFO - Models saved at episode 1400
2025-01-16 05:03:50,558 - INFO - Target networks updated
2025-01-16 05:03:50,626 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1400.
2025-01-16 05:03:50,626 - INFO - Episode 1400/98900: Winner=2, Reward=-24.55, EPSILON=0.987, (W=133,D=1,L=0)
2025-01-16 05:03:50,906 - INFO - Episode 1401/98900: Winner=2, Reward=-16.20, EPSILON=0.987, (W=134,D=1,L=0)
2025-01-16 05:03:51,191 - INFO - Episode 1402/98900: Winner=2, Reward=-12.55, EPSILON=0.987, (W=135,D=1,L=0)
2025-01-16 05:03:51,354 - INFO - Episode 1403/98900: Winner=2, Reward=17.75, EPSILON=0.987, (W=135,D=1,L=0)
2025-01-16 05:03:51,712 - DEBUG - Q-vals = [0.25959337 0.19248156 0.07839829 0.18373357 0.16962413 0.02961333
 0.08655576], best_act=3, best_val=0.184
2025-01-16 05:03:51,713 - DEBUG - Low Q-value (0.184), using MCTS.
2025-01-16 05:03:51,714 - INFO - Running MCTS with 66 simulations using 6 processes.
2025-01-16 05:03:54,662 - DEBUG - Aggregated action counts: {3: 2, 2: 4}
2025-01-16 05:03:54,662 - DEBUG - Chose best action 2
2025-01-16 05:03:54,674 - INFO - Episode 1404/98900: Winner=2, Reward=-28.00, EPSILON=0.987, (W=135,D=1,L=0)
2025-01-16 05:03:54,922 - INFO - Episode 1405/98900: Winner=2, Reward=6.70, EPSILON=0.987, (W=135,D=1,L=0)
2025-01-16 05:03:55,126 - INFO - Episode 1406/98900: Winner=2, Reward=-17.65, EPSILON=0.987, (W=136,D=1,L=0)
2025-01-16 05:03:55,328 - INFO - Episode 1407/98900: Winner=2, Reward=-0.20, EPSILON=0.987, (W=136,D=1,L=0)
2025-01-16 05:03:55,483 - INFO - Episode 1408/98900: Winner=2, Reward=-3.30, EPSILON=0.987, (W=137,D=1,L=0)
2025-01-16 05:03:55,687 - INFO - Episode 1409/98900: Winner=2, Reward=-12.55, EPSILON=0.987, (W=138,D=1,L=0)
2025-01-16 05:03:56,041 - INFO - Episode 1410/98900: Winner=2, Reward=-52.35, EPSILON=0.987, (W=138,D=1,L=0)
2025-01-16 05:03:56,157 - INFO - Episode 1411/98900: Winner=2, Reward=4.35, EPSILON=0.987, (W=138,D=1,L=0)
2025-01-16 05:03:56,281 - INFO - Episode 1412/98900: Winner=2, Reward=-0.45, EPSILON=0.987, (W=138,D=1,L=0)
2025-01-16 05:03:56,578 - INFO - Episode 1413/98900: Winner=2, Reward=-24.45, EPSILON=0.987, (W=138,D=1,L=0)
2025-01-16 05:03:56,820 - INFO - Episode 1414/98900: Winner=2, Reward=-10.80, EPSILON=0.987, (W=138,D=1,L=0)
2025-01-16 05:03:57,002 - INFO - Episode 1415/98900: Winner=2, Reward=19.20, EPSILON=0.987, (W=139,D=1,L=0)
2025-01-16 05:03:57,175 - INFO - Episode 1416/98900: Winner=2, Reward=-11.95, EPSILON=0.987, (W=140,D=1,L=0)
2025-01-16 05:03:57,207 - DEBUG - Q-vals = [0.08905008 0.07793056 0.36273858 0.24391787 0.08268517 0.08115811
 0.06251959], best_act=2, best_val=0.363
2025-01-16 05:03:57,207 - DEBUG - Low Q-value (0.363), using MCTS.
2025-01-16 05:03:57,207 - INFO - Running MCTS with 66 simulations using 6 processes.
2025-01-16 05:04:00,267 - DEBUG - Aggregated action counts: {0: 4, 1: 1, 3: 1}
2025-01-16 05:04:00,267 - DEBUG - Chose best action 0
2025-01-16 05:04:00,480 - INFO - Episode 1417/98900: Winner=2, Reward=0.45, EPSILON=0.987, (W=140,D=1,L=0)
2025-01-16 05:04:00,713 - INFO - Episode 1418/98900: Winner=2, Reward=-15.70, EPSILON=0.987, (W=141,D=1,L=0)
2025-01-16 05:04:00,837 - INFO - Episode 1419/98900: Winner=2, Reward=3.75, EPSILON=0.987, (W=141,D=1,L=0)
2025-01-16 05:04:00,958 - INFO - Episode 1420/98900: Winner=2, Reward=7.30, EPSILON=0.987, (W=141,D=1,L=0)
2025-01-16 05:04:01,155 - INFO - Episode 1421/98900: Winner=2, Reward=-1.10, EPSILON=0.987, (W=141,D=1,L=0)
2025-01-16 05:04:01,453 - INFO - Episode 1422/98900: Winner=2, Reward=-25.85, EPSILON=0.987, (W=141,D=1,L=0)
2025-01-16 05:04:01,653 - INFO - Episode 1423/98900: Winner=2, Reward=-3.10, EPSILON=0.987, (W=141,D=1,L=0)
2025-01-16 05:04:01,806 - INFO - Episode 1424/98900: Winner=2, Reward=5.25, EPSILON=0.987, (W=141,D=1,L=0)
2025-01-16 05:04:02,023 - INFO - Episode 1425/98900: Winner=2, Reward=-5.15, EPSILON=0.987, (W=141,D=1,L=0)
2025-01-16 05:04:02,187 - INFO - Episode 1426/98900: Winner=2, Reward=-1.05, EPSILON=0.987, (W=141,D=1,L=0)
2025-01-16 05:04:02,390 - INFO - Episode 1427/98900: Winner=2, Reward=-12.05, EPSILON=0.987, (W=142,D=1,L=0)
2025-01-16 05:04:02,715 - INFO - Episode 1428/98900: Winner=2, Reward=-20.95, EPSILON=0.987, (W=142,D=1,L=0)
2025-01-16 05:04:03,031 - INFO - Episode 1429/98900: Winner=2, Reward=-12.65, EPSILON=0.987, (W=143,D=1,L=0)
2025-01-16 05:04:03,232 - INFO - Episode 1430/98900: Winner=2, Reward=-2.60, EPSILON=0.987, (W=143,D=1,L=0)
2025-01-16 05:04:03,525 - INFO - Episode 1431/98900: Winner=2, Reward=-11.10, EPSILON=0.987, (W=143,D=1,L=0)
2025-01-16 05:04:03,686 - INFO - Episode 1432/98900: Winner=2, Reward=5.40, EPSILON=0.987, (W=144,D=1,L=0)
2025-01-16 05:04:03,979 - INFO - Episode 1433/98900: Winner=2, Reward=-10.35, EPSILON=0.987, (W=144,D=1,L=0)
2025-01-16 05:04:04,161 - INFO - Episode 1434/98900: Winner=2, Reward=3.50, EPSILON=0.987, (W=144,D=1,L=0)
2025-01-16 05:04:04,306 - INFO - Episode 1435/98900: Winner=2, Reward=-9.85, EPSILON=0.987, (W=145,D=1,L=0)
2025-01-16 05:04:04,594 - INFO - Episode 1436/98900: Winner=2, Reward=-20.90, EPSILON=0.987, (W=146,D=1,L=0)
2025-01-16 05:04:04,632 - DEBUG - Q-vals = [0.27072126 0.03994209 0.10843608 0.01568991 0.16870251 0.05604187
 0.3404662 ], best_act=6, best_val=0.340
2025-01-16 05:04:04,632 - DEBUG - Low Q-value (0.340), using MCTS.
2025-01-16 05:04:04,633 - INFO - Running MCTS with 67 simulations using 6 processes.
2025-01-16 05:04:07,650 - DEBUG - Aggregated action counts: {2: 2, 0: 4, 3: 1}
2025-01-16 05:04:07,650 - DEBUG - Chose best action 0
2025-01-16 05:04:07,948 - INFO - Episode 1437/98900: Winner=2, Reward=-9.45, EPSILON=0.987, (W=146,D=1,L=0)
2025-01-16 05:04:08,172 - INFO - Episode 1438/98900: Winner=2, Reward=-17.60, EPSILON=0.987, (W=147,D=1,L=0)
2025-01-16 05:04:08,460 - INFO - Episode 1439/98900: Winner=2, Reward=0.50, EPSILON=0.987, (W=147,D=1,L=0)
2025-01-16 05:04:08,750 - INFO - Episode 1440/98900: Winner=2, Reward=-27.70, EPSILON=0.987, (W=147,D=1,L=0)
2025-01-16 05:04:08,945 - INFO - Episode 1441/98900: Winner=2, Reward=0.65, EPSILON=0.987, (W=147,D=1,L=0)
2025-01-16 05:04:09,257 - INFO - Episode 1442/98900: Winner=2, Reward=-20.55, EPSILON=0.987, (W=148,D=1,L=0)
2025-01-16 05:04:09,542 - INFO - Episode 1443/98900: Winner=2, Reward=12.40, EPSILON=0.987, (W=148,D=1,L=0)
2025-01-16 05:04:09,781 - INFO - Episode 1444/98900: Winner=2, Reward=-13.95, EPSILON=0.987, (W=149,D=1,L=0)
2025-01-16 05:04:09,907 - DEBUG - Q-vals = [0.11506629 0.12180311 0.12407558 0.20322786 0.15347792 0.17981936
 0.10252991], best_act=3, best_val=0.203
2025-01-16 05:04:09,907 - DEBUG - Low Q-value (0.203), using MCTS.
2025-01-16 05:04:09,907 - INFO - Running MCTS with 67 simulations using 6 processes.
2025-01-16 05:04:13,238 - DEBUG - Aggregated action counts: {4: 2, 2: 3, 3: 1, 0: 1}
2025-01-16 05:04:13,238 - DEBUG - Chose best action 2
2025-01-16 05:04:13,309 - INFO - Episode 1445/98900: Winner=2, Reward=-1.05, EPSILON=0.987, (W=150,D=1,L=0)
2025-01-16 05:04:13,621 - INFO - Episode 1446/98900: Winner=2, Reward=-3.25, EPSILON=0.987, (W=150,D=1,L=0)
2025-01-16 05:04:14,028 - INFO - Episode 1447/98900: Winner=2, Reward=-95.30, EPSILON=0.987, (W=151,D=1,L=0)
2025-01-16 05:04:14,153 - INFO - Episode 1448/98900: Winner=2, Reward=1.00, EPSILON=0.987, (W=151,D=1,L=0)
2025-01-16 05:04:14,231 - INFO - Episode 1449/98900: Winner=2, Reward=1.05, EPSILON=0.987, (W=151,D=1,L=0)
2025-01-16 05:04:14,247 - DEBUG - Q-vals = [0.13250457 0.13767391 0.12230536 0.14087105 0.17663649 0.15128344
 0.13872519], best_act=4, best_val=0.177
2025-01-16 05:04:14,247 - DEBUG - Low Q-value (0.177), using MCTS.
2025-01-16 05:04:14,262 - INFO - Running MCTS with 68 simulations using 6 processes.
2025-01-16 05:04:17,818 - DEBUG - Aggregated action counts: {1: 1, 0: 3, 3: 3}
2025-01-16 05:04:17,818 - DEBUG - Chose best action 0
2025-01-16 05:04:18,099 - INFO - Episode 1450/98900: Winner=2, Reward=-7.15, EPSILON=0.987, (W=152,D=1,L=0)
2025-01-16 05:04:18,427 - INFO - Episode 1451/98900: Winner=2, Reward=-17.55, EPSILON=0.987, (W=152,D=1,L=0)
2025-01-16 05:04:18,723 - INFO - Episode 1452/98900: Winner=2, Reward=-17.10, EPSILON=0.987, (W=152,D=1,L=0)
2025-01-16 05:04:19,098 - INFO - Episode 1453/98900: Winner=2, Reward=-3.55, EPSILON=0.987, (W=152,D=1,L=0)
2025-01-16 05:04:19,241 - INFO - Episode 1454/98900: Winner=2, Reward=-8.50, EPSILON=0.987, (W=153,D=1,L=0)
2025-01-16 05:04:19,366 - INFO - Episode 1455/98900: Winner=2, Reward=15.40, EPSILON=0.987, (W=153,D=1,L=0)
2025-01-16 05:04:19,475 - DEBUG - Q-vals = [0.09016126 0.1256237  0.12384821 0.18144432 0.17540976 0.22655687
 0.07695576], best_act=5, best_val=0.227
2025-01-16 05:04:19,475 - DEBUG - Low Q-value (0.227), using MCTS.
2025-01-16 05:04:19,475 - INFO - Running MCTS with 68 simulations using 6 processes.
2025-01-16 05:04:22,272 - DEBUG - Aggregated action counts: {0: 3, 2: 1, 1: 2, 4: 1}
2025-01-16 05:04:22,272 - DEBUG - Chose best action 0
2025-01-16 05:04:22,428 - INFO - Episode 1456/98900: Winner=2, Reward=-16.60, EPSILON=0.987, (W=154,D=1,L=0)
2025-01-16 05:04:22,522 - INFO - Episode 1457/98900: Winner=2, Reward=0.15, EPSILON=0.987, (W=154,D=1,L=0)
2025-01-16 05:04:22,818 - INFO - Episode 1458/98900: Winner=2, Reward=-9.90, EPSILON=0.987, (W=154,D=1,L=0)
2025-01-16 05:04:22,990 - INFO - Episode 1459/98900: Winner=2, Reward=-17.85, EPSILON=0.987, (W=155,D=1,L=0)
2025-01-16 05:04:23,178 - INFO - Episode 1460/98900: Winner=2, Reward=-24.40, EPSILON=0.987, (W=156,D=1,L=0)
2025-01-16 05:04:23,412 - INFO - Episode 1461/98900: Winner=2, Reward=-12.35, EPSILON=0.987, (W=157,D=1,L=0)
2025-01-16 05:04:23,537 - INFO - Episode 1462/98900: Winner=2, Reward=-8.60, EPSILON=0.987, (W=158,D=1,L=0)
2025-01-16 05:04:23,599 - DEBUG - Q-vals = [0.04825561 0.0887343  0.13264515 0.11047423 0.21554573 0.37155566
 0.03278933], best_act=5, best_val=0.372
2025-01-16 05:04:23,599 - DEBUG - Low Q-value (0.372), using MCTS.
2025-01-16 05:04:23,599 - INFO - Running MCTS with 68 simulations using 6 processes.
2025-01-16 05:04:26,271 - DEBUG - Aggregated action counts: {1: 2, 0: 3, 2: 1, 5: 1}
2025-01-16 05:04:26,271 - DEBUG - Chose best action 0
2025-01-16 05:04:26,411 - INFO - Episode 1463/98900: Winner=2, Reward=-2.00, EPSILON=0.987, (W=158,D=1,L=0)
2025-01-16 05:04:26,630 - INFO - Episode 1464/98900: Winner=2, Reward=-18.15, EPSILON=0.987, (W=159,D=1,L=0)
2025-01-16 05:04:26,880 - INFO - Episode 1465/98900: Winner=2, Reward=-15.60, EPSILON=0.987, (W=159,D=1,L=0)
2025-01-16 05:04:27,067 - INFO - Episode 1466/98900: Winner=2, Reward=5.05, EPSILON=0.987, (W=159,D=1,L=0)
2025-01-16 05:04:27,380 - INFO - Episode 1467/98900: Winner=2, Reward=8.75, EPSILON=0.987, (W=159,D=1,L=0)
2025-01-16 05:04:27,802 - INFO - Episode 1468/98900: Winner=2, Reward=-51.45, EPSILON=0.987, (W=160,D=1,L=0)
2025-01-16 05:04:28,052 - INFO - Episode 1469/98900: Winner=2, Reward=7.25, EPSILON=0.987, (W=160,D=1,L=0)
2025-01-16 05:04:28,176 - INFO - Episode 1470/98900: Winner=2, Reward=-8.75, EPSILON=0.987, (W=161,D=1,L=0)
2025-01-16 05:04:28,270 - DEBUG - Q-vals = [0.13480543 0.13968408 0.14537622 0.14868927 0.14264424 0.17580897
 0.11299182], best_act=5, best_val=0.176
2025-01-16 05:04:28,270 - DEBUG - Low Q-value (0.176), using MCTS.
2025-01-16 05:04:28,270 - INFO - Running MCTS with 68 simulations using 6 processes.
2025-01-16 05:04:31,004 - DEBUG - Aggregated action counts: {2: 1, 1: 4, 4: 1, 0: 1}
2025-01-16 05:04:31,004 - DEBUG - Chose best action 1
2025-01-16 05:04:31,254 - INFO - Episode 1471/98900: Winner=2, Reward=-28.20, EPSILON=0.987, (W=162,D=1,L=0)
2025-01-16 05:04:31,551 - INFO - Episode 1472/98900: Winner=2, Reward=-37.65, EPSILON=0.987, (W=162,D=1,L=0)
2025-01-16 05:04:31,660 - INFO - Episode 1473/98900: Winner=2, Reward=-11.25, EPSILON=0.987, (W=163,D=1,L=0)
2025-01-16 05:04:31,770 - INFO - Episode 1474/98900: Winner=2, Reward=-0.05, EPSILON=0.987, (W=163,D=1,L=0)
2025-01-16 05:04:31,926 - INFO - Episode 1475/98900: Winner=2, Reward=15.65, EPSILON=0.987, (W=163,D=1,L=0)
2025-01-16 05:04:32,067 - INFO - Episode 1476/98900: Winner=2, Reward=13.95, EPSILON=0.987, (W=163,D=1,L=0)
2025-01-16 05:04:32,238 - DEBUG - Q-vals = [0.1897066  0.12054142 0.03004565 0.02802723 0.48693267 0.0373086
 0.10743785], best_act=4, best_val=0.487
2025-01-16 05:04:32,238 - DEBUG - Low Q-value (0.487), using MCTS.
2025-01-16 05:04:32,238 - INFO - Running MCTS with 69 simulations using 6 processes.
2025-01-16 05:04:35,004 - DEBUG - Aggregated action counts: {0: 4, 1: 3}
2025-01-16 05:04:35,004 - DEBUG - Chose best action 0
2025-01-16 05:04:35,098 - INFO - Episode 1477/98900: Winner=2, Reward=1.55, EPSILON=0.987, (W=164,D=1,L=0)
2025-01-16 05:04:35,269 - INFO - Episode 1478/98900: Winner=2, Reward=4.00, EPSILON=0.987, (W=164,D=1,L=0)
2025-01-16 05:04:35,441 - INFO - Episode 1479/98900: Winner=2, Reward=8.60, EPSILON=0.987, (W=164,D=1,L=0)
2025-01-16 05:04:35,800 - INFO - Episode 1480/98900: Winner=2, Reward=-51.80, EPSILON=0.987, (W=165,D=1,L=0)
2025-01-16 05:04:35,957 - INFO - Episode 1481/98900: Winner=2, Reward=11.15, EPSILON=0.987, (W=165,D=1,L=0)
2025-01-16 05:04:35,988 - DEBUG - Q-vals = [1.4002469e-01 7.3806196e-03 3.2192243e-03 4.0023569e-02 5.0430908e-04
 6.7107035e-03 8.0213690e-01], best_act=6, best_val=0.802
2025-01-16 05:04:35,988 - DEBUG - Low Q-value (0.802), using MCTS.
2025-01-16 05:04:35,988 - INFO - Running MCTS with 69 simulations using 6 processes.
2025-01-16 05:04:38,972 - DEBUG - Aggregated action counts: {3: 4, 2: 1, 0: 2}
2025-01-16 05:04:38,972 - DEBUG - Chose best action 3
2025-01-16 05:04:39,143 - INFO - Episode 1482/98900: Winner=2, Reward=9.75, EPSILON=0.987, (W=165,D=1,L=0)
2025-01-16 05:04:39,425 - INFO - Episode 1483/98900: Winner=2, Reward=-19.10, EPSILON=0.987, (W=165,D=1,L=0)
2025-01-16 05:04:39,690 - INFO - Episode 1484/98900: Winner=2, Reward=5.55, EPSILON=0.987, (W=165,D=1,L=0)
2025-01-16 05:04:39,846 - INFO - Episode 1485/98900: Winner=2, Reward=-10.70, EPSILON=0.987, (W=166,D=1,L=0)
2025-01-16 05:04:39,909 - INFO - Episode 1486/98900: Winner=2, Reward=8.25, EPSILON=0.987, (W=166,D=1,L=0)
2025-01-16 05:04:40,190 - INFO - Episode 1487/98900: Winner=2, Reward=19.80, EPSILON=0.987, (W=166,D=1,L=0)
2025-01-16 05:04:40,440 - INFO - Episode 1488/98900: Winner=2, Reward=12.95, EPSILON=0.987, (W=166,D=1,L=0)
2025-01-16 05:04:40,596 - INFO - Episode 1489/98900: Winner=2, Reward=13.95, EPSILON=0.987, (W=166,D=1,L=0)
2025-01-16 05:04:40,909 - INFO - Episode 1490/98900: Winner=2, Reward=-28.55, EPSILON=0.987, (W=167,D=1,L=0)
2025-01-16 05:04:41,112 - INFO - Episode 1491/98900: Winner=2, Reward=8.80, EPSILON=0.987, (W=167,D=1,L=0)
2025-01-16 05:04:41,315 - INFO - Episode 1492/98900: Winner=2, Reward=-9.45, EPSILON=0.987, (W=168,D=1,L=0)
2025-01-16 05:04:41,533 - INFO - Episode 1493/98900: Winner=2, Reward=-7.50, EPSILON=0.987, (W=169,D=1,L=0)
2025-01-16 05:04:41,721 - INFO - Episode 1494/98900: Winner=2, Reward=-17.70, EPSILON=0.987, (W=170,D=1,L=0)
2025-01-16 05:04:41,830 - INFO - Episode 1495/98900: Winner=2, Reward=5.75, EPSILON=0.987, (W=170,D=1,L=0)
2025-01-16 05:04:42,002 - INFO - Episode 1496/98900: Winner=2, Reward=-13.15, EPSILON=0.987, (W=171,D=1,L=0)
2025-01-16 05:04:42,221 - INFO - Episode 1497/98900: Winner=2, Reward=-18.10, EPSILON=0.987, (W=172,D=1,L=0)
2025-01-16 05:04:42,252 - DEBUG - Q-vals = [0.1413462  0.12299445 0.15462354 0.11193108 0.1548024  0.15965933
 0.154643  ], best_act=5, best_val=0.160
2025-01-16 05:04:42,252 - DEBUG - Low Q-value (0.160), using MCTS.
2025-01-16 05:04:42,252 - INFO - Running MCTS with 69 simulations using 6 processes.
2025-01-16 05:04:45,080 - DEBUG - Aggregated action counts: {2: 2, 3: 1, 1: 1, 4: 1, 0: 2}
2025-01-16 05:04:45,080 - DEBUG - Chose best action 2
2025-01-16 05:04:45,298 - INFO - Episode 1498/98900: Winner=2, Reward=0.05, EPSILON=0.987, (W=172,D=1,L=0)
2025-01-16 05:04:45,658 - INFO - Episode 1499/98900: Winner=2, Reward=-21.20, EPSILON=0.987, (W=172,D=1,L=0)
2025-01-16 05:04:46,017 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1500.
2025-01-16 05:04:46,017 - INFO - Models saved at episode 1500
2025-01-16 05:04:46,017 - INFO - Target networks updated
2025-01-16 05:04:46,079 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1500.
2025-01-16 05:04:46,079 - INFO - Episode 1500/98900: Winner=2, Reward=15.60, EPSILON=0.987, (W=173,D=1,L=0)
2025-01-16 05:04:46,314 - INFO - Episode 1501/98900: Winner=2, Reward=-9.40, EPSILON=0.987, (W=173,D=1,L=0)
2025-01-16 05:04:46,454 - INFO - Episode 1502/98900: Winner=2, Reward=-0.75, EPSILON=0.987, (W=173,D=1,L=0)
2025-01-16 05:04:46,610 - DEBUG - Q-vals = [0.20658733 0.10847303 0.1396866  0.10486938 0.20046438 0.12097607
 0.11894326], best_act=0, best_val=0.207
2025-01-16 05:04:46,610 - DEBUG - Low Q-value (0.207), using MCTS.
2025-01-16 05:04:46,610 - INFO - Running MCTS with 70 simulations using 6 processes.
2025-01-16 05:04:49,469 - DEBUG - Aggregated action counts: {3: 2, 0: 3, 6: 1, 2: 1}
2025-01-16 05:04:49,469 - DEBUG - Chose best action 0
2025-01-16 05:04:49,578 - INFO - Episode 1503/98900: Winner=2, Reward=0.85, EPSILON=0.987, (W=173,D=1,L=0)
2025-01-16 05:04:49,813 - DEBUG - Q-vals = [0.10676453 0.10381393 0.20237677 0.11380362 0.29366395 0.09441942
 0.08515786], best_act=4, best_val=0.294
2025-01-16 05:04:49,813 - DEBUG - Low Q-value (0.294), using MCTS.
2025-01-16 05:04:49,813 - INFO - Running MCTS with 70 simulations using 6 processes.
2025-01-16 05:04:52,547 - DEBUG - Aggregated action counts: {2: 2, 0: 4, 5: 1}
2025-01-16 05:04:52,547 - DEBUG - Chose best action 0
2025-01-16 05:04:52,687 - INFO - Episode 1504/98900: Winner=2, Reward=-60.70, EPSILON=0.987, (W=173,D=1,L=0)
2025-01-16 05:04:52,859 - INFO - Episode 1505/98900: Winner=2, Reward=5.55, EPSILON=0.987, (W=173,D=1,L=0)
2025-01-16 05:04:53,089 - INFO - Episode 1506/98900: Winner=2, Reward=-12.55, EPSILON=0.987, (W=174,D=1,L=0)
2025-01-16 05:04:53,276 - INFO - Episode 1507/98900: Winner=2, Reward=2.50, EPSILON=0.987, (W=175,D=1,L=0)
2025-01-16 05:04:53,508 - INFO - Episode 1508/98900: Winner=2, Reward=14.60, EPSILON=0.987, (W=175,D=1,L=0)
2025-01-16 05:04:53,579 - INFO - Episode 1509/98900: Winner=2, Reward=8.25, EPSILON=0.987, (W=175,D=1,L=0)
2025-01-16 05:04:53,660 - INFO - Episode 1510/98900: Winner=2, Reward=8.15, EPSILON=0.987, (W=175,D=1,L=0)
2025-01-16 05:04:53,924 - INFO - Episode 1511/98900: Winner=2, Reward=-31.15, EPSILON=0.986, (W=176,D=1,L=0)
2025-01-16 05:04:54,201 - INFO - Episode 1512/98900: Winner=2, Reward=18.75, EPSILON=0.986, (W=176,D=1,L=0)
2025-01-16 05:04:54,371 - INFO - Episode 1513/98900: Winner=2, Reward=2.15, EPSILON=0.986, (W=176,D=1,L=0)
2025-01-16 05:04:54,744 - INFO - Episode 1514/98900: Winner=2, Reward=-36.05, EPSILON=0.986, (W=177,D=1,L=0)
2025-01-16 05:04:54,941 - INFO - Episode 1515/98900: Winner=2, Reward=6.60, EPSILON=0.986, (W=177,D=1,L=0)
2025-01-16 05:04:55,177 - INFO - Episode 1516/98900: Winner=2, Reward=-0.05, EPSILON=0.986, (W=177,D=1,L=0)
2025-01-16 05:04:55,312 - INFO - Episode 1517/98900: Winner=2, Reward=12.85, EPSILON=0.986, (W=177,D=1,L=0)
2025-01-16 05:04:55,534 - INFO - Episode 1518/98900: Winner=2, Reward=-9.60, EPSILON=0.986, (W=178,D=1,L=0)
2025-01-16 05:04:55,752 - INFO - Episode 1519/98900: Winner=2, Reward=-1.85, EPSILON=0.986, (W=179,D=1,L=0)
2025-01-16 05:04:56,034 - INFO - Episode 1520/98900: Winner=2, Reward=-32.80, EPSILON=0.986, (W=180,D=1,L=0)
2025-01-16 05:04:56,252 - INFO - Episode 1521/98900: Winner=2, Reward=1.05, EPSILON=0.986, (W=181,D=1,L=0)
2025-01-16 05:04:56,395 - INFO - Episode 1522/98900: Winner=2, Reward=1.65, EPSILON=0.986, (W=181,D=1,L=0)
2025-01-16 05:04:56,663 - INFO - Episode 1523/98900: Winner=2, Reward=-13.00, EPSILON=0.986, (W=181,D=1,L=0)
2025-01-16 05:04:56,963 - INFO - Episode 1524/98900: Winner=2, Reward=10.25, EPSILON=0.986, (W=181,D=1,L=0)
2025-01-16 05:04:57,056 - INFO - Episode 1525/98900: Winner=2, Reward=0.45, EPSILON=0.986, (W=181,D=1,L=0)
2025-01-16 05:04:57,227 - INFO - Episode 1526/98900: Winner=2, Reward=9.55, EPSILON=0.986, (W=181,D=1,L=0)
2025-01-16 05:04:57,468 - DEBUG - Q-vals = [0.09678445 0.02783548 0.2321477  0.27427372 0.24958526 0.0293307
 0.09004267], best_act=3, best_val=0.274
2025-01-16 05:04:57,468 - DEBUG - Low Q-value (0.274), using MCTS.
2025-01-16 05:04:57,479 - INFO - Episode 1527/98900: Winner=2, Reward=-5.35, EPSILON=0.986, (W=182,D=1,L=0)
2025-01-16 05:04:57,863 - INFO - Episode 1528/98900: Winner=2, Reward=-58.05, EPSILON=0.986, (W=183,D=1,L=0)
2025-01-16 05:04:58,211 - INFO - Episode 1529/98900: Winner=2, Reward=-49.05, EPSILON=0.986, (W=184,D=1,L=0)
2025-01-16 05:04:58,459 - INFO - Episode 1530/98900: Winner=2, Reward=7.10, EPSILON=0.986, (W=184,D=1,L=0)
2025-01-16 05:04:58,709 - INFO - Episode 1531/98900: Winner=2, Reward=8.75, EPSILON=0.986, (W=184,D=1,L=0)
2025-01-16 05:04:58,908 - INFO - Episode 1532/98900: Winner=2, Reward=4.30, EPSILON=0.986, (W=184,D=1,L=0)
2025-01-16 05:04:59,178 - INFO - Episode 1533/98900: Winner=2, Reward=-24.05, EPSILON=0.986, (W=185,D=1,L=0)
2025-01-16 05:04:59,293 - INFO - Episode 1534/98900: Winner=2, Reward=5.25, EPSILON=0.986, (W=185,D=1,L=0)
2025-01-16 05:04:59,666 - INFO - Episode 1535/98900: Winner=2, Reward=-31.55, EPSILON=0.986, (W=185,D=1,L=0)
2025-01-16 05:04:59,932 - INFO - Episode 1536/98900: Winner=2, Reward=-10.30, EPSILON=0.986, (W=186,D=1,L=0)
2025-01-16 05:05:00,224 - INFO - Episode 1537/98900: Winner=2, Reward=-44.25, EPSILON=0.986, (W=187,D=1,L=0)
2025-01-16 05:05:00,465 - DEBUG - Q-vals = [0.10181631 0.06127519 0.11878312 0.17117123 0.21735837 0.17036754
 0.15922827], best_act=4, best_val=0.217
2025-01-16 05:05:00,465 - DEBUG - Low Q-value (0.217), using MCTS.
2025-01-16 05:05:00,475 - INFO - Episode 1538/98900: Winner=2, Reward=-17.60, EPSILON=0.986, (W=188,D=1,L=0)
2025-01-16 05:05:00,579 - INFO - Episode 1539/98900: Winner=2, Reward=7.25, EPSILON=0.986, (W=188,D=1,L=0)
2025-01-16 05:05:00,779 - INFO - Episode 1540/98900: Winner=2, Reward=-11.45, EPSILON=0.986, (W=189,D=1,L=0)
2025-01-16 05:05:01,027 - INFO - Episode 1541/98900: Winner=2, Reward=-12.30, EPSILON=0.986, (W=190,D=1,L=0)
2025-01-16 05:05:01,219 - INFO - Episode 1542/98900: Winner=2, Reward=-20.35, EPSILON=0.986, (W=191,D=1,L=0)
2025-01-16 05:05:01,560 - INFO - Episode 1543/98900: Winner=2, Reward=-61.65, EPSILON=0.986, (W=192,D=1,L=0)
2025-01-16 05:05:01,849 - INFO - Episode 1544/98900: Winner=2, Reward=-12.50, EPSILON=0.986, (W=192,D=1,L=0)
2025-01-16 05:05:01,976 - INFO - Episode 1545/98900: Winner=2, Reward=9.75, EPSILON=0.986, (W=192,D=1,L=0)
2025-01-16 05:05:02,197 - INFO - Episode 1546/98900: Winner=2, Reward=-17.95, EPSILON=0.986, (W=193,D=1,L=0)
2025-01-16 05:05:02,396 - INFO - Episode 1547/98900: Winner=2, Reward=-18.90, EPSILON=0.986, (W=194,D=1,L=0)
2025-01-16 05:05:02,701 - INFO - Episode 1548/98900: Winner=2, Reward=-27.05, EPSILON=0.986, (W=194,D=1,L=0)
2025-01-16 05:05:02,920 - INFO - Episode 1549/98900: Winner=2, Reward=-14.10, EPSILON=0.986, (W=195,D=1,L=0)
2025-01-16 05:05:03,136 - INFO - Episode 1550/98900: Winner=2, Reward=3.30, EPSILON=0.986, (W=195,D=1,L=0)
2025-01-16 05:05:03,439 - INFO - Episode 1551/98900: Winner=2, Reward=-41.15, EPSILON=0.986, (W=196,D=1,L=0)
2025-01-16 05:05:03,678 - INFO - Episode 1552/98900: Winner=2, Reward=8.10, EPSILON=0.986, (W=196,D=1,L=0)
2025-01-16 05:05:03,780 - INFO - Episode 1553/98900: Winner=2, Reward=-5.35, EPSILON=0.986, (W=196,D=1,L=0)
2025-01-16 05:05:03,921 - INFO - Episode 1554/98900: Winner=2, Reward=-7.50, EPSILON=0.986, (W=197,D=1,L=0)
2025-01-16 05:05:04,224 - INFO - Episode 1555/98900: Winner=2, Reward=-30.75, EPSILON=0.986, (W=198,D=1,L=0)
2025-01-16 05:05:04,506 - INFO - Episode 1556/98900: Winner=2, Reward=-7.10, EPSILON=0.986, (W=198,D=1,L=0)
2025-01-16 05:05:04,728 - INFO - Episode 1557/98900: Winner=2, Reward=-18.75, EPSILON=0.986, (W=198,D=1,L=0)
2025-01-16 05:05:05,063 - INFO - Episode 1558/98900: Winner=2, Reward=-19.85, EPSILON=0.986, (W=199,D=1,L=0)
2025-01-16 05:05:05,213 - DEBUG - Q-vals = [0.07981686 0.20642297 0.04762027 0.13900645 0.24516217 0.17893995
 0.10303142], best_act=4, best_val=0.245
2025-01-16 05:05:05,213 - DEBUG - Low Q-value (0.245), using MCTS.
2025-01-16 05:05:05,214 - INFO - Running MCTS with 72 simulations using 6 processes.
2025-01-16 05:05:07,931 - DEBUG - Aggregated action counts: {2: 2, 0: 3, 3: 1}
2025-01-16 05:05:07,931 - DEBUG - Chose best action 0
2025-01-16 05:05:07,999 - INFO - Episode 1559/98900: Winner=2, Reward=-0.55, EPSILON=0.986, (W=200,D=1,L=0)
2025-01-16 05:05:08,242 - INFO - Episode 1560/98900: Winner=2, Reward=-7.05, EPSILON=0.986, (W=200,D=1,L=0)
2025-01-16 05:05:08,506 - INFO - Episode 1561/98900: Winner=2, Reward=18.55, EPSILON=0.986, (W=200,D=1,L=0)
2025-01-16 05:05:08,756 - INFO - Episode 1562/98900: Winner=2, Reward=-12.25, EPSILON=0.986, (W=201,D=1,L=0)
2025-01-16 05:05:08,955 - INFO - Episode 1563/98900: Winner=2, Reward=-14.15, EPSILON=0.986, (W=202,D=1,L=0)
2025-01-16 05:05:09,195 - INFO - Episode 1564/98900: Winner=2, Reward=-23.25, EPSILON=0.986, (W=203,D=1,L=0)
2025-01-16 05:05:09,494 - INFO - Episode 1565/98900: Winner=2, Reward=-16.65, EPSILON=0.986, (W=204,D=1,L=0)
2025-01-16 05:05:09,709 - INFO - Episode 1566/98900: Winner=2, Reward=-8.35, EPSILON=0.986, (W=204,D=1,L=0)
2025-01-16 05:05:09,896 - INFO - Episode 1567/98900: Winner=2, Reward=-10.55, EPSILON=0.986, (W=204,D=1,L=0)
2025-01-16 05:05:10,035 - INFO - Episode 1568/98900: Winner=2, Reward=-3.65, EPSILON=0.986, (W=204,D=1,L=0)
2025-01-16 05:05:10,125 - INFO - Episode 1569/98900: Winner=2, Reward=-3.75, EPSILON=0.986, (W=205,D=1,L=0)
2025-01-16 05:05:10,333 - INFO - Episode 1570/98900: Winner=2, Reward=-10.70, EPSILON=0.986, (W=206,D=1,L=0)
2025-01-16 05:05:10,613 - INFO - Episode 1571/98900: Winner=2, Reward=-36.35, EPSILON=0.986, (W=207,D=1,L=0)
2025-01-16 05:05:10,730 - INFO - Episode 1572/98900: Winner=2, Reward=1.70, EPSILON=0.986, (W=207,D=1,L=0)
2025-01-16 05:05:11,008 - INFO - Episode 1573/98900: Winner=2, Reward=-25.55, EPSILON=0.986, (W=208,D=1,L=0)
2025-01-16 05:05:11,152 - DEBUG - Q-vals = [0.11578565 0.13969019 0.17534816 0.19913617 0.31058255 0.03017558
 0.02928171], best_act=4, best_val=0.311
2025-01-16 05:05:11,152 - DEBUG - Low Q-value (0.311), using MCTS.
2025-01-16 05:05:11,163 - INFO - Episode 1574/98900: Winner=2, Reward=8.15, EPSILON=0.986, (W=209,D=1,L=0)
2025-01-16 05:05:11,242 - DEBUG - Q-vals = [0.10902999 0.14208804 0.09753488 0.15344392 0.15200005 0.23058821
 0.11531493], best_act=5, best_val=0.231
2025-01-16 05:05:11,242 - DEBUG - Low Q-value (0.231), using MCTS.
2025-01-16 05:05:11,243 - INFO - Running MCTS with 73 simulations using 6 processes.
2025-01-16 05:05:14,162 - DEBUG - Aggregated action counts: {1: 1, 0: 5, 6: 1}
2025-01-16 05:05:14,163 - DEBUG - Chose best action 0
2025-01-16 05:05:14,186 - DEBUG - Q-vals = [0.11806183 0.1225162  0.0965929  0.15286486 0.16810735 0.21615425
 0.12570268], best_act=5, best_val=0.216
2025-01-16 05:05:14,186 - DEBUG - Low Q-value (0.216), using MCTS.
2025-01-16 05:05:14,187 - INFO - Running MCTS with 73 simulations using 6 processes.
2025-01-16 05:05:16,984 - DEBUG - Aggregated action counts: {0: 3, 6: 1, 1: 1, 2: 1, 5: 1}
2025-01-16 05:05:16,984 - DEBUG - Chose best action 0
2025-01-16 05:05:17,097 - INFO - Episode 1575/98900: Winner=2, Reward=-9.35, EPSILON=0.986, (W=210,D=1,L=0)
2025-01-16 05:05:17,382 - INFO - Episode 1576/98900: Winner=2, Reward=-24.00, EPSILON=0.986, (W=211,D=1,L=0)
2025-01-16 05:05:17,691 - INFO - Episode 1577/98900: Winner=2, Reward=-18.00, EPSILON=0.986, (W=211,D=1,L=0)
2025-01-16 05:05:17,953 - INFO - Episode 1578/98900: Winner=2, Reward=11.15, EPSILON=0.986, (W=211,D=1,L=0)
2025-01-16 05:05:18,233 - INFO - Episode 1579/98900: Winner=2, Reward=-22.65, EPSILON=0.986, (W=212,D=1,L=0)
2025-01-16 05:05:18,315 - DEBUG - Q-vals = [0.11869367 0.06051849 0.08008593 0.02940838 0.41577396 0.15705349
 0.1384661 ], best_act=4, best_val=0.416
2025-01-16 05:05:18,315 - DEBUG - Low Q-value (0.416), using MCTS.
2025-01-16 05:05:18,315 - INFO - Running MCTS with 73 simulations using 6 processes.
2025-01-16 05:05:21,164 - DEBUG - Aggregated action counts: {0: 4, 2: 1, 1: 1, 4: 1}
2025-01-16 05:05:21,165 - DEBUG - Chose best action 0
2025-01-16 05:05:21,330 - INFO - Episode 1580/98900: Winner=2, Reward=-10.00, EPSILON=0.986, (W=213,D=1,L=0)
2025-01-16 05:05:21,443 - INFO - Episode 1581/98900: Winner=2, Reward=-9.90, EPSILON=0.986, (W=214,D=1,L=0)
2025-01-16 05:05:21,700 - INFO - Episode 1582/98900: Winner=2, Reward=-5.75, EPSILON=0.986, (W=215,D=1,L=0)
2025-01-16 05:05:21,888 - INFO - Episode 1583/98900: Winner=2, Reward=-18.45, EPSILON=0.986, (W=216,D=1,L=0)
2025-01-16 05:05:22,258 - INFO - Episode 1584/98900: Winner=2, Reward=-14.95, EPSILON=0.986, (W=216,D=1,L=0)
2025-01-16 05:05:22,516 - INFO - Episode 1585/98900: Winner=2, Reward=35.75, EPSILON=0.986, (W=216,D=1,L=0)
2025-01-16 05:05:22,719 - INFO - Episode 1586/98900: Winner=2, Reward=-10.85, EPSILON=0.986, (W=217,D=1,L=0)
2025-01-16 05:05:22,985 - INFO - Episode 1587/98900: Winner=2, Reward=-14.60, EPSILON=0.986, (W=218,D=1,L=0)
2025-01-16 05:05:23,110 - INFO - Episode 1588/98900: Winner=2, Reward=-1.85, EPSILON=0.986, (W=219,D=1,L=0)
2025-01-16 05:05:23,235 - INFO - Episode 1589/98900: Winner=2, Reward=11.30, EPSILON=0.986, (W=219,D=1,L=0)
2025-01-16 05:05:23,406 - INFO - Episode 1590/98900: Winner=2, Reward=-6.45, EPSILON=0.986, (W=220,D=1,L=0)
2025-01-16 05:05:23,641 - DEBUG - Q-vals = [0.10473222 0.08770296 0.02825881 0.07398893 0.03187449 0.17057759
 0.50286496], best_act=6, best_val=0.503
2025-01-16 05:05:23,641 - DEBUG - Low Q-value (0.503), using MCTS.
2025-01-16 05:05:23,641 - INFO - Episode 1591/98900: Winner=2, Reward=-2.05, EPSILON=0.986, (W=221,D=1,L=0)
2025-01-16 05:05:23,906 - INFO - Episode 1592/98900: Winner=2, Reward=-15.55, EPSILON=0.986, (W=222,D=1,L=0)
2025-01-16 05:05:24,141 - INFO - Episode 1593/98900: Winner=2, Reward=18.75, EPSILON=0.986, (W=222,D=1,L=0)
2025-01-16 05:05:24,172 - DEBUG - Q-vals = [0.00237488 0.00419098 0.00811317 0.00260545 0.07415777 0.8895335
 0.01902419], best_act=5, best_val=0.890
2025-01-16 05:05:24,172 - DEBUG - Low Q-value (0.890), using MCTS.
2025-01-16 05:05:24,172 - INFO - Running MCTS with 73 simulations using 6 processes.
2025-01-16 05:05:27,015 - DEBUG - Aggregated action counts: {4: 1, 2: 2, 0: 3, 6: 1}
2025-01-16 05:05:27,015 - DEBUG - Chose best action 0
2025-01-16 05:05:27,327 - INFO - Episode 1594/98900: Winner=2, Reward=-51.55, EPSILON=0.986, (W=223,D=1,L=0)
2025-01-16 05:05:27,593 - INFO - Episode 1595/98900: Winner=2, Reward=-29.60, EPSILON=0.986, (W=224,D=1,L=0)
2025-01-16 05:05:27,952 - INFO - Episode 1596/98900: Winner=2, Reward=-64.95, EPSILON=0.986, (W=225,D=1,L=0)
2025-01-16 05:05:28,202 - INFO - Episode 1597/98900: Winner=2, Reward=-25.05, EPSILON=0.986, (W=225,D=1,L=0)
2025-01-16 05:05:28,311 - INFO - Episode 1598/98900: Winner=2, Reward=-9.60, EPSILON=0.986, (W=226,D=1,L=0)
2025-01-16 05:05:28,436 - DEBUG - Q-vals = [0.13940041 0.02354861 0.05481923 0.00629096 0.36833167 0.14378941
 0.26381963], best_act=4, best_val=0.368
2025-01-16 05:05:28,436 - DEBUG - Low Q-value (0.368), using MCTS.
2025-01-16 05:05:28,452 - INFO - Episode 1599/98900: Winner=2, Reward=-10.30, EPSILON=0.986, (W=227,D=1,L=0)
2025-01-16 05:05:28,764 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1600.
2025-01-16 05:05:28,764 - INFO - Models saved at episode 1600
2025-01-16 05:05:28,780 - INFO - Target networks updated
2025-01-16 05:05:28,827 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1600.
2025-01-16 05:05:28,827 - INFO - Episode 1600/98900: Winner=2, Reward=4.75, EPSILON=0.986, (W=228,D=1,L=0)
2025-01-16 05:05:29,139 - INFO - Episode 1601/98900: Winner=2, Reward=-45.05, EPSILON=0.986, (W=229,D=1,L=0)
2025-01-16 05:05:29,217 - DEBUG - Q-vals = [0.15147227 0.04606609 0.03471091 0.09513573 0.02316536 0.17785992
 0.47158974], best_act=6, best_val=0.472
2025-01-16 05:05:29,217 - DEBUG - Low Q-value (0.472), using MCTS.
2025-01-16 05:05:29,217 - INFO - Running MCTS with 74 simulations using 6 processes.
2025-01-16 05:05:32,092 - DEBUG - Aggregated action counts: {2: 1, 1: 4, 3: 1, 0: 1}
2025-01-16 05:05:32,092 - DEBUG - Chose best action 1
2025-01-16 05:05:32,326 - INFO - Episode 1602/98900: Winner=2, Reward=-26.90, EPSILON=0.986, (W=230,D=1,L=0)
2025-01-16 05:05:32,623 - INFO - Episode 1603/98900: Winner=2, Reward=-24.20, EPSILON=0.986, (W=231,D=1,L=0)
2025-01-16 05:05:32,717 - INFO - Episode 1604/98900: Winner=2, Reward=4.35, EPSILON=0.986, (W=231,D=1,L=0)
2025-01-16 05:05:32,951 - INFO - Episode 1605/98900: Winner=2, Reward=-19.60, EPSILON=0.986, (W=232,D=1,L=0)
2025-01-16 05:05:33,217 - INFO - Episode 1606/98900: Winner=2, Reward=6.70, EPSILON=0.986, (W=232,D=1,L=0)
2025-01-16 05:05:33,341 - INFO - Episode 1607/98900: Winner=2, Reward=9.10, EPSILON=0.986, (W=232,D=1,L=0)
2025-01-16 05:05:33,388 - DEBUG - Q-vals = [0.0939975  0.10173442 0.10746382 0.07191194 0.31941962 0.21197243
 0.0935002 ], best_act=4, best_val=0.319
2025-01-16 05:05:33,388 - DEBUG - Low Q-value (0.319), using MCTS.
2025-01-16 05:05:33,388 - INFO - Running MCTS with 74 simulations using 6 processes.
2025-01-16 05:05:36,138 - DEBUG - Aggregated action counts: {0: 4, 2: 1, 3: 1, 1: 1}
2025-01-16 05:05:36,138 - DEBUG - Chose best action 0
2025-01-16 05:05:36,294 - INFO - Episode 1608/98900: Winner=2, Reward=-3.55, EPSILON=0.986, (W=232,D=1,L=0)
2025-01-16 05:05:36,403 - INFO - Episode 1609/98900: Winner=2, Reward=-9.30, EPSILON=0.986, (W=233,D=1,L=0)
2025-01-16 05:05:36,747 - INFO - Episode 1610/98900: Winner=2, Reward=-21.15, EPSILON=0.986, (W=234,D=1,L=0)
2025-01-16 05:05:36,856 - INFO - Episode 1611/98900: Winner=2, Reward=-10.35, EPSILON=0.986, (W=235,D=1,L=0)
2025-01-16 05:05:37,122 - INFO - Episode 1612/98900: Winner=2, Reward=-14.70, EPSILON=0.986, (W=236,D=1,L=0)
2025-01-16 05:05:37,309 - INFO - Episode 1613/98900: Winner=2, Reward=-9.20, EPSILON=0.986, (W=237,D=1,L=0)
2025-01-16 05:05:37,466 - INFO - Episode 1614/98900: Winner=2, Reward=-12.95, EPSILON=0.986, (W=238,D=1,L=0)
2025-01-16 05:05:37,528 - DEBUG - Q-vals = [0.26386648 0.13884477 0.13180673 0.11045502 0.19319232 0.05839716
 0.10343751], best_act=0, best_val=0.264
2025-01-16 05:05:37,528 - DEBUG - Low Q-value (0.264), using MCTS.
2025-01-16 05:05:37,528 - INFO - Running MCTS with 74 simulations using 6 processes.
2025-01-16 05:05:40,199 - DEBUG - Aggregated action counts: {3: 2, 1: 1, 0: 4}
2025-01-16 05:05:40,199 - DEBUG - Chose best action 0
2025-01-16 05:05:40,340 - INFO - Episode 1615/98900: Winner=2, Reward=-12.15, EPSILON=0.986, (W=239,D=1,L=0)
2025-01-16 05:05:40,699 - INFO - Episode 1616/98900: Winner=2, Reward=-37.35, EPSILON=0.986, (W=239,D=1,L=0)
2025-01-16 05:05:40,871 - INFO - Episode 1617/98900: Winner=2, Reward=2.85, EPSILON=0.986, (W=239,D=1,L=0)
2025-01-16 05:05:40,887 - DEBUG - Q-vals = [0.44758618 0.08643571 0.01128987 0.05380326 0.01430603 0.02528522
 0.36129382], best_act=0, best_val=0.448
2025-01-16 05:05:40,887 - DEBUG - Low Q-value (0.448), using MCTS.
2025-01-16 05:05:40,887 - INFO - Running MCTS with 74 simulations using 6 processes.
2025-01-16 05:05:43,808 - DEBUG - Aggregated action counts: {1: 1, 6: 1, 5: 1, 2: 2, 4: 1, 0: 1}
2025-01-16 05:05:43,808 - DEBUG - Chose best action 2
2025-01-16 05:05:43,995 - INFO - Episode 1618/98900: Winner=2, Reward=12.50, EPSILON=0.986, (W=239,D=1,L=0)
2025-01-16 05:05:44,167 - DEBUG - Q-vals = [0.23616955 0.10296515 0.13600764 0.19756317 0.08171712 0.11209089
 0.13348648], best_act=0, best_val=0.236
2025-01-16 05:05:44,167 - DEBUG - Low Q-value (0.236), using MCTS.
2025-01-16 05:05:44,167 - INFO - Episode 1619/98900: Winner=2, Reward=17.05, EPSILON=0.986, (W=240,D=1,L=0)
2025-01-16 05:05:44,370 - DEBUG - Q-vals = [0.11654025 0.13104211 0.0400821  0.03675923 0.31737757 0.18706651
 0.1711322 ], best_act=5, best_val=0.187
2025-01-16 05:05:44,370 - DEBUG - Low Q-value (0.187), using MCTS.
2025-01-16 05:05:44,370 - INFO - Episode 1620/98900: Winner=2, Reward=-15.65, EPSILON=0.986, (W=241,D=1,L=0)
2025-01-16 05:05:44,636 - INFO - Episode 1621/98900: Winner=2, Reward=5.30, EPSILON=0.986, (W=241,D=1,L=0)
2025-01-16 05:05:44,808 - INFO - Episode 1622/98900: Winner=2, Reward=4.15, EPSILON=0.986, (W=241,D=1,L=0)
2025-01-16 05:05:45,120 - INFO - Episode 1623/98900: Winner=2, Reward=-38.95, EPSILON=0.985, (W=241,D=1,L=0)
2025-01-16 05:05:45,386 - INFO - Episode 1624/98900: Winner=2, Reward=-10.60, EPSILON=0.985, (W=241,D=1,L=0)
2025-01-16 05:05:45,792 - INFO - Episode 1625/98900: Winner=2, Reward=-67.35, EPSILON=0.985, (W=242,D=1,L=0)
2025-01-16 05:05:46,120 - INFO - Episode 1626/98900: Winner=2, Reward=-7.10, EPSILON=0.985, (W=242,D=1,L=0)
2025-01-16 05:05:46,292 - INFO - Episode 1627/98900: Winner=2, Reward=22.45, EPSILON=0.985, (W=242,D=1,L=0)
2025-01-16 05:05:46,542 - INFO - Episode 1628/98900: Winner=2, Reward=-38.95, EPSILON=0.985, (W=243,D=1,L=0)
2025-01-16 05:05:46,557 - DEBUG - Q-vals = [0.2813556  0.06672653 0.08217732 0.05700506 0.02182923 0.05510241
 0.4358039 ], best_act=6, best_val=0.436
2025-01-16 05:05:46,557 - DEBUG - Low Q-value (0.436), using MCTS.
2025-01-16 05:05:46,557 - INFO - Running MCTS with 75 simulations using 6 processes.
2025-01-16 05:05:49,385 - DEBUG - Aggregated action counts: {0: 4, 3: 2, 1: 1}
2025-01-16 05:05:49,385 - DEBUG - Chose best action 0
2025-01-16 05:05:49,729 - INFO - Episode 1629/98900: Winner=2, Reward=-35.55, EPSILON=0.985, (W=243,D=1,L=0)
2025-01-16 05:05:50,010 - INFO - Episode 1630/98900: Winner=2, Reward=-18.75, EPSILON=0.985, (W=244,D=1,L=0)
2025-01-16 05:05:50,260 - INFO - Episode 1631/98900: Winner=2, Reward=-24.10, EPSILON=0.985, (W=245,D=1,L=0)
2025-01-16 05:05:50,525 - INFO - Episode 1632/98900: Winner=2, Reward=-31.60, EPSILON=0.985, (W=246,D=1,L=0)
2025-01-16 05:05:50,713 - INFO - Episode 1633/98900: Winner=2, Reward=-18.25, EPSILON=0.985, (W=246,D=1,L=0)
2025-01-16 05:05:50,916 - INFO - Episode 1634/98900: Winner=2, Reward=-8.20, EPSILON=0.985, (W=247,D=1,L=0)
2025-01-16 05:05:50,931 - DEBUG - Q-vals = [0.40545943 0.07378914 0.00454326 0.09086002 0.004589   0.01166456
 0.40909454], best_act=6, best_val=0.409
2025-01-16 05:05:50,931 - DEBUG - Low Q-value (0.409), using MCTS.
2025-01-16 05:05:50,931 - INFO - Running MCTS with 75 simulations using 6 processes.
2025-01-16 05:05:53,541 - DEBUG - Aggregated action counts: {1: 2, 6: 1, 0: 2, 2: 2}
2025-01-16 05:05:53,541 - DEBUG - Chose best action 1
2025-01-16 05:05:53,900 - INFO - Episode 1635/98900: Winner=2, Reward=-34.75, EPSILON=0.985, (W=248,D=1,L=0)
2025-01-16 05:05:54,103 - INFO - Episode 1636/98900: Winner=2, Reward=-25.35, EPSILON=0.985, (W=249,D=1,L=0)
2025-01-16 05:05:54,353 - INFO - Episode 1637/98900: Winner=2, Reward=-0.10, EPSILON=0.985, (W=249,D=1,L=0)
2025-01-16 05:05:54,603 - INFO - Episode 1638/98900: Winner=2, Reward=-25.95, EPSILON=0.985, (W=250,D=1,L=0)
2025-01-16 05:05:54,806 - INFO - Episode 1639/98900: Winner=2, Reward=-0.80, EPSILON=0.985, (W=250,D=1,L=0)
2025-01-16 05:05:55,009 - INFO - Episode 1640/98900: Winner=2, Reward=-10.05, EPSILON=0.985, (W=251,D=1,L=0)
2025-01-16 05:05:55,243 - INFO - Episode 1641/98900: Winner=2, Reward=-3.65, EPSILON=0.985, (W=251,D=1,L=0)
2025-01-16 05:05:55,493 - DEBUG - Q-vals = [0.17678528 0.06005514 0.14162785 0.06395971 0.25318083 0.1279529
 0.17643832], best_act=4, best_val=0.253
2025-01-16 05:05:55,493 - DEBUG - Low Q-value (0.253), using MCTS.
2025-01-16 05:05:55,493 - INFO - Running MCTS with 75 simulations using 6 processes.
2025-01-16 05:05:58,149 - DEBUG - Aggregated action counts: {0: 2, 5: 2, 2: 1, 4: 1, 3: 1}
2025-01-16 05:05:58,149 - DEBUG - Chose best action 0
2025-01-16 05:05:58,274 - INFO - Episode 1642/98900: Winner=2, Reward=-59.20, EPSILON=0.985, (W=251,D=1,L=0)
2025-01-16 05:05:58,461 - INFO - Episode 1643/98900: Winner=2, Reward=-21.60, EPSILON=0.985, (W=252,D=1,L=0)
2025-01-16 05:05:58,743 - INFO - Episode 1644/98900: Winner=2, Reward=-12.65, EPSILON=0.985, (W=253,D=1,L=0)
2025-01-16 05:05:58,899 - INFO - Episode 1645/98900: Winner=2, Reward=10.50, EPSILON=0.985, (W=253,D=1,L=0)
2025-01-16 05:05:59,071 - INFO - Episode 1646/98900: Winner=2, Reward=-17.65, EPSILON=0.985, (W=254,D=1,L=0)
2025-01-16 05:05:59,352 - INFO - Episode 1647/98900: Winner=2, Reward=-20.65, EPSILON=0.985, (W=255,D=1,L=0)
2025-01-16 05:05:59,633 - INFO - Episode 1648/98900: Winner=2, Reward=-8.75, EPSILON=0.985, (W=255,D=1,L=0)
2025-01-16 05:05:59,867 - INFO - Episode 1649/98900: Winner=2, Reward=-20.40, EPSILON=0.985, (W=256,D=1,L=0)
2025-01-16 05:06:00,102 - INFO - Episode 1650/98900: Winner=2, Reward=22.85, EPSILON=0.985, (W=256,D=1,L=0)
2025-01-16 05:06:00,289 - INFO - Episode 1651/98900: Winner=2, Reward=25.15, EPSILON=0.985, (W=256,D=1,L=0)
2025-01-16 05:06:00,477 - INFO - Episode 1652/98900: Winner=2, Reward=-13.15, EPSILON=0.985, (W=257,D=1,L=0)
2025-01-16 05:06:00,555 - INFO - Episode 1653/98900: Winner=2, Reward=-0.55, EPSILON=0.985, (W=257,D=1,L=0)
2025-01-16 05:06:00,695 - INFO - Episode 1654/98900: Winner=2, Reward=-10.15, EPSILON=0.985, (W=258,D=1,L=0)
2025-01-16 05:06:01,023 - INFO - Episode 1655/98900: Winner=2, Reward=-69.00, EPSILON=0.985, (W=259,D=1,L=0)
2025-01-16 05:06:01,179 - INFO - Episode 1656/98900: Winner=2, Reward=17.90, EPSILON=0.985, (W=259,D=1,L=0)
2025-01-16 05:06:01,304 - INFO - Episode 1657/98900: Winner=2, Reward=8.60, EPSILON=0.985, (W=259,D=1,L=0)
2025-01-16 05:06:01,601 - INFO - Episode 1658/98900: Winner=2, Reward=-14.15, EPSILON=0.985, (W=260,D=1,L=0)
2025-01-16 05:06:01,664 - DEBUG - Q-vals = [0.09086452 0.08188117 0.12006753 0.10636803 0.16356365 0.33505756
 0.10219757], best_act=5, best_val=0.335
2025-01-16 05:06:01,664 - DEBUG - Low Q-value (0.335), using MCTS.
2025-01-16 05:06:01,664 - INFO - Running MCTS with 76 simulations using 6 processes.
2025-01-16 05:06:04,257 - DEBUG - Aggregated action counts: {0: 6, 1: 1}
2025-01-16 05:06:04,257 - DEBUG - Chose best action 0
2025-01-16 05:06:04,491 - INFO - Episode 1659/98900: Winner=2, Reward=-14.05, EPSILON=0.985, (W=261,D=1,L=0)
2025-01-16 05:06:04,616 - INFO - Episode 1660/98900: Winner=2, Reward=-8.95, EPSILON=0.985, (W=261,D=1,L=0)
2025-01-16 05:06:04,694 - INFO - Episode 1661/98900: Winner=2, Reward=8.15, EPSILON=0.985, (W=261,D=1,L=0)
2025-01-16 05:06:04,913 - INFO - Episode 1662/98900: Winner=2, Reward=-24.75, EPSILON=0.985, (W=262,D=1,L=0)
2025-01-16 05:06:05,194 - INFO - Episode 1663/98900: Winner=2, Reward=7.95, EPSILON=0.985, (W=262,D=1,L=0)
2025-01-16 05:06:05,382 - INFO - Episode 1664/98900: Winner=2, Reward=-8.05, EPSILON=0.985, (W=262,D=1,L=0)
2025-01-16 05:06:05,600 - INFO - Episode 1665/98900: Winner=2, Reward=-10.95, EPSILON=0.985, (W=262,D=1,L=0)
2025-01-16 05:06:05,850 - DEBUG - Q-vals = [0.09439197 0.04853788 0.06726079 0.22085239 0.13882187 0.19651206
 0.23362304], best_act=6, best_val=0.234
2025-01-16 05:06:05,850 - DEBUG - Low Q-value (0.234), using MCTS.
2025-01-16 05:06:05,850 - INFO - Episode 1666/98900: Winner=2, Reward=19.90, EPSILON=0.985, (W=263,D=1,L=0)
2025-01-16 05:06:06,178 - INFO - Episode 1667/98900: Winner=2, Reward=-29.95, EPSILON=0.985, (W=263,D=1,L=0)
2025-01-16 05:06:06,428 - INFO - Episode 1668/98900: Winner=2, Reward=1.85, EPSILON=0.985, (W=263,D=1,L=0)
2025-01-16 05:06:06,678 - INFO - Episode 1669/98900: Winner=2, Reward=-19.05, EPSILON=0.985, (W=264,D=1,L=0)
2025-01-16 05:06:06,928 - INFO - Episode 1670/98900: Winner=2, Reward=-42.55, EPSILON=0.985, (W=265,D=1,L=0)
2025-01-16 05:06:07,053 - INFO - Episode 1671/98900: Winner=2, Reward=-10.85, EPSILON=0.985, (W=266,D=1,L=0)
2025-01-16 05:06:07,334 - INFO - Episode 1672/98900: Winner=2, Reward=-17.25, EPSILON=0.985, (W=267,D=1,L=0)
2025-01-16 05:06:07,694 - INFO - Episode 1673/98900: Winner=2, Reward=-38.55, EPSILON=0.985, (W=267,D=1,L=0)
2025-01-16 05:06:07,975 - INFO - Episode 1674/98900: Winner=2, Reward=-38.00, EPSILON=0.985, (W=267,D=1,L=0)
2025-01-16 05:06:08,100 - INFO - Episode 1675/98900: Winner=2, Reward=15.75, EPSILON=0.985, (W=267,D=1,L=0)
2025-01-16 05:06:08,225 - DEBUG - Q-vals = [0.16920553 0.19128266 0.06249595 0.2552026  0.04782568 0.14635485
 0.12763274], best_act=3, best_val=0.255
2025-01-16 05:06:08,225 - DEBUG - Low Q-value (0.255), using MCTS.
2025-01-16 05:06:08,225 - INFO - Running MCTS with 77 simulations using 6 processes.
2025-01-16 05:06:10,896 - DEBUG - Aggregated action counts: {0: 4, 2: 2, 4: 1}
2025-01-16 05:06:10,896 - DEBUG - Chose best action 0
2025-01-16 05:06:11,068 - INFO - Episode 1676/98900: Winner=2, Reward=-18.10, EPSILON=0.985, (W=267,D=1,L=0)
2025-01-16 05:06:11,302 - INFO - Episode 1677/98900: Winner=2, Reward=6.75, EPSILON=0.985, (W=267,D=1,L=0)
2025-01-16 05:06:11,412 - INFO - Episode 1678/98900: Winner=2, Reward=-7.90, EPSILON=0.985, (W=268,D=1,L=0)
2025-01-16 05:06:11,568 - INFO - Episode 1679/98900: Winner=2, Reward=-9.85, EPSILON=0.985, (W=269,D=1,L=0)
2025-01-16 05:06:11,755 - DEBUG - Q-vals = [0.17400135 0.19745548 0.0611597  0.10595006 0.1362639  0.14332043
 0.18184909], best_act=1, best_val=0.197
2025-01-16 05:06:11,755 - DEBUG - Low Q-value (0.197), using MCTS.
2025-01-16 05:06:11,755 - INFO - Running MCTS with 77 simulations using 6 processes.
2025-01-16 05:06:14,474 - DEBUG - Aggregated action counts: {5: 2, 2: 1, 0: 3, 1: 1}
2025-01-16 05:06:14,474 - DEBUG - Chose best action 0
2025-01-16 05:06:14,505 - INFO - Episode 1680/98900: Winner=2, Reward=2.55, EPSILON=0.985, (W=269,D=1,L=0)
2025-01-16 05:06:14,536 - DEBUG - Q-vals = [0.22575904 0.08152611 0.12622328 0.14162207 0.10229544 0.16701186
 0.1555623 ], best_act=0, best_val=0.226
2025-01-16 05:06:14,536 - DEBUG - Low Q-value (0.226), using MCTS.
2025-01-16 05:06:14,536 - INFO - Running MCTS with 77 simulations using 6 processes.
2025-01-16 05:06:17,458 - DEBUG - Aggregated action counts: {2: 3, 5: 1, 4: 1, 3: 1, 0: 1}
2025-01-16 05:06:17,458 - DEBUG - Chose best action 2
2025-01-16 05:06:17,599 - INFO - Episode 1681/98900: Winner=2, Reward=-6.55, EPSILON=0.985, (W=269,D=1,L=0)
2025-01-16 05:06:17,692 - INFO - Episode 1682/98900: Winner=2, Reward=16.10, EPSILON=0.985, (W=269,D=1,L=0)
2025-01-16 05:06:17,911 - INFO - Episode 1683/98900: Winner=2, Reward=3.45, EPSILON=0.985, (W=269,D=1,L=0)
2025-01-16 05:06:18,036 - INFO - Episode 1684/98900: Winner=2, Reward=-10.05, EPSILON=0.985, (W=270,D=1,L=0)
2025-01-16 05:06:18,317 - INFO - Episode 1685/98900: Winner=2, Reward=-22.35, EPSILON=0.985, (W=270,D=1,L=0)
2025-01-16 05:06:18,536 - INFO - Episode 1686/98900: Winner=2, Reward=3.95, EPSILON=0.985, (W=271,D=1,L=0)
2025-01-16 05:06:18,724 - INFO - Episode 1687/98900: Winner=2, Reward=-19.80, EPSILON=0.985, (W=272,D=1,L=0)
2025-01-16 05:06:18,786 - DEBUG - Q-vals = [0.11679188 0.07238672 0.1361098  0.22054967 0.09400923 0.2528404
 0.10731231], best_act=5, best_val=0.253
2025-01-16 05:06:18,786 - DEBUG - Low Q-value (0.253), using MCTS.
2025-01-16 05:06:18,786 - INFO - Running MCTS with 77 simulations using 6 processes.
2025-01-16 05:06:21,895 - DEBUG - Aggregated action counts: {2: 2, 0: 4, 1: 1}
2025-01-16 05:06:21,895 - DEBUG - Chose best action 0
2025-01-16 05:06:22,129 - INFO - Episode 1688/98900: Winner=2, Reward=-9.35, EPSILON=0.985, (W=272,D=1,L=0)
2025-01-16 05:06:22,457 - INFO - Episode 1689/98900: Winner=2, Reward=-45.55, EPSILON=0.985, (W=273,D=1,L=0)
2025-01-16 05:06:22,816 - INFO - Episode 1690/98900: Winner=2, Reward=-53.35, EPSILON=0.985, (W=274,D=1,L=0)
2025-01-16 05:06:23,051 - INFO - Episode 1691/98900: Winner=2, Reward=-1.90, EPSILON=0.985, (W=274,D=1,L=0)
2025-01-16 05:06:23,270 - INFO - Episode 1692/98900: Winner=2, Reward=-24.65, EPSILON=0.985, (W=275,D=1,L=0)
2025-01-16 05:06:23,613 - INFO - Episode 1693/98900: Winner=2, Reward=-48.90, EPSILON=0.985, (W=276,D=1,L=0)
2025-01-16 05:06:23,785 - INFO - Episode 1694/98900: Winner=2, Reward=-10.80, EPSILON=0.985, (W=277,D=1,L=0)
2025-01-16 05:06:24,144 - INFO - Episode 1695/98900: Winner=2, Reward=-29.45, EPSILON=0.985, (W=277,D=1,L=0)
2025-01-16 05:06:24,301 - INFO - Episode 1696/98900: Winner=2, Reward=10.60, EPSILON=0.985, (W=277,D=1,L=0)
2025-01-16 05:06:24,582 - INFO - Episode 1697/98900: Winner=2, Reward=-10.15, EPSILON=0.985, (W=278,D=1,L=0)
2025-01-16 05:06:24,847 - INFO - Episode 1698/98900: Winner=2, Reward=-7.75, EPSILON=0.985, (W=278,D=1,L=0)
2025-01-16 05:06:25,191 - INFO - Episode 1699/98900: Winner=2, Reward=-39.45, EPSILON=0.985, (W=278,D=1,L=0)
2025-01-16 05:06:25,457 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1700.
2025-01-16 05:06:25,457 - INFO - Models saved at episode 1700
2025-01-16 05:06:25,457 - INFO - Target networks updated
2025-01-16 05:06:25,519 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1700.
2025-01-16 05:06:25,519 - INFO - Episode 1700/98900: Winner=2, Reward=8.55, EPSILON=0.985, (W=278,D=1,L=0)
2025-01-16 05:06:25,910 - INFO - Episode 1701/98900: Winner=2, Reward=-53.15, EPSILON=0.985, (W=279,D=1,L=0)
2025-01-16 05:06:26,003 - INFO - Episode 1702/98900: Winner=2, Reward=5.55, EPSILON=0.985, (W=279,D=1,L=0)
2025-01-16 05:06:26,191 - INFO - Episode 1703/98900: Winner=2, Reward=1.75, EPSILON=0.985, (W=279,D=1,L=0)
2025-01-16 05:06:26,456 - INFO - Episode 1704/98900: Winner=2, Reward=-6.95, EPSILON=0.985, (W=279,D=1,L=0)
2025-01-16 05:06:26,612 - INFO - Episode 1705/98900: Winner=2, Reward=-9.40, EPSILON=0.985, (W=280,D=1,L=0)
2025-01-16 05:06:26,816 - INFO - Episode 1706/98900: Winner=2, Reward=-2.25, EPSILON=0.985, (W=280,D=1,L=0)
2025-01-16 05:06:27,034 - INFO - Episode 1707/98900: Winner=2, Reward=-9.50, EPSILON=0.985, (W=280,D=1,L=0)
2025-01-16 05:06:27,159 - INFO - Episode 1708/98900: Winner=2, Reward=12.55, EPSILON=0.985, (W=280,D=1,L=0)
2025-01-16 05:06:27,441 - INFO - Episode 1709/98900: Winner=2, Reward=-8.70, EPSILON=0.985, (W=281,D=1,L=0)
2025-01-16 05:06:27,566 - INFO - Episode 1710/98900: Winner=2, Reward=2.20, EPSILON=0.985, (W=281,D=1,L=0)
2025-01-16 05:06:27,691 - INFO - Episode 1711/98900: Winner=2, Reward=-11.40, EPSILON=0.985, (W=282,D=1,L=0)
2025-01-16 05:06:27,753 - DEBUG - Q-vals = [0.32382992 0.07205292 0.17214534 0.06807149 0.09110784 0.11728147
 0.155511  ], best_act=0, best_val=0.324
2025-01-16 05:06:27,753 - DEBUG - Low Q-value (0.324), using MCTS.
2025-01-16 05:06:27,753 - INFO - Running MCTS with 78 simulations using 6 processes.
2025-01-16 05:06:30,565 - DEBUG - Aggregated action counts: {2: 2, 4: 1, 1: 1, 0: 2}
2025-01-16 05:06:30,565 - DEBUG - Chose best action 2
2025-01-16 05:06:30,752 - DEBUG - Q-vals = [0.11995375 0.00870975 0.27624944 0.02025444 0.1503404  0.10037797
 0.3241143 ], best_act=6, best_val=0.324
2025-01-16 05:06:30,752 - DEBUG - Low Q-value (0.324), using MCTS.
2025-01-16 05:06:30,752 - INFO - Running MCTS with 78 simulations using 6 processes.
2025-01-16 05:06:33,721 - DEBUG - Aggregated action counts: {0: 4, 3: 1, 4: 1}
2025-01-16 05:06:33,721 - DEBUG - Chose best action 0
2025-01-16 05:06:33,783 - INFO - Episode 1712/98900: Winner=2, Reward=-17.95, EPSILON=0.985, (W=283,D=1,L=0)
2025-01-16 05:06:34,018 - INFO - Episode 1713/98900: Winner=2, Reward=-12.70, EPSILON=0.985, (W=284,D=1,L=0)
2025-01-16 05:06:34,189 - INFO - Episode 1714/98900: Winner=2, Reward=7.70, EPSILON=0.985, (W=284,D=1,L=0)
2025-01-16 05:06:34,314 - INFO - Episode 1715/98900: Winner=2, Reward=-10.00, EPSILON=0.985, (W=285,D=1,L=0)
2025-01-16 05:06:34,564 - INFO - Episode 1716/98900: Winner=2, Reward=-0.85, EPSILON=0.985, (W=285,D=1,L=0)
2025-01-16 05:06:34,736 - INFO - Episode 1717/98900: Winner=2, Reward=-6.45, EPSILON=0.985, (W=286,D=1,L=0)
2025-01-16 05:06:34,966 - INFO - Episode 1718/98900: Winner=2, Reward=-6.90, EPSILON=0.985, (W=287,D=1,L=0)
2025-01-16 05:06:35,143 - INFO - Episode 1719/98900: Winner=2, Reward=-4.75, EPSILON=0.985, (W=287,D=1,L=0)
2025-01-16 05:06:35,472 - INFO - Episode 1720/98900: Winner=2, Reward=-43.00, EPSILON=0.985, (W=288,D=1,L=0)
2025-01-16 05:06:35,677 - INFO - Episode 1721/98900: Winner=2, Reward=5.35, EPSILON=0.985, (W=288,D=1,L=0)
2025-01-16 05:06:35,918 - INFO - Episode 1722/98900: Winner=2, Reward=17.10, EPSILON=0.985, (W=288,D=1,L=0)
2025-01-16 05:06:36,264 - INFO - Episode 1723/98900: Winner=2, Reward=-49.30, EPSILON=0.985, (W=289,D=1,L=0)
2025-01-16 05:06:36,503 - INFO - Episode 1724/98900: Winner=2, Reward=-18.35, EPSILON=0.985, (W=289,D=1,L=0)
2025-01-16 05:06:36,638 - INFO - Episode 1725/98900: Winner=2, Reward=-9.25, EPSILON=0.985, (W=290,D=1,L=0)
2025-01-16 05:06:37,117 - INFO - Episode 1726/98900: Winner=2, Reward=-90.70, EPSILON=0.985, (W=291,D=1,L=0)
2025-01-16 05:06:37,585 - INFO - Episode 1727/98900: Winner=2, Reward=-118.15, EPSILON=0.985, (W=292,D=1,L=0)
2025-01-16 05:06:37,939 - INFO - Episode 1728/98900: Winner=2, Reward=-46.15, EPSILON=0.985, (W=292,D=1,L=0)
2025-01-16 05:06:37,985 - DEBUG - Q-vals = [0.13167274 0.10720199 0.13427247 0.10636561 0.27512115 0.16797069
 0.07739532], best_act=4, best_val=0.275
2025-01-16 05:06:37,985 - DEBUG - Low Q-value (0.275), using MCTS.
2025-01-16 05:06:37,985 - INFO - Running MCTS with 79 simulations using 6 processes.
2025-01-16 05:06:40,674 - DEBUG - Aggregated action counts: {3: 1, 2: 1, 1: 4, 5: 1}
2025-01-16 05:06:40,674 - DEBUG - Chose best action 1
2025-01-16 05:06:40,883 - INFO - Episode 1729/98900: Winner=2, Reward=5.05, EPSILON=0.985, (W=292,D=1,L=0)
2025-01-16 05:06:41,019 - INFO - Episode 1730/98900: Winner=2, Reward=5.40, EPSILON=0.985, (W=292,D=1,L=0)
2025-01-16 05:06:41,056 - DEBUG - Q-vals = [0.13574234 0.10448427 0.12624909 0.14173512 0.153324   0.25952715
 0.07893807], best_act=5, best_val=0.260
2025-01-16 05:06:41,056 - DEBUG - Low Q-value (0.260), using MCTS.
2025-01-16 05:06:41,057 - INFO - Running MCTS with 79 simulations using 6 processes.
2025-01-16 05:06:43,700 - DEBUG - Aggregated action counts: {3: 2, 2: 2, 6: 1, 1: 1, 0: 1}
2025-01-16 05:06:43,700 - DEBUG - Chose best action 3
2025-01-16 05:06:43,913 - DEBUG - Q-vals = [0.19377163 0.05758913 0.10787525 0.10756233 0.34716615 0.03999192
 0.14604361], best_act=4, best_val=0.347
2025-01-16 05:06:43,913 - DEBUG - Low Q-value (0.347), using MCTS.
2025-01-16 05:06:43,925 - INFO - Episode 1731/98900: Winner=2, Reward=-15.00, EPSILON=0.985, (W=293,D=1,L=0)
2025-01-16 05:06:43,975 - DEBUG - Q-vals = [0.15616703 0.11302064 0.13467441 0.23125741 0.1520139  0.16855916
 0.04430743], best_act=3, best_val=0.231
2025-01-16 05:06:43,975 - DEBUG - Low Q-value (0.231), using MCTS.
2025-01-16 05:06:43,975 - INFO - Running MCTS with 79 simulations using 6 processes.
2025-01-16 05:06:46,643 - DEBUG - Aggregated action counts: {0: 2, 2: 3, 1: 1, 6: 1}
2025-01-16 05:06:46,643 - DEBUG - Chose best action 2
2025-01-16 05:06:46,876 - INFO - Episode 1732/98900: Winner=2, Reward=-46.80, EPSILON=0.985, (W=294,D=1,L=0)
2025-01-16 05:06:47,140 - INFO - Episode 1733/98900: Winner=2, Reward=-49.85, EPSILON=0.985, (W=295,D=1,L=0)
2025-01-16 05:06:47,352 - INFO - Episode 1734/98900: Winner=2, Reward=-8.15, EPSILON=0.985, (W=296,D=1,L=0)
2025-01-16 05:06:47,538 - INFO - Episode 1735/98900: Winner=2, Reward=16.50, EPSILON=0.985, (W=296,D=1,L=0)
2025-01-16 05:06:47,821 - INFO - Episode 1736/98900: Winner=2, Reward=8.95, EPSILON=0.984, (W=296,D=1,L=0)
2025-01-16 05:06:48,077 - INFO - Episode 1737/98900: Winner=2, Reward=-35.95, EPSILON=0.984, (W=296,D=1,L=0)
2025-01-16 05:06:48,377 - INFO - Episode 1738/98900: Winner=2, Reward=1.80, EPSILON=0.984, (W=297,D=1,L=0)
2025-01-16 05:06:48,548 - INFO - Episode 1739/98900: Winner=2, Reward=-0.55, EPSILON=0.984, (W=297,D=1,L=0)
2025-01-16 05:06:48,691 - INFO - Episode 1740/98900: Winner=2, Reward=-3.85, EPSILON=0.984, (W=297,D=1,L=0)
2025-01-16 05:06:48,921 - INFO - Episode 1741/98900: Winner=2, Reward=5.70, EPSILON=0.984, (W=297,D=1,L=0)
2025-01-16 05:06:49,267 - INFO - Episode 1742/98900: Winner=2, Reward=-36.80, EPSILON=0.984, (W=298,D=1,L=0)
2025-01-16 05:06:49,521 - INFO - Episode 1743/98900: Winner=2, Reward=-25.45, EPSILON=0.984, (W=298,D=1,L=0)
2025-01-16 05:06:49,723 - INFO - Episode 1744/98900: Winner=2, Reward=-16.20, EPSILON=0.984, (W=299,D=1,L=0)
2025-01-16 05:06:49,969 - INFO - Episode 1745/98900: Winner=2, Reward=-19.20, EPSILON=0.984, (W=300,D=1,L=0)
2025-01-16 05:06:50,152 - INFO - Episode 1746/98900: Winner=2, Reward=-17.05, EPSILON=0.984, (W=301,D=1,L=0)
2025-01-16 05:06:50,261 - DEBUG - Q-vals = [0.5347108  0.10950174 0.05337856 0.01075347 0.00922423 0.07096548
 0.21146564], best_act=0, best_val=0.535
2025-01-16 05:06:50,261 - DEBUG - Low Q-value (0.535), using MCTS.
2025-01-16 05:06:50,277 - INFO - Episode 1747/98900: Winner=2, Reward=-10.55, EPSILON=0.984, (W=302,D=1,L=0)
2025-01-16 05:06:50,549 - INFO - Episode 1748/98900: Winner=2, Reward=8.75, EPSILON=0.984, (W=302,D=1,L=0)
2025-01-16 05:06:50,788 - INFO - Episode 1749/98900: Winner=2, Reward=0.90, EPSILON=0.984, (W=302,D=1,L=0)
2025-01-16 05:06:51,088 - INFO - Episode 1750/98900: Winner=2, Reward=19.25, EPSILON=0.984, (W=302,D=1,L=0)
2025-01-16 05:06:51,269 - INFO - Episode 1751/98900: Winner=2, Reward=-10.35, EPSILON=0.984, (W=303,D=1,L=0)
2025-01-16 05:06:51,423 - DEBUG - Q-vals = [7.6183826e-01 9.2591517e-02 6.9853156e-03 6.7870272e-04 8.3960434e-03
 4.1603362e-03 1.2534994e-01], best_act=0, best_val=0.762
2025-01-16 05:06:51,423 - DEBUG - Low Q-value (0.762), using MCTS.
2025-01-16 05:06:51,439 - INFO - Episode 1752/98900: Winner=2, Reward=-5.60, EPSILON=0.984, (W=304,D=1,L=0)
2025-01-16 05:06:51,626 - INFO - Episode 1753/98900: Winner=2, Reward=5.00, EPSILON=0.984, (W=304,D=1,L=0)
2025-01-16 05:06:51,751 - DEBUG - Q-vals = [0.3673947  0.15834275 0.1656185  0.05080236 0.08812278 0.0418196
 0.12789932], best_act=0, best_val=0.367
2025-01-16 05:06:51,751 - DEBUG - Low Q-value (0.367), using MCTS.
2025-01-16 05:06:51,751 - INFO - Running MCTS with 80 simulations using 6 processes.
2025-01-16 05:06:54,408 - DEBUG - Aggregated action counts: {0: 5, 1: 2}
2025-01-16 05:06:54,408 - DEBUG - Chose best action 0
2025-01-16 05:06:54,470 - INFO - Episode 1754/98900: Winner=2, Reward=-25.40, EPSILON=0.984, (W=305,D=1,L=0)
2025-01-16 05:06:54,720 - INFO - Episode 1755/98900: Winner=2, Reward=12.45, EPSILON=0.984, (W=305,D=1,L=0)
2025-01-16 05:06:54,814 - DEBUG - Q-vals = [0.09065565 0.0478666  0.23582101 0.137012   0.12309781 0.2595491
 0.1059978 ], best_act=5, best_val=0.260
2025-01-16 05:06:54,814 - DEBUG - Low Q-value (0.260), using MCTS.
2025-01-16 05:06:54,814 - INFO - Running MCTS with 80 simulations using 6 processes.
2025-01-16 05:06:57,599 - DEBUG - Aggregated action counts: {1: 2, 6: 2, 3: 1, 5: 1, 0: 1}
2025-01-16 05:06:57,599 - DEBUG - Chose best action 1
2025-01-16 05:06:57,622 - DEBUG - Q-vals = [0.12036985 0.08630215 0.11858971 0.15609266 0.18403913 0.17658976
 0.15801677], best_act=4, best_val=0.184
2025-01-16 05:06:57,622 - DEBUG - Low Q-value (0.184), using MCTS.
2025-01-16 05:06:57,623 - INFO - Running MCTS with 80 simulations using 6 processes.
2025-01-16 05:07:00,471 - DEBUG - Aggregated action counts: {0: 2, 2: 1, 1: 1, 3: 2, 4: 1}
2025-01-16 05:07:00,471 - DEBUG - Chose best action 0
2025-01-16 05:07:00,643 - INFO - Episode 1756/98900: Winner=2, Reward=-49.15, EPSILON=0.984, (W=306,D=1,L=0)
2025-01-16 05:07:00,768 - INFO - Episode 1757/98900: Winner=2, Reward=-5.20, EPSILON=0.984, (W=306,D=1,L=0)
2025-01-16 05:07:01,002 - INFO - Episode 1758/98900: Winner=2, Reward=-5.85, EPSILON=0.984, (W=307,D=1,L=0)
2025-01-16 05:07:01,112 - DEBUG - Q-vals = [0.11007759 0.23908006 0.01292438 0.26726013 0.05906462 0.21519935
 0.09639387], best_act=3, best_val=0.267
2025-01-16 05:07:01,112 - DEBUG - Low Q-value (0.267), using MCTS.
2025-01-16 05:07:01,112 - INFO - Running MCTS with 80 simulations using 6 processes.
2025-01-16 05:07:03,846 - DEBUG - Aggregated action counts: {3: 2, 4: 1, 2: 3, 0: 1}
2025-01-16 05:07:03,846 - DEBUG - Chose best action 2
2025-01-16 05:07:04,184 - INFO - Episode 1759/98900: Winner=2, Reward=-6.05, EPSILON=0.984, (W=308,D=1,L=0)
2025-01-16 05:07:04,434 - INFO - Episode 1760/98900: Winner=2, Reward=-9.60, EPSILON=0.984, (W=309,D=1,L=0)
2025-01-16 05:07:04,715 - INFO - Episode 1761/98900: Winner=2, Reward=1.45, EPSILON=0.984, (W=309,D=1,L=0)
2025-01-16 05:07:05,043 - INFO - Episode 1762/98900: Winner=2, Reward=-8.65, EPSILON=0.984, (W=309,D=1,L=0)
2025-01-16 05:07:05,371 - INFO - Episode 1763/98900: Winner=2, Reward=-31.75, EPSILON=0.984, (W=310,D=1,L=0)
2025-01-16 05:07:05,481 - INFO - Episode 1764/98900: Winner=2, Reward=-4.35, EPSILON=0.984, (W=310,D=1,L=0)
2025-01-16 05:07:05,746 - INFO - Episode 1765/98900: Winner=2, Reward=-9.95, EPSILON=0.984, (W=310,D=1,L=0)
2025-01-16 05:07:05,871 - DEBUG - Q-vals = [0.09789567 0.0655834  0.13468517 0.2160476  0.17691736 0.24181701
 0.06705378], best_act=5, best_val=0.242
2025-01-16 05:07:05,871 - DEBUG - Low Q-value (0.242), using MCTS.
2025-01-16 05:07:05,871 - INFO - Running MCTS with 80 simulations using 6 processes.
2025-01-16 05:07:08,543 - DEBUG - Aggregated action counts: {0: 3, 2: 1, 3: 1, 5: 1, 1: 1}
2025-01-16 05:07:08,543 - DEBUG - Chose best action 0
2025-01-16 05:07:08,606 - INFO - Episode 1766/98900: Winner=2, Reward=3.85, EPSILON=0.984, (W=310,D=1,L=0)
2025-01-16 05:07:08,887 - INFO - Episode 1767/98900: Winner=2, Reward=-21.20, EPSILON=0.984, (W=311,D=1,L=0)
2025-01-16 05:07:09,012 - INFO - Episode 1768/98900: Winner=2, Reward=-9.35, EPSILON=0.984, (W=312,D=1,L=0)
2025-01-16 05:07:09,309 - INFO - Episode 1769/98900: Winner=2, Reward=-9.75, EPSILON=0.984, (W=313,D=1,L=0)
2025-01-16 05:07:09,547 - INFO - Episode 1770/98900: Winner=2, Reward=-10.25, EPSILON=0.984, (W=313,D=1,L=0)
2025-01-16 05:07:09,797 - INFO - Episode 1771/98900: Winner=2, Reward=-18.75, EPSILON=0.984, (W=314,D=1,L=0)
2025-01-16 05:07:09,865 - INFO - Episode 1772/98900: Winner=2, Reward=1.05, EPSILON=0.984, (W=314,D=1,L=0)
2025-01-16 05:07:10,067 - INFO - Episode 1773/98900: Winner=2, Reward=-22.85, EPSILON=0.984, (W=315,D=1,L=0)
2025-01-16 05:07:10,192 - INFO - Episode 1774/98900: Winner=2, Reward=-9.35, EPSILON=0.984, (W=316,D=1,L=0)
2025-01-16 05:07:10,551 - INFO - Episode 1775/98900: Winner=2, Reward=-80.85, EPSILON=0.984, (W=316,D=1,L=0)
2025-01-16 05:07:10,660 - DEBUG - Q-vals = [0.17708571 0.05607773 0.18629898 0.05455574 0.28396967 0.126518
 0.11549421], best_act=4, best_val=0.284
2025-01-16 05:07:10,660 - DEBUG - Low Q-value (0.284), using MCTS.
2025-01-16 05:07:10,660 - INFO - Running MCTS with 81 simulations using 6 processes.
2025-01-16 05:07:13,686 - DEBUG - Aggregated action counts: {1: 1, 2: 1, 5: 1, 4: 1, 0: 3}
2025-01-16 05:07:13,687 - DEBUG - Chose best action 0
2025-01-16 05:07:13,742 - INFO - Episode 1776/98900: Winner=2, Reward=-11.80, EPSILON=0.984, (W=317,D=1,L=0)
2025-01-16 05:07:13,973 - INFO - Episode 1777/98900: Winner=2, Reward=10.40, EPSILON=0.984, (W=317,D=1,L=0)
2025-01-16 05:07:14,189 - INFO - Episode 1778/98900: Winner=2, Reward=7.90, EPSILON=0.984, (W=317,D=1,L=0)
2025-01-16 05:07:14,422 - INFO - Episode 1779/98900: Winner=2, Reward=-24.65, EPSILON=0.984, (W=318,D=1,L=0)
2025-01-16 05:07:14,562 - INFO - Episode 1780/98900: Winner=2, Reward=1.25, EPSILON=0.984, (W=318,D=1,L=0)
2025-01-16 05:07:14,703 - DEBUG - Q-vals = [0.42751876 0.1291959  0.07208263 0.03636535 0.20519212 0.03004888
 0.0995963 ], best_act=0, best_val=0.428
2025-01-16 05:07:14,703 - DEBUG - Low Q-value (0.428), using MCTS.
2025-01-16 05:07:14,703 - INFO - Running MCTS with 81 simulations using 6 processes.
2025-01-16 05:07:17,482 - DEBUG - Aggregated action counts: {3: 3, 0: 3, 1: 1}
2025-01-16 05:07:17,482 - DEBUG - Chose best action 3
2025-01-16 05:07:17,575 - INFO - Episode 1781/98900: Winner=2, Reward=-30.45, EPSILON=0.984, (W=319,D=1,L=0)
2025-01-16 05:07:17,735 - INFO - Episode 1782/98900: Winner=2, Reward=-9.00, EPSILON=0.984, (W=320,D=1,L=0)
2025-01-16 05:07:17,953 - INFO - Episode 1783/98900: Winner=2, Reward=8.75, EPSILON=0.984, (W=320,D=1,L=0)
2025-01-16 05:07:18,094 - INFO - Episode 1784/98900: Winner=2, Reward=-12.50, EPSILON=0.984, (W=321,D=1,L=0)
2025-01-16 05:07:18,297 - INFO - Episode 1785/98900: Winner=2, Reward=-10.90, EPSILON=0.984, (W=322,D=1,L=0)
2025-01-16 05:07:18,547 - INFO - Episode 1786/98900: Winner=2, Reward=-1.85, EPSILON=0.984, (W=322,D=1,L=0)
2025-01-16 05:07:18,859 - INFO - Episode 1787/98900: Winner=2, Reward=-17.70, EPSILON=0.984, (W=322,D=1,L=0)
2025-01-16 05:07:19,025 - INFO - Episode 1788/98900: Winner=2, Reward=-15.30, EPSILON=0.984, (W=323,D=1,L=0)
2025-01-16 05:07:19,076 - INFO - Episode 1789/98900: Winner=2, Reward=0.00, EPSILON=0.984, (W=323,D=1,L=0)
2025-01-16 05:07:19,389 - DEBUG - Q-vals = [0.07385417 0.0343149  0.05373016 0.15076815 0.35581657 0.05890768
 0.2726083 ], best_act=4, best_val=0.356
2025-01-16 05:07:19,389 - DEBUG - Low Q-value (0.356), using MCTS.
2025-01-16 05:07:19,389 - INFO - Running MCTS with 81 simulations using 6 processes.
2025-01-16 05:07:22,139 - DEBUG - Aggregated action counts: {1: 3, 3: 4}
2025-01-16 05:07:22,139 - DEBUG - Chose best action 3
2025-01-16 05:07:22,295 - INFO - Episode 1790/98900: Winner=-1, Reward=-73.05, EPSILON=0.984, (W=323,D=2,L=0)
2025-01-16 05:07:22,592 - INFO - Episode 1791/98900: Winner=2, Reward=-28.60, EPSILON=0.984, (W=324,D=2,L=0)
2025-01-16 05:07:22,717 - INFO - Episode 1792/98900: Winner=2, Reward=8.20, EPSILON=0.984, (W=324,D=2,L=0)
2025-01-16 05:07:22,857 - INFO - Episode 1793/98900: Winner=2, Reward=-12.25, EPSILON=0.984, (W=325,D=2,L=0)
2025-01-16 05:07:23,138 - INFO - Episode 1794/98900: Winner=2, Reward=-27.15, EPSILON=0.984, (W=326,D=2,L=0)
2025-01-16 05:07:23,420 - INFO - Episode 1795/98900: Winner=2, Reward=-43.95, EPSILON=0.984, (W=327,D=2,L=0)
2025-01-16 05:07:23,576 - INFO - Episode 1796/98900: Winner=2, Reward=15.15, EPSILON=0.984, (W=327,D=2,L=0)
2025-01-16 05:07:23,873 - INFO - Episode 1797/98900: Winner=2, Reward=-41.35, EPSILON=0.984, (W=327,D=2,L=0)
2025-01-16 05:07:24,123 - INFO - Episode 1798/98900: Winner=2, Reward=-3.55, EPSILON=0.984, (W=327,D=2,L=0)
2025-01-16 05:07:24,185 - INFO - Episode 1799/98900: Winner=2, Reward=15.75, EPSILON=0.984, (W=327,D=2,L=0)
2025-01-16 05:07:24,435 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1800.
2025-01-16 05:07:24,435 - INFO - Models saved at episode 1800
2025-01-16 05:07:24,435 - INFO - Target networks updated
2025-01-16 05:07:24,497 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1800.
2025-01-16 05:07:24,497 - INFO - Episode 1800/98900: Winner=2, Reward=-22.30, EPSILON=0.984, (W=328,D=2,L=0)
2025-01-16 05:07:24,654 - INFO - Episode 1801/98900: Winner=2, Reward=7.55, EPSILON=0.984, (W=328,D=2,L=0)
2025-01-16 05:07:25,044 - INFO - Episode 1802/98900: Winner=2, Reward=-15.55, EPSILON=0.984, (W=329,D=2,L=0)
2025-01-16 05:07:25,325 - INFO - Episode 1803/98900: Winner=2, Reward=25.25, EPSILON=0.984, (W=329,D=2,L=0)
2025-01-16 05:07:25,544 - INFO - Episode 1804/98900: Winner=2, Reward=-2.35, EPSILON=0.984, (W=329,D=2,L=0)
2025-01-16 05:07:25,669 - INFO - Episode 1805/98900: Winner=2, Reward=-7.75, EPSILON=0.984, (W=330,D=2,L=0)
2025-01-16 05:07:25,892 - INFO - Episode 1806/98900: Winner=2, Reward=-1.55, EPSILON=0.984, (W=330,D=2,L=0)
2025-01-16 05:07:26,023 - INFO - Episode 1807/98900: Winner=2, Reward=-0.40, EPSILON=0.984, (W=330,D=2,L=0)
2025-01-16 05:07:26,251 - INFO - Episode 1808/98900: Winner=2, Reward=6.75, EPSILON=0.984, (W=330,D=2,L=0)
2025-01-16 05:07:26,359 - INFO - Episode 1809/98900: Winner=2, Reward=-11.75, EPSILON=0.984, (W=331,D=2,L=0)
2025-01-16 05:07:26,375 - DEBUG - Q-vals = [0.06487043 0.02243675 0.006654   0.57801354 0.00845174 0.0290087
 0.29056475], best_act=3, best_val=0.578
2025-01-16 05:07:26,375 - DEBUG - Low Q-value (0.578), using MCTS.
2025-01-16 05:07:26,375 - INFO - Running MCTS with 82 simulations using 6 processes.
2025-01-16 05:07:29,111 - DEBUG - Aggregated action counts: {1: 2, 6: 2, 3: 2, 0: 1}
2025-01-16 05:07:29,111 - DEBUG - Chose best action 1
2025-01-16 05:07:29,189 - INFO - Episode 1810/98900: Winner=2, Reward=-0.10, EPSILON=0.984, (W=331,D=2,L=0)
2025-01-16 05:07:29,389 - INFO - Episode 1811/98900: Winner=2, Reward=-1.20, EPSILON=0.984, (W=331,D=2,L=0)
2025-01-16 05:07:29,688 - DEBUG - Q-vals = [0.07405145 0.02034515 0.24522741 0.0324033  0.2846077  0.11203926
 0.23132573], best_act=2, best_val=0.245
2025-01-16 05:07:29,688 - DEBUG - Low Q-value (0.245), using MCTS.
2025-01-16 05:07:29,699 - INFO - Episode 1812/98900: Winner=2, Reward=-34.00, EPSILON=0.984, (W=332,D=2,L=0)
2025-01-16 05:07:29,934 - INFO - Episode 1813/98900: Winner=2, Reward=-12.05, EPSILON=0.984, (W=333,D=2,L=0)
2025-01-16 05:07:30,227 - INFO - Episode 1814/98900: Winner=2, Reward=-19.65, EPSILON=0.984, (W=333,D=2,L=0)
2025-01-16 05:07:30,367 - INFO - Episode 1815/98900: Winner=2, Reward=-8.85, EPSILON=0.984, (W=334,D=2,L=0)
2025-01-16 05:07:30,477 - INFO - Episode 1816/98900: Winner=2, Reward=6.65, EPSILON=0.984, (W=334,D=2,L=0)
2025-01-16 05:07:30,653 - INFO - Episode 1817/98900: Winner=2, Reward=-12.00, EPSILON=0.984, (W=335,D=2,L=0)
2025-01-16 05:07:30,947 - INFO - Episode 1818/98900: Winner=2, Reward=-0.15, EPSILON=0.984, (W=335,D=2,L=0)
2025-01-16 05:07:31,010 - DEBUG - Q-vals = [0.23534468 0.09942912 0.12939978 0.11401915 0.15612105 0.20192239
 0.06376381], best_act=0, best_val=0.235
2025-01-16 05:07:31,010 - DEBUG - Low Q-value (0.235), using MCTS.
2025-01-16 05:07:31,010 - INFO - Running MCTS with 82 simulations using 6 processes.
2025-01-16 05:07:34,253 - DEBUG - Aggregated action counts: {1: 1, 3: 1, 4: 2, 0: 2, 2: 1}
2025-01-16 05:07:34,253 - DEBUG - Chose best action 4
2025-01-16 05:07:34,514 - INFO - Episode 1819/98900: Winner=2, Reward=-26.50, EPSILON=0.984, (W=336,D=2,L=0)
2025-01-16 05:07:34,795 - INFO - Episode 1820/98900: Winner=2, Reward=-20.55, EPSILON=0.984, (W=337,D=2,L=0)
2025-01-16 05:07:34,949 - INFO - Episode 1821/98900: Winner=2, Reward=-4.50, EPSILON=0.984, (W=338,D=2,L=0)
2025-01-16 05:07:34,990 - DEBUG - Q-vals = [0.04685936 0.06420041 0.05698287 0.0144113  0.5495992  0.23407915
 0.03386774], best_act=4, best_val=0.550
2025-01-16 05:07:34,990 - DEBUG - Low Q-value (0.550), using MCTS.
2025-01-16 05:07:34,991 - INFO - Running MCTS with 82 simulations using 6 processes.
2025-01-16 05:07:38,390 - DEBUG - Aggregated action counts: {2: 2, 0: 2, 1: 2, 5: 1}
2025-01-16 05:07:38,391 - DEBUG - Chose best action 2
2025-01-16 05:07:38,829 - INFO - Episode 1822/98900: Winner=-1, Reward=-68.30, EPSILON=0.984, (W=338,D=3,L=0)
2025-01-16 05:07:39,221 - INFO - Episode 1823/98900: Winner=2, Reward=-13.65, EPSILON=0.984, (W=338,D=3,L=0)
2025-01-16 05:07:39,504 - INFO - Episode 1824/98900: Winner=2, Reward=-15.65, EPSILON=0.984, (W=338,D=3,L=0)
2025-01-16 05:07:39,754 - INFO - Episode 1825/98900: Winner=2, Reward=36.55, EPSILON=0.984, (W=338,D=3,L=0)
2025-01-16 05:07:39,848 - INFO - Episode 1826/98900: Winner=2, Reward=-1.95, EPSILON=0.984, (W=338,D=3,L=0)
2025-01-16 05:07:40,064 - INFO - Episode 1827/98900: Winner=2, Reward=-13.10, EPSILON=0.984, (W=339,D=3,L=0)
2025-01-16 05:07:40,255 - INFO - Episode 1828/98900: Winner=2, Reward=-14.00, EPSILON=0.984, (W=340,D=3,L=0)
2025-01-16 05:07:40,522 - DEBUG - Q-vals = [0.07973868 0.05746276 0.07691758 0.11313703 0.47783384 0.13253132
 0.06237881], best_act=3, best_val=0.113
2025-01-16 05:07:40,522 - DEBUG - Low Q-value (0.113), using MCTS.
2025-01-16 05:07:40,523 - INFO - Running MCTS with 83 simulations using 6 processes.
2025-01-16 05:07:43,667 - DEBUG - Aggregated action counts: {1: 2, 2: 2, 0: 3}
2025-01-16 05:07:43,667 - DEBUG - Chose best action 0
2025-01-16 05:07:43,788 - INFO - Episode 1829/98900: Winner=2, Reward=-52.85, EPSILON=0.984, (W=341,D=3,L=0)
2025-01-16 05:07:43,969 - INFO - Episode 1830/98900: Winner=2, Reward=-5.75, EPSILON=0.984, (W=342,D=3,L=0)
2025-01-16 05:07:44,047 - DEBUG - Q-vals = [0.22345293 0.04434125 0.05915808 0.13002631 0.35249066 0.02304314
 0.16748767], best_act=4, best_val=0.352
2025-01-16 05:07:44,047 - DEBUG - Low Q-value (0.352), using MCTS.
2025-01-16 05:07:44,048 - INFO - Running MCTS with 83 simulations using 6 processes.
2025-01-16 05:07:46,706 - DEBUG - Aggregated action counts: {0: 5, 1: 1, 3: 1}
2025-01-16 05:07:46,706 - DEBUG - Chose best action 0
2025-01-16 05:07:46,761 - INFO - Episode 1831/98900: Winner=2, Reward=6.40, EPSILON=0.984, (W=342,D=3,L=0)
2025-01-16 05:07:46,852 - INFO - Episode 1832/98900: Winner=2, Reward=5.35, EPSILON=0.984, (W=342,D=3,L=0)
2025-01-16 05:07:46,985 - INFO - Episode 1833/98900: Winner=2, Reward=-10.70, EPSILON=0.984, (W=343,D=3,L=0)
2025-01-16 05:07:47,280 - INFO - Episode 1834/98900: Winner=2, Reward=-19.45, EPSILON=0.984, (W=343,D=3,L=0)
2025-01-16 05:07:47,517 - INFO - Episode 1835/98900: Winner=2, Reward=1.70, EPSILON=0.984, (W=343,D=3,L=0)
2025-01-16 05:07:47,733 - DEBUG - Q-vals = [0.21571602 0.07761715 0.25026527 0.10628055 0.12679718 0.07732192
 0.14600183], best_act=2, best_val=0.250
2025-01-16 05:07:47,733 - DEBUG - Low Q-value (0.250), using MCTS.
2025-01-16 05:07:47,734 - INFO - Running MCTS with 83 simulations using 6 processes.
2025-01-16 05:07:50,578 - DEBUG - Aggregated action counts: {1: 1, 5: 1, 6: 1, 3: 2, 0: 2}
2025-01-16 05:07:50,578 - DEBUG - Chose best action 3
2025-01-16 05:07:50,625 - INFO - Episode 1836/98900: Winner=2, Reward=6.45, EPSILON=0.984, (W=343,D=3,L=0)
2025-01-16 05:07:50,963 - INFO - Episode 1837/98900: Winner=2, Reward=-13.40, EPSILON=0.984, (W=344,D=3,L=0)
2025-01-16 05:07:51,188 - INFO - Episode 1838/98900: Winner=2, Reward=11.20, EPSILON=0.984, (W=344,D=3,L=0)
2025-01-16 05:07:51,379 - INFO - Episode 1839/98900: Winner=2, Reward=-12.60, EPSILON=0.984, (W=345,D=3,L=0)
2025-01-16 05:07:51,660 - INFO - Episode 1840/98900: Winner=2, Reward=-1.55, EPSILON=0.984, (W=345,D=3,L=0)
2025-01-16 05:07:51,746 - INFO - Episode 1841/98900: Winner=2, Reward=0.45, EPSILON=0.984, (W=345,D=3,L=0)
2025-01-16 05:07:52,146 - INFO - Episode 1842/98900: Winner=2, Reward=-108.10, EPSILON=0.984, (W=345,D=3,L=0)
2025-01-16 05:07:52,457 - INFO - Episode 1843/98900: Winner=2, Reward=-17.85, EPSILON=0.984, (W=346,D=3,L=0)
2025-01-16 05:07:52,679 - INFO - Episode 1844/98900: Winner=2, Reward=-1.00, EPSILON=0.984, (W=346,D=3,L=0)
2025-01-16 05:07:52,833 - INFO - Episode 1845/98900: Winner=2, Reward=-5.55, EPSILON=0.984, (W=347,D=3,L=0)
2025-01-16 05:07:52,923 - INFO - Episode 1846/98900: Winner=2, Reward=0.90, EPSILON=0.984, (W=347,D=3,L=0)
2025-01-16 05:07:53,002 - DEBUG - Q-vals = [0.02147658 0.01797418 0.0834842  0.7995439  0.0060898  0.06567436
 0.00575689], best_act=3, best_val=0.800
2025-01-16 05:07:53,002 - DEBUG - Low Q-value (0.800), using MCTS.
2025-01-16 05:07:53,003 - INFO - Running MCTS with 83 simulations using 6 processes.
2025-01-16 05:07:56,028 - DEBUG - Aggregated action counts: {1: 1, 4: 1, 3: 2, 2: 1, 0: 2}
2025-01-16 05:07:56,028 - DEBUG - Chose best action 3
2025-01-16 05:07:56,253 - INFO - Episode 1847/98900: Winner=2, Reward=-32.95, EPSILON=0.984, (W=347,D=3,L=0)
2025-01-16 05:07:56,662 - INFO - Episode 1848/98900: Winner=2, Reward=-62.15, EPSILON=0.984, (W=348,D=3,L=0)
2025-01-16 05:07:56,756 - INFO - Episode 1849/98900: Winner=2, Reward=7.05, EPSILON=0.983, (W=348,D=3,L=0)
2025-01-16 05:07:57,000 - INFO - Episode 1850/98900: Winner=2, Reward=12.55, EPSILON=0.983, (W=348,D=3,L=0)
2025-01-16 05:07:57,181 - INFO - Episode 1851/98900: Winner=2, Reward=23.70, EPSILON=0.983, (W=348,D=3,L=0)
2025-01-16 05:07:57,275 - INFO - Episode 1852/98900: Winner=2, Reward=-9.15, EPSILON=0.983, (W=349,D=3,L=0)
2025-01-16 05:07:57,434 - INFO - Episode 1853/98900: Winner=2, Reward=6.80, EPSILON=0.983, (W=349,D=3,L=0)
2025-01-16 05:07:57,470 - DEBUG - Q-vals = [0.12146286 0.09213138 0.07471493 0.14748298 0.26529688 0.26881042
 0.03010046], best_act=5, best_val=0.269
2025-01-16 05:07:57,470 - DEBUG - Low Q-value (0.269), using MCTS.
2025-01-16 05:07:57,471 - INFO - Running MCTS with 84 simulations using 6 processes.
2025-01-16 05:08:00,790 - DEBUG - Aggregated action counts: {0: 1, 3: 2, 2: 3}
2025-01-16 05:08:00,790 - DEBUG - Chose best action 2
2025-01-16 05:08:01,051 - INFO - Episode 1854/98900: Winner=2, Reward=-24.35, EPSILON=0.983, (W=349,D=3,L=0)
2025-01-16 05:08:01,344 - INFO - Episode 1855/98900: Winner=2, Reward=-34.05, EPSILON=0.983, (W=350,D=3,L=0)
2025-01-16 05:08:01,593 - INFO - Episode 1856/98900: Winner=2, Reward=5.50, EPSILON=0.983, (W=350,D=3,L=0)
2025-01-16 05:08:01,841 - INFO - Episode 1857/98900: Winner=2, Reward=-15.80, EPSILON=0.983, (W=350,D=3,L=0)
2025-01-16 05:08:02,099 - INFO - Episode 1858/98900: Winner=2, Reward=-22.85, EPSILON=0.983, (W=351,D=3,L=0)
2025-01-16 05:08:02,296 - INFO - Episode 1859/98900: Winner=2, Reward=15.35, EPSILON=0.983, (W=351,D=3,L=0)
2025-01-16 05:08:02,556 - INFO - Episode 1860/98900: Winner=2, Reward=-20.25, EPSILON=0.983, (W=352,D=3,L=0)
2025-01-16 05:08:02,845 - INFO - Episode 1861/98900: Winner=2, Reward=-32.65, EPSILON=0.983, (W=353,D=3,L=0)
2025-01-16 05:08:03,159 - INFO - Episode 1862/98900: Winner=2, Reward=15.65, EPSILON=0.983, (W=354,D=3,L=0)
2025-01-16 05:08:03,524 - INFO - Episode 1863/98900: Winner=2, Reward=-39.55, EPSILON=0.983, (W=355,D=3,L=0)
2025-01-16 05:08:03,842 - INFO - Episode 1864/98900: Winner=2, Reward=24.45, EPSILON=0.983, (W=355,D=3,L=0)
2025-01-16 05:08:04,136 - INFO - Episode 1865/98900: Winner=2, Reward=-17.15, EPSILON=0.983, (W=355,D=3,L=0)
2025-01-16 05:08:04,564 - INFO - Episode 1866/98900: Winner=2, Reward=-62.15, EPSILON=0.983, (W=355,D=3,L=0)
2025-01-16 05:08:04,970 - INFO - Episode 1867/98900: Winner=2, Reward=-71.10, EPSILON=0.983, (W=356,D=3,L=0)
2025-01-16 05:08:05,163 - INFO - Episode 1868/98900: Winner=2, Reward=-12.65, EPSILON=0.983, (W=357,D=3,L=0)
2025-01-16 05:08:05,216 - INFO - Episode 1869/98900: Winner=2, Reward=7.75, EPSILON=0.983, (W=357,D=3,L=0)
2025-01-16 05:08:05,489 - INFO - Episode 1870/98900: Winner=2, Reward=2.10, EPSILON=0.983, (W=358,D=3,L=0)
2025-01-16 05:08:05,673 - INFO - Episode 1871/98900: Winner=2, Reward=13.05, EPSILON=0.983, (W=358,D=3,L=0)
2025-01-16 05:08:06,004 - INFO - Episode 1872/98900: Winner=2, Reward=-10.75, EPSILON=0.983, (W=358,D=3,L=0)
2025-01-16 05:08:06,142 - INFO - Episode 1873/98900: Winner=2, Reward=-9.75, EPSILON=0.983, (W=359,D=3,L=0)
2025-01-16 05:08:06,392 - INFO - Episode 1874/98900: Winner=2, Reward=-3.85, EPSILON=0.983, (W=360,D=3,L=0)
2025-01-16 05:08:06,683 - INFO - Episode 1875/98900: Winner=2, Reward=0.25, EPSILON=0.983, (W=360,D=3,L=0)
2025-01-16 05:08:06,877 - INFO - Episode 1876/98900: Winner=2, Reward=1.80, EPSILON=0.983, (W=360,D=3,L=0)
2025-01-16 05:08:07,096 - INFO - Episode 1877/98900: Winner=2, Reward=13.35, EPSILON=0.983, (W=360,D=3,L=0)
2025-01-16 05:08:07,299 - DEBUG - Q-vals = [0.0867822  0.18472582 0.06348164 0.24038006 0.08581591 0.0679442
 0.27087012], best_act=6, best_val=0.271
2025-01-16 05:08:07,299 - DEBUG - Low Q-value (0.271), using MCTS.
2025-01-16 05:08:07,299 - INFO - Episode 1878/98900: Winner=2, Reward=-24.65, EPSILON=0.983, (W=361,D=3,L=0)
2025-01-16 05:08:07,372 - DEBUG - Q-vals = [0.12474224 0.10013626 0.1209107  0.14294943 0.17808916 0.26229927
 0.07087289], best_act=5, best_val=0.262
2025-01-16 05:08:07,372 - DEBUG - Low Q-value (0.262), using MCTS.
2025-01-16 05:08:07,373 - INFO - Running MCTS with 85 simulations using 6 processes.
2025-01-16 05:08:10,132 - DEBUG - Aggregated action counts: {0: 4, 1: 2, 2: 1}
2025-01-16 05:08:10,132 - DEBUG - Chose best action 0
2025-01-16 05:08:10,241 - INFO - Episode 1879/98900: Winner=2, Reward=-11.30, EPSILON=0.983, (W=362,D=3,L=0)
2025-01-16 05:08:10,423 - INFO - Episode 1880/98900: Winner=2, Reward=21.35, EPSILON=0.983, (W=362,D=3,L=0)
2025-01-16 05:08:10,579 - INFO - Episode 1881/98900: Winner=2, Reward=-3.90, EPSILON=0.983, (W=363,D=3,L=0)
2025-01-16 05:08:10,815 - INFO - Episode 1882/98900: Winner=2, Reward=-10.15, EPSILON=0.983, (W=364,D=3,L=0)
2025-01-16 05:08:10,947 - INFO - Episode 1883/98900: Winner=2, Reward=-12.95, EPSILON=0.983, (W=365,D=3,L=0)
2025-01-16 05:08:11,143 - INFO - Episode 1884/98900: Winner=2, Reward=-0.35, EPSILON=0.983, (W=365,D=3,L=0)
2025-01-16 05:08:11,342 - INFO - Episode 1885/98900: Winner=2, Reward=-14.25, EPSILON=0.983, (W=366,D=3,L=0)
2025-01-16 05:08:11,668 - INFO - Episode 1886/98900: Winner=2, Reward=-7.85, EPSILON=0.983, (W=366,D=3,L=0)
2025-01-16 05:08:11,999 - INFO - Episode 1887/98900: Winner=2, Reward=-7.90, EPSILON=0.983, (W=366,D=3,L=0)
2025-01-16 05:08:12,194 - INFO - Episode 1888/98900: Winner=2, Reward=7.85, EPSILON=0.983, (W=366,D=3,L=0)
2025-01-16 05:08:12,435 - INFO - Episode 1889/98900: Winner=2, Reward=-23.85, EPSILON=0.983, (W=367,D=3,L=0)
2025-01-16 05:08:12,676 - INFO - Episode 1890/98900: Winner=2, Reward=-15.85, EPSILON=0.983, (W=368,D=3,L=0)
2025-01-16 05:08:12,985 - INFO - Episode 1891/98900: Winner=2, Reward=-25.90, EPSILON=0.983, (W=369,D=3,L=0)
2025-01-16 05:08:13,196 - INFO - Episode 1892/98900: Winner=2, Reward=2.15, EPSILON=0.983, (W=369,D=3,L=0)
2025-01-16 05:08:13,643 - INFO - Episode 1893/98900: Winner=2, Reward=-74.35, EPSILON=0.983, (W=370,D=3,L=0)
2025-01-16 05:08:13,757 - INFO - Episode 1894/98900: Winner=2, Reward=8.00, EPSILON=0.983, (W=370,D=3,L=0)
2025-01-16 05:08:13,824 - INFO - Episode 1895/98900: Winner=2, Reward=9.60, EPSILON=0.983, (W=370,D=3,L=0)
2025-01-16 05:08:14,175 - INFO - Episode 1896/98900: Winner=2, Reward=-59.20, EPSILON=0.983, (W=371,D=3,L=0)
2025-01-16 05:08:14,420 - INFO - Episode 1897/98900: Winner=2, Reward=0.05, EPSILON=0.983, (W=371,D=3,L=0)
2025-01-16 05:08:14,772 - INFO - Episode 1898/98900: Winner=2, Reward=-45.95, EPSILON=0.983, (W=372,D=3,L=0)
2025-01-16 05:08:14,834 - DEBUG - Q-vals = [0.09858925 0.05994366 0.14614668 0.1323946  0.06416983 0.44383445
 0.05492143], best_act=5, best_val=0.444
2025-01-16 05:08:14,834 - DEBUG - Low Q-value (0.444), using MCTS.
2025-01-16 05:08:14,834 - INFO - Running MCTS with 85 simulations using 6 processes.
2025-01-16 05:08:17,663 - DEBUG - Aggregated action counts: {0: 1, 2: 2, 6: 2, 4: 1, 1: 1}
2025-01-16 05:08:17,663 - DEBUG - Chose best action 2
2025-01-16 05:08:17,814 - INFO - Episode 1899/98900: Winner=2, Reward=-15.00, EPSILON=0.983, (W=373,D=3,L=0)
2025-01-16 05:08:18,048 - DEBUG - Q-vals = [0.0335172  0.03121089 0.05662781 0.38388902 0.07039916 0.13805206
 0.28630388], best_act=3, best_val=0.384
2025-01-16 05:08:18,048 - DEBUG - Low Q-value (0.384), using MCTS.
2025-01-16 05:08:18,050 - INFO - Running MCTS with 86 simulations using 6 processes.
2025-01-16 05:08:20,812 - DEBUG - Aggregated action counts: {4: 2, 1: 2, 5: 1, 2: 1, 0: 1}
2025-01-16 05:08:20,812 - DEBUG - Chose best action 4
2025-01-16 05:08:20,890 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1900.
2025-01-16 05:08:20,890 - INFO - Models saved at episode 1900
2025-01-16 05:08:20,890 - INFO - Target networks updated
2025-01-16 05:08:20,953 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1900.
2025-01-16 05:08:20,953 - INFO - Episode 1900/98900: Winner=2, Reward=12.45, EPSILON=0.983, (W=373,D=3,L=0)
2025-01-16 05:08:21,062 - INFO - Episode 1901/98900: Winner=2, Reward=-0.60, EPSILON=0.983, (W=373,D=3,L=0)
2025-01-16 05:08:21,364 - INFO - Episode 1902/98900: Winner=2, Reward=12.70, EPSILON=0.983, (W=373,D=3,L=0)
2025-01-16 05:08:21,611 - INFO - Episode 1903/98900: Winner=2, Reward=0.40, EPSILON=0.983, (W=373,D=3,L=0)
2025-01-16 05:08:21,918 - INFO - Episode 1904/98900: Winner=2, Reward=-10.05, EPSILON=0.983, (W=373,D=3,L=0)
2025-01-16 05:08:22,076 - INFO - Episode 1905/98900: Winner=2, Reward=7.95, EPSILON=0.983, (W=373,D=3,L=0)
2025-01-16 05:08:22,399 - INFO - Episode 1906/98900: Winner=2, Reward=1.15, EPSILON=0.983, (W=373,D=3,L=0)
2025-01-16 05:08:22,700 - INFO - Episode 1907/98900: Winner=2, Reward=3.45, EPSILON=0.983, (W=373,D=3,L=0)
2025-01-16 05:08:22,989 - INFO - Episode 1908/98900: Winner=2, Reward=-21.45, EPSILON=0.983, (W=374,D=3,L=0)
2025-01-16 05:08:23,039 - DEBUG - Q-vals = [0.02151527 0.10040237 0.01132262 0.6428617  0.0086646  0.20618486
 0.00904864], best_act=3, best_val=0.643
2025-01-16 05:08:23,039 - DEBUG - Low Q-value (0.643), using MCTS.
2025-01-16 05:08:23,039 - INFO - Running MCTS with 86 simulations using 6 processes.
2025-01-16 05:08:25,761 - DEBUG - Aggregated action counts: {0: 2, 1: 2, 4: 2, 3: 1}
2025-01-16 05:08:25,761 - DEBUG - Chose best action 0
2025-01-16 05:08:25,933 - INFO - Episode 1909/98900: Winner=2, Reward=0.45, EPSILON=0.983, (W=375,D=3,L=0)
2025-01-16 05:08:26,228 - INFO - Episode 1910/98900: Winner=2, Reward=-37.00, EPSILON=0.983, (W=375,D=3,L=0)
2025-01-16 05:08:26,525 - INFO - Episode 1911/98900: Winner=2, Reward=-28.65, EPSILON=0.983, (W=375,D=3,L=0)
2025-01-16 05:08:26,985 - INFO - Episode 1912/98900: Winner=-1, Reward=-36.35, EPSILON=0.983, (W=375,D=4,L=0)
2025-01-16 05:08:27,152 - DEBUG - Q-vals = [0.3517382  0.21475515 0.05075559 0.1304418  0.07521108 0.06270585
 0.11439231], best_act=0, best_val=0.352
2025-01-16 05:08:27,152 - DEBUG - Low Q-value (0.352), using MCTS.
2025-01-16 05:08:27,152 - INFO - Running MCTS with 86 simulations using 6 processes.
2025-01-16 05:08:30,160 - DEBUG - Aggregated action counts: {0: 2, 6: 2, 3: 1, 2: 1, 4: 1}
2025-01-16 05:08:30,161 - DEBUG - Chose best action 0
2025-01-16 05:08:30,217 - INFO - Episode 1913/98900: Winner=2, Reward=4.50, EPSILON=0.983, (W=376,D=4,L=0)
2025-01-16 05:08:30,305 - INFO - Episode 1914/98900: Winner=2, Reward=6.90, EPSILON=0.983, (W=376,D=4,L=0)
2025-01-16 05:08:30,508 - INFO - Episode 1915/98900: Winner=2, Reward=3.15, EPSILON=0.983, (W=376,D=4,L=0)
2025-01-16 05:08:30,665 - INFO - Episode 1916/98900: Winner=2, Reward=2.95, EPSILON=0.983, (W=377,D=4,L=0)
2025-01-16 05:08:31,086 - INFO - Episode 1917/98900: Winner=2, Reward=-34.60, EPSILON=0.983, (W=377,D=4,L=0)
2025-01-16 05:08:31,503 - INFO - Episode 1918/98900: Winner=2, Reward=-105.10, EPSILON=0.983, (W=377,D=4,L=0)
2025-01-16 05:08:31,637 - INFO - Episode 1919/98900: Winner=2, Reward=-10.15, EPSILON=0.983, (W=378,D=4,L=0)
2025-01-16 05:08:31,856 - INFO - Episode 1920/98900: Winner=2, Reward=-22.30, EPSILON=0.983, (W=379,D=4,L=0)
2025-01-16 05:08:31,918 - INFO - Episode 1921/98900: Winner=2, Reward=16.05, EPSILON=0.983, (W=379,D=4,L=0)
2025-01-16 05:08:32,126 - INFO - Episode 1922/98900: Winner=2, Reward=14.65, EPSILON=0.983, (W=379,D=4,L=0)
2025-01-16 05:08:32,357 - INFO - Episode 1923/98900: Winner=2, Reward=-8.70, EPSILON=0.983, (W=380,D=4,L=0)
2025-01-16 05:08:32,499 - INFO - Episode 1924/98900: Winner=2, Reward=-13.80, EPSILON=0.983, (W=381,D=4,L=0)
2025-01-16 05:08:32,839 - INFO - Episode 1925/98900: Winner=2, Reward=-45.55, EPSILON=0.983, (W=382,D=4,L=0)
2025-01-16 05:08:32,885 - DEBUG - Q-vals = [0.13720126 0.13285613 0.03317981 0.04055339 0.0918881  0.5068792
 0.05744203], best_act=5, best_val=0.507
2025-01-16 05:08:32,885 - DEBUG - Low Q-value (0.507), using MCTS.
2025-01-16 05:08:32,885 - INFO - Running MCTS with 87 simulations using 6 processes.
2025-01-16 05:08:35,609 - DEBUG - Aggregated action counts: {3: 1, 1: 2, 2: 2, 0: 2}
2025-01-16 05:08:35,609 - DEBUG - Chose best action 1
2025-01-16 05:08:35,655 - DEBUG - Q-vals = [0.14896545 0.11240619 0.14487997 0.10253854 0.25378218 0.1298188
 0.10760886], best_act=4, best_val=0.254
2025-01-16 05:08:35,655 - DEBUG - Low Q-value (0.254), using MCTS.
2025-01-16 05:08:35,655 - INFO - Running MCTS with 87 simulations using 6 processes.
2025-01-16 05:08:38,366 - DEBUG - Aggregated action counts: {4: 1, 0: 2, 1: 1, 3: 3}
2025-01-16 05:08:38,366 - DEBUG - Chose best action 3
2025-01-16 05:08:38,465 - INFO - Episode 1926/98900: Winner=2, Reward=4.90, EPSILON=0.983, (W=382,D=4,L=0)
2025-01-16 05:08:38,683 - INFO - Episode 1927/98900: Winner=2, Reward=-1.15, EPSILON=0.983, (W=382,D=4,L=0)
2025-01-16 05:08:38,838 - INFO - Episode 1928/98900: Winner=2, Reward=22.20, EPSILON=0.983, (W=382,D=4,L=0)
2025-01-16 05:08:38,969 - INFO - Episode 1929/98900: Winner=2, Reward=-1.05, EPSILON=0.983, (W=382,D=4,L=0)
2025-01-16 05:08:39,056 - DEBUG - Q-vals = [0.17266536 0.09551078 0.12378438 0.08203845 0.18560576 0.21727519
 0.12312013], best_act=5, best_val=0.217
2025-01-16 05:08:39,056 - DEBUG - Low Q-value (0.217), using MCTS.
2025-01-16 05:08:39,056 - INFO - Running MCTS with 87 simulations using 6 processes.
2025-01-16 05:08:41,825 - DEBUG - Aggregated action counts: {0: 3, 1: 2, 2: 2}
2025-01-16 05:08:41,825 - DEBUG - Chose best action 0
2025-01-16 05:08:41,898 - INFO - Episode 1930/98900: Winner=2, Reward=-2.70, EPSILON=0.983, (W=382,D=4,L=0)
2025-01-16 05:08:42,050 - INFO - Episode 1931/98900: Winner=2, Reward=-3.15, EPSILON=0.983, (W=382,D=4,L=0)
2025-01-16 05:08:42,202 - INFO - Episode 1932/98900: Winner=2, Reward=3.65, EPSILON=0.983, (W=382,D=4,L=0)
2025-01-16 05:08:42,486 - INFO - Episode 1933/98900: Winner=2, Reward=-12.35, EPSILON=0.983, (W=382,D=4,L=0)
2025-01-16 05:08:42,729 - INFO - Episode 1934/98900: Winner=2, Reward=-23.65, EPSILON=0.983, (W=383,D=4,L=0)
2025-01-16 05:08:43,102 - INFO - Episode 1935/98900: Winner=2, Reward=-77.05, EPSILON=0.983, (W=383,D=4,L=0)
2025-01-16 05:08:43,350 - INFO - Episode 1936/98900: Winner=2, Reward=-1.60, EPSILON=0.983, (W=383,D=4,L=0)
2025-01-16 05:08:43,608 - INFO - Episode 1937/98900: Winner=2, Reward=-25.70, EPSILON=0.983, (W=384,D=4,L=0)
2025-01-16 05:08:43,874 - INFO - Episode 1938/98900: Winner=2, Reward=-40.95, EPSILON=0.983, (W=385,D=4,L=0)
2025-01-16 05:08:44,021 - INFO - Episode 1939/98900: Winner=2, Reward=-1.40, EPSILON=0.983, (W=385,D=4,L=0)
2025-01-16 05:08:44,099 - INFO - Episode 1940/98900: Winner=2, Reward=-10.45, EPSILON=0.983, (W=386,D=4,L=0)
2025-01-16 05:08:44,437 - INFO - Episode 1941/98900: Winner=2, Reward=-52.60, EPSILON=0.983, (W=387,D=4,L=0)
2025-01-16 05:08:44,658 - INFO - Episode 1942/98900: Winner=2, Reward=-6.50, EPSILON=0.983, (W=388,D=4,L=0)
2025-01-16 05:08:44,854 - INFO - Episode 1943/98900: Winner=2, Reward=0.75, EPSILON=0.983, (W=388,D=4,L=0)
2025-01-16 05:08:45,036 - INFO - Episode 1944/98900: Winner=2, Reward=3.15, EPSILON=0.983, (W=388,D=4,L=0)
2025-01-16 05:08:45,145 - INFO - Episode 1945/98900: Winner=2, Reward=-0.40, EPSILON=0.983, (W=388,D=4,L=0)
2025-01-16 05:08:45,426 - INFO - Episode 1946/98900: Winner=2, Reward=17.15, EPSILON=0.983, (W=389,D=4,L=0)
2025-01-16 05:08:45,553 - INFO - Episode 1947/98900: Winner=2, Reward=-5.95, EPSILON=0.983, (W=390,D=4,L=0)
2025-01-16 05:08:45,844 - INFO - Episode 1948/98900: Winner=2, Reward=-27.80, EPSILON=0.983, (W=391,D=4,L=0)
2025-01-16 05:08:46,164 - INFO - Episode 1949/98900: Winner=2, Reward=-15.85, EPSILON=0.983, (W=392,D=4,L=0)
2025-01-16 05:08:46,429 - INFO - Episode 1950/98900: Winner=2, Reward=-48.15, EPSILON=0.983, (W=393,D=4,L=0)
2025-01-16 05:08:46,444 - DEBUG - Q-vals = [0.37013784 0.5124638  0.00222942 0.00056808 0.03130545 0.05042266
 0.03287269], best_act=1, best_val=0.512
2025-01-16 05:08:46,444 - DEBUG - Low Q-value (0.512), using MCTS.
2025-01-16 05:08:46,445 - INFO - Running MCTS with 88 simulations using 6 processes.
2025-01-16 05:08:49,163 - DEBUG - Aggregated action counts: {0: 3, 2: 2, 1: 2}
2025-01-16 05:08:49,164 - DEBUG - Chose best action 0
2025-01-16 05:08:49,308 - INFO - Episode 1951/98900: Winner=2, Reward=-3.85, EPSILON=0.983, (W=393,D=4,L=0)
2025-01-16 05:08:49,425 - INFO - Episode 1952/98900: Winner=2, Reward=1.75, EPSILON=0.983, (W=393,D=4,L=0)
2025-01-16 05:08:49,670 - INFO - Episode 1953/98900: Winner=2, Reward=6.85, EPSILON=0.983, (W=394,D=4,L=0)
2025-01-16 05:08:49,880 - INFO - Episode 1954/98900: Winner=2, Reward=0.85, EPSILON=0.983, (W=394,D=4,L=0)
2025-01-16 05:08:50,130 - INFO - Episode 1955/98900: Winner=2, Reward=13.95, EPSILON=0.983, (W=394,D=4,L=0)
2025-01-16 05:08:50,220 - INFO - Episode 1956/98900: Winner=2, Reward=-1.10, EPSILON=0.983, (W=394,D=4,L=0)
2025-01-16 05:08:50,272 - DEBUG - Q-vals = [0.2102672  0.13388385 0.15531753 0.06696846 0.09267758 0.2464614
 0.09442386], best_act=5, best_val=0.246
2025-01-16 05:08:50,272 - DEBUG - Low Q-value (0.246), using MCTS.
2025-01-16 05:08:50,272 - INFO - Running MCTS with 88 simulations using 6 processes.
2025-01-16 05:08:52,969 - DEBUG - Aggregated action counts: {2: 1, 0: 4, 4: 1, 1: 1}
2025-01-16 05:08:52,969 - DEBUG - Chose best action 0
2025-01-16 05:08:53,041 - INFO - Episode 1957/98900: Winner=2, Reward=-8.55, EPSILON=0.983, (W=395,D=4,L=0)
2025-01-16 05:08:53,218 - INFO - Episode 1958/98900: Winner=2, Reward=-0.65, EPSILON=0.983, (W=395,D=4,L=0)
2025-01-16 05:08:53,411 - INFO - Episode 1959/98900: Winner=2, Reward=0.85, EPSILON=0.983, (W=395,D=4,L=0)
2025-01-16 05:08:53,502 - INFO - Episode 1960/98900: Winner=2, Reward=0.75, EPSILON=0.983, (W=395,D=4,L=0)
2025-01-16 05:08:53,764 - INFO - Episode 1961/98900: Winner=2, Reward=-1.15, EPSILON=0.983, (W=396,D=4,L=0)
2025-01-16 05:08:53,971 - INFO - Episode 1962/98900: Winner=2, Reward=-5.25, EPSILON=0.982, (W=397,D=4,L=0)
2025-01-16 05:08:54,156 - INFO - Episode 1963/98900: Winner=2, Reward=-6.45, EPSILON=0.982, (W=398,D=4,L=0)
2025-01-16 05:08:54,433 - INFO - Episode 1964/98900: Winner=2, Reward=-31.40, EPSILON=0.982, (W=399,D=4,L=0)
2025-01-16 05:08:54,700 - INFO - Episode 1965/98900: Winner=2, Reward=9.90, EPSILON=0.982, (W=399,D=4,L=0)
2025-01-16 05:08:54,918 - INFO - Episode 1966/98900: Winner=2, Reward=-7.40, EPSILON=0.982, (W=399,D=4,L=0)
2025-01-16 05:08:55,216 - INFO - Episode 1967/98900: Winner=2, Reward=-25.85, EPSILON=0.982, (W=399,D=4,L=0)
2025-01-16 05:08:55,348 - INFO - Episode 1968/98900: Winner=2, Reward=-0.05, EPSILON=0.982, (W=399,D=4,L=0)
2025-01-16 05:08:55,649 - INFO - Episode 1969/98900: Winner=2, Reward=-30.45, EPSILON=0.982, (W=400,D=4,L=0)
2025-01-16 05:08:55,868 - INFO - Episode 1970/98900: Winner=2, Reward=1.95, EPSILON=0.982, (W=400,D=4,L=0)
2025-01-16 05:08:56,137 - DEBUG - Q-vals = [0.06505363 0.01381594 0.31078506 0.03306238 0.42600825 0.03624643
 0.1150282 ], best_act=6, best_val=0.115
2025-01-16 05:08:56,137 - DEBUG - Low Q-value (0.115), using MCTS.
2025-01-16 05:08:56,137 - INFO - Running MCTS with 88 simulations using 6 processes.
2025-01-16 05:08:58,827 - DEBUG - Aggregated action counts: {3: 1, 0: 4, 5: 2}
2025-01-16 05:08:58,827 - DEBUG - Chose best action 0
2025-01-16 05:08:58,894 - INFO - Episode 1971/98900: Winner=2, Reward=-38.75, EPSILON=0.982, (W=401,D=4,L=0)
2025-01-16 05:08:59,319 - INFO - Episode 1972/98900: Winner=2, Reward=-66.85, EPSILON=0.982, (W=402,D=4,L=0)
2025-01-16 05:08:59,378 - DEBUG - Q-vals = [7.0698827e-04 1.9895048e-03 2.3139508e-03 9.8213059e-01 4.0373320e-04
 9.2587695e-03 3.1966160e-03], best_act=3, best_val=0.982
2025-01-16 05:08:59,378 - DEBUG - Low Q-value (0.982), using MCTS.
2025-01-16 05:08:59,379 - INFO - Running MCTS with 88 simulations using 6 processes.
2025-01-16 05:09:02,134 - DEBUG - Aggregated action counts: {1: 2, 2: 3, 4: 1, 0: 1}
2025-01-16 05:09:02,134 - DEBUG - Chose best action 2
2025-01-16 05:09:02,293 - DEBUG - Q-vals = [0.12732953 0.0247786  0.21017371 0.02996133 0.49028176 0.02303072
 0.09444441], best_act=4, best_val=0.490
2025-01-16 05:09:02,293 - DEBUG - Low Q-value (0.490), using MCTS.
2025-01-16 05:09:02,303 - INFO - Episode 1973/98900: Winner=2, Reward=-13.45, EPSILON=0.982, (W=403,D=4,L=0)
2025-01-16 05:09:02,558 - INFO - Episode 1974/98900: Winner=2, Reward=15.35, EPSILON=0.982, (W=403,D=4,L=0)
2025-01-16 05:09:02,719 - INFO - Episode 1975/98900: Winner=2, Reward=-17.35, EPSILON=0.982, (W=404,D=4,L=0)
2025-01-16 05:09:02,870 - INFO - Episode 1976/98900: Winner=2, Reward=-5.60, EPSILON=0.982, (W=404,D=4,L=0)
2025-01-16 05:09:03,183 - INFO - Episode 1977/98900: Winner=2, Reward=-41.00, EPSILON=0.982, (W=404,D=4,L=0)
2025-01-16 05:09:03,488 - INFO - Episode 1978/98900: Winner=2, Reward=11.75, EPSILON=0.982, (W=404,D=4,L=0)
2025-01-16 05:09:03,628 - DEBUG - Q-vals = [0.26393643 0.0305396  0.33261743 0.12806912 0.13230397 0.01836742
 0.09416613], best_act=2, best_val=0.333
2025-01-16 05:09:03,628 - DEBUG - Low Q-value (0.333), using MCTS.
2025-01-16 05:09:03,628 - INFO - Running MCTS with 89 simulations using 6 processes.
2025-01-16 05:09:06,458 - DEBUG - Aggregated action counts: {4: 1, 5: 1, 6: 1, 3: 2, 0: 2}
2025-01-16 05:09:06,458 - DEBUG - Chose best action 3
2025-01-16 05:09:06,631 - INFO - Episode 1979/98900: Winner=2, Reward=-8.20, EPSILON=0.982, (W=405,D=4,L=0)
2025-01-16 05:09:06,741 - INFO - Episode 1980/98900: Winner=2, Reward=-11.05, EPSILON=0.982, (W=406,D=4,L=0)
2025-01-16 05:09:06,902 - INFO - Episode 1981/98900: Winner=2, Reward=-3.00, EPSILON=0.982, (W=406,D=4,L=0)
2025-01-16 05:09:07,020 - DEBUG - Q-vals = [0.09899686 0.11496867 0.08940557 0.07905009 0.17596118 0.21061292
 0.23100479], best_act=6, best_val=0.231
2025-01-16 05:09:07,020 - DEBUG - Low Q-value (0.231), using MCTS.
2025-01-16 05:09:07,020 - INFO - Running MCTS with 89 simulations using 6 processes.
2025-01-16 05:09:09,665 - DEBUG - Aggregated action counts: {3: 2, 0: 2, 1: 2, 2: 1}
2025-01-16 05:09:09,666 - DEBUG - Chose best action 3
2025-01-16 05:09:09,865 - INFO - Episode 1982/98900: Winner=2, Reward=-19.70, EPSILON=0.982, (W=406,D=4,L=0)
2025-01-16 05:09:10,172 - INFO - Episode 1983/98900: Winner=2, Reward=6.25, EPSILON=0.982, (W=406,D=4,L=0)
2025-01-16 05:09:10,476 - INFO - Episode 1984/98900: Winner=2, Reward=-54.20, EPSILON=0.982, (W=407,D=4,L=0)
2025-01-16 05:09:10,654 - INFO - Episode 1985/98900: Winner=2, Reward=11.30, EPSILON=0.982, (W=407,D=4,L=0)
2025-01-16 05:09:10,899 - INFO - Episode 1986/98900: Winner=2, Reward=20.15, EPSILON=0.982, (W=407,D=4,L=0)
2025-01-16 05:09:11,121 - INFO - Episode 1987/98900: Winner=2, Reward=8.95, EPSILON=0.982, (W=407,D=4,L=0)
2025-01-16 05:09:11,320 - INFO - Episode 1988/98900: Winner=2, Reward=-12.95, EPSILON=0.982, (W=408,D=4,L=0)
2025-01-16 05:09:11,542 - INFO - Episode 1989/98900: Winner=2, Reward=8.75, EPSILON=0.982, (W=408,D=4,L=0)
2025-01-16 05:09:11,871 - INFO - Episode 1990/98900: Winner=2, Reward=-52.15, EPSILON=0.982, (W=409,D=4,L=0)
2025-01-16 05:09:11,905 - DEBUG - Q-vals = [0.01690256 0.00520885 0.06586931 0.8941203  0.00700517 0.00511056
 0.00578337], best_act=3, best_val=0.894
2025-01-16 05:09:11,905 - DEBUG - Low Q-value (0.894), using MCTS.
2025-01-16 05:09:11,905 - INFO - Running MCTS with 89 simulations using 6 processes.
2025-01-16 05:09:14,681 - DEBUG - Aggregated action counts: {4: 1, 1: 2, 2: 1, 0: 3}
2025-01-16 05:09:14,681 - DEBUG - Chose best action 0
2025-01-16 05:09:14,944 - INFO - Episode 1991/98900: Winner=2, Reward=-2.20, EPSILON=0.982, (W=410,D=4,L=0)
2025-01-16 05:09:15,079 - INFO - Episode 1992/98900: Winner=2, Reward=14.65, EPSILON=0.982, (W=410,D=4,L=0)
2025-01-16 05:09:15,319 - DEBUG - Q-vals = [0.11227417 0.32373688 0.00604148 0.01789899 0.04290981 0.07586107
 0.4212776 ], best_act=6, best_val=0.421
2025-01-16 05:09:15,319 - DEBUG - Low Q-value (0.421), using MCTS.
2025-01-16 05:09:15,321 - INFO - Running MCTS with 89 simulations using 6 processes.
2025-01-16 05:09:18,054 - DEBUG - Aggregated action counts: {4: 1, 3: 4, 0: 2}
2025-01-16 05:09:18,054 - DEBUG - Chose best action 3
2025-01-16 05:09:18,106 - INFO - Episode 1993/98900: Winner=2, Reward=-13.90, EPSILON=0.982, (W=411,D=4,L=0)
2025-01-16 05:09:18,324 - INFO - Episode 1994/98900: Winner=2, Reward=4.75, EPSILON=0.982, (W=411,D=4,L=0)
2025-01-16 05:09:18,479 - INFO - Episode 1995/98900: Winner=2, Reward=-15.15, EPSILON=0.982, (W=412,D=4,L=0)
2025-01-16 05:09:18,698 - INFO - Episode 1996/98900: Winner=2, Reward=-16.50, EPSILON=0.982, (W=413,D=4,L=0)
2025-01-16 05:09:19,117 - INFO - Episode 1997/98900: Winner=2, Reward=-69.20, EPSILON=0.982, (W=413,D=4,L=0)
2025-01-16 05:09:19,252 - INFO - Episode 1998/98900: Winner=2, Reward=-7.95, EPSILON=0.982, (W=414,D=4,L=0)
2025-01-16 05:09:19,447 - INFO - Episode 1999/98900: Winner=2, Reward=-15.70, EPSILON=0.982, (W=415,D=4,L=0)
2025-01-16 05:09:19,661 - DEBUG - Q-vals = [0.02336321 0.01334293 0.23036462 0.68383336 0.01167844 0.00985065
 0.02756684], best_act=3, best_val=0.684
2025-01-16 05:09:19,661 - DEBUG - Low Q-value (0.684), using MCTS.
2025-01-16 05:09:19,736 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2000.
2025-01-16 05:09:19,737 - INFO - Models saved at episode 2000
2025-01-16 05:09:19,738 - INFO - Target networks updated
2025-01-16 05:09:19,797 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2000.
2025-01-16 05:09:19,797 - INFO - Episode 2000/98900: Winner=2, Reward=-1.95, EPSILON=0.982, (W=416,D=4,L=0)
2025-01-16 05:09:19,919 - DEBUG - Q-vals = [0.12677573 0.14237133 0.09075356 0.1488005  0.24743554 0.11126978
 0.13259357], best_act=4, best_val=0.247
2025-01-16 05:09:19,919 - DEBUG - Low Q-value (0.247), using MCTS.
2025-01-16 05:09:19,919 - INFO - Running MCTS with 90 simulations using 6 processes.
2025-01-16 05:09:22,724 - DEBUG - Aggregated action counts: {1: 2, 5: 1, 3: 2, 2: 1}
2025-01-16 05:09:22,724 - DEBUG - Chose best action 1
2025-01-16 05:09:22,911 - INFO - Episode 2001/98900: Winner=2, Reward=-49.15, EPSILON=0.982, (W=417,D=4,L=0)
2025-01-16 05:09:23,001 - INFO - Episode 2002/98900: Winner=2, Reward=-9.95, EPSILON=0.982, (W=418,D=4,L=0)
2025-01-16 05:09:23,223 - INFO - Episode 2003/98900: Winner=2, Reward=-8.65, EPSILON=0.982, (W=419,D=4,L=0)
2025-01-16 05:09:23,486 - INFO - Episode 2004/98900: Winner=2, Reward=1.15, EPSILON=0.982, (W=419,D=4,L=0)
2025-01-16 05:09:23,500 - DEBUG - Q-vals = [0.22827557 0.17417175 0.03014699 0.02817371 0.07659469 0.4315148
 0.03112247], best_act=5, best_val=0.432
2025-01-16 05:09:23,500 - DEBUG - Low Q-value (0.432), using MCTS.
2025-01-16 05:09:23,501 - INFO - Running MCTS with 90 simulations using 6 processes.
2025-01-16 05:09:26,185 - DEBUG - Aggregated action counts: {0: 2, 2: 2, 1: 2}
2025-01-16 05:09:26,185 - DEBUG - Chose best action 0
2025-01-16 05:09:26,530 - INFO - Episode 2005/98900: Winner=2, Reward=-24.50, EPSILON=0.982, (W=420,D=4,L=0)
2025-01-16 05:09:26,546 - DEBUG - Q-vals = [0.21465969 0.13825873 0.03248854 0.01841905 0.06689748 0.4977502
 0.03152633], best_act=5, best_val=0.498
2025-01-16 05:09:26,546 - DEBUG - Low Q-value (0.498), using MCTS.
2025-01-16 05:09:26,546 - INFO - Running MCTS with 90 simulations using 6 processes.
2025-01-16 05:09:29,341 - DEBUG - Aggregated action counts: {2: 1, 1: 2, 5: 1, 3: 1, 4: 1}
2025-01-16 05:09:29,341 - DEBUG - Chose best action 1
2025-01-16 05:09:29,669 - INFO - Episode 2006/98900: Winner=2, Reward=-51.90, EPSILON=0.982, (W=421,D=4,L=0)
2025-01-16 05:09:29,740 - INFO - Episode 2007/98900: Winner=2, Reward=8.25, EPSILON=0.982, (W=421,D=4,L=0)
2025-01-16 05:09:29,962 - INFO - Episode 2008/98900: Winner=2, Reward=-0.55, EPSILON=0.982, (W=422,D=4,L=0)
2025-01-16 05:09:30,309 - INFO - Episode 2009/98900: Winner=2, Reward=-1.00, EPSILON=0.982, (W=422,D=4,L=0)
2025-01-16 05:09:30,406 - DEBUG - Q-vals = [0.24046561 0.14836633 0.13626806 0.05999909 0.04171541 0.15338679
 0.21979865], best_act=0, best_val=0.240
2025-01-16 05:09:30,406 - DEBUG - Low Q-value (0.240), using MCTS.
2025-01-16 05:09:30,406 - INFO - Running MCTS with 90 simulations using 6 processes.
2025-01-16 05:09:33,313 - DEBUG - Aggregated action counts: {1: 1, 5: 2, 0: 2, 3: 1}
2025-01-16 05:09:33,313 - DEBUG - Chose best action 5
2025-01-16 05:09:33,521 - INFO - Episode 2010/98900: Winner=2, Reward=-2.00, EPSILON=0.982, (W=423,D=4,L=0)
2025-01-16 05:09:33,855 - INFO - Episode 2011/98900: Winner=2, Reward=-4.15, EPSILON=0.982, (W=423,D=4,L=0)
2025-01-16 05:09:34,030 - INFO - Episode 2012/98900: Winner=2, Reward=-5.45, EPSILON=0.982, (W=424,D=4,L=0)
2025-01-16 05:09:34,363 - INFO - Episode 2013/98900: Winner=2, Reward=-33.25, EPSILON=0.982, (W=424,D=4,L=0)
2025-01-16 05:09:34,641 - INFO - Episode 2014/98900: Winner=2, Reward=-12.40, EPSILON=0.982, (W=424,D=4,L=0)
2025-01-16 05:09:35,103 - INFO - Episode 2015/98900: Winner=2, Reward=-82.45, EPSILON=0.982, (W=424,D=4,L=0)
2025-01-16 05:09:35,426 - INFO - Episode 2016/98900: Winner=2, Reward=22.55, EPSILON=0.982, (W=424,D=4,L=0)
2025-01-16 05:09:35,720 - INFO - Episode 2017/98900: Winner=2, Reward=-12.05, EPSILON=0.982, (W=424,D=4,L=0)
2025-01-16 05:09:35,734 - DEBUG - Q-vals = [0.13874827 0.03334023 0.07249261 0.00262778 0.01790045 0.62486315
 0.11002742], best_act=5, best_val=0.625
2025-01-16 05:09:35,734 - DEBUG - Low Q-value (0.625), using MCTS.
2025-01-16 05:09:35,735 - INFO - Running MCTS with 90 simulations using 6 processes.
2025-01-16 05:09:38,719 - DEBUG - Aggregated action counts: {4: 2, 3: 2, 2: 2}
2025-01-16 05:09:38,719 - DEBUG - Chose best action 4
2025-01-16 05:09:38,750 - DEBUG - Q-vals = [0.19376335 0.075499   0.09848718 0.01362482 0.09734108 0.44689867
 0.07438586], best_act=5, best_val=0.447
2025-01-16 05:09:38,750 - DEBUG - Low Q-value (0.447), using MCTS.
2025-01-16 05:09:38,750 - INFO - Running MCTS with 90 simulations using 6 processes.
2025-01-16 05:09:41,515 - DEBUG - Aggregated action counts: {0: 1, 6: 1, 4: 3, 2: 1}
2025-01-16 05:09:41,515 - DEBUG - Chose best action 4
2025-01-16 05:09:41,687 - DEBUG - Q-vals = [0.16749144 0.09878518 0.13484511 0.06725428 0.15408418 0.20818165
 0.16935809], best_act=5, best_val=0.208
2025-01-16 05:09:41,687 - DEBUG - Low Q-value (0.208), using MCTS.
2025-01-16 05:09:41,687 - INFO - Running MCTS with 90 simulations using 6 processes.
2025-01-16 05:09:44,514 - DEBUG - Aggregated action counts: {2: 2, 0: 2, 1: 1, 3: 1}
2025-01-16 05:09:44,514 - DEBUG - Chose best action 2
2025-01-16 05:09:44,655 - INFO - Episode 2018/98900: Winner=2, Reward=-42.25, EPSILON=0.982, (W=425,D=4,L=0)
2025-01-16 05:09:44,749 - INFO - Episode 2019/98900: Winner=2, Reward=8.75, EPSILON=0.982, (W=425,D=4,L=0)
2025-01-16 05:09:45,014 - INFO - Episode 2020/98900: Winner=2, Reward=-10.50, EPSILON=0.982, (W=425,D=4,L=0)
2025-01-16 05:09:45,373 - INFO - Episode 2021/98900: Winner=2, Reward=-54.50, EPSILON=0.982, (W=425,D=4,L=0)
2025-01-16 05:09:45,733 - INFO - Episode 2022/98900: Winner=2, Reward=-54.40, EPSILON=0.982, (W=426,D=4,L=0)
2025-01-16 05:09:45,998 - INFO - Episode 2023/98900: Winner=2, Reward=-5.75, EPSILON=0.982, (W=426,D=4,L=0)
2025-01-16 05:09:46,233 - INFO - Episode 2024/98900: Winner=2, Reward=3.15, EPSILON=0.982, (W=426,D=4,L=0)
2025-01-16 05:09:46,545 - INFO - Episode 2025/98900: Winner=2, Reward=-42.05, EPSILON=0.982, (W=427,D=4,L=0)
2025-01-16 05:09:46,889 - INFO - Episode 2026/98900: Winner=2, Reward=-13.55, EPSILON=0.982, (W=427,D=4,L=0)
2025-01-16 05:09:46,967 - DEBUG - Q-vals = [0.14387792 0.05578968 0.21844783 0.16795754 0.02738686 0.15966232
 0.22687788], best_act=6, best_val=0.227
2025-01-16 05:09:46,983 - DEBUG - Low Q-value (0.227), using MCTS.
2025-01-16 05:09:46,983 - INFO - Running MCTS with 91 simulations using 6 processes.
2025-01-16 05:09:49,810 - DEBUG - Aggregated action counts: {1: 3, 0: 3, 3: 1}
2025-01-16 05:09:49,810 - DEBUG - Chose best action 1
2025-01-16 05:09:49,857 - DEBUG - Q-vals = [0.1491915  0.13266282 0.11251834 0.14774218 0.20577243 0.12702061
 0.12509201], best_act=4, best_val=0.206
2025-01-16 05:09:49,857 - DEBUG - Low Q-value (0.206), using MCTS.
2025-01-16 05:09:49,857 - INFO - Running MCTS with 91 simulations using 6 processes.
2025-01-16 05:09:52,560 - DEBUG - Aggregated action counts: {3: 3, 0: 3, 1: 1}
2025-01-16 05:09:52,560 - DEBUG - Chose best action 3
2025-01-16 05:09:52,622 - INFO - Episode 2027/98900: Winner=2, Reward=-3.05, EPSILON=0.982, (W=427,D=4,L=0)
2025-01-16 05:09:52,888 - INFO - Episode 2028/98900: Winner=2, Reward=-14.15, EPSILON=0.982, (W=427,D=4,L=0)
2025-01-16 05:09:53,200 - INFO - Episode 2029/98900: Winner=2, Reward=-2.20, EPSILON=0.982, (W=428,D=4,L=0)
2025-01-16 05:09:53,591 - INFO - Episode 2030/98900: Winner=2, Reward=-44.35, EPSILON=0.982, (W=429,D=4,L=0)
2025-01-16 05:09:53,825 - INFO - Episode 2031/98900: Winner=2, Reward=-14.30, EPSILON=0.982, (W=430,D=4,L=0)
2025-01-16 05:09:54,060 - INFO - Episode 2032/98900: Winner=2, Reward=-19.95, EPSILON=0.982, (W=431,D=4,L=0)
2025-01-16 05:09:54,138 - INFO - Episode 2033/98900: Winner=2, Reward=8.20, EPSILON=0.982, (W=431,D=4,L=0)
2025-01-16 05:09:54,341 - INFO - Episode 2034/98900: Winner=2, Reward=0.05, EPSILON=0.982, (W=431,D=4,L=0)
2025-01-16 05:09:54,560 - INFO - Episode 2035/98900: Winner=2, Reward=-1.05, EPSILON=0.982, (W=431,D=4,L=0)
2025-01-16 05:09:54,778 - INFO - Episode 2036/98900: Winner=2, Reward=17.45, EPSILON=0.982, (W=431,D=4,L=0)
2025-01-16 05:09:54,825 - DEBUG - Q-vals = [0.22382574 0.16862383 0.03374368 0.06497997 0.17358673 0.26036942
 0.07487066], best_act=5, best_val=0.260
2025-01-16 05:09:54,825 - DEBUG - Low Q-value (0.260), using MCTS.
2025-01-16 05:09:54,825 - INFO - Running MCTS with 91 simulations using 6 processes.
2025-01-16 05:09:57,653 - DEBUG - Aggregated action counts: {5: 1, 1: 3, 0: 3}
2025-01-16 05:09:57,653 - DEBUG - Chose best action 1
2025-01-16 05:09:57,840 - INFO - Episode 2037/98900: Winner=2, Reward=4.20, EPSILON=0.982, (W=431,D=4,L=0)
2025-01-16 05:09:58,121 - INFO - Episode 2038/98900: Winner=2, Reward=-18.80, EPSILON=0.982, (W=432,D=4,L=0)
2025-01-16 05:09:58,324 - INFO - Episode 2039/98900: Winner=2, Reward=-14.60, EPSILON=0.982, (W=433,D=4,L=0)
2025-01-16 05:09:58,402 - DEBUG - Q-vals = [0.13839997 0.09148012 0.16750298 0.06368848 0.1887404  0.1977619
 0.15242612], best_act=5, best_val=0.198
2025-01-16 05:09:58,402 - DEBUG - Low Q-value (0.198), using MCTS.
2025-01-16 05:09:58,402 - INFO - Running MCTS with 91 simulations using 6 processes.
2025-01-16 05:10:01,123 - DEBUG - Aggregated action counts: {0: 2, 3: 1, 2: 3, 1: 1}
2025-01-16 05:10:01,123 - DEBUG - Chose best action 2
2025-01-16 05:10:01,277 - INFO - Episode 2040/98900: Winner=2, Reward=-16.50, EPSILON=0.982, (W=434,D=4,L=0)
2025-01-16 05:10:01,580 - INFO - Episode 2041/98900: Winner=2, Reward=-25.45, EPSILON=0.982, (W=435,D=4,L=0)
2025-01-16 05:10:01,787 - INFO - Episode 2042/98900: Winner=2, Reward=19.45, EPSILON=0.982, (W=435,D=4,L=0)
2025-01-16 05:10:02,200 - INFO - Episode 2043/98900: Winner=2, Reward=-67.95, EPSILON=0.982, (W=435,D=4,L=0)
2025-01-16 05:10:02,470 - INFO - Episode 2044/98900: Winner=2, Reward=-8.50, EPSILON=0.982, (W=435,D=4,L=0)
2025-01-16 05:10:02,572 - DEBUG - Q-vals = [0.16914342 0.11985192 0.07454596 0.03382652 0.19255732 0.29429755
 0.11577729], best_act=5, best_val=0.294
2025-01-16 05:10:02,572 - DEBUG - Low Q-value (0.294), using MCTS.
2025-01-16 05:10:02,573 - INFO - Running MCTS with 91 simulations using 6 processes.
2025-01-16 05:10:05,304 - DEBUG - Aggregated action counts: {4: 1, 0: 1, 2: 1, 1: 2, 5: 2}
2025-01-16 05:10:05,304 - DEBUG - Chose best action 1
2025-01-16 05:10:05,401 - INFO - Episode 2045/98900: Winner=2, Reward=5.20, EPSILON=0.982, (W=435,D=4,L=0)
2025-01-16 05:10:05,815 - DEBUG - Q-vals = [0.0964602  0.1070619  0.05899036 0.24666391 0.09387894 0.09351972
 0.30342492], best_act=3, best_val=0.247
2025-01-16 05:10:05,815 - DEBUG - Low Q-value (0.247), using MCTS.
2025-01-16 05:10:05,826 - INFO - Episode 2046/98900: Winner=2, Reward=-67.65, EPSILON=0.982, (W=436,D=4,L=0)
2025-01-16 05:10:06,099 - INFO - Episode 2047/98900: Winner=2, Reward=-7.60, EPSILON=0.982, (W=437,D=4,L=0)
2025-01-16 05:10:06,360 - DEBUG - Q-vals = [0.09024554 0.05336891 0.22282647 0.20715766 0.21943882 0.10232363
 0.10463904], best_act=2, best_val=0.223
2025-01-16 05:10:06,360 - DEBUG - Low Q-value (0.223), using MCTS.
2025-01-16 05:10:06,362 - INFO - Running MCTS with 91 simulations using 6 processes.
2025-01-16 05:10:10,066 - DEBUG - Aggregated action counts: {4: 2, 1: 2, 0: 3}
2025-01-16 05:10:10,066 - DEBUG - Chose best action 0
2025-01-16 05:10:10,077 - INFO - Episode 2048/98900: Winner=2, Reward=14.70, EPSILON=0.982, (W=437,D=4,L=0)
2025-01-16 05:10:10,411 - INFO - Episode 2049/98900: Winner=2, Reward=-12.65, EPSILON=0.982, (W=437,D=4,L=0)
2025-01-16 05:10:10,597 - INFO - Episode 2050/98900: Winner=2, Reward=-13.45, EPSILON=0.982, (W=438,D=4,L=0)
2025-01-16 05:10:10,753 - INFO - Episode 2051/98900: Winner=2, Reward=-9.15, EPSILON=0.982, (W=439,D=4,L=0)
2025-01-16 05:10:10,925 - INFO - Episode 2052/98900: Winner=2, Reward=-17.45, EPSILON=0.982, (W=440,D=4,L=0)
2025-01-16 05:10:11,097 - DEBUG - Q-vals = [0.11321063 0.079613   0.1111203  0.15434818 0.25361195 0.10798668
 0.18010934], best_act=4, best_val=0.254
2025-01-16 05:10:11,097 - DEBUG - Low Q-value (0.254), using MCTS.
2025-01-16 05:10:11,114 - INFO - Running MCTS with 92 simulations using 6 processes.
2025-01-16 05:10:14,780 - DEBUG - Aggregated action counts: {1: 1, 2: 2, 3: 2, 0: 2}
2025-01-16 05:10:14,780 - DEBUG - Chose best action 2
2025-01-16 05:10:14,931 - INFO - Episode 2053/98900: Winner=2, Reward=-4.95, EPSILON=0.982, (W=440,D=4,L=0)
2025-01-16 05:10:15,136 - INFO - Episode 2054/98900: Winner=2, Reward=1.60, EPSILON=0.982, (W=440,D=4,L=0)
2025-01-16 05:10:15,274 - INFO - Episode 2055/98900: Winner=2, Reward=-12.20, EPSILON=0.982, (W=441,D=4,L=0)
2025-01-16 05:10:15,539 - INFO - Episode 2056/98900: Winner=2, Reward=-20.05, EPSILON=0.982, (W=442,D=4,L=0)
2025-01-16 05:10:15,633 - INFO - Episode 2057/98900: Winner=2, Reward=2.10, EPSILON=0.982, (W=442,D=4,L=0)
2025-01-16 05:10:15,914 - INFO - Episode 2058/98900: Winner=2, Reward=-25.90, EPSILON=0.982, (W=443,D=4,L=0)
2025-01-16 05:10:16,180 - INFO - Episode 2059/98900: Winner=2, Reward=-8.65, EPSILON=0.982, (W=443,D=4,L=0)
2025-01-16 05:10:16,320 - INFO - Episode 2060/98900: Winner=2, Reward=1.90, EPSILON=0.982, (W=443,D=4,L=0)
2025-01-16 05:10:16,430 - INFO - Episode 2061/98900: Winner=2, Reward=-2.45, EPSILON=0.982, (W=443,D=4,L=0)
2025-01-16 05:10:16,680 - DEBUG - Q-vals = [0.03461574 0.02887913 0.12597871 0.43871328 0.05289458 0.08512789
 0.23379059], best_act=6, best_val=0.234
2025-01-16 05:10:16,680 - DEBUG - Low Q-value (0.234), using MCTS.
2025-01-16 05:10:16,695 - INFO - Episode 2062/98900: Winner=2, Reward=-14.55, EPSILON=0.982, (W=444,D=4,L=0)
2025-01-16 05:10:17,008 - INFO - Episode 2063/98900: Winner=2, Reward=13.10, EPSILON=0.982, (W=444,D=4,L=0)
2025-01-16 05:10:17,195 - INFO - Episode 2064/98900: Winner=2, Reward=-16.35, EPSILON=0.982, (W=445,D=4,L=0)
2025-01-16 05:10:17,430 - INFO - Episode 2065/98900: Winner=2, Reward=-11.80, EPSILON=0.982, (W=446,D=4,L=0)
2025-01-16 05:10:17,555 - INFO - Episode 2066/98900: Winner=2, Reward=0.50, EPSILON=0.982, (W=446,D=4,L=0)
2025-01-16 05:10:17,883 - INFO - Episode 2067/98900: Winner=2, Reward=-7.85, EPSILON=0.982, (W=447,D=4,L=0)
2025-01-16 05:10:18,039 - INFO - Episode 2068/98900: Winner=2, Reward=-10.35, EPSILON=0.982, (W=448,D=4,L=0)
2025-01-16 05:10:18,258 - INFO - Episode 2069/98900: Winner=2, Reward=-24.80, EPSILON=0.982, (W=449,D=4,L=0)
2025-01-16 05:10:18,492 - INFO - Episode 2070/98900: Winner=2, Reward=0.65, EPSILON=0.982, (W=449,D=4,L=0)
2025-01-16 05:10:18,757 - INFO - Episode 2071/98900: Winner=2, Reward=-20.65, EPSILON=0.982, (W=450,D=4,L=0)
2025-01-16 05:10:18,945 - INFO - Episode 2072/98900: Winner=2, Reward=5.65, EPSILON=0.982, (W=450,D=4,L=0)
2025-01-16 05:10:19,117 - INFO - Episode 2073/98900: Winner=2, Reward=-5.85, EPSILON=0.982, (W=450,D=4,L=0)
2025-01-16 05:10:19,273 - INFO - Episode 2074/98900: Winner=2, Reward=-8.25, EPSILON=0.982, (W=450,D=4,L=0)
2025-01-16 05:10:19,601 - INFO - Episode 2075/98900: Winner=2, Reward=-26.25, EPSILON=0.981, (W=451,D=4,L=0)
2025-01-16 05:10:19,804 - INFO - Episode 2076/98900: Winner=2, Reward=-10.25, EPSILON=0.981, (W=451,D=4,L=0)
2025-01-16 05:10:20,116 - INFO - Episode 2077/98900: Winner=2, Reward=8.00, EPSILON=0.981, (W=451,D=4,L=0)
2025-01-16 05:10:20,445 - INFO - Episode 2078/98900: Winner=2, Reward=6.55, EPSILON=0.981, (W=451,D=4,L=0)
2025-01-16 05:10:20,569 - INFO - Episode 2079/98900: Winner=2, Reward=12.40, EPSILON=0.981, (W=451,D=4,L=0)
2025-01-16 05:10:20,632 - INFO - Episode 2080/98900: Winner=2, Reward=-0.05, EPSILON=0.981, (W=451,D=4,L=0)
2025-01-16 05:10:20,939 - INFO - Episode 2081/98900: Winner=2, Reward=-40.45, EPSILON=0.981, (W=452,D=4,L=0)
2025-01-16 05:10:21,184 - INFO - Episode 2082/98900: Winner=2, Reward=8.20, EPSILON=0.981, (W=452,D=4,L=0)
2025-01-16 05:10:21,289 - INFO - Episode 2083/98900: Winner=2, Reward=3.95, EPSILON=0.981, (W=453,D=4,L=0)
2025-01-16 05:10:21,409 - DEBUG - Q-vals = [0.15813106 0.12435158 0.14001869 0.15477857 0.1444898  0.14242923
 0.13580108], best_act=0, best_val=0.158
2025-01-16 05:10:21,409 - DEBUG - Low Q-value (0.158), using MCTS.
2025-01-16 05:10:21,409 - INFO - Running MCTS with 93 simulations using 6 processes.
2025-01-16 05:10:24,249 - DEBUG - Aggregated action counts: {5: 2, 2: 1, 1: 1, 0: 2, 6: 1}
2025-01-16 05:10:24,249 - DEBUG - Chose best action 5
2025-01-16 05:10:24,327 - INFO - Episode 2084/98900: Winner=2, Reward=-20.75, EPSILON=0.981, (W=454,D=4,L=0)
2025-01-16 05:10:24,608 - INFO - Episode 2085/98900: Winner=2, Reward=-3.45, EPSILON=0.981, (W=454,D=4,L=0)
2025-01-16 05:10:24,811 - INFO - Episode 2086/98900: Winner=2, Reward=-23.20, EPSILON=0.981, (W=455,D=4,L=0)
2025-01-16 05:10:25,045 - INFO - Episode 2087/98900: Winner=2, Reward=-27.15, EPSILON=0.981, (W=456,D=4,L=0)
2025-01-16 05:10:25,233 - INFO - Episode 2088/98900: Winner=2, Reward=-7.80, EPSILON=0.981, (W=457,D=4,L=0)
2025-01-16 05:10:25,342 - INFO - Episode 2089/98900: Winner=2, Reward=5.85, EPSILON=0.981, (W=457,D=4,L=0)
2025-01-16 05:10:25,616 - INFO - Episode 2090/98900: Winner=2, Reward=-17.65, EPSILON=0.981, (W=457,D=4,L=0)
2025-01-16 05:10:25,881 - INFO - Episode 2091/98900: Winner=2, Reward=-19.00, EPSILON=0.981, (W=457,D=4,L=0)
2025-01-16 05:10:25,896 - DEBUG - Q-vals = [9.9630260e-01 3.5228820e-03 1.0780157e-05 2.2644565e-06 8.4930525e-06
 5.9390975e-05 9.3465511e-05], best_act=0, best_val=0.996
2025-01-16 05:10:25,896 - DEBUG - Low Q-value (0.996), using MCTS.
2025-01-16 05:10:25,896 - INFO - Running MCTS with 93 simulations using 6 processes.
2025-01-16 05:10:28,737 - DEBUG - Aggregated action counts: {1: 2, 0: 2, 6: 1, 4: 1, 3: 1}
2025-01-16 05:10:28,737 - DEBUG - Chose best action 1
2025-01-16 05:10:28,815 - DEBUG - Q-vals = [0.16935116 0.16799738 0.09929033 0.10590078 0.14603804 0.18193267
 0.12948963], best_act=5, best_val=0.182
2025-01-16 05:10:28,815 - DEBUG - Low Q-value (0.182), using MCTS.
2025-01-16 05:10:28,815 - INFO - Running MCTS with 93 simulations using 6 processes.
2025-01-16 05:10:31,622 - DEBUG - Aggregated action counts: {6: 1, 3: 1, 0: 4, 1: 1}
2025-01-16 05:10:31,622 - DEBUG - Chose best action 0
2025-01-16 05:10:31,674 - INFO - Episode 2092/98900: Winner=2, Reward=17.55, EPSILON=0.981, (W=457,D=4,L=0)
2025-01-16 05:10:32,007 - INFO - Episode 2093/98900: Winner=2, Reward=-24.35, EPSILON=0.981, (W=457,D=4,L=0)
2025-01-16 05:10:32,161 - INFO - Episode 2094/98900: Winner=2, Reward=12.00, EPSILON=0.981, (W=457,D=4,L=0)
2025-01-16 05:10:32,341 - INFO - Episode 2095/98900: Winner=2, Reward=-11.15, EPSILON=0.981, (W=457,D=4,L=0)
2025-01-16 05:10:32,654 - INFO - Episode 2096/98900: Winner=2, Reward=-57.25, EPSILON=0.981, (W=458,D=4,L=0)
2025-01-16 05:10:32,732 - INFO - Episode 2097/98900: Winner=2, Reward=0.00, EPSILON=0.981, (W=458,D=4,L=0)
2025-01-16 05:10:32,950 - INFO - Episode 2098/98900: Winner=2, Reward=3.65, EPSILON=0.981, (W=458,D=4,L=0)
2025-01-16 05:10:33,060 - INFO - Episode 2099/98900: Winner=2, Reward=9.95, EPSILON=0.981, (W=458,D=4,L=0)
2025-01-16 05:10:33,356 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2100.
2025-01-16 05:10:33,356 - INFO - Models saved at episode 2100
2025-01-16 05:10:33,372 - INFO - Target networks updated
2025-01-16 05:10:33,419 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2100.
2025-01-16 05:10:33,419 - INFO - Episode 2100/98900: Winner=2, Reward=-29.55, EPSILON=0.981, (W=459,D=4,L=0)
2025-01-16 05:10:33,642 - INFO - Episode 2101/98900: Winner=2, Reward=-8.45, EPSILON=0.981, (W=460,D=4,L=0)
2025-01-16 05:10:33,812 - INFO - Episode 2102/98900: Winner=2, Reward=2.40, EPSILON=0.981, (W=460,D=4,L=0)
2025-01-16 05:10:34,132 - INFO - Episode 2103/98900: Winner=2, Reward=-52.55, EPSILON=0.981, (W=461,D=4,L=0)
2025-01-16 05:10:34,399 - INFO - Episode 2104/98900: Winner=2, Reward=-19.75, EPSILON=0.981, (W=461,D=4,L=0)
2025-01-16 05:10:34,572 - INFO - Episode 2105/98900: Winner=2, Reward=-13.45, EPSILON=0.981, (W=462,D=4,L=0)
2025-01-16 05:10:34,769 - INFO - Episode 2106/98900: Winner=2, Reward=-14.35, EPSILON=0.981, (W=463,D=4,L=0)
2025-01-16 05:10:34,992 - DEBUG - Q-vals = [0.15612048 0.020872   0.35213107 0.13266969 0.0702707  0.07679856
 0.19113746], best_act=2, best_val=0.352
2025-01-16 05:10:34,992 - DEBUG - Low Q-value (0.352), using MCTS.
2025-01-16 05:10:34,992 - INFO - Running MCTS with 94 simulations using 6 processes.
2025-01-16 05:10:37,964 - DEBUG - Aggregated action counts: {3: 5, 0: 2}
2025-01-16 05:10:37,964 - DEBUG - Chose best action 3
2025-01-16 05:10:38,175 - INFO - Episode 2107/98900: Winner=2, Reward=-90.45, EPSILON=0.981, (W=464,D=4,L=0)
2025-01-16 05:10:38,464 - INFO - Episode 2108/98900: Winner=2, Reward=-25.90, EPSILON=0.981, (W=464,D=4,L=0)
2025-01-16 05:10:38,652 - INFO - Episode 2109/98900: Winner=2, Reward=-6.05, EPSILON=0.981, (W=464,D=4,L=0)
2025-01-16 05:10:38,777 - DEBUG - Q-vals = [0.09918135 0.26972485 0.02815201 0.24307774 0.02848602 0.22111166
 0.11026643], best_act=1, best_val=0.270
2025-01-16 05:10:38,777 - DEBUG - Low Q-value (0.270), using MCTS.
2025-01-16 05:10:38,777 - INFO - Running MCTS with 94 simulations using 6 processes.
2025-01-16 05:10:41,823 - DEBUG - Aggregated action counts: {0: 2, 4: 2, 5: 2, 2: 1}
2025-01-16 05:10:41,823 - DEBUG - Chose best action 0
2025-01-16 05:10:41,963 - INFO - Episode 2110/98900: Winner=2, Reward=-1.25, EPSILON=0.981, (W=465,D=4,L=0)
2025-01-16 05:10:42,276 - INFO - Episode 2111/98900: Winner=2, Reward=2.35, EPSILON=0.981, (W=466,D=4,L=0)
2025-01-16 05:10:42,557 - INFO - Episode 2112/98900: Winner=2, Reward=21.00, EPSILON=0.981, (W=466,D=4,L=0)
2025-01-16 05:10:42,823 - INFO - Episode 2113/98900: Winner=2, Reward=-4.95, EPSILON=0.981, (W=466,D=4,L=0)
2025-01-16 05:10:43,198 - INFO - Episode 2114/98900: Winner=2, Reward=-63.80, EPSILON=0.981, (W=466,D=4,L=0)
2025-01-16 05:10:43,369 - INFO - Episode 2115/98900: Winner=2, Reward=-12.25, EPSILON=0.981, (W=467,D=4,L=0)
2025-01-16 05:10:43,697 - INFO - Episode 2116/98900: Winner=2, Reward=-26.65, EPSILON=0.981, (W=468,D=4,L=0)
2025-01-16 05:10:43,854 - INFO - Episode 2117/98900: Winner=2, Reward=-14.65, EPSILON=0.981, (W=469,D=4,L=0)
2025-01-16 05:10:44,088 - DEBUG - Q-vals = [0.19308555 0.08816728 0.21328236 0.21604809 0.12472107 0.09367189
 0.07102381], best_act=3, best_val=0.216
2025-01-16 05:10:44,088 - DEBUG - Low Q-value (0.216), using MCTS.
2025-01-16 05:10:44,104 - INFO - Episode 2118/98900: Winner=2, Reward=-26.40, EPSILON=0.981, (W=470,D=4,L=0)
2025-01-16 05:10:44,338 - INFO - Episode 2119/98900: Winner=2, Reward=-6.45, EPSILON=0.981, (W=471,D=4,L=0)
2025-01-16 05:10:44,463 - DEBUG - Q-vals = [0.10084739 0.0650214  0.03585897 0.02546424 0.09926452 0.5743369
 0.09920666], best_act=5, best_val=0.574
2025-01-16 05:10:44,463 - DEBUG - Low Q-value (0.574), using MCTS.
2025-01-16 05:10:44,463 - INFO - Running MCTS with 94 simulations using 6 processes.
2025-01-16 05:10:47,315 - DEBUG - Aggregated action counts: {0: 3, 2: 2, 3: 1, 1: 1}
2025-01-16 05:10:47,315 - DEBUG - Chose best action 0
2025-01-16 05:10:47,424 - INFO - Episode 2120/98900: Winner=2, Reward=-12.75, EPSILON=0.981, (W=472,D=4,L=0)
2025-01-16 05:10:47,543 - INFO - Episode 2121/98900: Winner=2, Reward=-5.30, EPSILON=0.981, (W=473,D=4,L=0)
2025-01-16 05:10:47,749 - INFO - Episode 2122/98900: Winner=2, Reward=8.40, EPSILON=0.981, (W=473,D=4,L=0)
2025-01-16 05:10:47,837 - DEBUG - Q-vals = [0.23852783 0.08065974 0.13208824 0.08716615 0.14196266 0.19429523
 0.12530014], best_act=0, best_val=0.239
2025-01-16 05:10:47,838 - DEBUG - Low Q-value (0.239), using MCTS.
2025-01-16 05:10:47,838 - INFO - Running MCTS with 94 simulations using 6 processes.
2025-01-16 05:10:50,666 - DEBUG - Aggregated action counts: {2: 1, 0: 4, 6: 1, 1: 1}
2025-01-16 05:10:50,666 - DEBUG - Chose best action 0
2025-01-16 05:10:50,911 - INFO - Episode 2123/98900: Winner=2, Reward=-49.60, EPSILON=0.981, (W=474,D=4,L=0)
2025-01-16 05:10:50,928 - DEBUG - Q-vals = [2.3600790e-03 6.2016519e-03 5.2296533e-04 3.8174834e-04 4.2540632e-02
 9.4571304e-01 2.2798486e-03], best_act=5, best_val=0.946
2025-01-16 05:10:50,928 - DEBUG - Low Q-value (0.946), using MCTS.
2025-01-16 05:10:50,928 - INFO - Running MCTS with 94 simulations using 6 processes.
2025-01-16 05:10:53,785 - DEBUG - Aggregated action counts: {3: 2, 4: 2, 6: 1, 1: 1, 0: 1}
2025-01-16 05:10:53,785 - DEBUG - Chose best action 3
2025-01-16 05:10:54,011 - DEBUG - Q-vals = [0.15616332 0.1279383  0.07230452 0.22079569 0.07286091 0.07721435
 0.272723  ], best_act=3, best_val=0.221
2025-01-16 05:10:54,011 - DEBUG - Low Q-value (0.221), using MCTS.
2025-01-16 05:10:54,012 - INFO - Running MCTS with 94 simulations using 6 processes.
2025-01-16 05:10:56,892 - DEBUG - Aggregated action counts: {3: 2, 2: 1, 0: 3, 1: 1}
2025-01-16 05:10:56,893 - DEBUG - Chose best action 0
2025-01-16 05:10:56,972 - INFO - Episode 2124/98900: Winner=2, Reward=-38.30, EPSILON=0.981, (W=474,D=4,L=0)
2025-01-16 05:10:57,129 - INFO - Episode 2125/98900: Winner=2, Reward=7.65, EPSILON=0.981, (W=474,D=4,L=0)
2025-01-16 05:10:57,135 - DEBUG - Q-vals = [5.71617067e-01 3.53998505e-03 1.57409888e-02 1.12031549e-02
 1.09148765e-04 6.73545823e-02 3.30434978e-01], best_act=0, best_val=0.572
2025-01-16 05:10:57,135 - DEBUG - Low Q-value (0.572), using MCTS.
2025-01-16 05:10:57,135 - INFO - Running MCTS with 95 simulations using 6 processes.
2025-01-16 05:11:00,564 - DEBUG - Aggregated action counts: {4: 1, 1: 1, 5: 1, 2: 1, 0: 3}
2025-01-16 05:11:00,564 - DEBUG - Chose best action 0
2025-01-16 05:11:00,817 - INFO - Episode 2126/98900: Winner=2, Reward=-2.20, EPSILON=0.981, (W=474,D=4,L=0)
2025-01-16 05:11:00,832 - DEBUG - Q-vals = [0.00526125 0.01581497 0.00317097 0.00901084 0.00284649 0.94782096
 0.01607445], best_act=5, best_val=0.948
2025-01-16 05:11:00,832 - DEBUG - Low Q-value (0.948), using MCTS.
2025-01-16 05:11:00,832 - INFO - Running MCTS with 95 simulations using 6 processes.
2025-01-16 05:11:03,705 - DEBUG - Aggregated action counts: {0: 3, 2: 1, 5: 1, 3: 2}
2025-01-16 05:11:03,705 - DEBUG - Chose best action 0
2025-01-16 05:11:03,896 - INFO - Episode 2127/98900: Winner=2, Reward=-1.75, EPSILON=0.981, (W=474,D=4,L=0)
2025-01-16 05:11:04,208 - INFO - Episode 2128/98900: Winner=2, Reward=6.80, EPSILON=0.981, (W=475,D=4,L=0)
2025-01-16 05:11:04,484 - INFO - Episode 2129/98900: Winner=2, Reward=-17.50, EPSILON=0.981, (W=476,D=4,L=0)
2025-01-16 05:11:04,556 - INFO - Episode 2130/98900: Winner=2, Reward=0.10, EPSILON=0.981, (W=476,D=4,L=0)
2025-01-16 05:11:04,688 - INFO - Episode 2131/98900: Winner=2, Reward=-3.25, EPSILON=0.981, (W=476,D=4,L=0)
2025-01-16 05:11:04,864 - INFO - Episode 2132/98900: Winner=2, Reward=12.65, EPSILON=0.981, (W=476,D=4,L=0)
2025-01-16 05:11:05,085 - INFO - Episode 2133/98900: Winner=2, Reward=-15.20, EPSILON=0.981, (W=477,D=4,L=0)
2025-01-16 05:11:05,186 - DEBUG - Q-vals = [0.09252844 0.06437427 0.14573665 0.526197   0.05193521 0.06143251
 0.05779593], best_act=3, best_val=0.526
2025-01-16 05:11:05,186 - DEBUG - Low Q-value (0.526), using MCTS.
2025-01-16 05:11:05,187 - INFO - Running MCTS with 95 simulations using 6 processes.
2025-01-16 05:11:08,156 - DEBUG - Aggregated action counts: {4: 1, 2: 2, 3: 2, 0: 2}
2025-01-16 05:11:08,156 - DEBUG - Chose best action 2
2025-01-16 05:11:08,363 - INFO - Episode 2134/98900: Winner=2, Reward=-31.55, EPSILON=0.981, (W=478,D=4,L=0)
2025-01-16 05:11:08,452 - INFO - Episode 2135/98900: Winner=2, Reward=-10.45, EPSILON=0.981, (W=479,D=4,L=0)
2025-01-16 05:11:08,731 - INFO - Episode 2136/98900: Winner=2, Reward=-11.35, EPSILON=0.981, (W=479,D=4,L=0)
2025-01-16 05:11:09,105 - INFO - Episode 2137/98900: Winner=2, Reward=-34.00, EPSILON=0.981, (W=480,D=4,L=0)
2025-01-16 05:11:09,309 - INFO - Episode 2138/98900: Winner=2, Reward=3.25, EPSILON=0.981, (W=480,D=4,L=0)
2025-01-16 05:11:09,345 - DEBUG - Q-vals = [0.21213448 0.05803706 0.05812388 0.10123474 0.27628925 0.2051076
 0.08907302], best_act=4, best_val=0.276
2025-01-16 05:11:09,345 - DEBUG - Low Q-value (0.276), using MCTS.
2025-01-16 05:11:09,345 - INFO - Running MCTS with 95 simulations using 6 processes.
2025-01-16 05:11:12,256 - DEBUG - Aggregated action counts: {6: 1, 1: 2, 5: 1, 4: 2, 0: 1}
2025-01-16 05:11:12,257 - DEBUG - Chose best action 1
2025-01-16 05:11:12,468 - INFO - Episode 2139/98900: Winner=2, Reward=-34.65, EPSILON=0.981, (W=481,D=4,L=0)
2025-01-16 05:11:12,652 - INFO - Episode 2140/98900: Winner=2, Reward=0.30, EPSILON=0.981, (W=481,D=4,L=0)
2025-01-16 05:11:12,915 - INFO - Episode 2141/98900: Winner=2, Reward=-38.65, EPSILON=0.981, (W=482,D=4,L=0)
2025-01-16 05:11:13,022 - INFO - Episode 2142/98900: Winner=2, Reward=-0.65, EPSILON=0.981, (W=482,D=4,L=0)
2025-01-16 05:11:13,286 - INFO - Episode 2143/98900: Winner=2, Reward=-15.60, EPSILON=0.981, (W=483,D=4,L=0)
2025-01-16 05:11:13,422 - DEBUG - Q-vals = [0.16731003 0.14217143 0.14354184 0.15338244 0.10871291 0.14881884
 0.13606247], best_act=0, best_val=0.167
2025-01-16 05:11:13,423 - DEBUG - Low Q-value (0.167), using MCTS.
2025-01-16 05:11:13,423 - INFO - Running MCTS with 95 simulations using 6 processes.
2025-01-16 05:11:16,905 - DEBUG - Aggregated action counts: {3: 2, 6: 1, 1: 1, 4: 2, 0: 1}
2025-01-16 05:11:16,905 - DEBUG - Chose best action 3
2025-01-16 05:11:16,986 - INFO - Episode 2144/98900: Winner=2, Reward=5.95, EPSILON=0.981, (W=483,D=4,L=0)
2025-01-16 05:11:17,381 - INFO - Episode 2145/98900: Winner=2, Reward=-83.60, EPSILON=0.981, (W=484,D=4,L=0)
2025-01-16 05:11:17,497 - INFO - Episode 2146/98900: Winner=2, Reward=6.95, EPSILON=0.981, (W=484,D=4,L=0)
2025-01-16 05:11:17,577 - DEBUG - Q-vals = [0.17330447 0.13952163 0.10054294 0.21131115 0.06177806 0.2302015
 0.08334023], best_act=5, best_val=0.230
2025-01-16 05:11:17,577 - DEBUG - Low Q-value (0.230), using MCTS.
2025-01-16 05:11:17,578 - INFO - Running MCTS with 95 simulations using 6 processes.
2025-01-16 05:11:20,823 - DEBUG - Aggregated action counts: {2: 1, 0: 2, 3: 2, 4: 1, 5: 1}
2025-01-16 05:11:20,823 - DEBUG - Chose best action 0
2025-01-16 05:11:21,084 - INFO - Episode 2147/98900: Winner=2, Reward=-17.95, EPSILON=0.981, (W=484,D=4,L=0)
2025-01-16 05:11:21,286 - INFO - Episode 2148/98900: Winner=2, Reward=-9.00, EPSILON=0.981, (W=485,D=4,L=0)
2025-01-16 05:11:21,574 - INFO - Episode 2149/98900: Winner=2, Reward=0.40, EPSILON=0.981, (W=485,D=4,L=0)
2025-01-16 05:11:21,832 - INFO - Episode 2150/98900: Winner=2, Reward=4.90, EPSILON=0.981, (W=485,D=4,L=0)
2025-01-16 05:11:21,993 - INFO - Episode 2151/98900: Winner=2, Reward=-9.20, EPSILON=0.981, (W=486,D=4,L=0)
2025-01-16 05:11:22,268 - INFO - Episode 2152/98900: Winner=2, Reward=-1.85, EPSILON=0.981, (W=486,D=4,L=0)
2025-01-16 05:11:22,589 - INFO - Episode 2153/98900: Winner=2, Reward=-5.60, EPSILON=0.981, (W=486,D=4,L=0)
2025-01-16 05:11:22,829 - INFO - Episode 2154/98900: Winner=2, Reward=1.30, EPSILON=0.981, (W=487,D=4,L=0)
2025-01-16 05:11:23,088 - INFO - Episode 2155/98900: Winner=2, Reward=-14.10, EPSILON=0.981, (W=488,D=4,L=0)
2025-01-16 05:11:23,199 - DEBUG - Q-vals = [0.05255871 0.06833813 0.092278   0.3798629  0.06677049 0.16771814
 0.1724736 ], best_act=3, best_val=0.380
2025-01-16 05:11:23,199 - DEBUG - Low Q-value (0.380), using MCTS.
2025-01-16 05:11:23,199 - INFO - Running MCTS with 96 simulations using 6 processes.
2025-01-16 05:11:26,303 - DEBUG - Aggregated action counts: {5: 1, 4: 1, 1: 1, 2: 2, 0: 1}
2025-01-16 05:11:26,303 - DEBUG - Chose best action 2
2025-01-16 05:11:26,439 - INFO - Episode 2156/98900: Winner=2, Reward=-10.05, EPSILON=0.981, (W=489,D=4,L=0)
2025-01-16 05:11:26,583 - INFO - Episode 2157/98900: Winner=2, Reward=8.85, EPSILON=0.981, (W=489,D=4,L=0)
2025-01-16 05:11:26,687 - DEBUG - Q-vals = [0.17448755 0.11496241 0.19457155 0.1555823  0.04931283 0.12882094
 0.18226238], best_act=2, best_val=0.195
2025-01-16 05:11:26,688 - DEBUG - Low Q-value (0.195), using MCTS.
2025-01-16 05:11:26,688 - INFO - Running MCTS with 96 simulations using 6 processes.
2025-01-16 05:11:30,281 - DEBUG - Aggregated action counts: {3: 1, 5: 2, 0: 1, 4: 1, 1: 1}
2025-01-16 05:11:30,281 - DEBUG - Chose best action 5
2025-01-16 05:11:30,375 - DEBUG - Q-vals = [0.2985638  0.07629763 0.12397841 0.05309054 0.18081604 0.07809789
 0.18915568], best_act=0, best_val=0.299
2025-01-16 05:11:30,375 - DEBUG - Low Q-value (0.299), using MCTS.
2025-01-16 05:11:30,375 - INFO - Episode 2158/98900: Winner=2, Reward=-12.85, EPSILON=0.981, (W=490,D=4,L=0)
2025-01-16 05:11:30,569 - INFO - Episode 2159/98900: Winner=2, Reward=-12.85, EPSILON=0.981, (W=491,D=4,L=0)
2025-01-16 05:11:30,765 - INFO - Episode 2160/98900: Winner=2, Reward=8.45, EPSILON=0.981, (W=491,D=4,L=0)
2025-01-16 05:11:31,090 - INFO - Episode 2161/98900: Winner=2, Reward=-24.55, EPSILON=0.981, (W=492,D=4,L=0)
2025-01-16 05:11:31,264 - INFO - Episode 2162/98900: Winner=2, Reward=11.65, EPSILON=0.981, (W=492,D=4,L=0)
2025-01-16 05:11:31,610 - INFO - Episode 2163/98900: Winner=2, Reward=-11.30, EPSILON=0.981, (W=492,D=4,L=0)
2025-01-16 05:11:31,793 - INFO - Episode 2164/98900: Winner=2, Reward=15.15, EPSILON=0.981, (W=492,D=4,L=0)
2025-01-16 05:11:31,948 - INFO - Episode 2165/98900: Winner=2, Reward=10.80, EPSILON=0.981, (W=492,D=4,L=0)
2025-01-16 05:11:32,193 - DEBUG - Q-vals = [0.06975981 0.03140587 0.19150068 0.07865553 0.26202837 0.15752462
 0.2091251 ], best_act=4, best_val=0.262
2025-01-16 05:11:32,193 - DEBUG - Low Q-value (0.262), using MCTS.
2025-01-16 05:11:32,195 - INFO - Running MCTS with 96 simulations using 6 processes.
2025-01-16 05:11:35,931 - DEBUG - Aggregated action counts: {0: 6}
2025-01-16 05:11:35,931 - DEBUG - Chose best action 0
2025-01-16 05:11:35,965 - INFO - Episode 2166/98900: Winner=2, Reward=-23.90, EPSILON=0.981, (W=493,D=4,L=0)
2025-01-16 05:11:36,387 - INFO - Episode 2167/98900: Winner=2, Reward=-48.60, EPSILON=0.981, (W=494,D=4,L=0)
2025-01-16 05:11:36,703 - INFO - Episode 2168/98900: Winner=2, Reward=-14.30, EPSILON=0.981, (W=495,D=4,L=0)
2025-01-16 05:11:36,889 - DEBUG - Q-vals = [0.35370773 0.1440642  0.01786855 0.08862989 0.1535151  0.13160354
 0.11061107], best_act=0, best_val=0.354
2025-01-16 05:11:36,889 - DEBUG - Low Q-value (0.354), using MCTS.
2025-01-16 05:11:36,890 - INFO - Running MCTS with 96 simulations using 6 processes.
2025-01-16 05:11:39,696 - DEBUG - Aggregated action counts: {1: 1, 5: 2, 4: 1, 0: 1, 3: 1}
2025-01-16 05:11:39,696 - DEBUG - Chose best action 5
2025-01-16 05:11:39,820 - INFO - Episode 2169/98900: Winner=2, Reward=-57.95, EPSILON=0.981, (W=496,D=4,L=0)
2025-01-16 05:11:40,037 - INFO - Episode 2170/98900: Winner=2, Reward=-8.55, EPSILON=0.981, (W=497,D=4,L=0)
2025-01-16 05:11:40,115 - INFO - Episode 2171/98900: Winner=2, Reward=-10.00, EPSILON=0.981, (W=498,D=4,L=0)
2025-01-16 05:11:40,275 - DEBUG - Q-vals = [0.17871507 0.11813674 0.11179963 0.15073039 0.16086258 0.13258216
 0.14717348], best_act=0, best_val=0.179
2025-01-16 05:11:40,275 - DEBUG - Low Q-value (0.179), using MCTS.
2025-01-16 05:11:40,276 - INFO - Running MCTS with 96 simulations using 6 processes.
2025-01-16 05:11:43,054 - DEBUG - Aggregated action counts: {1: 1, 3: 1, 6: 1, 4: 1, 0: 2}
2025-01-16 05:11:43,054 - DEBUG - Chose best action 0
2025-01-16 05:11:43,253 - INFO - Episode 2172/98900: Winner=2, Reward=-21.75, EPSILON=0.981, (W=499,D=4,L=0)
2025-01-16 05:11:43,437 - INFO - Episode 2173/98900: Winner=2, Reward=-4.15, EPSILON=0.981, (W=499,D=4,L=0)
2025-01-16 05:11:43,701 - INFO - Episode 2174/98900: Winner=2, Reward=-22.40, EPSILON=0.981, (W=500,D=4,L=0)
2025-01-16 05:11:43,967 - INFO - Episode 2175/98900: Winner=2, Reward=-13.40, EPSILON=0.981, (W=501,D=4,L=0)
2025-01-16 05:11:44,045 - DEBUG - Q-vals = [0.11092584 0.06947238 0.21695659 0.09655874 0.16422462 0.20538123
 0.13648066], best_act=2, best_val=0.217
2025-01-16 05:11:44,045 - DEBUG - Low Q-value (0.217), using MCTS.
2025-01-16 05:11:44,045 - INFO - Running MCTS with 97 simulations using 6 processes.
2025-01-16 05:11:46,810 - DEBUG - Aggregated action counts: {3: 1, 6: 1, 4: 2, 1: 2, 0: 1}
2025-01-16 05:11:46,810 - DEBUG - Chose best action 4
2025-01-16 05:11:47,060 - INFO - Episode 2176/98900: Winner=2, Reward=-56.30, EPSILON=0.981, (W=501,D=4,L=0)
2025-01-16 05:11:47,349 - DEBUG - Q-vals = [0.12102649 0.06308987 0.26046386 0.16803248 0.21920876 0.06663326
 0.10154527], best_act=4, best_val=0.219
2025-01-16 05:11:47,349 - DEBUG - Low Q-value (0.219), using MCTS.
2025-01-16 05:11:47,349 - INFO - Running MCTS with 97 simulations using 6 processes.
2025-01-16 05:11:50,267 - DEBUG - Aggregated action counts: {1: 2, 0: 3, 3: 2}
2025-01-16 05:11:50,267 - DEBUG - Chose best action 0
2025-01-16 05:11:50,387 - INFO - Episode 2177/98900: Winner=2, Reward=-45.30, EPSILON=0.981, (W=502,D=4,L=0)
2025-01-16 05:11:50,650 - INFO - Episode 2178/98900: Winner=2, Reward=-17.25, EPSILON=0.981, (W=503,D=4,L=0)
2025-01-16 05:11:50,866 - INFO - Episode 2179/98900: Winner=2, Reward=-5.75, EPSILON=0.981, (W=503,D=4,L=0)
2025-01-16 05:11:50,955 - INFO - Episode 2180/98900: Winner=2, Reward=1.10, EPSILON=0.981, (W=503,D=4,L=0)
2025-01-16 05:11:50,958 - DEBUG - Q-vals = [0.07223091 0.04596879 0.01134696 0.02635766 0.02184522 0.77442837
 0.04782209], best_act=5, best_val=0.774
2025-01-16 05:11:50,958 - DEBUG - Low Q-value (0.774), using MCTS.
2025-01-16 05:11:50,958 - INFO - Running MCTS with 97 simulations using 6 processes.
2025-01-16 05:11:53,778 - DEBUG - Aggregated action counts: {2: 1, 3: 2, 1: 1, 0: 2, 5: 1}
2025-01-16 05:11:53,778 - DEBUG - Chose best action 3
2025-01-16 05:11:53,987 - INFO - Episode 2181/98900: Winner=2, Reward=-8.60, EPSILON=0.981, (W=503,D=4,L=0)
2025-01-16 05:11:54,273 - INFO - Episode 2182/98900: Winner=2, Reward=8.95, EPSILON=0.981, (W=503,D=4,L=0)
2025-01-16 05:11:54,445 - INFO - Episode 2183/98900: Winner=2, Reward=-11.05, EPSILON=0.981, (W=504,D=4,L=0)
2025-01-16 05:11:54,804 - INFO - Episode 2184/98900: Winner=2, Reward=-35.05, EPSILON=0.981, (W=505,D=4,L=0)
2025-01-16 05:11:54,958 - INFO - Episode 2185/98900: Winner=2, Reward=-13.45, EPSILON=0.981, (W=506,D=4,L=0)
2025-01-16 05:11:55,126 - DEBUG - Q-vals = [0.06756555 0.09029568 0.06100331 0.45235696 0.10116658 0.11879924
 0.10881262], best_act=3, best_val=0.452
2025-01-16 05:11:55,126 - DEBUG - Low Q-value (0.452), using MCTS.
2025-01-16 05:11:55,138 - INFO - Episode 2186/98900: Winner=2, Reward=-15.45, EPSILON=0.981, (W=507,D=4,L=0)
2025-01-16 05:11:55,383 - INFO - Episode 2187/98900: Winner=2, Reward=-20.85, EPSILON=0.981, (W=508,D=4,L=0)
2025-01-16 05:11:55,503 - INFO - Episode 2188/98900: Winner=2, Reward=-6.25, EPSILON=0.981, (W=509,D=4,L=0)
2025-01-16 05:11:55,703 - INFO - Episode 2189/98900: Winner=2, Reward=3.70, EPSILON=0.980, (W=509,D=4,L=0)
2025-01-16 05:11:56,009 - INFO - Episode 2190/98900: Winner=2, Reward=-11.45, EPSILON=0.980, (W=509,D=4,L=0)
2025-01-16 05:11:56,241 - INFO - Episode 2191/98900: Winner=2, Reward=4.85, EPSILON=0.980, (W=509,D=4,L=0)
2025-01-16 05:11:56,490 - INFO - Episode 2192/98900: Winner=2, Reward=-16.85, EPSILON=0.980, (W=510,D=4,L=0)
2025-01-16 05:11:56,845 - INFO - Episode 2193/98900: Winner=2, Reward=-6.65, EPSILON=0.980, (W=510,D=4,L=0)
2025-01-16 05:11:57,045 - INFO - Episode 2194/98900: Winner=2, Reward=-5.00, EPSILON=0.980, (W=511,D=4,L=0)
2025-01-16 05:11:57,245 - INFO - Episode 2195/98900: Winner=2, Reward=-12.10, EPSILON=0.980, (W=511,D=4,L=0)
2025-01-16 05:11:57,427 - INFO - Episode 2196/98900: Winner=2, Reward=-5.30, EPSILON=0.980, (W=511,D=4,L=0)
2025-01-16 05:11:57,674 - INFO - Episode 2197/98900: Winner=2, Reward=-10.35, EPSILON=0.980, (W=512,D=4,L=0)
2025-01-16 05:11:57,829 - INFO - Episode 2198/98900: Winner=2, Reward=-3.35, EPSILON=0.980, (W=512,D=4,L=0)
2025-01-16 05:11:58,118 - INFO - Episode 2199/98900: Winner=2, Reward=-14.00, EPSILON=0.980, (W=513,D=4,L=0)
2025-01-16 05:11:58,474 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2200.
2025-01-16 05:11:58,474 - INFO - Models saved at episode 2200
2025-01-16 05:11:58,474 - INFO - Target networks updated
2025-01-16 05:11:58,537 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2200.
2025-01-16 05:11:58,537 - INFO - Episode 2200/98900: Winner=2, Reward=-31.20, EPSILON=0.980, (W=514,D=4,L=0)
2025-01-16 05:11:58,651 - INFO - Episode 2201/98900: Winner=2, Reward=0.20, EPSILON=0.980, (W=514,D=4,L=0)
2025-01-16 05:11:58,930 - INFO - Episode 2202/98900: Winner=2, Reward=15.05, EPSILON=0.980, (W=514,D=4,L=0)
2025-01-16 05:11:59,185 - INFO - Episode 2203/98900: Winner=2, Reward=-4.95, EPSILON=0.980, (W=514,D=4,L=0)
2025-01-16 05:11:59,354 - INFO - Episode 2204/98900: Winner=2, Reward=2.70, EPSILON=0.980, (W=514,D=4,L=0)
2025-01-16 05:11:59,550 - INFO - Episode 2205/98900: Winner=2, Reward=-10.80, EPSILON=0.980, (W=515,D=4,L=0)
2025-01-16 05:11:59,836 - INFO - Episode 2206/98900: Winner=2, Reward=14.65, EPSILON=0.980, (W=515,D=4,L=0)
2025-01-16 05:12:00,203 - INFO - Episode 2207/98900: Winner=2, Reward=-41.65, EPSILON=0.980, (W=515,D=4,L=0)
2025-01-16 05:12:00,533 - INFO - Episode 2208/98900: Winner=2, Reward=-11.80, EPSILON=0.980, (W=515,D=4,L=0)
2025-01-16 05:12:00,591 - DEBUG - Q-vals = [0.09907804 0.0708406  0.07345605 0.03146376 0.18483488 0.40518126
 0.1351454 ], best_act=5, best_val=0.405
2025-01-16 05:12:00,591 - DEBUG - Low Q-value (0.405), using MCTS.
2025-01-16 05:12:00,591 - INFO - Running MCTS with 98 simulations using 6 processes.
2025-01-16 05:12:03,353 - DEBUG - Aggregated action counts: {3: 1, 2: 2, 6: 1, 0: 2, 4: 1}
2025-01-16 05:12:03,354 - DEBUG - Chose best action 2
2025-01-16 05:12:03,618 - INFO - Episode 2209/98900: Winner=2, Reward=-10.70, EPSILON=0.980, (W=515,D=4,L=0)
2025-01-16 05:12:03,786 - INFO - Episode 2210/98900: Winner=2, Reward=9.35, EPSILON=0.980, (W=515,D=4,L=0)
2025-01-16 05:12:04,158 - INFO - Episode 2211/98900: Winner=2, Reward=-1.40, EPSILON=0.980, (W=515,D=4,L=0)
2025-01-16 05:12:04,291 - INFO - Episode 2212/98900: Winner=2, Reward=13.05, EPSILON=0.980, (W=515,D=4,L=0)
2025-01-16 05:12:04,431 - INFO - Episode 2213/98900: Winner=2, Reward=0.25, EPSILON=0.980, (W=515,D=4,L=0)
2025-01-16 05:12:04,773 - INFO - Episode 2214/98900: Winner=2, Reward=-10.40, EPSILON=0.980, (W=516,D=4,L=0)
2025-01-16 05:12:05,008 - INFO - Episode 2215/98900: Winner=2, Reward=-12.50, EPSILON=0.980, (W=517,D=4,L=0)
2025-01-16 05:12:05,234 - DEBUG - Q-vals = [0.26269722 0.18001376 0.080773   0.03961304 0.22954087 0.12838419
 0.07897792], best_act=4, best_val=0.230
2025-01-16 05:12:05,234 - DEBUG - Low Q-value (0.230), using MCTS.
2025-01-16 05:12:05,244 - INFO - Episode 2216/98900: Winner=2, Reward=-17.35, EPSILON=0.980, (W=518,D=4,L=0)
2025-01-16 05:12:05,458 - INFO - Episode 2217/98900: Winner=2, Reward=-9.00, EPSILON=0.980, (W=519,D=4,L=0)
2025-01-16 05:12:05,725 - INFO - Episode 2218/98900: Winner=2, Reward=-21.35, EPSILON=0.980, (W=519,D=4,L=0)
2025-01-16 05:12:05,994 - INFO - Episode 2219/98900: Winner=2, Reward=-2.25, EPSILON=0.980, (W=520,D=4,L=0)
2025-01-16 05:12:06,158 - DEBUG - Q-vals = [0.13118729 0.0962211  0.16568008 0.24739861 0.09644113 0.13495685
 0.12811495], best_act=3, best_val=0.247
2025-01-16 05:12:06,158 - DEBUG - Low Q-value (0.247), using MCTS.
2025-01-16 05:12:06,158 - INFO - Running MCTS with 98 simulations using 6 processes.
2025-01-16 05:12:09,649 - DEBUG - Aggregated action counts: {2: 2, 1: 2, 3: 1, 0: 2}
2025-01-16 05:12:09,649 - DEBUG - Chose best action 2
2025-01-16 05:12:09,682 - INFO - Episode 2220/98900: Winner=2, Reward=-11.15, EPSILON=0.980, (W=521,D=4,L=0)
2025-01-16 05:12:09,868 - INFO - Episode 2221/98900: Winner=2, Reward=-10.15, EPSILON=0.980, (W=522,D=4,L=0)
2025-01-16 05:12:09,983 - INFO - Episode 2222/98900: Winner=2, Reward=-9.95, EPSILON=0.980, (W=523,D=4,L=0)
2025-01-16 05:12:10,243 - INFO - Episode 2223/98900: Winner=2, Reward=-18.10, EPSILON=0.980, (W=524,D=4,L=0)
2025-01-16 05:12:10,361 - INFO - Episode 2224/98900: Winner=2, Reward=-1.75, EPSILON=0.980, (W=524,D=4,L=0)
2025-01-16 05:12:10,517 - INFO - Episode 2225/98900: Winner=2, Reward=-16.00, EPSILON=0.980, (W=525,D=4,L=0)
2025-01-16 05:12:10,767 - DEBUG - Q-vals = [0.27337873 0.04770791 0.2649306  0.22412543 0.08077832 0.03467655
 0.07440235], best_act=2, best_val=0.265
2025-01-16 05:12:10,767 - DEBUG - Low Q-value (0.265), using MCTS.
2025-01-16 05:12:10,767 - INFO - Episode 2226/98900: Winner=2, Reward=-20.50, EPSILON=0.980, (W=526,D=4,L=0)
2025-01-16 05:12:11,133 - INFO - Episode 2227/98900: Winner=2, Reward=-46.05, EPSILON=0.980, (W=526,D=4,L=0)
2025-01-16 05:12:11,351 - INFO - Episode 2228/98900: Winner=2, Reward=-15.75, EPSILON=0.980, (W=526,D=4,L=0)
2025-01-16 05:12:11,632 - INFO - Episode 2229/98900: Winner=2, Reward=-17.75, EPSILON=0.980, (W=526,D=4,L=0)
2025-01-16 05:12:11,788 - INFO - Episode 2230/98900: Winner=2, Reward=17.55, EPSILON=0.980, (W=526,D=4,L=0)
2025-01-16 05:12:11,992 - INFO - Episode 2231/98900: Winner=2, Reward=-9.20, EPSILON=0.980, (W=527,D=4,L=0)
2025-01-16 05:12:12,170 - INFO - Episode 2232/98900: Winner=2, Reward=-7.75, EPSILON=0.980, (W=528,D=4,L=0)
2025-01-16 05:12:12,526 - INFO - Episode 2233/98900: Winner=2, Reward=-26.35, EPSILON=0.980, (W=529,D=4,L=0)
2025-01-16 05:12:12,639 - INFO - Episode 2234/98900: Winner=2, Reward=8.80, EPSILON=0.980, (W=529,D=4,L=0)
2025-01-16 05:12:12,777 - INFO - Episode 2235/98900: Winner=2, Reward=1.50, EPSILON=0.980, (W=529,D=4,L=0)
2025-01-16 05:12:12,921 - DEBUG - Q-vals = [0.09673177 0.04540876 0.24661121 0.48049778 0.0587879  0.03900205
 0.03296052], best_act=3, best_val=0.480
2025-01-16 05:12:12,921 - DEBUG - Low Q-value (0.480), using MCTS.
2025-01-16 05:12:12,921 - INFO - Running MCTS with 99 simulations using 6 processes.
2025-01-16 05:12:16,215 - DEBUG - Aggregated action counts: {5: 1, 3: 2, 1: 1, 2: 2, 0: 1}
2025-01-16 05:12:16,215 - DEBUG - Chose best action 3
2025-01-16 05:12:16,246 - INFO - Episode 2236/98900: Winner=2, Reward=1.00, EPSILON=0.980, (W=529,D=4,L=0)
2025-01-16 05:12:16,371 - INFO - Episode 2237/98900: Winner=2, Reward=-3.75, EPSILON=0.980, (W=529,D=4,L=0)
2025-01-16 05:12:16,574 - INFO - Episode 2238/98900: Winner=2, Reward=9.05, EPSILON=0.980, (W=529,D=4,L=0)
2025-01-16 05:12:16,605 - DEBUG - Q-vals = [0.27625236 0.10668398 0.01999077 0.00628551 0.00172765 0.5083036
 0.0807561 ], best_act=5, best_val=0.508
2025-01-16 05:12:16,605 - DEBUG - Low Q-value (0.508), using MCTS.
2025-01-16 05:12:16,605 - INFO - Running MCTS with 99 simulations using 6 processes.
2025-01-16 05:12:19,948 - DEBUG - Aggregated action counts: {0: 3, 2: 1, 1: 1, 6: 1, 5: 1}
2025-01-16 05:12:19,948 - DEBUG - Chose best action 0
2025-01-16 05:12:20,307 - INFO - Episode 2239/98900: Winner=2, Reward=-45.85, EPSILON=0.980, (W=530,D=4,L=0)
2025-01-16 05:12:20,479 - INFO - Episode 2240/98900: Winner=2, Reward=27.85, EPSILON=0.980, (W=530,D=4,L=0)
2025-01-16 05:12:20,792 - INFO - Episode 2241/98900: Winner=2, Reward=-37.95, EPSILON=0.980, (W=531,D=4,L=0)
2025-01-16 05:12:21,104 - INFO - Episode 2242/98900: Winner=2, Reward=-15.85, EPSILON=0.980, (W=531,D=4,L=0)
2025-01-16 05:12:21,323 - INFO - Episode 2243/98900: Winner=2, Reward=11.05, EPSILON=0.980, (W=531,D=4,L=0)
2025-01-16 05:12:21,401 - INFO - Episode 2244/98900: Winner=2, Reward=1.40, EPSILON=0.980, (W=531,D=4,L=0)
2025-01-16 05:12:21,635 - INFO - Episode 2245/98900: Winner=2, Reward=-10.15, EPSILON=0.980, (W=531,D=4,L=0)
2025-01-16 05:12:21,807 - DEBUG - Q-vals = [0.05153494 0.07529412 0.11481784 0.5199943  0.02866149 0.13967799
 0.07001934], best_act=3, best_val=0.520
2025-01-16 05:12:21,807 - DEBUG - Low Q-value (0.520), using MCTS.
2025-01-16 05:12:21,807 - INFO - Running MCTS with 99 simulations using 6 processes.
2025-01-16 05:12:25,252 - DEBUG - Aggregated action counts: {1: 2, 6: 1, 0: 2, 4: 1, 2: 1}
2025-01-16 05:12:25,252 - DEBUG - Chose best action 1
2025-01-16 05:12:25,392 - INFO - Episode 2246/98900: Winner=2, Reward=-4.40, EPSILON=0.980, (W=531,D=4,L=0)
2025-01-16 05:12:25,658 - INFO - Episode 2247/98900: Winner=2, Reward=-3.55, EPSILON=0.980, (W=531,D=4,L=0)
2025-01-16 05:12:25,830 - INFO - Episode 2248/98900: Winner=2, Reward=14.30, EPSILON=0.980, (W=531,D=4,L=0)
2025-01-16 05:12:26,033 - INFO - Episode 2249/98900: Winner=2, Reward=2.15, EPSILON=0.980, (W=531,D=4,L=0)
2025-01-16 05:12:26,220 - INFO - Episode 2250/98900: Winner=2, Reward=-4.65, EPSILON=0.980, (W=531,D=4,L=0)
2025-01-16 05:12:26,517 - INFO - Episode 2251/98900: Winner=2, Reward=14.90, EPSILON=0.980, (W=531,D=4,L=0)
2025-01-16 05:12:26,705 - INFO - Episode 2252/98900: Winner=2, Reward=-2.50, EPSILON=0.980, (W=532,D=4,L=0)
2025-01-16 05:12:26,720 - DEBUG - Q-vals = [0.19294643 0.13765623 0.01871386 0.3000979  0.00919347 0.23631817
 0.10507387], best_act=3, best_val=0.300
2025-01-16 05:12:26,720 - DEBUG - Low Q-value (0.300), using MCTS.
2025-01-16 05:12:26,720 - INFO - Running MCTS with 100 simulations using 6 processes.
2025-01-16 05:12:29,814 - DEBUG - Aggregated action counts: {1: 3, 0: 3, 3: 1}
2025-01-16 05:12:29,814 - DEBUG - Chose best action 1
2025-01-16 05:12:30,095 - INFO - Episode 2253/98900: Winner=2, Reward=-6.55, EPSILON=0.980, (W=532,D=4,L=0)
2025-01-16 05:12:30,205 - INFO - Episode 2254/98900: Winner=2, Reward=-9.60, EPSILON=0.980, (W=533,D=4,L=0)
2025-01-16 05:12:30,580 - INFO - Episode 2255/98900: Winner=2, Reward=-40.05, EPSILON=0.980, (W=534,D=4,L=0)
2025-01-16 05:12:30,830 - INFO - Episode 2256/98900: Winner=2, Reward=1.85, EPSILON=0.980, (W=534,D=4,L=0)
2025-01-16 05:12:31,251 - INFO - Episode 2257/98900: Winner=2, Reward=-68.50, EPSILON=0.980, (W=534,D=4,L=0)
2025-01-16 05:12:31,595 - INFO - Episode 2258/98900: Winner=2, Reward=-35.30, EPSILON=0.980, (W=535,D=4,L=0)
2025-01-16 05:12:31,939 - INFO - Episode 2259/98900: Winner=2, Reward=-15.95, EPSILON=0.980, (W=535,D=4,L=0)
2025-01-16 05:12:32,173 - INFO - Episode 2260/98900: Winner=2, Reward=-18.25, EPSILON=0.980, (W=536,D=4,L=0)
2025-01-16 05:12:32,564 - INFO - Episode 2261/98900: Winner=2, Reward=-49.35, EPSILON=0.980, (W=536,D=4,L=0)
2025-01-16 05:12:32,846 - INFO - Episode 2262/98900: Winner=2, Reward=-10.90, EPSILON=0.980, (W=536,D=4,L=0)
2025-01-16 05:12:33,221 - INFO - Episode 2263/98900: Winner=2, Reward=-77.50, EPSILON=0.980, (W=536,D=4,L=0)
2025-01-16 05:12:33,455 - INFO - Episode 2264/98900: Winner=2, Reward=7.75, EPSILON=0.980, (W=536,D=4,L=0)
2025-01-16 05:12:33,611 - INFO - Episode 2265/98900: Winner=2, Reward=-9.50, EPSILON=0.980, (W=537,D=4,L=0)
2025-01-16 05:12:33,752 - INFO - Episode 2266/98900: Winner=2, Reward=1.70, EPSILON=0.980, (W=537,D=4,L=0)
2025-01-16 05:12:34,033 - INFO - Episode 2267/98900: Winner=2, Reward=-12.55, EPSILON=0.980, (W=538,D=4,L=0)
2025-01-16 05:12:34,173 - INFO - Episode 2268/98900: Winner=2, Reward=-6.40, EPSILON=0.980, (W=538,D=4,L=0)
2025-01-16 05:12:34,314 - INFO - Episode 2269/98900: Winner=2, Reward=6.50, EPSILON=0.980, (W=539,D=4,L=0)
2025-01-16 05:12:34,595 - INFO - Episode 2270/98900: Winner=2, Reward=0.00, EPSILON=0.980, (W=539,D=4,L=0)
2025-01-16 05:12:34,673 - INFO - Episode 2271/98900: Winner=2, Reward=1.10, EPSILON=0.980, (W=539,D=4,L=0)
2025-01-16 05:12:34,970 - INFO - Episode 2272/98900: Winner=2, Reward=-20.40, EPSILON=0.980, (W=540,D=4,L=0)
2025-01-16 05:12:35,064 - DEBUG - Q-vals = [0.11368102 0.09054603 0.20025055 0.2962164  0.06929614 0.13441178
 0.09559817], best_act=3, best_val=0.296
2025-01-16 05:12:35,064 - DEBUG - Low Q-value (0.296), using MCTS.
2025-01-16 05:12:35,064 - INFO - Running MCTS with 100 simulations using 6 processes.
2025-01-16 05:12:37,923 - DEBUG - Aggregated action counts: {3: 2, 2: 1, 1: 2, 0: 2}
2025-01-16 05:12:37,923 - DEBUG - Chose best action 3
2025-01-16 05:12:38,110 - DEBUG - Q-vals = [0.05255335 0.1872848  0.04368505 0.41033784 0.04076518 0.18148664
 0.08388708], best_act=3, best_val=0.410
2025-01-16 05:12:38,110 - DEBUG - Low Q-value (0.410), using MCTS.
2025-01-16 05:12:38,126 - INFO - Episode 2273/98900: Winner=2, Reward=-29.15, EPSILON=0.980, (W=541,D=4,L=0)
2025-01-16 05:12:38,298 - INFO - Episode 2274/98900: Winner=2, Reward=-14.85, EPSILON=0.980, (W=542,D=4,L=0)
2025-01-16 05:12:38,579 - INFO - Episode 2275/98900: Winner=2, Reward=12.45, EPSILON=0.980, (W=542,D=4,L=0)
2025-01-16 05:12:38,766 - INFO - Episode 2276/98900: Winner=2, Reward=10.55, EPSILON=0.980, (W=542,D=4,L=0)
2025-01-16 05:12:38,860 - INFO - Episode 2277/98900: Winner=2, Reward=4.45, EPSILON=0.980, (W=542,D=4,L=0)
2025-01-16 05:12:39,048 - INFO - Episode 2278/98900: Winner=2, Reward=-12.25, EPSILON=0.980, (W=543,D=4,L=0)
2025-01-16 05:12:39,313 - INFO - Episode 2279/98900: Winner=2, Reward=-11.65, EPSILON=0.980, (W=544,D=4,L=0)
2025-01-16 05:12:39,501 - INFO - Episode 2280/98900: Winner=2, Reward=-0.45, EPSILON=0.980, (W=544,D=4,L=0)
2025-01-16 05:12:39,672 - INFO - Episode 2281/98900: Winner=2, Reward=-5.80, EPSILON=0.980, (W=545,D=4,L=0)
2025-01-16 05:12:39,954 - INFO - Episode 2282/98900: Winner=2, Reward=4.35, EPSILON=0.980, (W=545,D=4,L=0)
2025-01-16 05:12:40,125 - DEBUG - Q-vals = [0.13494775 0.06898427 0.18162936 0.20159332 0.09726784 0.12994802
 0.18562953], best_act=3, best_val=0.202
2025-01-16 05:12:40,125 - DEBUG - Low Q-value (0.202), using MCTS.
2025-01-16 05:12:40,125 - INFO - Episode 2283/98900: Winner=2, Reward=0.25, EPSILON=0.980, (W=546,D=4,L=0)
2025-01-16 05:12:40,360 - INFO - Episode 2284/98900: Winner=2, Reward=-20.25, EPSILON=0.980, (W=547,D=4,L=0)
2025-01-16 05:12:40,578 - DEBUG - Q-vals = [0.04196068 0.02767843 0.26578474 0.34435472 0.00646756 0.19865811
 0.11509572], best_act=3, best_val=0.344
2025-01-16 05:12:40,578 - DEBUG - Low Q-value (0.344), using MCTS.
2025-01-16 05:12:40,578 - INFO - Running MCTS with 101 simulations using 6 processes.
2025-01-16 05:12:43,250 - DEBUG - Aggregated action counts: {6: 1, 0: 3, 2: 2, 1: 1}
2025-01-16 05:12:43,250 - DEBUG - Chose best action 0
2025-01-16 05:12:43,265 - INFO - Episode 2285/98900: Winner=2, Reward=9.75, EPSILON=0.980, (W=547,D=4,L=0)
2025-01-16 05:12:43,422 - INFO - Episode 2286/98900: Winner=2, Reward=0.85, EPSILON=0.980, (W=547,D=4,L=0)
2025-01-16 05:12:43,484 - DEBUG - Q-vals = [0.11039834 0.03814497 0.0965943  0.08728374 0.05042152 0.24294345
 0.37421367], best_act=6, best_val=0.374
2025-01-16 05:12:43,484 - DEBUG - Low Q-value (0.374), using MCTS.
2025-01-16 05:12:43,484 - INFO - Running MCTS with 101 simulations using 6 processes.
2025-01-16 05:12:46,249 - DEBUG - Aggregated action counts: {3: 4, 5: 1, 2: 1, 0: 1}
2025-01-16 05:12:46,249 - DEBUG - Chose best action 3
2025-01-16 05:12:46,358 - INFO - Episode 2287/98900: Winner=2, Reward=-11.75, EPSILON=0.980, (W=548,D=4,L=0)
2025-01-16 05:12:46,561 - DEBUG - Q-vals = [0.22419348 0.06453276 0.20823424 0.05142836 0.1925436  0.11433032
 0.14473721], best_act=0, best_val=0.224
2025-01-16 05:12:46,561 - DEBUG - Low Q-value (0.224), using MCTS.
2025-01-16 05:12:46,561 - INFO - Running MCTS with 101 simulations using 6 processes.
2025-01-16 05:12:49,327 - DEBUG - Aggregated action counts: {1: 2, 0: 3, 3: 2}
2025-01-16 05:12:49,327 - DEBUG - Chose best action 0
2025-01-16 05:12:49,452 - INFO - Episode 2288/98900: Winner=2, Reward=-26.35, EPSILON=0.980, (W=549,D=4,L=0)
2025-01-16 05:12:49,764 - INFO - Episode 2289/98900: Winner=2, Reward=-24.35, EPSILON=0.980, (W=550,D=4,L=0)
2025-01-16 05:12:49,873 - DEBUG - Q-vals = [0.12442838 0.06550221 0.22599809 0.10232052 0.20617938 0.15718892
 0.11838251], best_act=2, best_val=0.226
2025-01-16 05:12:49,873 - DEBUG - Low Q-value (0.226), using MCTS.
2025-01-16 05:12:49,873 - INFO - Running MCTS with 101 simulations using 6 processes.
2025-01-16 05:12:52,670 - DEBUG - Aggregated action counts: {2: 1, 0: 4, 4: 1, 3: 1}
2025-01-16 05:12:52,670 - DEBUG - Chose best action 0
2025-01-16 05:12:52,811 - INFO - Episode 2290/98900: Winner=2, Reward=-6.05, EPSILON=0.980, (W=551,D=4,L=0)
2025-01-16 05:12:52,967 - INFO - Episode 2291/98900: Winner=2, Reward=-12.35, EPSILON=0.980, (W=552,D=4,L=0)
2025-01-16 05:12:53,358 - DEBUG - Q-vals = [0.0355294  0.01081356 0.35163742 0.44926497 0.05835448 0.03308781
 0.06131241], best_act=6, best_val=0.061
2025-01-16 05:12:53,358 - DEBUG - Low Q-value (0.061), using MCTS.
2025-01-16 05:12:53,358 - INFO - Episode 2292/98900: Winner=2, Reward=-68.75, EPSILON=0.980, (W=553,D=4,L=0)
2025-01-16 05:12:53,561 - INFO - Episode 2293/98900: Winner=2, Reward=-3.00, EPSILON=0.980, (W=553,D=4,L=0)
2025-01-16 05:12:53,623 - DEBUG - Q-vals = [0.25621977 0.12658814 0.11029774 0.04976978 0.17263837 0.18003415
 0.1044521 ], best_act=0, best_val=0.256
2025-01-16 05:12:53,623 - DEBUG - Low Q-value (0.256), using MCTS.
2025-01-16 05:12:53,623 - INFO - Running MCTS with 101 simulations using 6 processes.
2025-01-16 05:12:56,936 - DEBUG - Aggregated action counts: {1: 1, 3: 3, 6: 1, 0: 2}
2025-01-16 05:12:56,936 - DEBUG - Chose best action 3
2025-01-16 05:12:57,170 - INFO - Episode 2294/98900: Winner=2, Reward=-39.15, EPSILON=0.980, (W=554,D=4,L=0)
2025-01-16 05:12:57,326 - INFO - Episode 2295/98900: Winner=2, Reward=13.95, EPSILON=0.980, (W=554,D=4,L=0)
2025-01-16 05:12:57,592 - INFO - Episode 2296/98900: Winner=2, Reward=16.75, EPSILON=0.980, (W=554,D=4,L=0)
2025-01-16 05:12:57,998 - INFO - Episode 2297/98900: Winner=2, Reward=-42.85, EPSILON=0.980, (W=554,D=4,L=0)
2025-01-16 05:12:58,014 - DEBUG - Q-vals = [9.58794475e-01 5.25480229e-03 1.76071171e-02 1.59977016e-03
 2.09737133e-04 6.49597216e-03 1.00380415e-02], best_act=0, best_val=0.959
2025-01-16 05:12:58,014 - DEBUG - Low Q-value (0.959), using MCTS.
2025-01-16 05:12:58,014 - INFO - Running MCTS with 101 simulations using 6 processes.
2025-01-16 05:13:01,305 - DEBUG - Aggregated action counts: {4: 3, 1: 2, 2: 1, 0: 1}
2025-01-16 05:13:01,305 - DEBUG - Chose best action 4
2025-01-16 05:13:01,493 - INFO - Episode 2298/98900: Winner=2, Reward=-6.65, EPSILON=0.980, (W=554,D=4,L=0)
2025-01-16 05:13:01,696 - INFO - Episode 2299/98900: Winner=2, Reward=2.65, EPSILON=0.980, (W=554,D=4,L=0)
2025-01-16 05:13:02,031 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2300.
2025-01-16 05:13:02,031 - INFO - Models saved at episode 2300
2025-01-16 05:13:02,031 - INFO - Target networks updated
2025-01-16 05:13:02,093 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2300.
2025-01-16 05:13:02,093 - INFO - Episode 2300/98900: Winner=2, Reward=0.35, EPSILON=0.980, (W=555,D=4,L=0)
2025-01-16 05:13:02,218 - INFO - Episode 2301/98900: Winner=2, Reward=18.90, EPSILON=0.980, (W=555,D=4,L=0)
2025-01-16 05:13:02,359 - INFO - Episode 2302/98900: Winner=2, Reward=-1.85, EPSILON=0.979, (W=555,D=4,L=0)
2025-01-16 05:13:02,531 - DEBUG - Q-vals = [0.13568635 0.15608625 0.10415442 0.31036842 0.1665784  0.06953195
 0.05759407], best_act=3, best_val=0.310
2025-01-16 05:13:02,531 - DEBUG - Low Q-value (0.310), using MCTS.
2025-01-16 05:13:02,546 - INFO - Episode 2303/98900: Winner=2, Reward=-12.35, EPSILON=0.979, (W=556,D=4,L=0)
2025-01-16 05:13:02,640 - INFO - Episode 2304/98900: Winner=2, Reward=0.50, EPSILON=0.979, (W=556,D=4,L=0)
2025-01-16 05:13:02,749 - INFO - Episode 2305/98900: Winner=2, Reward=9.70, EPSILON=0.979, (W=556,D=4,L=0)
2025-01-16 05:13:02,827 - INFO - Episode 2306/98900: Winner=2, Reward=-10.25, EPSILON=0.979, (W=557,D=4,L=0)
2025-01-16 05:13:02,921 - INFO - Episode 2307/98900: Winner=2, Reward=1.95, EPSILON=0.979, (W=557,D=4,L=0)
2025-01-16 05:13:03,077 - INFO - Episode 2308/98900: Winner=2, Reward=-7.00, EPSILON=0.979, (W=558,D=4,L=0)
2025-01-16 05:13:03,249 - INFO - Episode 2309/98900: Winner=2, Reward=-7.35, EPSILON=0.979, (W=559,D=4,L=0)
2025-01-16 05:13:03,608 - INFO - Episode 2310/98900: Winner=2, Reward=-2.85, EPSILON=0.979, (W=559,D=4,L=0)
2025-01-16 05:13:03,831 - INFO - Episode 2311/98900: Winner=2, Reward=18.00, EPSILON=0.979, (W=559,D=4,L=0)
2025-01-16 05:13:04,113 - INFO - Episode 2312/98900: Winner=2, Reward=-17.05, EPSILON=0.979, (W=560,D=4,L=0)
2025-01-16 05:13:04,360 - INFO - Episode 2313/98900: Winner=2, Reward=-0.40, EPSILON=0.979, (W=560,D=4,L=0)
2025-01-16 05:13:04,516 - INFO - Episode 2314/98900: Winner=2, Reward=17.30, EPSILON=0.979, (W=560,D=4,L=0)
2025-01-16 05:13:04,547 - DEBUG - Q-vals = [0.25580403 0.15390903 0.08795202 0.10598996 0.09001224 0.12695286
 0.17937984], best_act=0, best_val=0.256
2025-01-16 05:13:04,547 - DEBUG - Low Q-value (0.256), using MCTS.
2025-01-16 05:13:04,547 - INFO - Running MCTS with 102 simulations using 6 processes.
2025-01-16 05:13:07,337 - DEBUG - Aggregated action counts: {3: 2, 0: 1, 2: 2, 1: 1}
2025-01-16 05:13:07,337 - DEBUG - Chose best action 3
2025-01-16 05:13:07,493 - INFO - Episode 2315/98900: Winner=2, Reward=-14.35, EPSILON=0.979, (W=560,D=4,L=0)
2025-01-16 05:13:07,556 - DEBUG - Q-vals = [0.14744112 0.09700754 0.09720674 0.07676762 0.1731794  0.22163136
 0.1867662 ], best_act=5, best_val=0.222
2025-01-16 05:13:07,556 - DEBUG - Low Q-value (0.222), using MCTS.
2025-01-16 05:13:07,556 - INFO - Running MCTS with 102 simulations using 6 processes.
2025-01-16 05:13:10,442 - DEBUG - Aggregated action counts: {2: 1, 0: 1, 6: 1, 4: 2, 3: 1}
2025-01-16 05:13:10,442 - DEBUG - Chose best action 4
2025-01-16 05:13:10,692 - INFO - Episode 2316/98900: Winner=2, Reward=-6.30, EPSILON=0.979, (W=560,D=4,L=0)
2025-01-16 05:13:10,829 - INFO - Episode 2317/98900: Winner=2, Reward=8.95, EPSILON=0.979, (W=560,D=4,L=0)
2025-01-16 05:13:10,846 - DEBUG - Q-vals = [8.9154792e-01 4.1903132e-03 8.1792712e-02 2.3120018e-03 1.3527914e-04
 7.8023970e-03 1.2219320e-02], best_act=0, best_val=0.892
2025-01-16 05:13:10,846 - DEBUG - Low Q-value (0.892), using MCTS.
2025-01-16 05:13:10,846 - INFO - Running MCTS with 102 simulations using 6 processes.
2025-01-16 05:13:13,551 - DEBUG - Aggregated action counts: {0: 4, 1: 1, 2: 1}
2025-01-16 05:13:13,551 - DEBUG - Chose best action 0
2025-01-16 05:13:13,738 - INFO - Episode 2318/98900: Winner=2, Reward=-8.25, EPSILON=0.979, (W=561,D=4,L=0)
2025-01-16 05:13:14,004 - INFO - Episode 2319/98900: Winner=2, Reward=-14.80, EPSILON=0.979, (W=562,D=4,L=0)
2025-01-16 05:13:14,207 - INFO - Episode 2320/98900: Winner=2, Reward=-2.15, EPSILON=0.979, (W=562,D=4,L=0)
2025-01-16 05:13:14,410 - INFO - Episode 2321/98900: Winner=2, Reward=5.20, EPSILON=0.979, (W=562,D=4,L=0)
2025-01-16 05:13:14,504 - INFO - Episode 2322/98900: Winner=2, Reward=0.10, EPSILON=0.979, (W=562,D=4,L=0)
2025-01-16 05:13:14,723 - INFO - Episode 2323/98900: Winner=2, Reward=19.10, EPSILON=0.979, (W=562,D=4,L=0)
2025-01-16 05:13:14,910 - INFO - Episode 2324/98900: Winner=2, Reward=2.30, EPSILON=0.979, (W=562,D=4,L=0)
2025-01-16 05:13:15,129 - INFO - Episode 2325/98900: Winner=2, Reward=0.15, EPSILON=0.979, (W=562,D=4,L=0)
2025-01-16 05:13:15,222 - INFO - Episode 2326/98900: Winner=2, Reward=2.30, EPSILON=0.979, (W=562,D=4,L=0)
2025-01-16 05:13:15,379 - INFO - Episode 2327/98900: Winner=2, Reward=-3.75, EPSILON=0.979, (W=562,D=4,L=0)
2025-01-16 05:13:15,582 - INFO - Episode 2328/98900: Winner=2, Reward=27.90, EPSILON=0.979, (W=562,D=4,L=0)
2025-01-16 05:13:15,879 - INFO - Episode 2329/98900: Winner=2, Reward=-44.40, EPSILON=0.979, (W=563,D=4,L=0)
2025-01-16 05:13:16,019 - DEBUG - Q-vals = [0.19060408 0.13553944 0.11690015 0.17750046 0.17980717 0.09361885
 0.1060299 ], best_act=0, best_val=0.191
2025-01-16 05:13:16,019 - DEBUG - Low Q-value (0.191), using MCTS.
2025-01-16 05:13:16,019 - INFO - Episode 2330/98900: Winner=2, Reward=-7.80, EPSILON=0.979, (W=564,D=4,L=0)
2025-01-16 05:13:16,222 - DEBUG - Q-vals = [0.17265157 0.07028167 0.22743882 0.2660564  0.12994301 0.05361606
 0.08001252], best_act=3, best_val=0.266
2025-01-16 05:13:16,222 - DEBUG - Low Q-value (0.266), using MCTS.
2025-01-16 05:13:16,222 - INFO - Running MCTS with 103 simulations using 6 processes.
2025-01-16 05:13:18,925 - DEBUG - Aggregated action counts: {1: 1, 0: 4, 5: 1, 3: 1}
2025-01-16 05:13:18,925 - DEBUG - Chose best action 0
2025-01-16 05:13:19,050 - INFO - Episode 2331/98900: Winner=2, Reward=2.65, EPSILON=0.979, (W=564,D=4,L=0)
2025-01-16 05:13:19,144 - DEBUG - Q-vals = [0.1791615  0.15978056 0.09994625 0.20589724 0.08378157 0.16029319
 0.11113967], best_act=3, best_val=0.206
2025-01-16 05:13:19,144 - DEBUG - Low Q-value (0.206), using MCTS.
2025-01-16 05:13:19,144 - INFO - Running MCTS with 103 simulations using 6 processes.
2025-01-16 05:13:21,878 - DEBUG - Aggregated action counts: {4: 2, 0: 2, 3: 2, 1: 1}
2025-01-16 05:13:21,878 - DEBUG - Chose best action 4
2025-01-16 05:13:22,190 - INFO - Episode 2332/98900: Winner=2, Reward=-60.20, EPSILON=0.979, (W=564,D=4,L=0)
2025-01-16 05:13:22,550 - INFO - Episode 2333/98900: Winner=2, Reward=-23.70, EPSILON=0.979, (W=565,D=4,L=0)
2025-01-16 05:13:22,840 - INFO - Episode 2334/98900: Winner=2, Reward=-39.60, EPSILON=0.979, (W=566,D=4,L=0)
2025-01-16 05:13:23,113 - INFO - Episode 2335/98900: Winner=2, Reward=-0.75, EPSILON=0.979, (W=567,D=4,L=0)
2025-01-16 05:13:23,394 - INFO - Episode 2336/98900: Winner=2, Reward=-18.00, EPSILON=0.979, (W=568,D=4,L=0)
2025-01-16 05:13:23,769 - INFO - Episode 2337/98900: Winner=2, Reward=-10.55, EPSILON=0.979, (W=568,D=4,L=0)
2025-01-16 05:13:23,956 - INFO - Episode 2338/98900: Winner=2, Reward=5.25, EPSILON=0.979, (W=568,D=4,L=0)
2025-01-16 05:13:24,128 - INFO - Episode 2339/98900: Winner=2, Reward=-8.25, EPSILON=0.979, (W=569,D=4,L=0)
2025-01-16 05:13:24,331 - INFO - Episode 2340/98900: Winner=2, Reward=-2.30, EPSILON=0.979, (W=569,D=4,L=0)
2025-01-16 05:13:24,503 - DEBUG - Q-vals = [0.1851842  0.11916923 0.09588639 0.31282187 0.09632652 0.06810149
 0.12251034], best_act=3, best_val=0.313
2025-01-16 05:13:24,503 - DEBUG - Low Q-value (0.313), using MCTS.
2025-01-16 05:13:24,503 - INFO - Episode 2341/98900: Winner=2, Reward=-8.60, EPSILON=0.979, (W=570,D=4,L=0)
2025-01-16 05:13:24,644 - DEBUG - Q-vals = [0.07008155 0.04048071 0.1596676  0.26645404 0.16766387 0.0974481
 0.19820416], best_act=3, best_val=0.266
2025-01-16 05:13:24,644 - DEBUG - Low Q-value (0.266), using MCTS.
2025-01-16 05:13:24,659 - INFO - Episode 2342/98900: Winner=2, Reward=-9.65, EPSILON=0.979, (W=571,D=4,L=0)
2025-01-16 05:13:24,816 - DEBUG - Q-vals = [0.17064184 0.10759974 0.12816356 0.14531638 0.1921011  0.10054173
 0.15563573], best_act=4, best_val=0.192
2025-01-16 05:13:24,816 - DEBUG - Low Q-value (0.192), using MCTS.
2025-01-16 05:13:24,816 - INFO - Running MCTS with 103 simulations using 6 processes.
2025-01-16 05:13:27,768 - DEBUG - Aggregated action counts: {3: 2, 4: 1, 1: 3, 2: 1}
2025-01-16 05:13:27,768 - DEBUG - Chose best action 1
2025-01-16 05:13:27,830 - INFO - Episode 2343/98900: Winner=2, Reward=-0.20, EPSILON=0.979, (W=571,D=4,L=0)
2025-01-16 05:13:28,049 - DEBUG - Q-vals = [0.34901255 0.0479377  0.16692708 0.0631555  0.18834855 0.04072414
 0.14389452], best_act=0, best_val=0.349
2025-01-16 05:13:28,049 - DEBUG - Low Q-value (0.349), using MCTS.
2025-01-16 05:13:28,049 - INFO - Running MCTS with 103 simulations using 6 processes.
2025-01-16 05:13:30,917 - DEBUG - Aggregated action counts: {3: 3, 4: 1, 1: 2, 5: 1}
2025-01-16 05:13:30,917 - DEBUG - Chose best action 3
2025-01-16 05:13:30,980 - INFO - Episode 2344/98900: Winner=2, Reward=-9.85, EPSILON=0.979, (W=572,D=4,L=0)
2025-01-16 05:13:31,276 - INFO - Episode 2345/98900: Winner=2, Reward=-26.25, EPSILON=0.979, (W=573,D=4,L=0)
2025-01-16 05:13:31,579 - INFO - Episode 2346/98900: Winner=2, Reward=-37.85, EPSILON=0.979, (W=574,D=4,L=0)
2025-01-16 05:13:31,645 - DEBUG - Q-vals = [0.1619     0.13255042 0.1270711  0.14213699 0.12888548 0.1610714
 0.14638464], best_act=0, best_val=0.162
2025-01-16 05:13:31,645 - DEBUG - Low Q-value (0.162), using MCTS.
2025-01-16 05:13:31,645 - INFO - Running MCTS with 103 simulations using 6 processes.
2025-01-16 05:13:34,935 - DEBUG - Aggregated action counts: {6: 1, 3: 1, 2: 5}
2025-01-16 05:13:34,935 - DEBUG - Chose best action 2
2025-01-16 05:13:35,214 - INFO - Episode 2347/98900: Winner=2, Reward=-43.35, EPSILON=0.979, (W=575,D=4,L=0)
2025-01-16 05:13:35,433 - INFO - Episode 2348/98900: Winner=2, Reward=-3.20, EPSILON=0.979, (W=575,D=4,L=0)
2025-01-16 05:13:35,620 - INFO - Episode 2349/98900: Winner=2, Reward=14.45, EPSILON=0.979, (W=575,D=4,L=0)
2025-01-16 05:13:35,901 - INFO - Episode 2350/98900: Winner=2, Reward=-17.20, EPSILON=0.979, (W=576,D=4,L=0)
2025-01-16 05:13:36,073 - INFO - Episode 2351/98900: Winner=2, Reward=0.00, EPSILON=0.979, (W=576,D=4,L=0)
2025-01-16 05:13:36,276 - INFO - Episode 2352/98900: Winner=2, Reward=0.45, EPSILON=0.979, (W=576,D=4,L=0)
2025-01-16 05:13:36,519 - INFO - Episode 2353/98900: Winner=2, Reward=-11.65, EPSILON=0.979, (W=577,D=4,L=0)
2025-01-16 05:13:36,687 - INFO - Episode 2354/98900: Winner=2, Reward=-3.20, EPSILON=0.979, (W=577,D=4,L=0)
2025-01-16 05:13:36,846 - INFO - Episode 2355/98900: Winner=2, Reward=13.60, EPSILON=0.979, (W=578,D=4,L=0)
2025-01-16 05:13:37,029 - INFO - Episode 2356/98900: Winner=2, Reward=2.95, EPSILON=0.979, (W=578,D=4,L=0)
2025-01-16 05:13:37,148 - INFO - Episode 2357/98900: Winner=2, Reward=-2.60, EPSILON=0.979, (W=578,D=4,L=0)
2025-01-16 05:13:37,523 - INFO - Episode 2358/98900: Winner=2, Reward=-81.70, EPSILON=0.979, (W=578,D=4,L=0)
2025-01-16 05:13:37,599 - DEBUG - Q-vals = [0.23859099 0.0990695  0.12839001 0.11772201 0.07848332 0.16929634
 0.16844785], best_act=0, best_val=0.239
2025-01-16 05:13:37,599 - DEBUG - Low Q-value (0.239), using MCTS.
2025-01-16 05:13:37,599 - INFO - Running MCTS with 104 simulations using 6 processes.
2025-01-16 05:13:40,469 - DEBUG - Aggregated action counts: {1: 2, 5: 2, 3: 1, 0: 2}
2025-01-16 05:13:40,469 - DEBUG - Chose best action 1
2025-01-16 05:13:40,516 - INFO - Episode 2359/98900: Winner=2, Reward=0.95, EPSILON=0.979, (W=578,D=4,L=0)
2025-01-16 05:13:40,862 - INFO - Episode 2360/98900: Winner=2, Reward=-13.90, EPSILON=0.979, (W=579,D=4,L=0)
2025-01-16 05:13:41,018 - INFO - Episode 2361/98900: Winner=2, Reward=-2.45, EPSILON=0.979, (W=579,D=4,L=0)
2025-01-16 05:13:41,174 - INFO - Episode 2362/98900: Winner=2, Reward=-6.15, EPSILON=0.979, (W=579,D=4,L=0)
2025-01-16 05:13:41,494 - INFO - Episode 2363/98900: Winner=2, Reward=-36.95, EPSILON=0.979, (W=580,D=4,L=0)
2025-01-16 05:13:41,780 - INFO - Episode 2364/98900: Winner=2, Reward=7.95, EPSILON=0.979, (W=580,D=4,L=0)
2025-01-16 05:13:41,871 - DEBUG - Q-vals = [0.14860603 0.13710344 0.12178049 0.1870886  0.11758739 0.15071423
 0.13711986], best_act=3, best_val=0.187
2025-01-16 05:13:41,871 - DEBUG - Low Q-value (0.187), using MCTS.
2025-01-16 05:13:41,872 - INFO - Running MCTS with 104 simulations using 6 processes.
2025-01-16 05:13:44,606 - DEBUG - Aggregated action counts: {2: 3, 1: 3, 0: 1}
2025-01-16 05:13:44,606 - DEBUG - Chose best action 2
2025-01-16 05:13:44,769 - INFO - Episode 2365/98900: Winner=2, Reward=-6.75, EPSILON=0.979, (W=581,D=4,L=0)
2025-01-16 05:13:44,951 - DEBUG - Q-vals = [0.17561644 0.06134066 0.17380907 0.11818153 0.01626235 0.14215405
 0.3126359 ], best_act=6, best_val=0.313
2025-01-16 05:13:44,951 - DEBUG - Low Q-value (0.313), using MCTS.
2025-01-16 05:13:44,967 - INFO - Episode 2366/98900: Winner=2, Reward=-9.50, EPSILON=0.979, (W=582,D=4,L=0)
2025-01-16 05:13:45,186 - INFO - Episode 2367/98900: Winner=2, Reward=-10.40, EPSILON=0.979, (W=583,D=4,L=0)
2025-01-16 05:13:45,452 - INFO - Episode 2368/98900: Winner=2, Reward=-8.15, EPSILON=0.979, (W=584,D=4,L=0)
2025-01-16 05:13:45,609 - DEBUG - Q-vals = [0.08506825 0.06536718 0.11355166 0.56122    0.03215607 0.07398064
 0.06865612], best_act=3, best_val=0.561
2025-01-16 05:13:45,609 - DEBUG - Low Q-value (0.561), using MCTS.
2025-01-16 05:13:45,609 - INFO - Running MCTS with 104 simulations using 6 processes.
2025-01-16 05:13:48,505 - DEBUG - Aggregated action counts: {1: 1, 3: 1, 4: 2, 2: 1, 6: 1, 0: 1}
2025-01-16 05:13:48,505 - DEBUG - Chose best action 4
2025-01-16 05:13:48,633 - INFO - Episode 2369/98900: Winner=2, Reward=-27.10, EPSILON=0.979, (W=585,D=4,L=0)
2025-01-16 05:13:48,749 - INFO - Episode 2370/98900: Winner=2, Reward=2.65, EPSILON=0.979, (W=585,D=4,L=0)
2025-01-16 05:13:48,952 - INFO - Episode 2371/98900: Winner=2, Reward=0.05, EPSILON=0.979, (W=585,D=4,L=0)
2025-01-16 05:13:48,967 - DEBUG - Q-vals = [8.1811420e-05 1.8476577e-01 7.0752941e-07 6.6542469e-07 4.0271618e-07
 8.1510043e-01 5.0179486e-05], best_act=5, best_val=0.815
2025-01-16 05:13:48,967 - DEBUG - Low Q-value (0.815), using MCTS.
2025-01-16 05:13:48,968 - INFO - Running MCTS with 104 simulations using 6 processes.
2025-01-16 05:13:52,062 - DEBUG - Aggregated action counts: {2: 1, 0: 3, 4: 1, 3: 1, 5: 1}
2025-01-16 05:13:52,062 - DEBUG - Chose best action 0
2025-01-16 05:13:52,261 - DEBUG - Q-vals = [0.12267209 0.11323819 0.12537445 0.22091813 0.16894476 0.0905339
 0.15831843], best_act=3, best_val=0.221
2025-01-16 05:13:52,261 - DEBUG - Low Q-value (0.221), using MCTS.
2025-01-16 05:13:52,261 - INFO - Running MCTS with 104 simulations using 6 processes.
2025-01-16 05:13:55,270 - DEBUG - Aggregated action counts: {0: 2, 2: 1, 4: 1, 1: 1, 6: 1, 5: 1}
2025-01-16 05:13:55,270 - DEBUG - Chose best action 0
2025-01-16 05:13:55,368 - INFO - Episode 2372/98900: Winner=2, Reward=-0.50, EPSILON=0.979, (W=585,D=4,L=0)
2025-01-16 05:13:55,750 - INFO - Episode 2373/98900: Winner=2, Reward=-13.25, EPSILON=0.979, (W=586,D=4,L=0)
2025-01-16 05:13:56,041 - INFO - Episode 2374/98900: Winner=2, Reward=-14.55, EPSILON=0.979, (W=587,D=4,L=0)
2025-01-16 05:13:56,304 - INFO - Episode 2375/98900: Winner=2, Reward=-1.00, EPSILON=0.979, (W=587,D=4,L=0)
2025-01-16 05:13:56,519 - INFO - Episode 2376/98900: Winner=2, Reward=3.90, EPSILON=0.979, (W=587,D=4,L=0)
2025-01-16 05:13:56,768 - INFO - Episode 2377/98900: Winner=2, Reward=-6.75, EPSILON=0.979, (W=587,D=4,L=0)
2025-01-16 05:13:57,096 - INFO - Episode 2378/98900: Winner=2, Reward=-10.15, EPSILON=0.979, (W=587,D=4,L=0)
2025-01-16 05:13:57,435 - INFO - Episode 2379/98900: Winner=2, Reward=-59.20, EPSILON=0.979, (W=588,D=4,L=0)
2025-01-16 05:13:57,569 - INFO - Episode 2380/98900: Winner=2, Reward=-9.95, EPSILON=0.979, (W=589,D=4,L=0)
2025-01-16 05:13:57,720 - INFO - Episode 2381/98900: Winner=2, Reward=-10.80, EPSILON=0.979, (W=590,D=4,L=0)
2025-01-16 05:13:57,921 - INFO - Episode 2382/98900: Winner=2, Reward=-4.60, EPSILON=0.979, (W=590,D=4,L=0)
2025-01-16 05:13:58,241 - DEBUG - Q-vals = [0.06220235 0.05012419 0.05723462 0.02731158 0.6572719  0.05420762
 0.09164777], best_act=4, best_val=0.657
2025-01-16 05:13:58,241 - DEBUG - Low Q-value (0.657), using MCTS.
2025-01-16 05:13:58,241 - INFO - Episode 2383/98900: Winner=2, Reward=-25.70, EPSILON=0.979, (W=591,D=4,L=0)
2025-01-16 05:13:58,492 - INFO - Episode 2384/98900: Winner=2, Reward=19.35, EPSILON=0.979, (W=591,D=4,L=0)
2025-01-16 05:13:58,586 - INFO - Episode 2385/98900: Winner=2, Reward=14.15, EPSILON=0.979, (W=591,D=4,L=0)
2025-01-16 05:13:58,783 - INFO - Episode 2386/98900: Winner=2, Reward=29.85, EPSILON=0.979, (W=591,D=4,L=0)
2025-01-16 05:13:59,150 - INFO - Episode 2387/98900: Winner=2, Reward=-35.55, EPSILON=0.979, (W=592,D=4,L=0)
2025-01-16 05:13:59,187 - DEBUG - Q-vals = [0.3290669  0.03890648 0.1511598  0.0494609  0.0681664  0.14627512
 0.21696441], best_act=0, best_val=0.329
2025-01-16 05:13:59,187 - DEBUG - Low Q-value (0.329), using MCTS.
2025-01-16 05:13:59,187 - INFO - Running MCTS with 105 simulations using 6 processes.
2025-01-16 05:14:02,227 - DEBUG - Aggregated action counts: {3: 2, 1: 3, 0: 2}
2025-01-16 05:14:02,227 - DEBUG - Chose best action 1
2025-01-16 05:14:02,336 - INFO - Episode 2388/98900: Winner=2, Reward=5.20, EPSILON=0.979, (W=592,D=4,L=0)
2025-01-16 05:14:02,571 - INFO - Episode 2389/98900: Winner=2, Reward=-26.45, EPSILON=0.979, (W=593,D=4,L=0)
2025-01-16 05:14:02,914 - INFO - Episode 2390/98900: Winner=2, Reward=-27.95, EPSILON=0.979, (W=594,D=4,L=0)
2025-01-16 05:14:03,196 - INFO - Episode 2391/98900: Winner=2, Reward=3.05, EPSILON=0.979, (W=594,D=4,L=0)
2025-01-16 05:14:03,289 - DEBUG - Q-vals = [0.1555184  0.13979222 0.14623038 0.15063392 0.12615459 0.13181312
 0.14985742], best_act=0, best_val=0.156
2025-01-16 05:14:03,289 - DEBUG - Low Q-value (0.156), using MCTS.
2025-01-16 05:14:03,289 - INFO - Running MCTS with 105 simulations using 6 processes.
2025-01-16 05:14:06,476 - DEBUG - Aggregated action counts: {1: 2, 0: 4, 4: 1}
2025-01-16 05:14:06,476 - DEBUG - Chose best action 0
2025-01-16 05:14:06,586 - INFO - Episode 2392/98900: Winner=2, Reward=5.20, EPSILON=0.979, (W=594,D=4,L=0)
2025-01-16 05:14:06,836 - INFO - Episode 2393/98900: Winner=2, Reward=-16.65, EPSILON=0.979, (W=594,D=4,L=0)
2025-01-16 05:14:07,101 - INFO - Episode 2394/98900: Winner=2, Reward=-26.60, EPSILON=0.979, (W=595,D=4,L=0)
2025-01-16 05:14:07,367 - INFO - Episode 2395/98900: Winner=2, Reward=-3.50, EPSILON=0.979, (W=595,D=4,L=0)
2025-01-16 05:14:07,726 - INFO - Episode 2396/98900: Winner=2, Reward=-29.55, EPSILON=0.979, (W=596,D=4,L=0)
2025-01-16 05:14:08,023 - INFO - Episode 2397/98900: Winner=2, Reward=49.10, EPSILON=0.979, (W=596,D=4,L=0)
2025-01-16 05:14:08,085 - INFO - Episode 2398/98900: Winner=2, Reward=0.55, EPSILON=0.979, (W=596,D=4,L=0)
2025-01-16 05:14:08,382 - INFO - Episode 2399/98900: Winner=2, Reward=-21.90, EPSILON=0.979, (W=596,D=4,L=0)
2025-01-16 05:14:08,710 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2400.
2025-01-16 05:14:08,710 - INFO - Models saved at episode 2400
2025-01-16 05:14:08,710 - INFO - Target networks updated
2025-01-16 05:14:08,773 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2400.
2025-01-16 05:14:08,773 - INFO - Episode 2400/98900: Winner=2, Reward=7.60, EPSILON=0.979, (W=596,D=4,L=0)
2025-01-16 05:14:09,023 - INFO - Episode 2401/98900: Winner=2, Reward=14.35, EPSILON=0.979, (W=596,D=4,L=0)
2025-01-16 05:14:09,210 - INFO - Episode 2402/98900: Winner=2, Reward=-12.95, EPSILON=0.979, (W=596,D=4,L=0)
2025-01-16 05:14:09,335 - INFO - Episode 2403/98900: Winner=2, Reward=-9.60, EPSILON=0.979, (W=597,D=4,L=0)
2025-01-16 05:14:09,679 - INFO - Episode 2404/98900: Winner=2, Reward=-12.20, EPSILON=0.979, (W=597,D=4,L=0)
2025-01-16 05:14:09,788 - INFO - Episode 2405/98900: Winner=2, Reward=-7.65, EPSILON=0.979, (W=598,D=4,L=0)
2025-01-16 05:14:10,023 - INFO - Episode 2406/98900: Winner=2, Reward=-9.90, EPSILON=0.979, (W=599,D=4,L=0)
2025-01-16 05:14:10,210 - INFO - Episode 2407/98900: Winner=2, Reward=0.95, EPSILON=0.979, (W=599,D=4,L=0)
2025-01-16 05:14:10,538 - INFO - Episode 2408/98900: Winner=2, Reward=-60.95, EPSILON=0.979, (W=600,D=4,L=0)
2025-01-16 05:14:10,944 - INFO - Episode 2409/98900: Winner=2, Reward=-33.40, EPSILON=0.979, (W=601,D=4,L=0)
2025-01-16 05:14:11,132 - DEBUG - Q-vals = [0.18448688 0.42081943 0.01393197 0.20516457 0.03327775 0.09158318
 0.05073621], best_act=1, best_val=0.421
2025-01-16 05:14:11,132 - DEBUG - Low Q-value (0.421), using MCTS.
2025-01-16 05:14:11,132 - INFO - Episode 2410/98900: Winner=2, Reward=-24.60, EPSILON=0.979, (W=602,D=4,L=0)
2025-01-16 05:14:11,491 - DEBUG - Q-vals = [0.05427523 0.05018279 0.23217344 0.5199737  0.02859765 0.02427042
 0.09052676], best_act=3, best_val=0.520
2025-01-16 05:14:11,491 - DEBUG - Low Q-value (0.520), using MCTS.
2025-01-16 05:14:11,491 - INFO - Running MCTS with 106 simulations using 6 processes.
2025-01-16 05:14:14,444 - DEBUG - Aggregated action counts: {2: 4, 3: 2, 0: 1}
2025-01-16 05:14:14,444 - DEBUG - Chose best action 2
2025-01-16 05:14:14,479 - INFO - Episode 2411/98900: Winner=2, Reward=-34.55, EPSILON=0.979, (W=602,D=4,L=0)
2025-01-16 05:14:14,573 - INFO - Episode 2412/98900: Winner=2, Reward=1.25, EPSILON=0.979, (W=602,D=4,L=0)
2025-01-16 05:14:14,684 - DEBUG - Q-vals = [0.16938709 0.12190746 0.14037806 0.14275223 0.1568218  0.12539619
 0.14335722], best_act=0, best_val=0.169
2025-01-16 05:14:14,684 - DEBUG - Low Q-value (0.169), using MCTS.
2025-01-16 05:14:14,684 - INFO - Running MCTS with 106 simulations using 6 processes.
2025-01-16 05:14:17,707 - DEBUG - Aggregated action counts: {2: 1, 5: 1, 0: 3, 1: 1, 6: 1}
2025-01-16 05:14:17,707 - DEBUG - Chose best action 0
2025-01-16 05:14:17,785 - INFO - Episode 2413/98900: Winner=2, Reward=14.65, EPSILON=0.979, (W=602,D=4,L=0)
2025-01-16 05:14:18,032 - INFO - Episode 2414/98900: Winner=2, Reward=6.35, EPSILON=0.979, (W=602,D=4,L=0)
2025-01-16 05:14:18,157 - INFO - Episode 2415/98900: Winner=2, Reward=7.50, EPSILON=0.978, (W=602,D=4,L=0)
2025-01-16 05:14:18,391 - INFO - Episode 2416/98900: Winner=2, Reward=-12.70, EPSILON=0.978, (W=602,D=4,L=0)
2025-01-16 05:14:18,782 - INFO - Episode 2417/98900: Winner=2, Reward=-45.65, EPSILON=0.978, (W=602,D=4,L=0)
2025-01-16 05:14:19,079 - INFO - Episode 2418/98900: Winner=2, Reward=18.05, EPSILON=0.978, (W=602,D=4,L=0)
2025-01-16 05:14:19,152 - INFO - Episode 2419/98900: Winner=2, Reward=0.70, EPSILON=0.978, (W=602,D=4,L=0)
2025-01-16 05:14:19,372 - INFO - Episode 2420/98900: Winner=2, Reward=-2.85, EPSILON=0.978, (W=603,D=4,L=0)
2025-01-16 05:14:19,450 - DEBUG - Q-vals = [0.16734013 0.1489465  0.13650419 0.1738453  0.11160196 0.12649041
 0.1352715 ], best_act=3, best_val=0.174
2025-01-16 05:14:19,450 - DEBUG - Low Q-value (0.174), using MCTS.
2025-01-16 05:14:19,450 - INFO - Running MCTS with 106 simulations using 6 processes.
2025-01-16 05:14:22,274 - DEBUG - Aggregated action counts: {2: 1, 0: 2, 3: 2, 1: 1, 4: 1}
2025-01-16 05:14:22,274 - DEBUG - Chose best action 0
2025-01-16 05:14:22,481 - INFO - Episode 2421/98900: Winner=2, Reward=-24.00, EPSILON=0.978, (W=604,D=4,L=0)
2025-01-16 05:14:22,642 - INFO - Episode 2422/98900: Winner=2, Reward=-11.55, EPSILON=0.978, (W=605,D=4,L=0)
2025-01-16 05:14:23,026 - INFO - Episode 2423/98900: Winner=2, Reward=-17.85, EPSILON=0.978, (W=605,D=4,L=0)
2025-01-16 05:14:23,304 - INFO - Episode 2424/98900: Winner=2, Reward=-24.00, EPSILON=0.978, (W=606,D=4,L=0)
2025-01-16 05:14:23,509 - INFO - Episode 2425/98900: Winner=2, Reward=3.40, EPSILON=0.978, (W=606,D=4,L=0)
2025-01-16 05:14:23,675 - DEBUG - Q-vals = [0.18476447 0.14219965 0.09083214 0.13550913 0.08401361 0.16535904
 0.19732198], best_act=6, best_val=0.197
2025-01-16 05:14:23,675 - DEBUG - Low Q-value (0.197), using MCTS.
2025-01-16 05:14:23,686 - INFO - Episode 2426/98900: Winner=2, Reward=-16.60, EPSILON=0.978, (W=607,D=4,L=0)
2025-01-16 05:14:23,891 - DEBUG - Q-vals = [0.23445182 0.09532639 0.17297387 0.1101839  0.16875017 0.14001706
 0.07829679], best_act=0, best_val=0.234
2025-01-16 05:14:23,891 - DEBUG - Low Q-value (0.234), using MCTS.
2025-01-16 05:14:23,907 - INFO - Episode 2427/98900: Winner=2, Reward=-4.45, EPSILON=0.978, (W=608,D=4,L=0)
2025-01-16 05:14:23,973 - DEBUG - Q-vals = [0.26563206 0.10690962 0.11063177 0.12428203 0.13155872 0.07380424
 0.18718152], best_act=0, best_val=0.266
2025-01-16 05:14:23,973 - DEBUG - Low Q-value (0.266), using MCTS.
2025-01-16 05:14:23,973 - INFO - Running MCTS with 107 simulations using 6 processes.
2025-01-16 05:14:26,814 - DEBUG - Aggregated action counts: {0: 3, 2: 2, 3: 1, 6: 1}
2025-01-16 05:14:26,814 - DEBUG - Chose best action 0
2025-01-16 05:14:27,033 - INFO - Episode 2428/98900: Winner=2, Reward=-22.90, EPSILON=0.978, (W=608,D=4,L=0)
2025-01-16 05:14:27,158 - DEBUG - Q-vals = [0.07172759 0.05803633 0.09960337 0.0659952  0.17589526 0.27290413
 0.25583813], best_act=5, best_val=0.273
2025-01-16 05:14:27,158 - DEBUG - Low Q-value (0.273), using MCTS.
2025-01-16 05:14:27,158 - INFO - Running MCTS with 107 simulations using 6 processes.
2025-01-16 05:14:29,992 - DEBUG - Aggregated action counts: {6: 1, 1: 1, 2: 1, 4: 1, 5: 2, 0: 1}
2025-01-16 05:14:29,992 - DEBUG - Chose best action 5
2025-01-16 05:14:30,101 - INFO - Episode 2429/98900: Winner=2, Reward=-10.95, EPSILON=0.978, (W=609,D=4,L=0)
2025-01-16 05:14:30,254 - DEBUG - Q-vals = [0.10796008 0.05741903 0.19307645 0.14378536 0.12326355 0.13879143
 0.2357041 ], best_act=6, best_val=0.236
2025-01-16 05:14:30,254 - DEBUG - Low Q-value (0.236), using MCTS.
2025-01-16 05:14:30,254 - INFO - Running MCTS with 107 simulations using 6 processes.
2025-01-16 05:14:33,160 - DEBUG - Aggregated action counts: {4: 2, 3: 1, 6: 1, 0: 3}
2025-01-16 05:14:33,160 - DEBUG - Chose best action 0
2025-01-16 05:14:33,207 - INFO - Episode 2430/98900: Winner=2, Reward=-9.80, EPSILON=0.978, (W=610,D=4,L=0)
2025-01-16 05:14:33,426 - INFO - Episode 2431/98900: Winner=2, Reward=-23.20, EPSILON=0.978, (W=611,D=4,L=0)
2025-01-16 05:14:33,722 - INFO - Episode 2432/98900: Winner=2, Reward=4.55, EPSILON=0.978, (W=611,D=4,L=0)
2025-01-16 05:14:33,988 - INFO - Episode 2433/98900: Winner=2, Reward=-31.55, EPSILON=0.978, (W=612,D=4,L=0)
2025-01-16 05:14:34,129 - INFO - Episode 2434/98900: Winner=2, Reward=-8.25, EPSILON=0.978, (W=613,D=4,L=0)
2025-01-16 05:14:34,348 - INFO - Episode 2435/98900: Winner=2, Reward=1.90, EPSILON=0.978, (W=614,D=4,L=0)
2025-01-16 05:14:34,542 - DEBUG - Q-vals = [0.11209328 0.04385678 0.23470108 0.49961144 0.03121672 0.05820017
 0.02032049], best_act=3, best_val=0.500
2025-01-16 05:14:34,542 - DEBUG - Low Q-value (0.500), using MCTS.
2025-01-16 05:14:34,543 - INFO - Running MCTS with 107 simulations using 6 processes.
2025-01-16 05:14:37,488 - DEBUG - Aggregated action counts: {3: 3, 0: 4}
2025-01-16 05:14:37,488 - DEBUG - Chose best action 0
2025-01-16 05:14:37,610 - INFO - Episode 2436/98900: Winner=2, Reward=-35.50, EPSILON=0.978, (W=615,D=4,L=0)
2025-01-16 05:14:37,905 - INFO - Episode 2437/98900: Winner=2, Reward=-23.25, EPSILON=0.978, (W=616,D=4,L=0)
2025-01-16 05:14:38,233 - INFO - Episode 2438/98900: Winner=2, Reward=-19.95, EPSILON=0.978, (W=617,D=4,L=0)
2025-01-16 05:14:38,561 - INFO - Episode 2439/98900: Winner=2, Reward=-3.45, EPSILON=0.978, (W=618,D=4,L=0)
2025-01-16 05:14:38,733 - INFO - Episode 2440/98900: Winner=2, Reward=-9.90, EPSILON=0.978, (W=619,D=4,L=0)
2025-01-16 05:14:38,826 - DEBUG - Q-vals = [0.32625446 0.05027455 0.1844807  0.04035159 0.02353371 0.12400938
 0.25109565], best_act=0, best_val=0.326
2025-01-16 05:14:38,826 - DEBUG - Low Q-value (0.326), using MCTS.
2025-01-16 05:14:38,826 - INFO - Running MCTS with 107 simulations using 6 processes.
2025-01-16 05:14:41,623 - DEBUG - Aggregated action counts: {6: 1, 1: 2, 3: 2, 5: 1, 0: 1}
2025-01-16 05:14:41,623 - DEBUG - Chose best action 1
2025-01-16 05:14:41,717 - DEBUG - Q-vals = [0.02915067 0.21238926 0.02695107 0.3847021  0.03539976 0.2406222
 0.07078498], best_act=3, best_val=0.385
2025-01-16 05:14:41,717 - DEBUG - Low Q-value (0.385), using MCTS.
2025-01-16 05:14:41,717 - INFO - Running MCTS with 107 simulations using 6 processes.
2025-01-16 05:14:44,576 - DEBUG - Aggregated action counts: {2: 1, 6: 3, 3: 1, 1: 1, 0: 1}
2025-01-16 05:14:44,576 - DEBUG - Chose best action 6
2025-01-16 05:14:44,669 - INFO - Episode 2441/98900: Winner=2, Reward=-23.95, EPSILON=0.978, (W=620,D=4,L=0)
2025-01-16 05:14:45,076 - INFO - Episode 2442/98900: Winner=2, Reward=-71.05, EPSILON=0.978, (W=620,D=4,L=0)
2025-01-16 05:14:45,388 - INFO - Episode 2443/98900: Winner=2, Reward=-12.15, EPSILON=0.978, (W=620,D=4,L=0)
2025-01-16 05:14:45,513 - DEBUG - Q-vals = [0.11511865 0.19302416 0.0681268  0.50653565 0.03165547 0.05850999
 0.02702932], best_act=3, best_val=0.507
2025-01-16 05:14:45,513 - DEBUG - Low Q-value (0.507), using MCTS.
2025-01-16 05:14:45,529 - INFO - Episode 2444/98900: Winner=2, Reward=-9.10, EPSILON=0.978, (W=621,D=4,L=0)
2025-01-16 05:14:45,872 - INFO - Episode 2445/98900: Winner=2, Reward=-26.25, EPSILON=0.978, (W=622,D=4,L=0)
2025-01-16 05:14:45,966 - INFO - Episode 2446/98900: Winner=2, Reward=0.30, EPSILON=0.978, (W=622,D=4,L=0)
2025-01-16 05:14:46,200 - INFO - Episode 2447/98900: Winner=2, Reward=10.45, EPSILON=0.978, (W=622,D=4,L=0)
2025-01-16 05:14:46,372 - DEBUG - Q-vals = [0.24516039 0.12902805 0.09862568 0.07286366 0.09783967 0.1308437
 0.22563882], best_act=0, best_val=0.245
2025-01-16 05:14:46,372 - DEBUG - Low Q-value (0.245), using MCTS.
2025-01-16 05:14:46,372 - INFO - Episode 2448/98900: Winner=2, Reward=-3.85, EPSILON=0.978, (W=623,D=4,L=0)
2025-01-16 05:14:46,482 - INFO - Episode 2449/98900: Winner=2, Reward=-8.20, EPSILON=0.978, (W=624,D=4,L=0)
2025-01-16 05:14:46,638 - DEBUG - Q-vals = [0.2241154  0.2865122  0.04272093 0.06609923 0.176344   0.12016644
 0.08404188], best_act=1, best_val=0.287
2025-01-16 05:14:46,638 - DEBUG - Low Q-value (0.287), using MCTS.
2025-01-16 05:14:46,638 - INFO - Running MCTS with 108 simulations using 6 processes.
2025-01-16 05:14:49,778 - DEBUG - Aggregated action counts: {6: 2, 1: 1, 3: 1, 4: 1, 0: 1}
2025-01-16 05:14:49,778 - DEBUG - Chose best action 6
2025-01-16 05:14:50,029 - INFO - Episode 2450/98900: Winner=2, Reward=-3.95, EPSILON=0.978, (W=624,D=4,L=0)
2025-01-16 05:14:50,185 - INFO - Episode 2451/98900: Winner=2, Reward=18.75, EPSILON=0.978, (W=624,D=4,L=0)
2025-01-16 05:14:50,498 - INFO - Episode 2452/98900: Winner=2, Reward=-22.10, EPSILON=0.978, (W=625,D=4,L=0)
2025-01-16 05:14:50,638 - INFO - Episode 2453/98900: Winner=2, Reward=-10.70, EPSILON=0.978, (W=626,D=4,L=0)
2025-01-16 05:14:51,060 - INFO - Episode 2454/98900: Winner=2, Reward=-53.05, EPSILON=0.978, (W=626,D=4,L=0)
2025-01-16 05:14:51,138 - INFO - Episode 2455/98900: Winner=2, Reward=-0.35, EPSILON=0.978, (W=626,D=4,L=0)
2025-01-16 05:14:51,310 - INFO - Episode 2456/98900: Winner=2, Reward=-6.60, EPSILON=0.978, (W=626,D=4,L=0)
2025-01-16 05:14:51,482 - INFO - Episode 2457/98900: Winner=2, Reward=1.55, EPSILON=0.978, (W=626,D=4,L=0)
2025-01-16 05:14:51,575 - INFO - Episode 2458/98900: Winner=2, Reward=0.80, EPSILON=0.978, (W=626,D=4,L=0)
2025-01-16 05:14:51,763 - DEBUG - Q-vals = [0.2819101  0.24805734 0.01752878 0.05396404 0.00762944 0.17816594
 0.21274434], best_act=0, best_val=0.282
2025-01-16 05:14:51,763 - DEBUG - Low Q-value (0.282), using MCTS.
2025-01-16 05:14:51,763 - INFO - Running MCTS with 108 simulations using 6 processes.
2025-01-16 05:14:54,715 - DEBUG - Aggregated action counts: {2: 1, 0: 2, 4: 1, 6: 1, 1: 1}
2025-01-16 05:14:54,715 - DEBUG - Chose best action 0
2025-01-16 05:14:54,840 - INFO - Episode 2459/98900: Winner=2, Reward=-2.20, EPSILON=0.978, (W=626,D=4,L=0)
2025-01-16 05:14:54,950 - DEBUG - Q-vals = [0.15995358 0.09893423 0.15723892 0.07128599 0.23865367 0.10906179
 0.16487181], best_act=4, best_val=0.239
2025-01-16 05:14:54,950 - DEBUG - Low Q-value (0.239), using MCTS.
2025-01-16 05:14:54,965 - INFO - Episode 2460/98900: Winner=2, Reward=-9.95, EPSILON=0.978, (W=627,D=4,L=0)
2025-01-16 05:14:55,278 - INFO - Episode 2461/98900: Winner=2, Reward=-43.05, EPSILON=0.978, (W=628,D=4,L=0)
2025-01-16 05:14:55,481 - INFO - Episode 2462/98900: Winner=2, Reward=-8.00, EPSILON=0.978, (W=629,D=4,L=0)
2025-01-16 05:14:55,606 - INFO - Episode 2463/98900: Winner=2, Reward=12.25, EPSILON=0.978, (W=629,D=4,L=0)
2025-01-16 05:14:55,903 - INFO - Episode 2464/98900: Winner=2, Reward=-38.40, EPSILON=0.978, (W=629,D=4,L=0)
2025-01-16 05:14:56,257 - INFO - Episode 2465/98900: Winner=2, Reward=-43.25, EPSILON=0.978, (W=630,D=4,L=0)
2025-01-16 05:14:56,649 - DEBUG - Q-vals = [0.0059656  0.02351571 0.01817375 0.8496551  0.00130387 0.09607872
 0.00530737], best_act=3, best_val=0.850
2025-01-16 05:14:56,649 - DEBUG - Low Q-value (0.850), using MCTS.
2025-01-16 05:14:56,664 - INFO - Episode 2466/98900: Winner=2, Reward=-48.75, EPSILON=0.978, (W=631,D=4,L=0)
2025-01-16 05:14:56,857 - INFO - Episode 2467/98900: Winner=2, Reward=-5.05, EPSILON=0.978, (W=631,D=4,L=0)
2025-01-16 05:14:57,264 - INFO - Episode 2468/98900: Winner=2, Reward=-70.30, EPSILON=0.978, (W=632,D=4,L=0)
2025-01-16 05:14:57,421 - INFO - Episode 2469/98900: Winner=2, Reward=-2.85, EPSILON=0.978, (W=632,D=4,L=0)
2025-01-16 05:14:57,577 - INFO - Episode 2470/98900: Winner=2, Reward=-10.05, EPSILON=0.978, (W=633,D=4,L=0)
2025-01-16 05:14:57,656 - DEBUG - Q-vals = [0.2312459  0.12876065 0.12467637 0.10719447 0.11912329 0.11012727
 0.17887196], best_act=0, best_val=0.231
2025-01-16 05:14:57,656 - DEBUG - Low Q-value (0.231), using MCTS.
2025-01-16 05:14:57,656 - INFO - Running MCTS with 108 simulations using 6 processes.
2025-01-16 05:15:00,328 - DEBUG - Aggregated action counts: {2: 1, 3: 2, 6: 2, 4: 1}
2025-01-16 05:15:00,328 - DEBUG - Chose best action 3
2025-01-16 05:15:00,559 - INFO - Episode 2471/98900: Winner=2, Reward=-23.65, EPSILON=0.978, (W=633,D=4,L=0)
2025-01-16 05:15:00,749 - DEBUG - Q-vals = [0.17402858 0.0964101  0.09180497 0.11579478 0.03069983 0.09664853
 0.3946132 ], best_act=6, best_val=0.395
2025-01-16 05:15:00,749 - DEBUG - Low Q-value (0.395), using MCTS.
2025-01-16 05:15:00,750 - INFO - Running MCTS with 108 simulations using 6 processes.
2025-01-16 05:15:03,465 - DEBUG - Aggregated action counts: {3: 1, 0: 2, 4: 2, 6: 1}
2025-01-16 05:15:03,465 - DEBUG - Chose best action 0
2025-01-16 05:15:03,595 - INFO - Episode 2472/98900: Winner=2, Reward=23.40, EPSILON=0.978, (W=633,D=4,L=0)
2025-01-16 05:15:03,720 - INFO - Episode 2473/98900: Winner=2, Reward=-0.45, EPSILON=0.978, (W=633,D=4,L=0)
2025-01-16 05:15:04,095 - INFO - Episode 2474/98900: Winner=2, Reward=-64.55, EPSILON=0.978, (W=633,D=4,L=0)
2025-01-16 05:15:04,241 - INFO - Episode 2475/98900: Winner=2, Reward=-17.05, EPSILON=0.978, (W=634,D=4,L=0)
2025-01-16 05:15:04,257 - DEBUG - Q-vals = [0.02106031 0.01287693 0.00114879 0.00320111 0.0008134  0.2586733
 0.7022262 ], best_act=6, best_val=0.702
2025-01-16 05:15:04,257 - DEBUG - Low Q-value (0.702), using MCTS.
2025-01-16 05:15:04,257 - INFO - Running MCTS with 109 simulations using 6 processes.
2025-01-16 05:15:06,946 - DEBUG - Aggregated action counts: {5: 2, 4: 1, 1: 1, 0: 3}
2025-01-16 05:15:06,946 - DEBUG - Chose best action 0
2025-01-16 05:15:07,300 - INFO - Episode 2476/98900: Winner=2, Reward=-31.50, EPSILON=0.978, (W=635,D=4,L=0)
2025-01-16 05:15:07,522 - INFO - Episode 2477/98900: Winner=2, Reward=-12.85, EPSILON=0.978, (W=635,D=4,L=0)
2025-01-16 05:15:07,613 - INFO - Episode 2478/98900: Winner=2, Reward=16.10, EPSILON=0.978, (W=635,D=4,L=0)
2025-01-16 05:15:07,837 - INFO - Episode 2479/98900: Winner=2, Reward=-27.95, EPSILON=0.978, (W=636,D=4,L=0)
2025-01-16 05:15:08,062 - INFO - Episode 2480/98900: Winner=2, Reward=-7.05, EPSILON=0.978, (W=636,D=4,L=0)
2025-01-16 05:15:08,226 - INFO - Episode 2481/98900: Winner=2, Reward=12.35, EPSILON=0.978, (W=636,D=4,L=0)
2025-01-16 05:15:08,470 - INFO - Episode 2482/98900: Winner=2, Reward=-22.80, EPSILON=0.978, (W=637,D=4,L=0)
2025-01-16 05:15:08,626 - INFO - Episode 2483/98900: Winner=2, Reward=-11.70, EPSILON=0.978, (W=638,D=4,L=0)
2025-01-16 05:15:08,896 - INFO - Episode 2484/98900: Winner=2, Reward=0.95, EPSILON=0.978, (W=639,D=4,L=0)
2025-01-16 05:15:09,167 - INFO - Episode 2485/98900: Winner=2, Reward=0.05, EPSILON=0.978, (W=639,D=4,L=0)
2025-01-16 05:15:09,371 - INFO - Episode 2486/98900: Winner=2, Reward=-0.15, EPSILON=0.978, (W=640,D=4,L=0)
2025-01-16 05:15:09,454 - DEBUG - Q-vals = [0.19675067 0.14197797 0.1377655  0.07522882 0.12570505 0.17076145
 0.15181053], best_act=0, best_val=0.197
2025-01-16 05:15:09,454 - DEBUG - Low Q-value (0.197), using MCTS.
2025-01-16 05:15:09,455 - INFO - Running MCTS with 109 simulations using 6 processes.
2025-01-16 05:15:12,195 - DEBUG - Aggregated action counts: {2: 2, 1: 1, 0: 3, 3: 1}
2025-01-16 05:15:12,195 - DEBUG - Chose best action 0
2025-01-16 05:15:12,256 - INFO - Episode 2487/98900: Winner=2, Reward=-0.80, EPSILON=0.978, (W=640,D=4,L=0)
2025-01-16 05:15:12,398 - INFO - Episode 2488/98900: Winner=2, Reward=-8.45, EPSILON=0.978, (W=641,D=4,L=0)
2025-01-16 05:15:12,617 - INFO - Episode 2489/98900: Winner=2, Reward=-13.95, EPSILON=0.978, (W=642,D=4,L=0)
2025-01-16 05:15:12,889 - INFO - Episode 2490/98900: Winner=2, Reward=-32.95, EPSILON=0.978, (W=643,D=4,L=0)
2025-01-16 05:15:13,031 - INFO - Episode 2491/98900: Winner=2, Reward=4.30, EPSILON=0.978, (W=643,D=4,L=0)
2025-01-16 05:15:13,159 - INFO - Episode 2492/98900: Winner=2, Reward=-11.85, EPSILON=0.978, (W=644,D=4,L=0)
2025-01-16 05:15:13,471 - INFO - Episode 2493/98900: Winner=2, Reward=-36.75, EPSILON=0.978, (W=645,D=4,L=0)
2025-01-16 05:15:13,586 - INFO - Episode 2494/98900: Winner=2, Reward=9.85, EPSILON=0.978, (W=645,D=4,L=0)
2025-01-16 05:15:13,618 - DEBUG - Q-vals = [3.0267779e-02 2.6684817e-02 8.6563630e-03 9.3267381e-01 3.2799617e-05
 7.9187041e-04 8.9258188e-04], best_act=3, best_val=0.933
2025-01-16 05:15:13,618 - DEBUG - Low Q-value (0.933), using MCTS.
2025-01-16 05:15:13,618 - INFO - Running MCTS with 109 simulations using 6 processes.
2025-01-16 05:15:16,302 - DEBUG - Aggregated action counts: {0: 2, 1: 2, 4: 1, 2: 1, 3: 1}
2025-01-16 05:15:16,302 - DEBUG - Chose best action 0
2025-01-16 05:15:16,355 - INFO - Episode 2495/98900: Winner=2, Reward=-2.75, EPSILON=0.978, (W=646,D=4,L=0)
2025-01-16 05:15:16,479 - DEBUG - Q-vals = [0.14098792 0.10966464 0.12567216 0.08157715 0.25505587 0.1179835
 0.16905876], best_act=4, best_val=0.255
2025-01-16 05:15:16,479 - DEBUG - Low Q-value (0.255), using MCTS.
2025-01-16 05:15:16,480 - INFO - Running MCTS with 109 simulations using 6 processes.
2025-01-16 05:15:19,329 - DEBUG - Aggregated action counts: {3: 2, 5: 1, 0: 2, 2: 1, 4: 1}
2025-01-16 05:15:19,329 - DEBUG - Chose best action 3
2025-01-16 05:15:19,505 - INFO - Episode 2496/98900: Winner=2, Reward=-46.10, EPSILON=0.978, (W=647,D=4,L=0)
2025-01-16 05:15:19,849 - INFO - Episode 2497/98900: Winner=2, Reward=-31.25, EPSILON=0.978, (W=647,D=4,L=0)
2025-01-16 05:15:20,072 - INFO - Episode 2498/98900: Winner=2, Reward=-7.95, EPSILON=0.978, (W=648,D=4,L=0)
2025-01-16 05:15:20,150 - DEBUG - Q-vals = [0.14811715 0.15478906 0.06372131 0.02271397 0.19879754 0.27798718
 0.13387372], best_act=5, best_val=0.278
2025-01-16 05:15:20,150 - DEBUG - Low Q-value (0.278), using MCTS.
2025-01-16 05:15:20,150 - INFO - Running MCTS with 109 simulations using 6 processes.
2025-01-16 05:15:22,753 - DEBUG - Aggregated action counts: {1: 1, 3: 4, 2: 1, 6: 1}
2025-01-16 05:15:22,753 - DEBUG - Chose best action 3
2025-01-16 05:15:22,894 - INFO - Episode 2499/98900: Winner=2, Reward=-0.05, EPSILON=0.978, (W=648,D=4,L=0)
2025-01-16 05:15:23,248 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2500.
2025-01-16 05:15:23,248 - INFO - Models saved at episode 2500
2025-01-16 05:15:23,248 - INFO - Target networks updated
2025-01-16 05:15:23,311 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2500.
2025-01-16 05:15:23,311 - INFO - Episode 2500/98900: Winner=2, Reward=-18.85, EPSILON=0.978, (W=648,D=4,L=0)
2025-01-16 05:15:23,496 - INFO - Episode 2501/98900: Winner=2, Reward=13.15, EPSILON=0.978, (W=648,D=4,L=0)
2025-01-16 05:15:23,630 - INFO - Episode 2502/98900: Winner=2, Reward=10.35, EPSILON=0.978, (W=648,D=4,L=0)
2025-01-16 05:15:23,796 - DEBUG - Q-vals = [0.07652327 0.01883713 0.17937896 0.02452104 0.41447896 0.0750479
 0.21121277], best_act=4, best_val=0.414
2025-01-16 05:15:23,796 - DEBUG - Low Q-value (0.414), using MCTS.
2025-01-16 05:15:23,796 - INFO - Running MCTS with 110 simulations using 6 processes.
2025-01-16 05:15:26,614 - DEBUG - Aggregated action counts: {1: 2, 6: 3, 0: 2}
2025-01-16 05:15:26,614 - DEBUG - Chose best action 6
2025-01-16 05:15:26,645 - INFO - Episode 2503/98900: Winner=2, Reward=-6.25, EPSILON=0.978, (W=648,D=4,L=0)
2025-01-16 05:15:26,748 - INFO - Episode 2504/98900: Winner=2, Reward=-0.50, EPSILON=0.978, (W=648,D=4,L=0)
2025-01-16 05:15:27,129 - INFO - Episode 2505/98900: Winner=2, Reward=-24.95, EPSILON=0.978, (W=648,D=4,L=0)
2025-01-16 05:15:27,229 - INFO - Episode 2506/98900: Winner=2, Reward=20.90, EPSILON=0.978, (W=648,D=4,L=0)
2025-01-16 05:15:27,417 - INFO - Episode 2507/98900: Winner=2, Reward=-4.25, EPSILON=0.978, (W=648,D=4,L=0)
2025-01-16 05:15:27,626 - INFO - Episode 2508/98900: Winner=2, Reward=-13.75, EPSILON=0.978, (W=648,D=4,L=0)
2025-01-16 05:15:27,857 - INFO - Episode 2509/98900: Winner=2, Reward=-11.65, EPSILON=0.978, (W=648,D=4,L=0)
2025-01-16 05:15:28,044 - DEBUG - Q-vals = [0.13112797 0.03108817 0.40075937 0.2160115  0.06550601 0.03615516
 0.11935181], best_act=2, best_val=0.401
2025-01-16 05:15:28,044 - DEBUG - Low Q-value (0.401), using MCTS.
2025-01-16 05:15:28,044 - INFO - Running MCTS with 110 simulations using 6 processes.
2025-01-16 05:15:30,804 - DEBUG - Aggregated action counts: {2: 2, 4: 2, 1: 3}
2025-01-16 05:15:30,804 - DEBUG - Chose best action 1
2025-01-16 05:15:30,815 - INFO - Episode 2510/98900: Winner=2, Reward=7.75, EPSILON=0.978, (W=648,D=4,L=0)
2025-01-16 05:15:31,078 - INFO - Episode 2511/98900: Winner=2, Reward=-1.65, EPSILON=0.978, (W=648,D=4,L=0)
2025-01-16 05:15:31,440 - INFO - Episode 2512/98900: Winner=2, Reward=11.35, EPSILON=0.978, (W=648,D=4,L=0)
2025-01-16 05:15:31,585 - DEBUG - Q-vals = [0.17405099 0.15358715 0.11912111 0.11939953 0.16144313 0.12239116
 0.150007  ], best_act=0, best_val=0.174
2025-01-16 05:15:31,585 - DEBUG - Low Q-value (0.174), using MCTS.
2025-01-16 05:15:31,585 - INFO - Running MCTS with 110 simulations using 6 processes.
2025-01-16 05:15:34,347 - DEBUG - Aggregated action counts: {1: 1, 0: 2, 3: 2, 4: 1, 5: 1}
2025-01-16 05:15:34,348 - DEBUG - Chose best action 0
2025-01-16 05:15:34,380 - INFO - Episode 2513/98900: Winner=2, Reward=4.80, EPSILON=0.978, (W=649,D=4,L=0)
2025-01-16 05:15:34,630 - INFO - Episode 2514/98900: Winner=2, Reward=-11.80, EPSILON=0.978, (W=650,D=4,L=0)
2025-01-16 05:15:34,862 - INFO - Episode 2515/98900: Winner=2, Reward=-2.25, EPSILON=0.978, (W=650,D=4,L=0)
2025-01-16 05:15:35,097 - INFO - Episode 2516/98900: Winner=2, Reward=-31.25, EPSILON=0.978, (W=651,D=4,L=0)
2025-01-16 05:15:35,367 - INFO - Episode 2517/98900: Winner=2, Reward=-26.35, EPSILON=0.978, (W=651,D=4,L=0)
2025-01-16 05:15:35,537 - DEBUG - Q-vals = [0.15215942 0.12154495 0.15534735 0.09174673 0.22574449 0.10416818
 0.14928891], best_act=4, best_val=0.226
2025-01-16 05:15:35,537 - DEBUG - Low Q-value (0.226), using MCTS.
2025-01-16 05:15:35,537 - INFO - Running MCTS with 110 simulations using 6 processes.
2025-01-16 05:15:38,414 - DEBUG - Aggregated action counts: {5: 1, 4: 1, 6: 1, 2: 2, 1: 1, 0: 1}
2025-01-16 05:15:38,414 - DEBUG - Chose best action 2
2025-01-16 05:15:38,577 - INFO - Episode 2518/98900: Winner=2, Reward=-28.30, EPSILON=0.978, (W=652,D=4,L=0)
2025-01-16 05:15:38,835 - INFO - Episode 2519/98900: Winner=2, Reward=-42.45, EPSILON=0.978, (W=653,D=4,L=0)
2025-01-16 05:15:39,048 - INFO - Episode 2520/98900: Winner=2, Reward=-2.40, EPSILON=0.978, (W=653,D=4,L=0)
2025-01-16 05:15:39,173 - DEBUG - Q-vals = [0.15884206 0.15113567 0.1412358  0.13971737 0.14337698 0.13120537
 0.1344867 ], best_act=0, best_val=0.159
2025-01-16 05:15:39,173 - DEBUG - Low Q-value (0.159), using MCTS.
2025-01-16 05:15:39,173 - INFO - Running MCTS with 110 simulations using 6 processes.
2025-01-16 05:15:41,908 - DEBUG - Aggregated action counts: {1: 2, 2: 3, 3: 1, 0: 1}
2025-01-16 05:15:41,908 - DEBUG - Chose best action 2
2025-01-16 05:15:42,008 - INFO - Episode 2521/98900: Winner=2, Reward=-21.20, EPSILON=0.978, (W=654,D=4,L=0)
2025-01-16 05:15:42,071 - DEBUG - Q-vals = [0.08670349 0.07021396 0.37515628 0.10274529 0.05436472 0.23841076
 0.07240546], best_act=2, best_val=0.375
2025-01-16 05:15:42,071 - DEBUG - Low Q-value (0.375), using MCTS.
2025-01-16 05:15:42,071 - INFO - Running MCTS with 110 simulations using 6 processes.
2025-01-16 05:15:44,731 - DEBUG - Aggregated action counts: {0: 3, 1: 1, 2: 1, 3: 1, 5: 1}
2025-01-16 05:15:44,731 - DEBUG - Chose best action 0
2025-01-16 05:15:44,997 - INFO - Episode 2522/98900: Winner=2, Reward=-30.50, EPSILON=0.978, (W=655,D=4,L=0)
2025-01-16 05:15:45,309 - INFO - Episode 2523/98900: Winner=2, Reward=-30.70, EPSILON=0.978, (W=656,D=4,L=0)
2025-01-16 05:15:45,497 - INFO - Episode 2524/98900: Winner=2, Reward=-9.95, EPSILON=0.978, (W=657,D=4,L=0)
2025-01-16 05:15:45,716 - INFO - Episode 2525/98900: Winner=2, Reward=-14.75, EPSILON=0.978, (W=658,D=4,L=0)
2025-01-16 05:15:45,903 - INFO - Episode 2526/98900: Winner=2, Reward=-11.60, EPSILON=0.978, (W=659,D=4,L=0)
2025-01-16 05:15:46,028 - DEBUG - Q-vals = [0.1127623  0.1856319  0.12037031 0.12905091 0.14150654 0.16542237
 0.14525574], best_act=1, best_val=0.186
2025-01-16 05:15:46,028 - DEBUG - Low Q-value (0.186), using MCTS.
2025-01-16 05:15:46,028 - INFO - Running MCTS with 111 simulations using 6 processes.
2025-01-16 05:15:48,815 - DEBUG - Aggregated action counts: {3: 3, 0: 2, 1: 1, 4: 1}
2025-01-16 05:15:48,815 - DEBUG - Chose best action 3
2025-01-16 05:15:48,990 - INFO - Episode 2527/98900: Winner=2, Reward=-11.95, EPSILON=0.978, (W=659,D=4,L=0)
2025-01-16 05:15:49,224 - INFO - Episode 2528/98900: Winner=2, Reward=-46.40, EPSILON=0.978, (W=660,D=4,L=0)
2025-01-16 05:15:49,458 - INFO - Episode 2529/98900: Winner=2, Reward=9.40, EPSILON=0.977, (W=660,D=4,L=0)
2025-01-16 05:15:49,696 - DEBUG - Q-vals = [0.12571757 0.07652591 0.21531576 0.11928813 0.25930387 0.1366085
 0.06724031], best_act=2, best_val=0.215
2025-01-16 05:15:49,696 - DEBUG - Low Q-value (0.215), using MCTS.
2025-01-16 05:15:49,700 - INFO - Episode 2530/98900: Winner=2, Reward=-11.65, EPSILON=0.977, (W=661,D=4,L=0)
2025-01-16 05:15:49,763 - INFO - Episode 2531/98900: Winner=2, Reward=8.20, EPSILON=0.977, (W=661,D=4,L=0)
2025-01-16 05:15:49,934 - INFO - Episode 2532/98900: Winner=2, Reward=-1.85, EPSILON=0.977, (W=661,D=4,L=0)
2025-01-16 05:15:50,106 - INFO - Episode 2533/98900: Winner=2, Reward=8.45, EPSILON=0.977, (W=661,D=4,L=0)
2025-01-16 05:15:50,282 - DEBUG - Q-vals = [0.1397543  0.09496936 0.18574283 0.10679067 0.18719926 0.09859507
 0.18694851], best_act=4, best_val=0.187
2025-01-16 05:15:50,282 - DEBUG - Low Q-value (0.187), using MCTS.
2025-01-16 05:15:50,283 - INFO - Running MCTS with 111 simulations using 6 processes.
2025-01-16 05:15:52,908 - DEBUG - Aggregated action counts: {1: 3, 3: 2, 6: 1, 0: 1}
2025-01-16 05:15:52,908 - DEBUG - Chose best action 1
2025-01-16 05:15:52,954 - INFO - Episode 2534/98900: Winner=2, Reward=-2.40, EPSILON=0.977, (W=662,D=4,L=0)
2025-01-16 05:15:53,168 - INFO - Episode 2535/98900: Winner=2, Reward=13.15, EPSILON=0.977, (W=663,D=4,L=0)
2025-01-16 05:15:53,476 - INFO - Episode 2536/98900: Winner=2, Reward=2.65, EPSILON=0.977, (W=663,D=4,L=0)
2025-01-16 05:15:53,736 - INFO - Episode 2537/98900: Winner=2, Reward=-20.00, EPSILON=0.977, (W=664,D=4,L=0)
2025-01-16 05:15:53,878 - INFO - Episode 2538/98900: Winner=2, Reward=5.75, EPSILON=0.977, (W=664,D=4,L=0)
2025-01-16 05:15:54,177 - INFO - Episode 2539/98900: Winner=2, Reward=-4.95, EPSILON=0.977, (W=664,D=4,L=0)
2025-01-16 05:15:54,413 - INFO - Episode 2540/98900: Winner=2, Reward=-28.80, EPSILON=0.977, (W=664,D=4,L=0)
2025-01-16 05:15:54,659 - INFO - Episode 2541/98900: Winner=2, Reward=-11.25, EPSILON=0.977, (W=664,D=4,L=0)
2025-01-16 05:15:54,905 - INFO - Episode 2542/98900: Winner=2, Reward=-7.60, EPSILON=0.977, (W=664,D=4,L=0)
2025-01-16 05:15:55,100 - INFO - Episode 2543/98900: Winner=2, Reward=-9.75, EPSILON=0.977, (W=665,D=4,L=0)
2025-01-16 05:15:55,334 - DEBUG - Q-vals = [0.0793905  0.08509937 0.10785303 0.24142697 0.20911425 0.1579893
 0.11912654], best_act=3, best_val=0.241
2025-01-16 05:15:55,334 - DEBUG - Low Q-value (0.241), using MCTS.
2025-01-16 05:15:55,334 - INFO - Running MCTS with 111 simulations using 6 processes.
2025-01-16 05:15:57,977 - DEBUG - Aggregated action counts: {5: 1, 2: 2, 3: 2, 1: 1, 0: 1}
2025-01-16 05:15:57,977 - DEBUG - Chose best action 2
2025-01-16 05:15:58,040 - INFO - Episode 2544/98900: Winner=2, Reward=-10.40, EPSILON=0.977, (W=665,D=4,L=0)
2025-01-16 05:15:58,240 - INFO - Episode 2545/98900: Winner=2, Reward=10.95, EPSILON=0.977, (W=665,D=4,L=0)
2025-01-16 05:15:58,498 - INFO - Episode 2546/98900: Winner=2, Reward=-3.20, EPSILON=0.977, (W=666,D=4,L=0)
2025-01-16 05:15:58,701 - INFO - Episode 2547/98900: Winner=2, Reward=-9.95, EPSILON=0.977, (W=666,D=4,L=0)
2025-01-16 05:15:58,748 - DEBUG - Q-vals = [0.22565003 0.20385452 0.06781966 0.12358012 0.05737754 0.09209611
 0.22962204], best_act=6, best_val=0.230
2025-01-16 05:15:58,748 - DEBUG - Low Q-value (0.230), using MCTS.
2025-01-16 05:15:58,748 - INFO - Running MCTS with 111 simulations using 6 processes.
2025-01-16 05:16:01,617 - DEBUG - Aggregated action counts: {0: 2, 3: 3, 1: 1, 5: 1}
2025-01-16 05:16:01,617 - DEBUG - Chose best action 3
2025-01-16 05:16:01,719 - INFO - Episode 2548/98900: Winner=2, Reward=-8.15, EPSILON=0.977, (W=667,D=4,L=0)
2025-01-16 05:16:01,811 - DEBUG - Q-vals = [0.14554068 0.13348764 0.17409137 0.26397404 0.06064707 0.09608232
 0.12617685], best_act=3, best_val=0.264
2025-01-16 05:16:01,811 - DEBUG - Low Q-value (0.264), using MCTS.
2025-01-16 05:16:01,811 - INFO - Running MCTS with 111 simulations using 6 processes.
2025-01-16 05:16:04,961 - DEBUG - Aggregated action counts: {0: 3, 5: 1, 3: 1, 2: 1, 4: 1}
2025-01-16 05:16:04,961 - DEBUG - Chose best action 0
2025-01-16 05:16:04,993 - DEBUG - Q-vals = [0.14591342 0.11244646 0.20209917 0.2656484  0.06672339 0.08770245
 0.11946668], best_act=3, best_val=0.266
2025-01-16 05:16:04,993 - DEBUG - Low Q-value (0.266), using MCTS.
2025-01-16 05:16:04,993 - INFO - Running MCTS with 111 simulations using 6 processes.
2025-01-16 05:16:07,961 - DEBUG - Aggregated action counts: {4: 2, 0: 3, 5: 1, 3: 1}
2025-01-16 05:16:07,961 - DEBUG - Chose best action 0
2025-01-16 05:16:08,008 - DEBUG - Q-vals = [0.01791841 0.03536347 0.03593208 0.69839835 0.00863906 0.13551432
 0.06823426], best_act=3, best_val=0.698
2025-01-16 05:16:08,008 - DEBUG - Low Q-value (0.698), using MCTS.
2025-01-16 05:16:08,008 - INFO - Running MCTS with 111 simulations using 6 processes.
2025-01-16 05:16:11,401 - DEBUG - Aggregated action counts: {3: 2, 1: 2, 2: 1, 0: 2}
2025-01-16 05:16:11,401 - DEBUG - Chose best action 3
2025-01-16 05:16:11,571 - INFO - Episode 2549/98900: Winner=2, Reward=-19.45, EPSILON=0.977, (W=668,D=4,L=0)
2025-01-16 05:16:11,878 - INFO - Episode 2550/98900: Winner=2, Reward=-5.20, EPSILON=0.977, (W=668,D=4,L=0)
2025-01-16 05:16:12,016 - INFO - Episode 2551/98900: Winner=2, Reward=-1.75, EPSILON=0.977, (W=668,D=4,L=0)
2025-01-16 05:16:12,283 - INFO - Episode 2552/98900: Winner=2, Reward=0.40, EPSILON=0.977, (W=668,D=4,L=0)
2025-01-16 05:16:12,586 - INFO - Episode 2553/98900: Winner=2, Reward=6.25, EPSILON=0.977, (W=668,D=4,L=0)
2025-01-16 05:16:12,912 - INFO - Episode 2554/98900: Winner=2, Reward=-49.15, EPSILON=0.977, (W=669,D=4,L=0)
2025-01-16 05:16:13,189 - INFO - Episode 2555/98900: Winner=2, Reward=-3.30, EPSILON=0.977, (W=669,D=4,L=0)
2025-01-16 05:16:13,332 - INFO - Episode 2556/98900: Winner=2, Reward=0.70, EPSILON=0.977, (W=670,D=4,L=0)
2025-01-16 05:16:13,364 - DEBUG - Q-vals = [2.3130335e-02 1.1958390e-02 4.0899636e-03 7.9636386e-04 3.9809442e-04
 9.4972163e-01 9.9051865e-03], best_act=5, best_val=0.950
2025-01-16 05:16:13,364 - DEBUG - Low Q-value (0.950), using MCTS.
2025-01-16 05:16:13,364 - INFO - Running MCTS with 112 simulations using 6 processes.
2025-01-16 05:16:16,855 - DEBUG - Aggregated action counts: {1: 3, 2: 1, 5: 1, 3: 1, 0: 1}
2025-01-16 05:16:16,855 - DEBUG - Chose best action 1
2025-01-16 05:16:17,021 - INFO - Episode 2557/98900: Winner=2, Reward=4.40, EPSILON=0.977, (W=670,D=4,L=0)
2025-01-16 05:16:17,200 - INFO - Episode 2558/98900: Winner=2, Reward=-3.25, EPSILON=0.977, (W=670,D=4,L=0)
2025-01-16 05:16:17,450 - INFO - Episode 2559/98900: Winner=2, Reward=8.85, EPSILON=0.977, (W=670,D=4,L=0)
2025-01-16 05:16:17,669 - INFO - Episode 2560/98900: Winner=2, Reward=-12.70, EPSILON=0.977, (W=671,D=4,L=0)
2025-01-16 05:16:17,731 - DEBUG - Q-vals = [0.34699103 0.14308393 0.18342052 0.16772814 0.02777411 0.03039333
 0.10060886], best_act=0, best_val=0.347
2025-01-16 05:16:17,731 - DEBUG - Low Q-value (0.347), using MCTS.
2025-01-16 05:16:17,731 - INFO - Running MCTS with 112 simulations using 6 processes.
2025-01-16 05:16:20,909 - DEBUG - Aggregated action counts: {2: 2, 1: 2, 6: 2, 0: 1}
2025-01-16 05:16:20,909 - DEBUG - Chose best action 2
2025-01-16 05:16:21,065 - INFO - Episode 2561/98900: Winner=2, Reward=7.85, EPSILON=0.977, (W=671,D=4,L=0)
2025-01-16 05:16:21,312 - INFO - Episode 2562/98900: Winner=2, Reward=20.80, EPSILON=0.977, (W=671,D=4,L=0)
2025-01-16 05:16:21,546 - INFO - Episode 2563/98900: Winner=2, Reward=-13.70, EPSILON=0.977, (W=672,D=4,L=0)
2025-01-16 05:16:21,624 - DEBUG - Q-vals = [0.16615587 0.16341215 0.13744716 0.14446646 0.12079761 0.12055469
 0.14716612], best_act=0, best_val=0.166
2025-01-16 05:16:21,624 - DEBUG - Low Q-value (0.166), using MCTS.
2025-01-16 05:16:21,624 - INFO - Running MCTS with 112 simulations using 6 processes.
2025-01-16 05:16:24,530 - DEBUG - Aggregated action counts: {2: 2, 3: 1, 1: 1, 5: 1, 4: 1, 0: 1}
2025-01-16 05:16:24,530 - DEBUG - Chose best action 2
2025-01-16 05:16:24,624 - INFO - Episode 2564/98900: Winner=2, Reward=20.30, EPSILON=0.977, (W=672,D=4,L=0)
2025-01-16 05:16:24,780 - INFO - Episode 2565/98900: Winner=2, Reward=-11.15, EPSILON=0.977, (W=673,D=4,L=0)
2025-01-16 05:16:25,092 - INFO - Episode 2566/98900: Winner=2, Reward=-7.05, EPSILON=0.977, (W=673,D=4,L=0)
2025-01-16 05:16:25,405 - INFO - Episode 2567/98900: Winner=2, Reward=-15.25, EPSILON=0.977, (W=673,D=4,L=0)
2025-01-16 05:16:25,764 - INFO - Episode 2568/98900: Winner=2, Reward=-76.65, EPSILON=0.977, (W=673,D=4,L=0)
2025-01-16 05:16:26,061 - INFO - Episode 2569/98900: Winner=2, Reward=21.45, EPSILON=0.977, (W=673,D=4,L=0)
2025-01-16 05:16:26,436 - INFO - Episode 2570/98900: Winner=2, Reward=-45.80, EPSILON=0.977, (W=674,D=4,L=0)
2025-01-16 05:16:26,779 - INFO - Episode 2571/98900: Winner=2, Reward=-55.95, EPSILON=0.977, (W=675,D=4,L=0)
2025-01-16 05:16:26,982 - INFO - Episode 2572/98900: Winner=2, Reward=-5.35, EPSILON=0.977, (W=675,D=4,L=0)
2025-01-16 05:16:27,310 - INFO - Episode 2573/98900: Winner=2, Reward=-53.15, EPSILON=0.977, (W=676,D=4,L=0)
2025-01-16 05:16:27,482 - INFO - Episode 2574/98900: Winner=2, Reward=-13.80, EPSILON=0.977, (W=677,D=4,L=0)
2025-01-16 05:16:27,623 - INFO - Episode 2575/98900: Winner=2, Reward=-3.35, EPSILON=0.977, (W=677,D=4,L=0)
2025-01-16 05:16:27,888 - INFO - Episode 2576/98900: Winner=2, Reward=-4.45, EPSILON=0.977, (W=678,D=4,L=0)
2025-01-16 05:16:27,982 - INFO - Episode 2577/98900: Winner=2, Reward=0.60, EPSILON=0.977, (W=678,D=4,L=0)
2025-01-16 05:16:28,248 - INFO - Episode 2578/98900: Winner=2, Reward=-3.05, EPSILON=0.977, (W=678,D=4,L=0)
2025-01-16 05:16:28,373 - INFO - Episode 2579/98900: Winner=2, Reward=9.55, EPSILON=0.977, (W=678,D=4,L=0)
2025-01-16 05:16:28,451 - DEBUG - Q-vals = [0.09872671 0.08035801 0.08824307 0.37512198 0.06057563 0.09336765
 0.20360701], best_act=3, best_val=0.375
2025-01-16 05:16:28,451 - DEBUG - Low Q-value (0.375), using MCTS.
2025-01-16 05:16:28,451 - INFO - Running MCTS with 113 simulations using 6 processes.
2025-01-16 05:16:31,165 - DEBUG - Aggregated action counts: {4: 3, 0: 3, 1: 1}
2025-01-16 05:16:31,165 - DEBUG - Chose best action 4
2025-01-16 05:16:31,477 - INFO - Episode 2580/98900: Winner=2, Reward=-15.30, EPSILON=0.977, (W=678,D=4,L=0)
2025-01-16 05:16:31,536 - DEBUG - Q-vals = [0.13794301 0.0775385  0.15246716 0.0710325  0.27153054 0.12773497
 0.16175334], best_act=4, best_val=0.272
2025-01-16 05:16:31,536 - DEBUG - Low Q-value (0.272), using MCTS.
2025-01-16 05:16:31,537 - INFO - Running MCTS with 113 simulations using 6 processes.
2025-01-16 05:16:34,290 - DEBUG - Aggregated action counts: {0: 2, 1: 5}
2025-01-16 05:16:34,290 - DEBUG - Chose best action 1
2025-01-16 05:16:34,461 - INFO - Episode 2581/98900: Winner=2, Reward=-6.15, EPSILON=0.977, (W=678,D=4,L=0)
2025-01-16 05:16:34,605 - INFO - Episode 2582/98900: Winner=2, Reward=-10.55, EPSILON=0.977, (W=679,D=4,L=0)
2025-01-16 05:16:35,000 - INFO - Episode 2583/98900: Winner=2, Reward=-78.95, EPSILON=0.977, (W=680,D=4,L=0)
2025-01-16 05:16:35,216 - DEBUG - Q-vals = [0.08893501 0.33106768 0.03090294 0.07906379 0.03238743 0.40105215
 0.03659101], best_act=5, best_val=0.401
2025-01-16 05:16:35,216 - DEBUG - Low Q-value (0.401), using MCTS.
2025-01-16 05:16:35,218 - INFO - Running MCTS with 113 simulations using 6 processes.
2025-01-16 05:16:38,102 - DEBUG - Aggregated action counts: {1: 2, 5: 1, 4: 1, 0: 3}
2025-01-16 05:16:38,103 - DEBUG - Chose best action 0
2025-01-16 05:16:38,164 - INFO - Episode 2584/98900: Winner=2, Reward=-28.25, EPSILON=0.977, (W=680,D=4,L=0)
2025-01-16 05:16:38,397 - INFO - Episode 2585/98900: Winner=2, Reward=-9.45, EPSILON=0.977, (W=681,D=4,L=0)
2025-01-16 05:16:38,579 - INFO - Episode 2586/98900: Winner=2, Reward=-2.95, EPSILON=0.977, (W=682,D=4,L=0)
2025-01-16 05:16:38,594 - DEBUG - Q-vals = [0.41195625 0.13579436 0.1711632  0.0495172  0.019485   0.07307302
 0.13901104], best_act=0, best_val=0.412
2025-01-16 05:16:38,594 - DEBUG - Low Q-value (0.412), using MCTS.
2025-01-16 05:16:38,594 - INFO - Running MCTS with 113 simulations using 6 processes.
2025-01-16 05:16:41,602 - DEBUG - Aggregated action counts: {1: 2, 4: 2, 3: 1, 0: 2}
2025-01-16 05:16:41,602 - DEBUG - Chose best action 1
2025-01-16 05:16:41,967 - INFO - Episode 2587/98900: Winner=2, Reward=-43.20, EPSILON=0.977, (W=683,D=4,L=0)
2025-01-16 05:16:42,101 - INFO - Episode 2588/98900: Winner=2, Reward=-14.35, EPSILON=0.977, (W=684,D=4,L=0)
2025-01-16 05:16:42,254 - INFO - Episode 2589/98900: Winner=2, Reward=0.25, EPSILON=0.977, (W=684,D=4,L=0)
2025-01-16 05:16:42,418 - DEBUG - Q-vals = [0.12051708 0.09906206 0.21371157 0.12625204 0.26063335 0.06783095
 0.11199304], best_act=4, best_val=0.261
2025-01-16 05:16:42,418 - DEBUG - Low Q-value (0.261), using MCTS.
2025-01-16 05:16:42,428 - INFO - Episode 2590/98900: Winner=2, Reward=-16.85, EPSILON=0.977, (W=685,D=4,L=0)
2025-01-16 05:16:42,683 - INFO - Episode 2591/98900: Winner=2, Reward=-18.10, EPSILON=0.977, (W=686,D=4,L=0)
2025-01-16 05:16:43,015 - INFO - Episode 2592/98900: Winner=2, Reward=21.50, EPSILON=0.977, (W=686,D=4,L=0)
2025-01-16 05:16:43,239 - INFO - Episode 2593/98900: Winner=2, Reward=9.60, EPSILON=0.977, (W=686,D=4,L=0)
2025-01-16 05:16:43,485 - INFO - Episode 2594/98900: Winner=2, Reward=8.35, EPSILON=0.977, (W=686,D=4,L=0)
2025-01-16 05:16:43,681 - INFO - Episode 2595/98900: Winner=2, Reward=-15.25, EPSILON=0.977, (W=686,D=4,L=0)
2025-01-16 05:16:44,015 - INFO - Episode 2596/98900: Winner=2, Reward=-18.15, EPSILON=0.977, (W=687,D=4,L=0)
2025-01-16 05:16:44,326 - INFO - Episode 2597/98900: Winner=2, Reward=-24.75, EPSILON=0.977, (W=688,D=4,L=0)
2025-01-16 05:16:44,538 - DEBUG - Q-vals = [0.09597105 0.0804764  0.2901089  0.09804243 0.26013726 0.09699099
 0.07827298], best_act=2, best_val=0.290
2025-01-16 05:16:44,538 - DEBUG - Low Q-value (0.290), using MCTS.
2025-01-16 05:16:44,554 - INFO - Episode 2598/98900: Winner=2, Reward=-13.75, EPSILON=0.977, (W=689,D=4,L=0)
2025-01-16 05:16:44,909 - INFO - Episode 2599/98900: Winner=2, Reward=-27.60, EPSILON=0.977, (W=689,D=4,L=0)
2025-01-16 05:16:45,201 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2600.
2025-01-16 05:16:45,201 - INFO - Models saved at episode 2600
2025-01-16 05:16:45,201 - INFO - Target networks updated
2025-01-16 05:16:45,259 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2600.
2025-01-16 05:16:45,259 - INFO - Episode 2600/98900: Winner=2, Reward=-6.40, EPSILON=0.977, (W=690,D=4,L=0)
2025-01-16 05:16:45,638 - INFO - Episode 2601/98900: Winner=2, Reward=-41.95, EPSILON=0.977, (W=691,D=4,L=0)
2025-01-16 05:16:45,753 - DEBUG - Q-vals = [0.12365857 0.08990644 0.15199076 0.07601766 0.27190664 0.10261256
 0.18390743], best_act=4, best_val=0.272
2025-01-16 05:16:45,753 - DEBUG - Low Q-value (0.272), using MCTS.
2025-01-16 05:16:45,769 - INFO - Episode 2602/98900: Winner=2, Reward=-10.20, EPSILON=0.977, (W=692,D=4,L=0)
2025-01-16 05:16:45,956 - INFO - Episode 2603/98900: Winner=2, Reward=-13.70, EPSILON=0.977, (W=693,D=4,L=0)
2025-01-16 05:16:46,160 - INFO - Episode 2604/98900: Winner=2, Reward=-25.30, EPSILON=0.977, (W=694,D=4,L=0)
2025-01-16 05:16:46,410 - INFO - Episode 2605/98900: Winner=2, Reward=-10.95, EPSILON=0.977, (W=694,D=4,L=0)
2025-01-16 05:16:46,745 - INFO - Episode 2606/98900: Winner=2, Reward=-16.15, EPSILON=0.977, (W=695,D=4,L=0)
2025-01-16 05:16:46,866 - INFO - Episode 2607/98900: Winner=2, Reward=5.25, EPSILON=0.977, (W=695,D=4,L=0)
2025-01-16 05:16:47,255 - INFO - Episode 2608/98900: Winner=2, Reward=-63.30, EPSILON=0.977, (W=695,D=4,L=0)
2025-01-16 05:16:47,389 - INFO - Episode 2609/98900: Winner=2, Reward=7.75, EPSILON=0.977, (W=695,D=4,L=0)
2025-01-16 05:16:47,576 - INFO - Episode 2610/98900: Winner=2, Reward=-21.80, EPSILON=0.977, (W=696,D=4,L=0)
2025-01-16 05:16:47,842 - INFO - Episode 2611/98900: Winner=2, Reward=-4.70, EPSILON=0.977, (W=696,D=4,L=0)
2025-01-16 05:16:48,107 - INFO - Episode 2612/98900: Winner=2, Reward=-2.40, EPSILON=0.977, (W=696,D=4,L=0)
2025-01-16 05:16:48,326 - INFO - Episode 2613/98900: Winner=2, Reward=19.10, EPSILON=0.977, (W=696,D=4,L=0)
2025-01-16 05:16:48,482 - DEBUG - Q-vals = [0.12918429 0.18539736 0.16574703 0.13075908 0.14731237 0.10486275
 0.13673721], best_act=1, best_val=0.185
2025-01-16 05:16:48,482 - DEBUG - Low Q-value (0.185), using MCTS.
2025-01-16 05:16:48,482 - INFO - Running MCTS with 114 simulations using 6 processes.
2025-01-16 05:16:51,388 - DEBUG - Aggregated action counts: {0: 1, 2: 2, 6: 2, 3: 1}
2025-01-16 05:16:51,388 - DEBUG - Chose best action 2
2025-01-16 05:16:51,513 - INFO - Episode 2614/98900: Winner=2, Reward=-18.95, EPSILON=0.977, (W=697,D=4,L=0)
2025-01-16 05:16:51,997 - INFO - Episode 2615/98900: Winner=2, Reward=-95.70, EPSILON=0.977, (W=698,D=4,L=0)
2025-01-16 05:16:52,091 - INFO - Episode 2616/98900: Winner=2, Reward=1.35, EPSILON=0.977, (W=698,D=4,L=0)
2025-01-16 05:16:52,232 - INFO - Episode 2617/98900: Winner=2, Reward=4.00, EPSILON=0.977, (W=698,D=4,L=0)
2025-01-16 05:16:52,591 - INFO - Episode 2618/98900: Winner=2, Reward=-2.15, EPSILON=0.977, (W=698,D=4,L=0)
2025-01-16 05:16:52,716 - INFO - Episode 2619/98900: Winner=2, Reward=-3.20, EPSILON=0.977, (W=698,D=4,L=0)
2025-01-16 05:16:53,028 - INFO - Episode 2620/98900: Winner=2, Reward=-9.75, EPSILON=0.977, (W=698,D=4,L=0)
2025-01-16 05:16:53,138 - DEBUG - Q-vals = [0.15628543 0.1435904  0.12502535 0.13815765 0.11530834 0.10369633
 0.21793646], best_act=6, best_val=0.218
2025-01-16 05:16:53,138 - DEBUG - Low Q-value (0.218), using MCTS.
2025-01-16 05:16:53,138 - INFO - Running MCTS with 114 simulations using 6 processes.
2025-01-16 05:16:55,871 - DEBUG - Aggregated action counts: {3: 1, 2: 2, 0: 1, 1: 1, 6: 1}
2025-01-16 05:16:55,871 - DEBUG - Chose best action 2
2025-01-16 05:16:56,152 - INFO - Episode 2621/98900: Winner=2, Reward=-44.15, EPSILON=0.977, (W=699,D=4,L=0)
2025-01-16 05:16:56,402 - INFO - Episode 2622/98900: Winner=2, Reward=-18.45, EPSILON=0.977, (W=699,D=4,L=0)
2025-01-16 05:16:56,762 - INFO - Episode 2623/98900: Winner=2, Reward=-34.60, EPSILON=0.977, (W=700,D=4,L=0)
2025-01-16 05:16:56,809 - DEBUG - Q-vals = [0.22999592 0.13714947 0.06067991 0.2921879  0.06025036 0.09798799
 0.12174839], best_act=3, best_val=0.292
2025-01-16 05:16:56,809 - DEBUG - Low Q-value (0.292), using MCTS.
2025-01-16 05:16:56,809 - INFO - Running MCTS with 114 simulations using 6 processes.
2025-01-16 05:16:59,480 - DEBUG - Aggregated action counts: {0: 3, 3: 1, 2: 2}
2025-01-16 05:16:59,480 - DEBUG - Chose best action 0
2025-01-16 05:16:59,605 - INFO - Episode 2624/98900: Winner=2, Reward=5.70, EPSILON=0.977, (W=700,D=4,L=0)
2025-01-16 05:16:59,715 - INFO - Episode 2625/98900: Winner=2, Reward=-10.00, EPSILON=0.977, (W=701,D=4,L=0)
2025-01-16 05:16:59,918 - INFO - Episode 2626/98900: Winner=2, Reward=-2.55, EPSILON=0.977, (W=701,D=4,L=0)
2025-01-16 05:17:00,152 - INFO - Episode 2627/98900: Winner=2, Reward=-2.05, EPSILON=0.977, (W=701,D=4,L=0)
2025-01-16 05:17:00,339 - INFO - Episode 2628/98900: Winner=2, Reward=-10.40, EPSILON=0.977, (W=702,D=4,L=0)
2025-01-16 05:17:00,402 - DEBUG - Q-vals = [0.16995001 0.08118453 0.10657369 0.07392514 0.15353821 0.19353063
 0.22129774], best_act=6, best_val=0.221
2025-01-16 05:17:00,402 - DEBUG - Low Q-value (0.221), using MCTS.
2025-01-16 05:17:00,402 - INFO - Running MCTS with 115 simulations using 6 processes.
2025-01-16 05:17:03,058 - DEBUG - Aggregated action counts: {0: 2, 4: 2, 2: 1, 3: 2}
2025-01-16 05:17:03,058 - DEBUG - Chose best action 0
2025-01-16 05:17:03,261 - INFO - Episode 2629/98900: Winner=2, Reward=-6.55, EPSILON=0.977, (W=702,D=4,L=0)
2025-01-16 05:17:03,355 - INFO - Episode 2630/98900: Winner=2, Reward=7.55, EPSILON=0.977, (W=702,D=4,L=0)
2025-01-16 05:17:03,527 - INFO - Episode 2631/98900: Winner=2, Reward=-12.60, EPSILON=0.977, (W=703,D=4,L=0)
2025-01-16 05:17:03,668 - INFO - Episode 2632/98900: Winner=2, Reward=-0.15, EPSILON=0.977, (W=703,D=4,L=0)
2025-01-16 05:17:04,011 - INFO - Episode 2633/98900: Winner=2, Reward=-12.80, EPSILON=0.977, (W=704,D=4,L=0)
2025-01-16 05:17:04,230 - INFO - Episode 2634/98900: Winner=2, Reward=-0.65, EPSILON=0.977, (W=704,D=4,L=0)
2025-01-16 05:17:04,417 - INFO - Episode 2635/98900: Winner=2, Reward=9.05, EPSILON=0.977, (W=704,D=4,L=0)
2025-01-16 05:17:04,527 - INFO - Episode 2636/98900: Winner=2, Reward=13.55, EPSILON=0.977, (W=704,D=4,L=0)
2025-01-16 05:17:04,605 - INFO - Episode 2637/98900: Winner=2, Reward=1.20, EPSILON=0.977, (W=704,D=4,L=0)
2025-01-16 05:17:04,699 - INFO - Episode 2638/98900: Winner=2, Reward=6.15, EPSILON=0.977, (W=704,D=4,L=0)
2025-01-16 05:17:05,027 - INFO - Episode 2639/98900: Winner=2, Reward=-47.50, EPSILON=0.977, (W=705,D=4,L=0)
2025-01-16 05:17:05,105 - INFO - Episode 2640/98900: Winner=2, Reward=1.05, EPSILON=0.977, (W=705,D=4,L=0)
2025-01-16 05:17:05,308 - INFO - Episode 2641/98900: Winner=2, Reward=-16.85, EPSILON=0.977, (W=706,D=4,L=0)
2025-01-16 05:17:05,542 - INFO - Episode 2642/98900: Winner=2, Reward=-15.25, EPSILON=0.977, (W=706,D=4,L=0)
2025-01-16 05:17:05,901 - INFO - Episode 2643/98900: Winner=2, Reward=-5.55, EPSILON=0.976, (W=706,D=4,L=0)
2025-01-16 05:17:06,058 - INFO - Episode 2644/98900: Winner=2, Reward=3.65, EPSILON=0.976, (W=706,D=4,L=0)
2025-01-16 05:17:06,245 - INFO - Episode 2645/98900: Winner=2, Reward=8.30, EPSILON=0.976, (W=706,D=4,L=0)
2025-01-16 05:17:06,395 - INFO - Episode 2646/98900: Winner=2, Reward=5.55, EPSILON=0.976, (W=706,D=4,L=0)
2025-01-16 05:17:06,555 - DEBUG - Q-vals = [0.16043991 0.12262362 0.15000795 0.11550963 0.16907397 0.07444396
 0.20790097], best_act=6, best_val=0.208
2025-01-16 05:17:06,555 - DEBUG - Low Q-value (0.208), using MCTS.
2025-01-16 05:17:06,556 - INFO - Running MCTS with 115 simulations using 6 processes.
2025-01-16 05:17:09,345 - DEBUG - Aggregated action counts: {4: 2, 0: 3, 1: 2}
2025-01-16 05:17:09,345 - DEBUG - Chose best action 0
2025-01-16 05:17:09,492 - INFO - Episode 2647/98900: Winner=2, Reward=-16.80, EPSILON=0.976, (W=707,D=4,L=0)
2025-01-16 05:17:09,648 - DEBUG - Q-vals = [0.05685952 0.02405536 0.00937787 0.27238858 0.00630079 0.01684905
 0.6141688 ], best_act=6, best_val=0.614
2025-01-16 05:17:09,648 - DEBUG - Low Q-value (0.614), using MCTS.
2025-01-16 05:17:09,648 - INFO - Running MCTS with 115 simulations using 6 processes.
2025-01-16 05:17:12,403 - DEBUG - Aggregated action counts: {1: 3, 6: 2, 3: 2}
2025-01-16 05:17:12,403 - DEBUG - Chose best action 1
2025-01-16 05:17:12,427 - DEBUG - Q-vals = [0.14169548 0.02813001 0.21158896 0.09334549 0.02539528 0.01918126
 0.48066348], best_act=6, best_val=0.481
2025-01-16 05:17:12,427 - DEBUG - Low Q-value (0.481), using MCTS.
2025-01-16 05:17:12,428 - INFO - Running MCTS with 115 simulations using 6 processes.
2025-01-16 05:17:15,269 - DEBUG - Aggregated action counts: {0: 1, 3: 2, 6: 2, 2: 1, 4: 1}
2025-01-16 05:17:15,269 - DEBUG - Chose best action 3
2025-01-16 05:17:15,363 - DEBUG - Q-vals = [0.06967304 0.05531406 0.1172827  0.4649862  0.06164459 0.12790573
 0.10319363], best_act=3, best_val=0.465
2025-01-16 05:17:15,363 - DEBUG - Low Q-value (0.465), using MCTS.
2025-01-16 05:17:15,363 - INFO - Running MCTS with 115 simulations using 6 processes.
2025-01-16 05:17:18,081 - DEBUG - Aggregated action counts: {6: 1, 3: 5, 5: 1}
2025-01-16 05:17:18,081 - DEBUG - Chose best action 3
2025-01-16 05:17:18,128 - DEBUG - Q-vals = [0.10202245 0.06856403 0.11863593 0.23620655 0.1504872  0.07836497
 0.2457188 ], best_act=6, best_val=0.246
2025-01-16 05:17:18,128 - DEBUG - Low Q-value (0.246), using MCTS.
2025-01-16 05:17:18,144 - INFO - Episode 2648/98900: Winner=2, Reward=-31.65, EPSILON=0.976, (W=708,D=4,L=0)
2025-01-16 05:17:18,300 - INFO - Episode 2649/98900: Winner=2, Reward=-10.65, EPSILON=0.976, (W=709,D=4,L=0)
2025-01-16 05:17:18,378 - DEBUG - Q-vals = [0.1368226  0.11609814 0.11481922 0.37981808 0.04898091 0.10247594
 0.10098505], best_act=3, best_val=0.380
2025-01-16 05:17:18,378 - DEBUG - Low Q-value (0.380), using MCTS.
2025-01-16 05:17:18,378 - INFO - Running MCTS with 116 simulations using 6 processes.
2025-01-16 05:17:21,127 - DEBUG - Aggregated action counts: {1: 2, 0: 3, 6: 1, 3: 1}
2025-01-16 05:17:21,127 - DEBUG - Chose best action 0
2025-01-16 05:17:21,596 - INFO - Episode 2650/98900: Winner=2, Reward=-4.35, EPSILON=0.976, (W=709,D=4,L=0)
2025-01-16 05:17:21,815 - INFO - Episode 2651/98900: Winner=2, Reward=5.15, EPSILON=0.976, (W=710,D=4,L=0)
2025-01-16 05:17:22,127 - INFO - Episode 2652/98900: Winner=2, Reward=-46.15, EPSILON=0.976, (W=710,D=4,L=0)
2025-01-16 05:17:22,221 - DEBUG - Q-vals = [0.11943814 0.09293108 0.14425796 0.19042127 0.0690124  0.15022439
 0.23371486], best_act=6, best_val=0.234
2025-01-16 05:17:22,221 - DEBUG - Low Q-value (0.234), using MCTS.
2025-01-16 05:17:22,221 - INFO - Running MCTS with 116 simulations using 6 processes.
2025-01-16 05:17:25,205 - DEBUG - Aggregated action counts: {0: 2, 5: 1, 6: 1, 3: 1, 1: 2}
2025-01-16 05:17:25,205 - DEBUG - Chose best action 0
2025-01-16 05:17:25,315 - INFO - Episode 2653/98900: Winner=2, Reward=-15.95, EPSILON=0.976, (W=711,D=4,L=0)
2025-01-16 05:17:25,424 - DEBUG - Q-vals = [0.16571167 0.1441954  0.11336634 0.09828509 0.20324074 0.10885382
 0.16634695], best_act=4, best_val=0.203
2025-01-16 05:17:25,424 - DEBUG - Low Q-value (0.203), using MCTS.
2025-01-16 05:17:25,424 - INFO - Running MCTS with 116 simulations using 6 processes.
2025-01-16 05:17:28,205 - DEBUG - Aggregated action counts: {0: 4, 3: 1, 4: 1, 1: 1}
2025-01-16 05:17:28,205 - DEBUG - Chose best action 0
2025-01-16 05:17:28,424 - INFO - Episode 2654/98900: Winner=2, Reward=-14.40, EPSILON=0.976, (W=711,D=4,L=0)
2025-01-16 05:17:28,596 - INFO - Episode 2655/98900: Winner=2, Reward=-12.30, EPSILON=0.976, (W=712,D=4,L=0)
2025-01-16 05:17:28,658 - DEBUG - Q-vals = [0.10229177 0.09455463 0.08409607 0.26780924 0.08398041 0.11290781
 0.25436005], best_act=3, best_val=0.268
2025-01-16 05:17:28,658 - DEBUG - Low Q-value (0.268), using MCTS.
2025-01-16 05:17:28,658 - INFO - Running MCTS with 116 simulations using 6 processes.
2025-01-16 05:17:31,361 - DEBUG - Aggregated action counts: {5: 3, 6: 1, 1: 2, 0: 1}
2025-01-16 05:17:31,361 - DEBUG - Chose best action 5
2025-01-16 05:17:31,596 - DEBUG - Q-vals = [0.03593053 0.10169123 0.05415314 0.67103416 0.03141517 0.02428808
 0.0814877 ], best_act=3, best_val=0.671
2025-01-16 05:17:31,596 - DEBUG - Low Q-value (0.671), using MCTS.
2025-01-16 05:17:31,611 - INFO - Episode 2656/98900: Winner=2, Reward=-26.95, EPSILON=0.976, (W=713,D=4,L=0)
2025-01-16 05:17:31,814 - INFO - Episode 2657/98900: Winner=2, Reward=-10.25, EPSILON=0.976, (W=714,D=4,L=0)
2025-01-16 05:17:32,142 - INFO - Episode 2658/98900: Winner=2, Reward=-14.50, EPSILON=0.976, (W=715,D=4,L=0)
2025-01-16 05:17:32,283 - DEBUG - Q-vals = [0.12325589 0.12221085 0.12455055 0.11722182 0.23493524 0.09757419
 0.18025148], best_act=4, best_val=0.235
2025-01-16 05:17:32,283 - DEBUG - Low Q-value (0.235), using MCTS.
2025-01-16 05:17:32,299 - INFO - Episode 2659/98900: Winner=2, Reward=-9.60, EPSILON=0.976, (W=716,D=4,L=0)
2025-01-16 05:17:32,564 - DEBUG - Q-vals = [0.0812575  0.10506089 0.13392025 0.13884394 0.35005304 0.06121897
 0.12964544], best_act=4, best_val=0.350
2025-01-16 05:17:32,564 - DEBUG - Low Q-value (0.350), using MCTS.
2025-01-16 05:17:32,564 - INFO - Running MCTS with 116 simulations using 6 processes.
2025-01-16 05:17:35,414 - DEBUG - Aggregated action counts: {2: 2, 6: 1, 4: 1, 0: 3}
2025-01-16 05:17:35,414 - DEBUG - Chose best action 0
2025-01-16 05:17:35,599 - INFO - Episode 2660/98900: Winner=2, Reward=-78.35, EPSILON=0.976, (W=717,D=4,L=0)
2025-01-16 05:17:35,774 - INFO - Episode 2661/98900: Winner=2, Reward=-14.70, EPSILON=0.976, (W=718,D=4,L=0)
2025-01-16 05:17:36,014 - INFO - Episode 2662/98900: Winner=2, Reward=-17.05, EPSILON=0.976, (W=719,D=4,L=0)
2025-01-16 05:17:36,180 - DEBUG - Q-vals = [0.16046527 0.16669764 0.12154384 0.18172158 0.16095756 0.07419835
 0.13441558], best_act=3, best_val=0.182
2025-01-16 05:17:36,180 - DEBUG - Low Q-value (0.182), using MCTS.
2025-01-16 05:17:36,191 - INFO - Episode 2663/98900: Winner=2, Reward=-8.85, EPSILON=0.976, (W=720,D=4,L=0)
2025-01-16 05:17:36,497 - INFO - Episode 2664/98900: Winner=2, Reward=-14.75, EPSILON=0.976, (W=720,D=4,L=0)
2025-01-16 05:17:36,673 - INFO - Episode 2665/98900: Winner=2, Reward=-26.05, EPSILON=0.976, (W=721,D=4,L=0)
2025-01-16 05:17:36,839 - DEBUG - Q-vals = [0.19570413 0.16375811 0.11603958 0.16470921 0.14152168 0.08161174
 0.13665563], best_act=0, best_val=0.196
2025-01-16 05:17:36,839 - DEBUG - Low Q-value (0.196), using MCTS.
2025-01-16 05:17:36,840 - INFO - Running MCTS with 116 simulations using 6 processes.
2025-01-16 05:17:39,592 - DEBUG - Aggregated action counts: {1: 3, 3: 1, 0: 3}
2025-01-16 05:17:39,593 - DEBUG - Chose best action 1
2025-01-16 05:17:39,691 - INFO - Episode 2666/98900: Winner=2, Reward=-11.50, EPSILON=0.976, (W=722,D=4,L=0)
2025-01-16 05:17:39,808 - INFO - Episode 2667/98900: Winner=2, Reward=0.85, EPSILON=0.976, (W=722,D=4,L=0)
2025-01-16 05:17:39,901 - INFO - Episode 2668/98900: Winner=2, Reward=16.25, EPSILON=0.976, (W=722,D=4,L=0)
2025-01-16 05:17:40,018 - INFO - Episode 2669/98900: Winner=2, Reward=-11.85, EPSILON=0.976, (W=723,D=4,L=0)
2025-01-16 05:17:40,277 - INFO - Episode 2670/98900: Winner=2, Reward=-14.15, EPSILON=0.976, (W=724,D=4,L=0)
2025-01-16 05:17:40,516 - DEBUG - Q-vals = [0.16659795 0.13340412 0.11453342 0.07504347 0.2279975  0.08956525
 0.19285822], best_act=4, best_val=0.228
2025-01-16 05:17:40,516 - DEBUG - Low Q-value (0.228), using MCTS.
2025-01-16 05:17:40,517 - INFO - Running MCTS with 116 simulations using 6 processes.
2025-01-16 05:17:43,415 - DEBUG - Aggregated action counts: {2: 2, 1: 1, 5: 1, 4: 2, 0: 1}
2025-01-16 05:17:43,415 - DEBUG - Chose best action 2
2025-01-16 05:17:43,522 - INFO - Episode 2671/98900: Winner=2, Reward=-11.05, EPSILON=0.976, (W=724,D=4,L=0)
2025-01-16 05:17:43,727 - DEBUG - Q-vals = [0.14860547 0.05873165 0.4251088  0.15450181 0.10440645 0.03729269
 0.07135324], best_act=2, best_val=0.425
2025-01-16 05:17:43,727 - DEBUG - Low Q-value (0.425), using MCTS.
2025-01-16 05:17:43,727 - INFO - Running MCTS with 116 simulations using 6 processes.
2025-01-16 05:17:46,423 - DEBUG - Aggregated action counts: {3: 3, 1: 2, 2: 1, 4: 1}
2025-01-16 05:17:46,423 - DEBUG - Chose best action 3
2025-01-16 05:17:46,477 - INFO - Episode 2672/98900: Winner=2, Reward=-14.45, EPSILON=0.976, (W=725,D=4,L=0)
2025-01-16 05:17:46,683 - INFO - Episode 2673/98900: Winner=2, Reward=-3.25, EPSILON=0.976, (W=725,D=4,L=0)
2025-01-16 05:17:46,995 - INFO - Episode 2674/98900: Winner=2, Reward=-17.15, EPSILON=0.976, (W=726,D=4,L=0)
2025-01-16 05:17:47,188 - DEBUG - Q-vals = [0.14449295 0.12401228 0.12453613 0.14381383 0.21333016 0.10003314
 0.14978151], best_act=4, best_val=0.213
2025-01-16 05:17:47,188 - DEBUG - Low Q-value (0.213), using MCTS.
2025-01-16 05:17:47,189 - INFO - Running MCTS with 117 simulations using 6 processes.
2025-01-16 05:17:50,235 - DEBUG - Aggregated action counts: {6: 1, 0: 3, 4: 2, 3: 1}
2025-01-16 05:17:50,235 - DEBUG - Chose best action 0
2025-01-16 05:17:50,329 - INFO - Episode 2675/98900: Winner=2, Reward=-23.40, EPSILON=0.976, (W=727,D=4,L=0)
2025-01-16 05:17:50,532 - INFO - Episode 2676/98900: Winner=2, Reward=-12.35, EPSILON=0.976, (W=728,D=4,L=0)
2025-01-16 05:17:50,648 - INFO - Episode 2677/98900: Winner=2, Reward=-1.45, EPSILON=0.976, (W=728,D=4,L=0)
2025-01-16 05:17:50,934 - INFO - Episode 2678/98900: Winner=2, Reward=-36.50, EPSILON=0.976, (W=729,D=4,L=0)
2025-01-16 05:17:50,995 - INFO - Episode 2679/98900: Winner=2, Reward=7.75, EPSILON=0.976, (W=729,D=4,L=0)
2025-01-16 05:17:51,105 - INFO - Episode 2680/98900: Winner=2, Reward=16.45, EPSILON=0.976, (W=729,D=4,L=0)
2025-01-16 05:17:51,242 - INFO - Episode 2681/98900: Winner=2, Reward=0.25, EPSILON=0.976, (W=729,D=4,L=0)
2025-01-16 05:17:51,646 - INFO - Episode 2682/98900: Winner=2, Reward=-61.80, EPSILON=0.976, (W=729,D=4,L=0)
2025-01-16 05:17:51,707 - DEBUG - Q-vals = [0.06053022 0.0260186  0.27616522 0.12025846 0.059474   0.22564973
 0.23190375], best_act=2, best_val=0.276
2025-01-16 05:17:51,708 - DEBUG - Low Q-value (0.276), using MCTS.
2025-01-16 05:17:51,708 - INFO - Running MCTS with 117 simulations using 6 processes.
2025-01-16 05:17:55,024 - DEBUG - Aggregated action counts: {2: 4, 0: 2, 3: 1}
2025-01-16 05:17:55,024 - DEBUG - Chose best action 2
2025-01-16 05:17:55,232 - INFO - Episode 2683/98900: Winner=2, Reward=-27.95, EPSILON=0.976, (W=729,D=4,L=0)
2025-01-16 05:17:55,361 - INFO - Episode 2684/98900: Winner=2, Reward=-10.80, EPSILON=0.976, (W=730,D=4,L=0)
2025-01-16 05:17:55,644 - INFO - Episode 2685/98900: Winner=2, Reward=-28.30, EPSILON=0.976, (W=731,D=4,L=0)
2025-01-16 05:17:55,723 - DEBUG - Q-vals = [0.00408589 0.00160381 0.05324174 0.07366957 0.00148139 0.769934
 0.09598359], best_act=5, best_val=0.770
2025-01-16 05:17:55,724 - DEBUG - Low Q-value (0.770), using MCTS.
2025-01-16 05:17:55,724 - INFO - Running MCTS with 117 simulations using 6 processes.
2025-01-16 05:17:58,493 - DEBUG - Aggregated action counts: {2: 3, 0: 2, 6: 1, 1: 1}
2025-01-16 05:17:58,493 - DEBUG - Chose best action 2
2025-01-16 05:17:58,698 - INFO - Episode 2686/98900: Winner=2, Reward=-28.70, EPSILON=0.976, (W=731,D=4,L=0)
2025-01-16 05:17:58,738 - DEBUG - Q-vals = [0.08569124 0.03601144 0.30005157 0.11710212 0.0333274  0.28030297
 0.14751333], best_act=2, best_val=0.300
2025-01-16 05:17:58,738 - DEBUG - Low Q-value (0.300), using MCTS.
2025-01-16 05:17:58,738 - INFO - Running MCTS with 117 simulations using 6 processes.
2025-01-16 05:18:01,409 - DEBUG - Aggregated action counts: {1: 2, 4: 2, 3: 2, 0: 1}
2025-01-16 05:18:01,409 - DEBUG - Chose best action 1
2025-01-16 05:18:01,610 - INFO - Episode 2687/98900: Winner=2, Reward=-16.05, EPSILON=0.976, (W=732,D=4,L=0)
2025-01-16 05:18:01,791 - INFO - Episode 2688/98900: Winner=2, Reward=-5.65, EPSILON=0.976, (W=733,D=4,L=0)
2025-01-16 05:18:02,127 - INFO - Episode 2689/98900: Winner=2, Reward=-37.25, EPSILON=0.976, (W=733,D=4,L=0)
2025-01-16 05:18:02,428 - INFO - Episode 2690/98900: Winner=2, Reward=-37.25, EPSILON=0.976, (W=733,D=4,L=0)
2025-01-16 05:18:02,647 - INFO - Episode 2691/98900: Winner=2, Reward=-20.85, EPSILON=0.976, (W=734,D=4,L=0)
2025-01-16 05:18:02,725 - DEBUG - Q-vals = [0.19350867 0.15024506 0.11154798 0.15898007 0.09919734 0.11468823
 0.1718327 ], best_act=0, best_val=0.194
2025-01-16 05:18:02,725 - DEBUG - Low Q-value (0.194), using MCTS.
2025-01-16 05:18:02,725 - INFO - Running MCTS with 117 simulations using 6 processes.
2025-01-16 05:18:05,457 - DEBUG - Aggregated action counts: {3: 2, 4: 1, 6: 1, 1: 1, 2: 1, 0: 1}
2025-01-16 05:18:05,457 - DEBUG - Chose best action 3
2025-01-16 05:18:05,531 - INFO - Episode 2692/98900: Winner=2, Reward=0.00, EPSILON=0.976, (W=734,D=4,L=0)
2025-01-16 05:18:05,728 - INFO - Episode 2693/98900: Winner=2, Reward=-8.05, EPSILON=0.976, (W=735,D=4,L=0)
2025-01-16 05:18:05,935 - INFO - Episode 2694/98900: Winner=2, Reward=-4.85, EPSILON=0.976, (W=735,D=4,L=0)
2025-01-16 05:18:06,131 - INFO - Episode 2695/98900: Winner=2, Reward=1.80, EPSILON=0.976, (W=735,D=4,L=0)
2025-01-16 05:18:06,380 - INFO - Episode 2696/98900: Winner=2, Reward=-24.00, EPSILON=0.976, (W=735,D=4,L=0)
2025-01-16 05:18:06,646 - INFO - Episode 2697/98900: Winner=2, Reward=-27.05, EPSILON=0.976, (W=736,D=4,L=0)
2025-01-16 05:18:06,884 - INFO - Episode 2698/98900: Winner=2, Reward=-19.05, EPSILON=0.976, (W=737,D=4,L=0)
2025-01-16 05:18:07,045 - DEBUG - Q-vals = [0.16958325 0.15069696 0.1647623  0.18807332 0.132606   0.10296997
 0.09130815], best_act=3, best_val=0.188
2025-01-16 05:18:07,045 - DEBUG - Low Q-value (0.188), using MCTS.
2025-01-16 05:18:07,045 - INFO - Running MCTS with 117 simulations using 6 processes.
2025-01-16 05:18:10,052 - DEBUG - Aggregated action counts: {0: 4, 2: 1, 3: 2}
2025-01-16 05:18:10,052 - DEBUG - Chose best action 0
2025-01-16 05:18:10,153 - INFO - Episode 2699/98900: Winner=2, Reward=-26.70, EPSILON=0.976, (W=738,D=4,L=0)
2025-01-16 05:18:10,461 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2700.
2025-01-16 05:18:10,461 - INFO - Models saved at episode 2700
2025-01-16 05:18:10,477 - INFO - Target networks updated
2025-01-16 05:18:10,523 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2700.
2025-01-16 05:18:10,523 - INFO - Episode 2700/98900: Winner=2, Reward=-11.70, EPSILON=0.976, (W=739,D=4,L=0)
2025-01-16 05:18:10,780 - INFO - Episode 2701/98900: Winner=2, Reward=-23.10, EPSILON=0.976, (W=740,D=4,L=0)
2025-01-16 05:18:11,060 - INFO - Episode 2702/98900: Winner=2, Reward=-3.05, EPSILON=0.976, (W=741,D=4,L=0)
2025-01-16 05:18:11,195 - INFO - Episode 2703/98900: Winner=2, Reward=-1.75, EPSILON=0.976, (W=741,D=4,L=0)
2025-01-16 05:18:11,521 - INFO - Episode 2704/98900: Winner=2, Reward=-67.45, EPSILON=0.976, (W=742,D=4,L=0)
2025-01-16 05:18:11,626 - INFO - Episode 2705/98900: Winner=2, Reward=-9.65, EPSILON=0.976, (W=743,D=4,L=0)
2025-01-16 05:18:11,844 - DEBUG - Q-vals = [0.06345344 0.04236838 0.04634965 0.03935542 0.15615804 0.07361402
 0.5787011 ], best_act=6, best_val=0.579
2025-01-16 05:18:11,844 - DEBUG - Low Q-value (0.579), using MCTS.
2025-01-16 05:18:11,844 - INFO - Running MCTS with 118 simulations using 6 processes.
2025-01-16 05:18:14,620 - DEBUG - Aggregated action counts: {1: 2, 3: 2, 6: 2, 0: 1}
2025-01-16 05:18:14,620 - DEBUG - Chose best action 1
2025-01-16 05:18:14,714 - INFO - Episode 2706/98900: Winner=2, Reward=-38.75, EPSILON=0.976, (W=744,D=4,L=0)
2025-01-16 05:18:14,948 - INFO - Episode 2707/98900: Winner=2, Reward=-8.95, EPSILON=0.976, (W=744,D=4,L=0)
2025-01-16 05:18:15,182 - INFO - Episode 2708/98900: Winner=2, Reward=-19.30, EPSILON=0.976, (W=745,D=4,L=0)
2025-01-16 05:18:15,415 - DEBUG - Q-vals = [0.18756893 0.5724265  0.01800063 0.06625111 0.03983254 0.10758643
 0.00833383], best_act=1, best_val=0.572
2025-01-16 05:18:15,415 - DEBUG - Low Q-value (0.572), using MCTS.
2025-01-16 05:18:15,431 - INFO - Episode 2709/98900: Winner=2, Reward=-24.80, EPSILON=0.976, (W=746,D=4,L=0)
2025-01-16 05:18:15,538 - DEBUG - Q-vals = [0.13524044 0.04713899 0.20753492 0.02574669 0.27804276 0.10688609
 0.19941013], best_act=4, best_val=0.278
2025-01-16 05:18:15,538 - DEBUG - Low Q-value (0.278), using MCTS.
2025-01-16 05:18:15,549 - INFO - Episode 2710/98900: Winner=2, Reward=-8.75, EPSILON=0.976, (W=747,D=4,L=0)
2025-01-16 05:18:15,808 - INFO - Episode 2711/98900: Winner=2, Reward=-15.95, EPSILON=0.976, (W=748,D=4,L=0)
2025-01-16 05:18:16,066 - INFO - Episode 2712/98900: Winner=2, Reward=-15.50, EPSILON=0.976, (W=748,D=4,L=0)
2025-01-16 05:18:16,246 - INFO - Episode 2713/98900: Winner=2, Reward=11.75, EPSILON=0.976, (W=748,D=4,L=0)
2025-01-16 05:18:16,606 - INFO - Episode 2714/98900: Winner=2, Reward=-43.25, EPSILON=0.976, (W=748,D=4,L=0)
2025-01-16 05:18:16,702 - DEBUG - Q-vals = [0.19488512 0.12839451 0.03787565 0.06504645 0.40691602 0.06247609
 0.10440621], best_act=4, best_val=0.407
2025-01-16 05:18:16,702 - DEBUG - Low Q-value (0.407), using MCTS.
2025-01-16 05:18:16,702 - INFO - Running MCTS with 118 simulations using 6 processes.
2025-01-16 05:18:19,371 - DEBUG - Aggregated action counts: {2: 1, 5: 1, 1: 3, 0: 2}
2025-01-16 05:18:19,371 - DEBUG - Chose best action 1
2025-01-16 05:18:19,445 - INFO - Episode 2715/98900: Winner=2, Reward=15.45, EPSILON=0.976, (W=748,D=4,L=0)
2025-01-16 05:18:19,508 - DEBUG - Q-vals = [0.19531229 0.12473971 0.12136783 0.09134599 0.07376406 0.23964784
 0.15382226], best_act=5, best_val=0.240
2025-01-16 05:18:19,508 - DEBUG - Low Q-value (0.240), using MCTS.
2025-01-16 05:18:19,508 - INFO - Running MCTS with 118 simulations using 6 processes.
2025-01-16 05:18:22,356 - DEBUG - Aggregated action counts: {1: 1, 4: 1, 0: 3, 2: 2}
2025-01-16 05:18:22,356 - DEBUG - Chose best action 0
2025-01-16 05:18:22,595 - INFO - Episode 2716/98900: Winner=2, Reward=-28.85, EPSILON=0.976, (W=749,D=4,L=0)
2025-01-16 05:18:22,746 - DEBUG - Q-vals = [0.24813339 0.20100261 0.09764504 0.08984207 0.179393   0.11213608
 0.07184776], best_act=0, best_val=0.248
2025-01-16 05:18:22,746 - DEBUG - Low Q-value (0.248), using MCTS.
2025-01-16 05:18:22,747 - INFO - Running MCTS with 118 simulations using 6 processes.
2025-01-16 05:18:25,612 - DEBUG - Aggregated action counts: {3: 2, 1: 1, 0: 4}
2025-01-16 05:18:25,612 - DEBUG - Chose best action 0
2025-01-16 05:18:25,750 - INFO - Episode 2717/98900: Winner=2, Reward=-8.55, EPSILON=0.976, (W=749,D=4,L=0)
2025-01-16 05:18:26,017 - INFO - Episode 2718/98900: Winner=2, Reward=-1.75, EPSILON=0.976, (W=750,D=4,L=0)
2025-01-16 05:18:26,384 - INFO - Episode 2719/98900: Winner=2, Reward=12.25, EPSILON=0.976, (W=750,D=4,L=0)
2025-01-16 05:18:26,526 - INFO - Episode 2720/98900: Winner=2, Reward=13.90, EPSILON=0.976, (W=750,D=4,L=0)
2025-01-16 05:18:26,762 - INFO - Episode 2721/98900: Winner=2, Reward=-1.25, EPSILON=0.976, (W=750,D=4,L=0)
2025-01-16 05:18:27,010 - INFO - Episode 2722/98900: Winner=2, Reward=-4.90, EPSILON=0.976, (W=750,D=4,L=0)
2025-01-16 05:18:27,229 - INFO - Episode 2723/98900: Winner=2, Reward=-10.80, EPSILON=0.976, (W=751,D=4,L=0)
2025-01-16 05:18:27,610 - INFO - Episode 2724/98900: Winner=2, Reward=-45.60, EPSILON=0.976, (W=752,D=4,L=0)
2025-01-16 05:18:27,844 - INFO - Episode 2725/98900: Winner=2, Reward=9.60, EPSILON=0.976, (W=752,D=4,L=0)
2025-01-16 05:18:28,150 - INFO - Episode 2726/98900: Winner=2, Reward=-36.40, EPSILON=0.976, (W=753,D=4,L=0)
2025-01-16 05:18:28,360 - INFO - Episode 2727/98900: Winner=2, Reward=11.25, EPSILON=0.976, (W=753,D=4,L=0)
2025-01-16 05:18:28,529 - INFO - Episode 2728/98900: Winner=2, Reward=-2.85, EPSILON=0.976, (W=753,D=4,L=0)
2025-01-16 05:18:28,670 - INFO - Episode 2729/98900: Winner=2, Reward=-6.60, EPSILON=0.976, (W=754,D=4,L=0)
2025-01-16 05:18:28,717 - DEBUG - Q-vals = [0.05486981 0.02498981 0.2547489  0.06444888 0.0772514  0.3380803
 0.18561086], best_act=5, best_val=0.338
2025-01-16 05:18:28,717 - DEBUG - Low Q-value (0.338), using MCTS.
2025-01-16 05:18:28,717 - INFO - Running MCTS with 119 simulations using 6 processes.
2025-01-16 05:18:31,534 - DEBUG - Aggregated action counts: {4: 2, 2: 1, 0: 3, 3: 1}
2025-01-16 05:18:31,534 - DEBUG - Chose best action 0
2025-01-16 05:18:31,600 - INFO - Episode 2730/98900: Winner=2, Reward=-10.15, EPSILON=0.976, (W=755,D=4,L=0)
2025-01-16 05:18:31,766 - INFO - Episode 2731/98900: Winner=2, Reward=-8.35, EPSILON=0.976, (W=756,D=4,L=0)
2025-01-16 05:18:31,966 - INFO - Episode 2732/98900: Winner=2, Reward=-6.10, EPSILON=0.976, (W=756,D=4,L=0)
2025-01-16 05:18:32,184 - INFO - Episode 2733/98900: Winner=2, Reward=-11.65, EPSILON=0.976, (W=757,D=4,L=0)
2025-01-16 05:18:32,364 - DEBUG - Q-vals = [0.11395874 0.04995482 0.19003424 0.01427793 0.23552202 0.09581072
 0.3004415 ], best_act=6, best_val=0.300
2025-01-16 05:18:32,364 - DEBUG - Low Q-value (0.300), using MCTS.
2025-01-16 05:18:32,366 - INFO - Running MCTS with 119 simulations using 6 processes.
2025-01-16 05:18:35,307 - DEBUG - Aggregated action counts: {1: 2, 0: 2, 2: 1, 6: 1, 4: 1}
2025-01-16 05:18:35,307 - DEBUG - Chose best action 1
2025-01-16 05:18:35,431 - INFO - Episode 2734/98900: Winner=2, Reward=-9.35, EPSILON=0.976, (W=757,D=4,L=0)
2025-01-16 05:18:35,697 - INFO - Episode 2735/98900: Winner=2, Reward=-22.95, EPSILON=0.976, (W=758,D=4,L=0)
2025-01-16 05:18:35,885 - INFO - Episode 2736/98900: Winner=2, Reward=-13.15, EPSILON=0.976, (W=758,D=4,L=0)
2025-01-16 05:18:35,900 - DEBUG - Q-vals = [2.2614975e-02 9.7446942e-01 7.3715430e-11 7.7232076e-10 3.4939004e-10
 2.9156010e-03 4.2390234e-09], best_act=1, best_val=0.974
2025-01-16 05:18:35,900 - DEBUG - Low Q-value (0.974), using MCTS.
2025-01-16 05:18:35,900 - INFO - Running MCTS with 119 simulations using 6 processes.
2025-01-16 05:18:38,916 - DEBUG - Aggregated action counts: {0: 3, 2: 1, 5: 1, 4: 1, 3: 1}
2025-01-16 05:18:38,916 - DEBUG - Chose best action 0
2025-01-16 05:18:39,150 - INFO - Episode 2737/98900: Winner=2, Reward=-3.10, EPSILON=0.976, (W=758,D=4,L=0)
2025-01-16 05:18:39,338 - INFO - Episode 2738/98900: Winner=2, Reward=-5.60, EPSILON=0.976, (W=759,D=4,L=0)
2025-01-16 05:18:39,494 - INFO - Episode 2739/98900: Winner=2, Reward=-11.90, EPSILON=0.976, (W=760,D=4,L=0)
2025-01-16 05:18:39,634 - INFO - Episode 2740/98900: Winner=2, Reward=11.35, EPSILON=0.976, (W=760,D=4,L=0)
2025-01-16 05:18:39,931 - INFO - Episode 2741/98900: Winner=2, Reward=-36.20, EPSILON=0.976, (W=761,D=4,L=0)
2025-01-16 05:18:40,197 - INFO - Episode 2742/98900: Winner=2, Reward=-18.40, EPSILON=0.976, (W=762,D=4,L=0)
2025-01-16 05:18:40,353 - DEBUG - Q-vals = [0.14927223 0.09526792 0.23442222 0.10040835 0.17486028 0.05163608
 0.19413297], best_act=2, best_val=0.234
2025-01-16 05:18:40,353 - DEBUG - Low Q-value (0.234), using MCTS.
2025-01-16 05:18:40,353 - INFO - Running MCTS with 119 simulations using 6 processes.
2025-01-16 05:18:43,368 - DEBUG - Aggregated action counts: {0: 3, 3: 1, 4: 1, 5: 2}
2025-01-16 05:18:43,368 - DEBUG - Chose best action 0
2025-01-16 05:18:43,446 - INFO - Episode 2743/98900: Winner=2, Reward=-1.35, EPSILON=0.976, (W=763,D=4,L=0)
2025-01-16 05:18:43,602 - INFO - Episode 2744/98900: Winner=2, Reward=-12.25, EPSILON=0.976, (W=764,D=4,L=0)
2025-01-16 05:18:43,805 - INFO - Episode 2745/98900: Winner=2, Reward=5.65, EPSILON=0.976, (W=764,D=4,L=0)
2025-01-16 05:18:43,930 - INFO - Episode 2746/98900: Winner=2, Reward=-0.85, EPSILON=0.976, (W=764,D=4,L=0)
2025-01-16 05:18:44,118 - INFO - Episode 2747/98900: Winner=2, Reward=-17.75, EPSILON=0.976, (W=765,D=4,L=0)
2025-01-16 05:18:44,321 - INFO - Episode 2748/98900: Winner=2, Reward=-12.75, EPSILON=0.976, (W=766,D=4,L=0)
2025-01-16 05:18:44,493 - DEBUG - Q-vals = [0.15497899 0.11036184 0.17159863 0.1213832  0.12982254 0.0780355
 0.23381934], best_act=6, best_val=0.234
2025-01-16 05:18:44,493 - DEBUG - Low Q-value (0.234), using MCTS.
2025-01-16 05:18:44,509 - INFO - Running MCTS with 119 simulations using 6 processes.
2025-01-16 05:18:47,584 - DEBUG - Aggregated action counts: {6: 2, 4: 1, 2: 1, 0: 2, 1: 1}
2025-01-16 05:18:47,584 - DEBUG - Chose best action 6
2025-01-16 05:18:47,619 - DEBUG - Q-vals = [0.1524199  0.09691355 0.3702912  0.17204037 0.04863477 0.03659752
 0.1231027 ], best_act=2, best_val=0.370
2025-01-16 05:18:47,619 - DEBUG - Low Q-value (0.370), using MCTS.
2025-01-16 05:18:47,620 - INFO - Running MCTS with 119 simulations using 6 processes.
2025-01-16 05:18:50,914 - DEBUG - Aggregated action counts: {6: 1, 5: 1, 0: 2, 2: 1, 4: 2}
2025-01-16 05:18:50,915 - DEBUG - Chose best action 0
2025-01-16 05:18:51,040 - INFO - Episode 2749/98900: Winner=2, Reward=-1.00, EPSILON=0.976, (W=766,D=4,L=0)
2025-01-16 05:18:51,356 - INFO - Episode 2750/98900: Winner=2, Reward=-32.55, EPSILON=0.976, (W=767,D=4,L=0)
2025-01-16 05:18:51,624 - INFO - Episode 2751/98900: Winner=2, Reward=-21.10, EPSILON=0.976, (W=768,D=4,L=0)
2025-01-16 05:18:51,780 - DEBUG - Q-vals = [0.24461667 0.14975166 0.1079654  0.19069123 0.06074103 0.08768071
 0.15855333], best_act=0, best_val=0.245
2025-01-16 05:18:51,780 - DEBUG - Low Q-value (0.245), using MCTS.
2025-01-16 05:18:51,781 - INFO - Running MCTS with 120 simulations using 6 processes.
2025-01-16 05:18:54,730 - DEBUG - Aggregated action counts: {0: 1, 1: 1, 2: 1, 3: 3}
2025-01-16 05:18:54,730 - DEBUG - Chose best action 3
2025-01-16 05:18:55,073 - INFO - Episode 2752/98900: Winner=2, Reward=-16.50, EPSILON=0.976, (W=769,D=4,L=0)
2025-01-16 05:18:55,239 - INFO - Episode 2753/98900: Winner=2, Reward=-8.00, EPSILON=0.976, (W=770,D=4,L=0)
2025-01-16 05:18:55,448 - INFO - Episode 2754/98900: Winner=2, Reward=3.90, EPSILON=0.976, (W=770,D=4,L=0)
2025-01-16 05:18:55,718 - INFO - Episode 2755/98900: Winner=2, Reward=-26.50, EPSILON=0.976, (W=771,D=4,L=0)
2025-01-16 05:18:55,957 - INFO - Episode 2756/98900: Winner=2, Reward=9.45, EPSILON=0.976, (W=771,D=4,L=0)
2025-01-16 05:18:56,069 - INFO - Episode 2757/98900: Winner=2, Reward=-8.20, EPSILON=0.975, (W=772,D=4,L=0)
2025-01-16 05:18:56,438 - INFO - Episode 2758/98900: Winner=2, Reward=-14.50, EPSILON=0.975, (W=773,D=4,L=0)
2025-01-16 05:18:56,476 - DEBUG - Q-vals = [1.6252894e-02 1.6719058e-02 2.5261703e-03 9.6106130e-01 2.1232871e-04
 2.9961902e-03 2.3215279e-04], best_act=3, best_val=0.961
2025-01-16 05:18:56,476 - DEBUG - Low Q-value (0.961), using MCTS.
2025-01-16 05:18:56,476 - INFO - Running MCTS with 120 simulations using 6 processes.
2025-01-16 05:18:59,618 - DEBUG - Aggregated action counts: {3: 1, 2: 2, 4: 1, 0: 1, 1: 1}
2025-01-16 05:18:59,618 - DEBUG - Chose best action 2
2025-01-16 05:18:59,683 - DEBUG - Q-vals = [0.16666734 0.11629274 0.13587257 0.13136582 0.13216408 0.13839939
 0.17923808], best_act=6, best_val=0.179
2025-01-16 05:18:59,683 - DEBUG - Low Q-value (0.179), using MCTS.
2025-01-16 05:18:59,683 - INFO - Running MCTS with 120 simulations using 6 processes.
2025-01-16 05:19:02,823 - DEBUG - Aggregated action counts: {5: 1, 4: 3, 3: 1, 2: 1}
2025-01-16 05:19:02,823 - DEBUG - Chose best action 4
2025-01-16 05:19:03,170 - INFO - Episode 2759/98900: Winner=2, Reward=-55.05, EPSILON=0.975, (W=774,D=4,L=0)
2025-01-16 05:19:03,371 - INFO - Episode 2760/98900: Winner=2, Reward=-19.45, EPSILON=0.975, (W=775,D=4,L=0)
2025-01-16 05:19:03,502 - INFO - Episode 2761/98900: Winner=2, Reward=-10.55, EPSILON=0.975, (W=776,D=4,L=0)
2025-01-16 05:19:03,747 - INFO - Episode 2762/98900: Winner=2, Reward=-0.80, EPSILON=0.975, (W=776,D=4,L=0)
2025-01-16 05:19:03,886 - INFO - Episode 2763/98900: Winner=2, Reward=-12.05, EPSILON=0.975, (W=777,D=4,L=0)
2025-01-16 05:19:04,003 - INFO - Episode 2764/98900: Winner=2, Reward=6.95, EPSILON=0.975, (W=777,D=4,L=0)
2025-01-16 05:19:04,141 - INFO - Episode 2765/98900: Winner=2, Reward=-9.95, EPSILON=0.975, (W=778,D=4,L=0)
2025-01-16 05:19:04,281 - INFO - Episode 2766/98900: Winner=2, Reward=3.55, EPSILON=0.975, (W=778,D=4,L=0)
2025-01-16 05:19:04,454 - DEBUG - Q-vals = [0.15199034 0.16292994 0.15066616 0.12368636 0.17060563 0.09416371
 0.14595783], best_act=4, best_val=0.171
2025-01-16 05:19:04,454 - DEBUG - Low Q-value (0.171), using MCTS.
2025-01-16 05:19:04,465 - INFO - Episode 2767/98900: Winner=2, Reward=-9.65, EPSILON=0.975, (W=779,D=4,L=0)
2025-01-16 05:19:04,525 - DEBUG - Q-vals = [0.05457799 0.03603946 0.08238825 0.03788244 0.04326701 0.5406757
 0.2051692 ], best_act=5, best_val=0.541
2025-01-16 05:19:04,526 - DEBUG - Low Q-value (0.541), using MCTS.
2025-01-16 05:19:04,526 - INFO - Running MCTS with 120 simulations using 6 processes.
2025-01-16 05:19:07,685 - DEBUG - Aggregated action counts: {3: 1, 2: 3, 5: 1, 1: 1}
2025-01-16 05:19:07,685 - DEBUG - Chose best action 2
2025-01-16 05:19:07,716 - INFO - Episode 2768/98900: Winner=2, Reward=0.45, EPSILON=0.975, (W=779,D=4,L=0)
2025-01-16 05:19:07,784 - INFO - Episode 2769/98900: Winner=2, Reward=0.25, EPSILON=0.975, (W=779,D=4,L=0)
2025-01-16 05:19:07,900 - INFO - Episode 2770/98900: Winner=2, Reward=0.40, EPSILON=0.975, (W=779,D=4,L=0)
2025-01-16 05:19:08,144 - INFO - Episode 2771/98900: Winner=2, Reward=-6.05, EPSILON=0.975, (W=780,D=4,L=0)
2025-01-16 05:19:08,396 - INFO - Episode 2772/98900: Winner=2, Reward=-3.50, EPSILON=0.975, (W=780,D=4,L=0)
2025-01-16 05:19:08,759 - INFO - Episode 2773/98900: Winner=2, Reward=-21.55, EPSILON=0.975, (W=780,D=4,L=0)
2025-01-16 05:19:08,989 - INFO - Episode 2774/98900: Winner=2, Reward=32.70, EPSILON=0.975, (W=780,D=4,L=0)
2025-01-16 05:19:09,005 - DEBUG - Q-vals = [2.0606091e-02 9.7139233e-01 2.2789878e-08 2.4918368e-08 1.4946879e-08
 8.0013815e-03 2.2741172e-07], best_act=1, best_val=0.971
2025-01-16 05:19:09,005 - DEBUG - Low Q-value (0.971), using MCTS.
2025-01-16 05:19:09,005 - INFO - Running MCTS with 121 simulations using 6 processes.
2025-01-16 05:19:12,086 - DEBUG - Aggregated action counts: {3: 1, 0: 3, 2: 1, 5: 2}
2025-01-16 05:19:12,086 - DEBUG - Chose best action 0
2025-01-16 05:19:12,257 - INFO - Episode 2775/98900: Winner=2, Reward=7.35, EPSILON=0.975, (W=780,D=4,L=0)
2025-01-16 05:19:12,429 - DEBUG - Q-vals = [0.15509866 0.09879524 0.10778361 0.13259746 0.11361658 0.09588068
 0.29622775], best_act=6, best_val=0.296
2025-01-16 05:19:12,429 - DEBUG - Low Q-value (0.296), using MCTS.
2025-01-16 05:19:12,429 - INFO - Running MCTS with 121 simulations using 6 processes.
2025-01-16 05:19:15,507 - DEBUG - Aggregated action counts: {2: 2, 6: 1, 0: 1, 1: 1, 3: 2}
2025-01-16 05:19:15,507 - DEBUG - Chose best action 2
2025-01-16 05:19:15,569 - INFO - Episode 2776/98900: Winner=2, Reward=1.90, EPSILON=0.975, (W=780,D=4,L=0)
2025-01-16 05:19:15,866 - INFO - Episode 2777/98900: Winner=2, Reward=-6.20, EPSILON=0.975, (W=780,D=4,L=0)
2025-01-16 05:19:16,178 - INFO - Episode 2778/98900: Winner=2, Reward=-31.95, EPSILON=0.975, (W=781,D=4,L=0)
2025-01-16 05:19:16,427 - INFO - Episode 2779/98900: Winner=2, Reward=-18.45, EPSILON=0.975, (W=782,D=4,L=0)
2025-01-16 05:19:16,672 - INFO - Episode 2780/98900: Winner=2, Reward=13.05, EPSILON=0.975, (W=782,D=4,L=0)
2025-01-16 05:19:16,966 - INFO - Episode 2781/98900: Winner=2, Reward=-49.20, EPSILON=0.975, (W=783,D=4,L=0)
2025-01-16 05:19:17,068 - INFO - Episode 2782/98900: Winner=2, Reward=-10.40, EPSILON=0.975, (W=784,D=4,L=0)
2025-01-16 05:19:17,414 - INFO - Episode 2783/98900: Winner=2, Reward=-13.85, EPSILON=0.975, (W=785,D=4,L=0)
2025-01-16 05:19:17,682 - INFO - Episode 2784/98900: Winner=2, Reward=-18.00, EPSILON=0.975, (W=786,D=4,L=0)
2025-01-16 05:19:18,049 - INFO - Episode 2785/98900: Winner=2, Reward=1.55, EPSILON=0.975, (W=786,D=4,L=0)
2025-01-16 05:19:18,337 - INFO - Episode 2786/98900: Winner=2, Reward=-1.25, EPSILON=0.975, (W=786,D=4,L=0)
2025-01-16 05:19:18,571 - INFO - Episode 2787/98900: Winner=2, Reward=7.40, EPSILON=0.975, (W=786,D=4,L=0)
2025-01-16 05:19:18,791 - INFO - Episode 2788/98900: Winner=2, Reward=-9.60, EPSILON=0.975, (W=786,D=4,L=0)
2025-01-16 05:19:18,986 - INFO - Episode 2789/98900: Winner=2, Reward=-15.25, EPSILON=0.975, (W=787,D=4,L=0)
2025-01-16 05:19:19,249 - DEBUG - Q-vals = [0.1341756  0.22748373 0.0267203  0.18720832 0.05169335 0.08648945
 0.28622925], best_act=6, best_val=0.286
2025-01-16 05:19:19,249 - DEBUG - Low Q-value (0.286), using MCTS.
2025-01-16 05:19:19,262 - INFO - Episode 2790/98900: Winner=2, Reward=-11.25, EPSILON=0.975, (W=788,D=4,L=0)
2025-01-16 05:19:19,432 - INFO - Episode 2791/98900: Winner=2, Reward=-10.05, EPSILON=0.975, (W=788,D=4,L=0)
2025-01-16 05:19:19,557 - DEBUG - Q-vals = [0.08118483 0.04316213 0.19492379 0.3753714  0.04971976 0.08058827
 0.17504978], best_act=3, best_val=0.375
2025-01-16 05:19:19,557 - DEBUG - Low Q-value (0.375), using MCTS.
2025-01-16 05:19:19,573 - INFO - Episode 2792/98900: Winner=2, Reward=-9.80, EPSILON=0.975, (W=789,D=4,L=0)
2025-01-16 05:19:19,838 - DEBUG - Q-vals = [0.06830613 0.06329526 0.30237228 0.32147175 0.11543145 0.03759717
 0.091526  ], best_act=3, best_val=0.321
2025-01-16 05:19:19,838 - DEBUG - Low Q-value (0.321), using MCTS.
2025-01-16 05:19:19,838 - INFO - Episode 2793/98900: Winner=2, Reward=-16.55, EPSILON=0.975, (W=790,D=4,L=0)
2025-01-16 05:19:19,948 - INFO - Episode 2794/98900: Winner=2, Reward=11.65, EPSILON=0.975, (W=790,D=4,L=0)
2025-01-16 05:19:20,151 - INFO - Episode 2795/98900: Winner=2, Reward=0.60, EPSILON=0.975, (W=790,D=4,L=0)
2025-01-16 05:19:20,401 - INFO - Episode 2796/98900: Winner=2, Reward=-17.60, EPSILON=0.975, (W=790,D=4,L=0)
2025-01-16 05:19:20,494 - INFO - Episode 2797/98900: Winner=2, Reward=7.95, EPSILON=0.975, (W=790,D=4,L=0)
2025-01-16 05:19:20,682 - INFO - Episode 2798/98900: Winner=2, Reward=-19.15, EPSILON=0.975, (W=791,D=4,L=0)
2025-01-16 05:19:21,010 - INFO - Episode 2799/98900: Winner=2, Reward=8.40, EPSILON=0.975, (W=791,D=4,L=0)
2025-01-16 05:19:21,334 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2800.
2025-01-16 05:19:21,334 - INFO - Models saved at episode 2800
2025-01-16 05:19:21,334 - INFO - Target networks updated
2025-01-16 05:19:21,381 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2800.
2025-01-16 05:19:21,381 - INFO - Episode 2800/98900: Winner=2, Reward=-5.30, EPSILON=0.975, (W=792,D=4,L=0)
2025-01-16 05:19:21,616 - INFO - Episode 2801/98900: Winner=2, Reward=-9.25, EPSILON=0.975, (W=793,D=4,L=0)
2025-01-16 05:19:21,631 - DEBUG - Q-vals = [2.1585582e-03 9.9575609e-01 1.7507870e-10 6.8861694e-10 2.4227946e-09
 2.0853418e-03 1.3801885e-08], best_act=1, best_val=0.996
2025-01-16 05:19:21,631 - DEBUG - Low Q-value (0.996), using MCTS.
2025-01-16 05:19:21,631 - INFO - Running MCTS with 122 simulations using 6 processes.
2025-01-16 05:19:24,474 - DEBUG - Aggregated action counts: {0: 4, 4: 1, 5: 1, 1: 1}
2025-01-16 05:19:24,474 - DEBUG - Chose best action 0
2025-01-16 05:19:24,740 - INFO - Episode 2802/98900: Winner=2, Reward=-27.75, EPSILON=0.975, (W=794,D=4,L=0)
2025-01-16 05:19:24,881 - INFO - Episode 2803/98900: Winner=2, Reward=-10.75, EPSILON=0.975, (W=795,D=4,L=0)
2025-01-16 05:19:25,068 - INFO - Episode 2804/98900: Winner=2, Reward=2.65, EPSILON=0.975, (W=795,D=4,L=0)
2025-01-16 05:19:25,209 - DEBUG - Q-vals = [0.10563021 0.25087115 0.0669175  0.15655936 0.08226269 0.13748795
 0.20027111], best_act=1, best_val=0.251
2025-01-16 05:19:25,209 - DEBUG - Low Q-value (0.251), using MCTS.
2025-01-16 05:19:25,209 - INFO - Running MCTS with 122 simulations using 6 processes.
2025-01-16 05:19:27,974 - DEBUG - Aggregated action counts: {2: 1, 1: 3, 3: 2, 0: 1}
2025-01-16 05:19:27,974 - DEBUG - Chose best action 1
2025-01-16 05:19:28,193 - INFO - Episode 2805/98900: Winner=2, Reward=-33.15, EPSILON=0.975, (W=796,D=4,L=0)
2025-01-16 05:19:28,443 - INFO - Episode 2806/98900: Winner=2, Reward=0.55, EPSILON=0.975, (W=797,D=4,L=0)
2025-01-16 05:19:28,740 - DEBUG - Q-vals = [0.1043621  0.1951936  0.3118605  0.18597497 0.09815326 0.04215468
 0.06230094], best_act=2, best_val=0.312
2025-01-16 05:19:28,740 - DEBUG - Low Q-value (0.312), using MCTS.
2025-01-16 05:19:28,755 - INFO - Episode 2807/98900: Winner=2, Reward=-26.45, EPSILON=0.975, (W=798,D=4,L=0)
2025-01-16 05:19:28,943 - DEBUG - Q-vals = [0.13692863 0.15378909 0.16483088 0.21791513 0.11793633 0.07120822
 0.13739169], best_act=3, best_val=0.218
2025-01-16 05:19:28,943 - DEBUG - Low Q-value (0.218), using MCTS.
2025-01-16 05:19:28,958 - INFO - Episode 2808/98900: Winner=2, Reward=-11.55, EPSILON=0.975, (W=799,D=4,L=0)
2025-01-16 05:19:29,005 - DEBUG - Q-vals = [0.18744405 0.0871771  0.08319764 0.16042551 0.06191607 0.15185343
 0.26798624], best_act=6, best_val=0.268
2025-01-16 05:19:29,005 - DEBUG - Low Q-value (0.268), using MCTS.
2025-01-16 05:19:29,005 - INFO - Running MCTS with 122 simulations using 6 processes.
2025-01-16 05:19:31,755 - DEBUG - Aggregated action counts: {2: 2, 5: 1, 4: 1, 3: 1, 0: 2}
2025-01-16 05:19:31,755 - DEBUG - Chose best action 2
2025-01-16 05:19:31,880 - INFO - Episode 2809/98900: Winner=2, Reward=-6.85, EPSILON=0.975, (W=799,D=4,L=0)
2025-01-16 05:19:32,067 - INFO - Episode 2810/98900: Winner=2, Reward=-11.40, EPSILON=0.975, (W=799,D=4,L=0)
2025-01-16 05:19:32,083 - DEBUG - Q-vals = [0.06037874 0.023508   0.017578   0.04563042 0.01342067 0.30456343
 0.5349207 ], best_act=6, best_val=0.535
2025-01-16 05:19:32,083 - DEBUG - Low Q-value (0.535), using MCTS.
2025-01-16 05:19:32,083 - INFO - Running MCTS with 122 simulations using 6 processes.
2025-01-16 05:19:34,771 - DEBUG - Aggregated action counts: {6: 1, 1: 1, 2: 1, 5: 1, 4: 1, 3: 1, 0: 1}
2025-01-16 05:19:34,771 - DEBUG - Chose best action 6
2025-01-16 05:19:34,943 - INFO - Episode 2811/98900: Winner=2, Reward=-17.25, EPSILON=0.975, (W=800,D=4,L=0)
2025-01-16 05:19:35,068 - DEBUG - Q-vals = [0.22363834 0.22702591 0.0611202  0.34564173 0.03507298 0.0482352
 0.05926558], best_act=3, best_val=0.346
2025-01-16 05:19:35,068 - DEBUG - Low Q-value (0.346), using MCTS.
2025-01-16 05:19:35,083 - INFO - Episode 2812/98900: Winner=2, Reward=-9.50, EPSILON=0.975, (W=801,D=4,L=0)
2025-01-16 05:19:35,239 - INFO - Episode 2813/98900: Winner=2, Reward=-4.60, EPSILON=0.975, (W=801,D=4,L=0)
2025-01-16 05:19:35,427 - INFO - Episode 2814/98900: Winner=2, Reward=2.45, EPSILON=0.975, (W=801,D=4,L=0)
2025-01-16 05:19:35,614 - INFO - Episode 2815/98900: Winner=2, Reward=-11.65, EPSILON=0.975, (W=801,D=4,L=0)
2025-01-16 05:19:35,864 - INFO - Episode 2816/98900: Winner=2, Reward=-25.95, EPSILON=0.975, (W=802,D=4,L=0)
2025-01-16 05:19:36,036 - INFO - Episode 2817/98900: Winner=2, Reward=-10.85, EPSILON=0.975, (W=803,D=4,L=0)
2025-01-16 05:19:36,270 - INFO - Episode 2818/98900: Winner=2, Reward=9.40, EPSILON=0.975, (W=803,D=4,L=0)
2025-01-16 05:19:36,583 - INFO - Episode 2819/98900: Winner=2, Reward=-10.55, EPSILON=0.975, (W=804,D=4,L=0)
2025-01-16 05:19:36,692 - INFO - Episode 2820/98900: Winner=2, Reward=23.95, EPSILON=0.975, (W=804,D=4,L=0)
2025-01-16 05:19:37,098 - INFO - Episode 2821/98900: Winner=2, Reward=-68.45, EPSILON=0.975, (W=805,D=4,L=0)
2025-01-16 05:19:37,286 - INFO - Episode 2822/98900: Winner=2, Reward=-1.45, EPSILON=0.975, (W=805,D=4,L=0)
2025-01-16 05:19:37,442 - INFO - Episode 2823/98900: Winner=2, Reward=-12.85, EPSILON=0.975, (W=806,D=4,L=0)
2025-01-16 05:19:37,489 - DEBUG - Q-vals = [0.16540085 0.12352577 0.11192846 0.22828674 0.06100666 0.11926748
 0.19058411], best_act=3, best_val=0.228
2025-01-16 05:19:37,489 - DEBUG - Low Q-value (0.228), using MCTS.
2025-01-16 05:19:37,489 - INFO - Running MCTS with 122 simulations using 6 processes.
2025-01-16 05:19:40,301 - DEBUG - Aggregated action counts: {5: 1, 1: 1, 4: 1, 3: 3, 0: 1}
2025-01-16 05:19:40,301 - DEBUG - Chose best action 3
2025-01-16 05:19:40,551 - INFO - Episode 2824/98900: Winner=2, Reward=-19.80, EPSILON=0.975, (W=807,D=4,L=0)
2025-01-16 05:19:40,770 - INFO - Episode 2825/98900: Winner=2, Reward=-9.80, EPSILON=0.975, (W=807,D=4,L=0)
2025-01-16 05:19:41,004 - INFO - Episode 2826/98900: Winner=2, Reward=-9.35, EPSILON=0.975, (W=808,D=4,L=0)
2025-01-16 05:19:41,254 - INFO - Episode 2827/98900: Winner=2, Reward=-18.35, EPSILON=0.975, (W=808,D=4,L=0)
2025-01-16 05:19:41,551 - INFO - Episode 2828/98900: Winner=2, Reward=-10.05, EPSILON=0.975, (W=809,D=4,L=0)
2025-01-16 05:19:41,769 - INFO - Episode 2829/98900: Winner=2, Reward=-6.70, EPSILON=0.975, (W=810,D=4,L=0)
2025-01-16 05:19:42,082 - INFO - Episode 2830/98900: Winner=2, Reward=-23.95, EPSILON=0.975, (W=811,D=4,L=0)
2025-01-16 05:19:42,176 - DEBUG - Q-vals = [0.18201853 0.13136676 0.14882994 0.11707967 0.16699368 0.08708698
 0.16662449], best_act=0, best_val=0.182
2025-01-16 05:19:42,176 - DEBUG - Low Q-value (0.182), using MCTS.
2025-01-16 05:19:42,176 - INFO - Running MCTS with 123 simulations using 6 processes.
2025-01-16 05:19:45,050 - DEBUG - Aggregated action counts: {3: 2, 1: 1, 4: 3, 0: 1}
2025-01-16 05:19:45,050 - DEBUG - Chose best action 4
2025-01-16 05:19:45,222 - INFO - Episode 2831/98900: Winner=2, Reward=-15.10, EPSILON=0.975, (W=812,D=4,L=0)
2025-01-16 05:19:45,425 - INFO - Episode 2832/98900: Winner=2, Reward=0.75, EPSILON=0.975, (W=812,D=4,L=0)
2025-01-16 05:19:45,581 - INFO - Episode 2833/98900: Winner=2, Reward=0.00, EPSILON=0.975, (W=812,D=4,L=0)
2025-01-16 05:19:45,753 - INFO - Episode 2834/98900: Winner=2, Reward=0.25, EPSILON=0.975, (W=813,D=4,L=0)
2025-01-16 05:19:46,081 - INFO - Episode 2835/98900: Winner=2, Reward=-37.55, EPSILON=0.975, (W=814,D=4,L=0)
2025-01-16 05:19:46,331 - INFO - Episode 2836/98900: Winner=2, Reward=26.30, EPSILON=0.975, (W=814,D=4,L=0)
2025-01-16 05:19:46,581 - INFO - Episode 2837/98900: Winner=2, Reward=10.25, EPSILON=0.975, (W=814,D=4,L=0)
2025-01-16 05:19:46,690 - INFO - Episode 2838/98900: Winner=2, Reward=-4.65, EPSILON=0.975, (W=815,D=4,L=0)
2025-01-16 05:19:46,846 - INFO - Episode 2839/98900: Winner=2, Reward=22.35, EPSILON=0.975, (W=815,D=4,L=0)
2025-01-16 05:19:47,034 - INFO - Episode 2840/98900: Winner=2, Reward=5.00, EPSILON=0.975, (W=815,D=4,L=0)
2025-01-16 05:19:47,253 - INFO - Episode 2841/98900: Winner=2, Reward=-13.60, EPSILON=0.975, (W=816,D=4,L=0)
2025-01-16 05:19:47,581 - INFO - Episode 2842/98900: Winner=2, Reward=-1.60, EPSILON=0.975, (W=816,D=4,L=0)
2025-01-16 05:19:47,721 - INFO - Episode 2843/98900: Winner=2, Reward=-1.45, EPSILON=0.975, (W=817,D=4,L=0)
2025-01-16 05:19:47,846 - INFO - Episode 2844/98900: Winner=2, Reward=0.40, EPSILON=0.975, (W=817,D=4,L=0)
2025-01-16 05:19:48,049 - INFO - Episode 2845/98900: Winner=2, Reward=-23.90, EPSILON=0.975, (W=818,D=4,L=0)
2025-01-16 05:19:48,080 - DEBUG - Q-vals = [0.21948124 0.10635985 0.1519623  0.2453697  0.06637573 0.0862125
 0.12423873], best_act=3, best_val=0.245
2025-01-16 05:19:48,080 - DEBUG - Low Q-value (0.245), using MCTS.
2025-01-16 05:19:48,080 - INFO - Running MCTS with 123 simulations using 6 processes.
2025-01-16 05:19:51,002 - DEBUG - Aggregated action counts: {2: 2, 4: 1, 0: 4}
2025-01-16 05:19:51,002 - DEBUG - Chose best action 0
2025-01-16 05:19:51,088 - DEBUG - Q-vals = [0.15765232 0.09588745 0.11489245 0.10425609 0.2283178  0.10621034
 0.19278358], best_act=4, best_val=0.228
2025-01-16 05:19:51,088 - DEBUG - Low Q-value (0.228), using MCTS.
2025-01-16 05:19:51,088 - INFO - Running MCTS with 123 simulations using 6 processes.
2025-01-16 05:19:53,870 - DEBUG - Aggregated action counts: {3: 1, 0: 2, 1: 4}
2025-01-16 05:19:53,870 - DEBUG - Chose best action 1
2025-01-16 05:19:54,007 - INFO - Episode 2846/98900: Winner=2, Reward=8.95, EPSILON=0.975, (W=819,D=4,L=0)
2025-01-16 05:19:54,226 - INFO - Episode 2847/98900: Winner=2, Reward=12.70, EPSILON=0.975, (W=819,D=4,L=0)
2025-01-16 05:19:54,515 - INFO - Episode 2848/98900: Winner=2, Reward=-29.65, EPSILON=0.975, (W=820,D=4,L=0)
2025-01-16 05:19:54,616 - DEBUG - Q-vals = [0.1256577  0.05586467 0.40152687 0.03518253 0.21215892 0.08551135
 0.08409803], best_act=2, best_val=0.402
2025-01-16 05:19:54,616 - DEBUG - Low Q-value (0.402), using MCTS.
2025-01-16 05:19:54,616 - INFO - Running MCTS with 123 simulations using 6 processes.
2025-01-16 05:19:57,331 - DEBUG - Aggregated action counts: {3: 4, 2: 1, 0: 2}
2025-01-16 05:19:57,331 - DEBUG - Chose best action 3
2025-01-16 05:19:57,383 - INFO - Episode 2849/98900: Winner=2, Reward=9.05, EPSILON=0.975, (W=820,D=4,L=0)
2025-01-16 05:19:57,582 - INFO - Episode 2850/98900: Winner=2, Reward=32.25, EPSILON=0.975, (W=820,D=4,L=0)
2025-01-16 05:19:57,756 - INFO - Episode 2851/98900: Winner=2, Reward=10.40, EPSILON=0.975, (W=820,D=4,L=0)
2025-01-16 05:19:58,037 - INFO - Episode 2852/98900: Winner=2, Reward=0.30, EPSILON=0.975, (W=820,D=4,L=0)
2025-01-16 05:19:58,298 - INFO - Episode 2853/98900: Winner=2, Reward=-21.30, EPSILON=0.975, (W=821,D=4,L=0)
2025-01-16 05:19:58,506 - DEBUG - Q-vals = [0.13154614 0.15250367 0.20612662 0.1888786  0.14924552 0.05737521
 0.11432426], best_act=2, best_val=0.206
2025-01-16 05:19:58,506 - DEBUG - Low Q-value (0.206), using MCTS.
2025-01-16 05:19:58,516 - INFO - Episode 2854/98900: Winner=2, Reward=-10.65, EPSILON=0.975, (W=822,D=4,L=0)
2025-01-16 05:19:58,858 - INFO - Episode 2855/98900: Winner=2, Reward=-37.25, EPSILON=0.975, (W=822,D=4,L=0)
2025-01-16 05:19:58,917 - DEBUG - Q-vals = [0.14595175 0.12078686 0.12163414 0.20147699 0.10073763 0.14272313
 0.16668956], best_act=3, best_val=0.201
2025-01-16 05:19:58,917 - DEBUG - Low Q-value (0.201), using MCTS.
2025-01-16 05:19:58,918 - INFO - Running MCTS with 124 simulations using 6 processes.
2025-01-16 05:20:01,623 - DEBUG - Aggregated action counts: {1: 1, 4: 2, 0: 3, 3: 1}
2025-01-16 05:20:01,623 - DEBUG - Chose best action 0
2025-01-16 05:20:01,660 - INFO - Episode 2856/98900: Winner=2, Reward=1.20, EPSILON=0.975, (W=823,D=4,L=0)
2025-01-16 05:20:01,926 - INFO - Episode 2857/98900: Winner=2, Reward=11.35, EPSILON=0.975, (W=823,D=4,L=0)
2025-01-16 05:20:02,228 - INFO - Episode 2858/98900: Winner=2, Reward=-3.55, EPSILON=0.975, (W=823,D=4,L=0)
2025-01-16 05:20:02,484 - INFO - Episode 2859/98900: Winner=2, Reward=-21.35, EPSILON=0.975, (W=824,D=4,L=0)
2025-01-16 05:20:02,666 - INFO - Episode 2860/98900: Winner=2, Reward=22.45, EPSILON=0.975, (W=824,D=4,L=0)
2025-01-16 05:20:02,962 - INFO - Episode 2861/98900: Winner=2, Reward=-32.55, EPSILON=0.975, (W=825,D=4,L=0)
2025-01-16 05:20:02,999 - DEBUG - Q-vals = [0.10583224 0.05310431 0.10962071 0.04238926 0.08783864 0.41469234
 0.1865225 ], best_act=5, best_val=0.415
2025-01-16 05:20:02,999 - DEBUG - Low Q-value (0.415), using MCTS.
2025-01-16 05:20:02,999 - INFO - Running MCTS with 124 simulations using 6 processes.
2025-01-16 05:20:05,823 - DEBUG - Aggregated action counts: {0: 3, 4: 1, 1: 1, 3: 1, 6: 1}
2025-01-16 05:20:05,823 - DEBUG - Chose best action 0
2025-01-16 05:20:05,846 - DEBUG - Q-vals = [0.15388022 0.10467812 0.09723759 0.18534763 0.09194762 0.18945868
 0.17745008], best_act=5, best_val=0.189
2025-01-16 05:20:05,846 - DEBUG - Low Q-value (0.189), using MCTS.
2025-01-16 05:20:05,846 - INFO - Running MCTS with 124 simulations using 6 processes.
2025-01-16 05:20:08,820 - DEBUG - Aggregated action counts: {6: 1, 0: 3, 1: 2, 2: 1}
2025-01-16 05:20:08,821 - DEBUG - Chose best action 0
2025-01-16 05:20:09,037 - INFO - Episode 2862/98900: Winner=2, Reward=-15.90, EPSILON=0.975, (W=826,D=4,L=0)
2025-01-16 05:20:09,099 - DEBUG - Q-vals = [0.15567984 0.10956785 0.1500841  0.14708449 0.11728401 0.16673155
 0.1535682 ], best_act=5, best_val=0.167
2025-01-16 05:20:09,100 - DEBUG - Low Q-value (0.167), using MCTS.
2025-01-16 05:20:09,100 - INFO - Running MCTS with 124 simulations using 6 processes.
2025-01-16 05:20:11,890 - DEBUG - Aggregated action counts: {0: 3, 3: 3, 1: 1}
2025-01-16 05:20:11,890 - DEBUG - Chose best action 0
2025-01-16 05:20:12,120 - INFO - Episode 2863/98900: Winner=2, Reward=8.90, EPSILON=0.975, (W=827,D=4,L=0)
2025-01-16 05:20:12,264 - INFO - Episode 2864/98900: Winner=2, Reward=2.30, EPSILON=0.975, (W=828,D=4,L=0)
2025-01-16 05:20:12,408 - DEBUG - Q-vals = [0.15760402 0.11888715 0.13848245 0.12006255 0.14771982 0.11240782
 0.20483616], best_act=6, best_val=0.205
2025-01-16 05:20:12,408 - DEBUG - Low Q-value (0.205), using MCTS.
2025-01-16 05:20:12,418 - INFO - Episode 2865/98900: Winner=2, Reward=-19.35, EPSILON=0.975, (W=829,D=4,L=0)
2025-01-16 05:20:12,673 - INFO - Episode 2866/98900: Winner=2, Reward=3.05, EPSILON=0.975, (W=829,D=4,L=0)
2025-01-16 05:20:12,942 - INFO - Episode 2867/98900: Winner=2, Reward=-11.65, EPSILON=0.975, (W=830,D=4,L=0)
2025-01-16 05:20:13,163 - INFO - Episode 2868/98900: Winner=2, Reward=33.00, EPSILON=0.975, (W=830,D=4,L=0)
2025-01-16 05:20:13,337 - INFO - Episode 2869/98900: Winner=2, Reward=2.75, EPSILON=0.975, (W=830,D=4,L=0)
2025-01-16 05:20:13,639 - INFO - Episode 2870/98900: Winner=2, Reward=-29.70, EPSILON=0.975, (W=831,D=4,L=0)
2025-01-16 05:20:13,675 - DEBUG - Q-vals = [0.13848507 0.06297543 0.13184455 0.03731011 0.23401786 0.24458468
 0.15078229], best_act=5, best_val=0.245
2025-01-16 05:20:13,675 - DEBUG - Low Q-value (0.245), using MCTS.
2025-01-16 05:20:13,675 - INFO - Running MCTS with 124 simulations using 6 processes.
2025-01-16 05:20:16,399 - DEBUG - Aggregated action counts: {2: 2, 3: 1, 5: 1, 0: 3}
2025-01-16 05:20:16,399 - DEBUG - Chose best action 0
2025-01-16 05:20:16,473 - INFO - Episode 2871/98900: Winner=2, Reward=6.50, EPSILON=0.974, (W=831,D=4,L=0)
2025-01-16 05:20:16,598 - DEBUG - Q-vals = [0.17126854 0.1002091  0.29589087 0.22199263 0.03393143 0.04177605
 0.13493131], best_act=2, best_val=0.296
2025-01-16 05:20:16,598 - DEBUG - Low Q-value (0.296), using MCTS.
2025-01-16 05:20:16,599 - INFO - Running MCTS with 124 simulations using 6 processes.
2025-01-16 05:20:19,768 - DEBUG - Aggregated action counts: {2: 1, 0: 3, 3: 2, 6: 1}
2025-01-16 05:20:19,768 - DEBUG - Chose best action 0
2025-01-16 05:20:19,850 - INFO - Episode 2872/98900: Winner=2, Reward=9.60, EPSILON=0.974, (W=831,D=4,L=0)
2025-01-16 05:20:20,060 - DEBUG - Q-vals = [0.07626748 0.07053293 0.29204267 0.20149416 0.10994222 0.05816551
 0.19155513], best_act=2, best_val=0.292
2025-01-16 05:20:20,060 - DEBUG - Low Q-value (0.292), using MCTS.
2025-01-16 05:20:20,061 - INFO - Running MCTS with 124 simulations using 6 processes.
2025-01-16 05:20:23,274 - DEBUG - Aggregated action counts: {4: 3, 3: 2, 2: 1, 0: 1}
2025-01-16 05:20:23,275 - DEBUG - Chose best action 4
2025-01-16 05:20:23,421 - INFO - Episode 2873/98900: Winner=2, Reward=-56.95, EPSILON=0.974, (W=832,D=4,L=0)
2025-01-16 05:20:23,585 - DEBUG - Q-vals = [0.18046743 0.20123027 0.07266265 0.05344195 0.16421618 0.20009318
 0.12788834], best_act=1, best_val=0.201
2025-01-16 05:20:23,585 - DEBUG - Low Q-value (0.201), using MCTS.
2025-01-16 05:20:23,586 - INFO - Running MCTS with 124 simulations using 6 processes.
2025-01-16 05:20:26,805 - DEBUG - Aggregated action counts: {2: 2, 0: 5}
2025-01-16 05:20:26,805 - DEBUG - Chose best action 0
2025-01-16 05:20:26,852 - INFO - Episode 2874/98900: Winner=2, Reward=42.95, EPSILON=0.974, (W=832,D=4,L=0)
2025-01-16 05:20:27,118 - INFO - Episode 2875/98900: Winner=2, Reward=-8.80, EPSILON=0.974, (W=832,D=4,L=0)
2025-01-16 05:20:27,211 - DEBUG - Q-vals = [0.14829585 0.06552587 0.1687837  0.10238667 0.15326302 0.12056215
 0.24118264], best_act=6, best_val=0.241
2025-01-16 05:20:27,211 - DEBUG - Low Q-value (0.241), using MCTS.
2025-01-16 05:20:27,211 - INFO - Running MCTS with 125 simulations using 6 processes.
2025-01-16 05:20:30,206 - DEBUG - Aggregated action counts: {4: 1, 5: 1, 0: 2, 1: 2, 2: 1}
2025-01-16 05:20:30,206 - DEBUG - Chose best action 0
2025-01-16 05:20:30,262 - DEBUG - Q-vals = [0.17231858 0.09882718 0.14118204 0.10646408 0.18482475 0.11025952
 0.18612385], best_act=6, best_val=0.186
2025-01-16 05:20:30,263 - DEBUG - Low Q-value (0.186), using MCTS.
2025-01-16 05:20:30,264 - INFO - Running MCTS with 125 simulations using 6 processes.
2025-01-16 05:20:33,233 - DEBUG - Aggregated action counts: {2: 3, 0: 2, 3: 2}
2025-01-16 05:20:33,234 - DEBUG - Chose best action 2
2025-01-16 05:20:33,258 - DEBUG - Q-vals = [0.213807   0.15698668 0.13276522 0.12126549 0.12051748 0.1038943
 0.15076378], best_act=0, best_val=0.214
2025-01-16 05:20:33,258 - DEBUG - Low Q-value (0.214), using MCTS.
2025-01-16 05:20:33,259 - INFO - Running MCTS with 125 simulations using 6 processes.
2025-01-16 05:20:36,107 - DEBUG - Aggregated action counts: {1: 2, 0: 2, 2: 3}
2025-01-16 05:20:36,107 - DEBUG - Chose best action 2
2025-01-16 05:20:36,230 - INFO - Episode 2876/98900: Winner=2, Reward=1.20, EPSILON=0.974, (W=832,D=4,L=0)
2025-01-16 05:20:36,507 - INFO - Episode 2877/98900: Winner=2, Reward=-15.85, EPSILON=0.974, (W=833,D=4,L=0)
2025-01-16 05:20:36,753 - INFO - Episode 2878/98900: Winner=2, Reward=14.95, EPSILON=0.974, (W=833,D=4,L=0)
2025-01-16 05:20:37,013 - INFO - Episode 2879/98900: Winner=2, Reward=-10.25, EPSILON=0.974, (W=833,D=4,L=0)
2025-01-16 05:20:37,129 - DEBUG - Q-vals = [0.2490048  0.19650342 0.07581324 0.08057761 0.06259513 0.16673538
 0.16877045], best_act=0, best_val=0.249
2025-01-16 05:20:37,129 - DEBUG - Low Q-value (0.249), using MCTS.
2025-01-16 05:20:37,145 - INFO - Episode 2880/98900: Winner=2, Reward=-16.15, EPSILON=0.974, (W=834,D=4,L=0)
2025-01-16 05:20:37,376 - INFO - Episode 2881/98900: Winner=2, Reward=6.15, EPSILON=0.974, (W=835,D=4,L=0)
2025-01-16 05:20:37,629 - INFO - Episode 2882/98900: Winner=2, Reward=-0.60, EPSILON=0.974, (W=836,D=4,L=0)
2025-01-16 05:20:37,861 - INFO - Episode 2883/98900: Winner=2, Reward=-5.55, EPSILON=0.974, (W=837,D=4,L=0)
2025-01-16 05:20:38,163 - INFO - Episode 2884/98900: Winner=2, Reward=6.10, EPSILON=0.974, (W=837,D=4,L=0)
2025-01-16 05:20:38,336 - INFO - Episode 2885/98900: Winner=2, Reward=1.70, EPSILON=0.974, (W=837,D=4,L=0)
2025-01-16 05:20:38,483 - DEBUG - Q-vals = [0.17227258 0.11835435 0.13452888 0.10049164 0.14583096 0.11482993
 0.21369162], best_act=6, best_val=0.214
2025-01-16 05:20:38,483 - DEBUG - Low Q-value (0.214), using MCTS.
2025-01-16 05:20:38,485 - INFO - Running MCTS with 125 simulations using 6 processes.
2025-01-16 05:20:41,562 - DEBUG - Aggregated action counts: {0: 3, 3: 2, 2: 2}
2025-01-16 05:20:41,562 - DEBUG - Chose best action 0
2025-01-16 05:20:41,640 - INFO - Episode 2886/98900: Winner=2, Reward=-12.25, EPSILON=0.974, (W=838,D=4,L=0)
2025-01-16 05:20:42,109 - INFO - Episode 2887/98900: Winner=-1, Reward=-109.55, EPSILON=0.974, (W=838,D=5,L=0)
2025-01-16 05:20:42,296 - INFO - Episode 2888/98900: Winner=2, Reward=-13.50, EPSILON=0.974, (W=839,D=5,L=0)
2025-01-16 05:20:42,629 - INFO - Episode 2889/98900: Winner=2, Reward=-27.20, EPSILON=0.974, (W=840,D=5,L=0)
2025-01-16 05:20:42,895 - INFO - Episode 2890/98900: Winner=2, Reward=-48.30, EPSILON=0.974, (W=841,D=5,L=0)
2025-01-16 05:20:42,910 - DEBUG - Q-vals = [1.6685676e-02 1.7709756e-01 1.0157842e-06 8.0620283e-01 7.2797434e-08
 1.0492252e-05 2.3244172e-06], best_act=3, best_val=0.806
2025-01-16 05:20:42,910 - DEBUG - Low Q-value (0.806), using MCTS.
2025-01-16 05:20:42,910 - INFO - Running MCTS with 125 simulations using 6 processes.
2025-01-16 05:20:45,856 - DEBUG - Aggregated action counts: {0: 2, 2: 1, 5: 3, 1: 1}
2025-01-16 05:20:45,856 - DEBUG - Chose best action 5
2025-01-16 05:20:46,102 - INFO - Episode 2891/98900: Winner=2, Reward=-6.55, EPSILON=0.974, (W=841,D=5,L=0)
2025-01-16 05:20:46,280 - INFO - Episode 2892/98900: Winner=2, Reward=-1.80, EPSILON=0.974, (W=841,D=5,L=0)
2025-01-16 05:20:46,409 - INFO - Episode 2893/98900: Winner=2, Reward=1.55, EPSILON=0.974, (W=841,D=5,L=0)
2025-01-16 05:20:46,712 - INFO - Episode 2894/98900: Winner=2, Reward=-29.00, EPSILON=0.974, (W=842,D=5,L=0)
2025-01-16 05:20:47,010 - INFO - Episode 2895/98900: Winner=2, Reward=-39.70, EPSILON=0.974, (W=842,D=5,L=0)
2025-01-16 05:20:47,195 - INFO - Episode 2896/98900: Winner=2, Reward=28.90, EPSILON=0.974, (W=842,D=5,L=0)
2025-01-16 05:20:47,371 - INFO - Episode 2897/98900: Winner=2, Reward=3.95, EPSILON=0.974, (W=842,D=5,L=0)
2025-01-16 05:20:47,386 - DEBUG - Q-vals = [0.12461741 0.17955999 0.00754369 0.03930021 0.02201281 0.5778126
 0.04915329], best_act=5, best_val=0.578
2025-01-16 05:20:47,386 - DEBUG - Low Q-value (0.578), using MCTS.
2025-01-16 05:20:47,386 - INFO - Running MCTS with 125 simulations using 6 processes.
2025-01-16 05:20:50,159 - DEBUG - Aggregated action counts: {2: 3, 0: 3, 3: 1}
2025-01-16 05:20:50,159 - DEBUG - Chose best action 2
2025-01-16 05:20:50,184 - DEBUG - Q-vals = [0.19514814 0.08788939 0.0586062  0.23434667 0.10975879 0.15173866
 0.16251214], best_act=3, best_val=0.234
2025-01-16 05:20:50,184 - DEBUG - Low Q-value (0.234), using MCTS.
2025-01-16 05:20:50,184 - INFO - Running MCTS with 125 simulations using 6 processes.
2025-01-16 05:20:52,935 - DEBUG - Aggregated action counts: {5: 2, 2: 1, 1: 2, 3: 1, 0: 1}
2025-01-16 05:20:52,935 - DEBUG - Chose best action 5
2025-01-16 05:20:53,215 - INFO - Episode 2898/98900: Winner=2, Reward=-15.10, EPSILON=0.974, (W=842,D=5,L=0)
2025-01-16 05:20:53,564 - INFO - Episode 2899/98900: Winner=2, Reward=-15.40, EPSILON=0.974, (W=843,D=5,L=0)
2025-01-16 05:20:53,769 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2900.
2025-01-16 05:20:53,769 - INFO - Models saved at episode 2900
2025-01-16 05:20:53,770 - INFO - Target networks updated
2025-01-16 05:20:53,815 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2900.
2025-01-16 05:20:53,815 - INFO - Episode 2900/98900: Winner=2, Reward=-14.95, EPSILON=0.974, (W=844,D=5,L=0)
2025-01-16 05:20:53,866 - DEBUG - Q-vals = [0.17727491 0.09711824 0.10340212 0.07450444 0.1236713  0.27331138
 0.15071769], best_act=5, best_val=0.273
2025-01-16 05:20:53,866 - DEBUG - Low Q-value (0.273), using MCTS.
2025-01-16 05:20:53,867 - INFO - Running MCTS with 126 simulations using 6 processes.
2025-01-16 05:20:56,780 - DEBUG - Aggregated action counts: {3: 1, 0: 2, 4: 1, 1: 1, 2: 1}
2025-01-16 05:20:56,780 - DEBUG - Chose best action 0
2025-01-16 05:20:56,895 - INFO - Episode 2901/98900: Winner=2, Reward=6.15, EPSILON=0.974, (W=845,D=5,L=0)
2025-01-16 05:20:57,131 - INFO - Episode 2902/98900: Winner=2, Reward=-6.15, EPSILON=0.974, (W=845,D=5,L=0)
2025-01-16 05:20:57,314 - INFO - Episode 2903/98900: Winner=2, Reward=2.80, EPSILON=0.974, (W=845,D=5,L=0)
2025-01-16 05:20:57,435 - INFO - Episode 2904/98900: Winner=2, Reward=-11.10, EPSILON=0.974, (W=846,D=5,L=0)
2025-01-16 05:20:57,665 - INFO - Episode 2905/98900: Winner=2, Reward=1.55, EPSILON=0.974, (W=846,D=5,L=0)
2025-01-16 05:20:57,913 - INFO - Episode 2906/98900: Winner=2, Reward=-27.15, EPSILON=0.974, (W=847,D=5,L=0)
2025-01-16 05:20:58,063 - INFO - Episode 2907/98900: Winner=2, Reward=-11.90, EPSILON=0.974, (W=848,D=5,L=0)
2025-01-16 05:20:58,243 - INFO - Episode 2908/98900: Winner=2, Reward=8.10, EPSILON=0.974, (W=848,D=5,L=0)
2025-01-16 05:20:58,449 - INFO - Episode 2909/98900: Winner=2, Reward=5.85, EPSILON=0.974, (W=848,D=5,L=0)
2025-01-16 05:20:58,528 - INFO - Episode 2910/98900: Winner=2, Reward=1.85, EPSILON=0.974, (W=848,D=5,L=0)
2025-01-16 05:20:58,560 - DEBUG - Q-vals = [0.18096738 0.03829866 0.02646011 0.10856619 0.02070871 0.5848371
 0.04016181], best_act=5, best_val=0.585
2025-01-16 05:20:58,560 - DEBUG - Low Q-value (0.585), using MCTS.
2025-01-16 05:20:58,560 - INFO - Running MCTS with 126 simulations using 6 processes.
2025-01-16 05:21:01,280 - DEBUG - Aggregated action counts: {0: 2, 2: 3, 1: 1}
2025-01-16 05:21:01,280 - DEBUG - Chose best action 2
2025-01-16 05:21:01,615 - INFO - Episode 2911/98900: Winner=2, Reward=-26.45, EPSILON=0.974, (W=849,D=5,L=0)
2025-01-16 05:21:01,832 - INFO - Episode 2912/98900: Winner=2, Reward=-20.75, EPSILON=0.974, (W=850,D=5,L=0)
2025-01-16 05:21:02,212 - INFO - Episode 2913/98900: Winner=2, Reward=-77.25, EPSILON=0.974, (W=851,D=5,L=0)
2025-01-16 05:21:02,553 - INFO - Episode 2914/98900: Winner=2, Reward=-14.10, EPSILON=0.974, (W=851,D=5,L=0)
2025-01-16 05:21:02,865 - INFO - Episode 2915/98900: Winner=2, Reward=8.50, EPSILON=0.974, (W=851,D=5,L=0)
2025-01-16 05:21:03,026 - INFO - Episode 2916/98900: Winner=2, Reward=4.75, EPSILON=0.974, (W=851,D=5,L=0)
2025-01-16 05:21:03,196 - INFO - Episode 2917/98900: Winner=2, Reward=21.70, EPSILON=0.974, (W=851,D=5,L=0)
2025-01-16 05:21:03,212 - DEBUG - Q-vals = [0.17314984 0.08900589 0.08003329 0.05947104 0.20339619 0.25924024
 0.13570352], best_act=5, best_val=0.259
2025-01-16 05:21:03,212 - DEBUG - Low Q-value (0.259), using MCTS.
2025-01-16 05:21:03,212 - INFO - Running MCTS with 126 simulations using 6 processes.
2025-01-16 05:21:05,942 - DEBUG - Aggregated action counts: {5: 1, 2: 2, 0: 1, 4: 1, 1: 1}
2025-01-16 05:21:05,942 - DEBUG - Chose best action 2
2025-01-16 05:21:06,197 - INFO - Episode 2918/98900: Winner=2, Reward=-26.95, EPSILON=0.974, (W=852,D=5,L=0)
2025-01-16 05:21:06,388 - DEBUG - Q-vals = [0.08202839 0.07111637 0.30445376 0.10645747 0.20479317 0.11693527
 0.11421558], best_act=2, best_val=0.304
2025-01-16 05:21:06,388 - DEBUG - Low Q-value (0.304), using MCTS.
2025-01-16 05:21:06,389 - INFO - Running MCTS with 126 simulations using 6 processes.
2025-01-16 05:21:09,253 - DEBUG - Aggregated action counts: {6: 2, 2: 1, 3: 1, 1: 2}
2025-01-16 05:21:09,253 - DEBUG - Chose best action 6
2025-01-16 05:21:09,446 - INFO - Episode 2919/98900: Winner=2, Reward=-31.50, EPSILON=0.974, (W=853,D=5,L=0)
2025-01-16 05:21:09,727 - INFO - Episode 2920/98900: Winner=2, Reward=1.15, EPSILON=0.974, (W=853,D=5,L=0)
2025-01-16 05:21:09,962 - INFO - Episode 2921/98900: Winner=2, Reward=-8.50, EPSILON=0.974, (W=854,D=5,L=0)
2025-01-16 05:21:09,978 - DEBUG - Q-vals = [0.11820048 0.01756806 0.83074975 0.00558522 0.00185501 0.01929885
 0.00674254], best_act=2, best_val=0.831
2025-01-16 05:21:09,978 - DEBUG - Low Q-value (0.831), using MCTS.
2025-01-16 05:21:09,978 - INFO - Running MCTS with 126 simulations using 6 processes.
2025-01-16 05:21:12,862 - DEBUG - Aggregated action counts: {2: 3, 0: 1, 1: 1, 4: 1}
2025-01-16 05:21:12,862 - DEBUG - Chose best action 2
2025-01-16 05:21:13,352 - INFO - Episode 2922/98900: Winner=2, Reward=-3.60, EPSILON=0.974, (W=855,D=5,L=0)
2025-01-16 05:21:13,525 - DEBUG - Q-vals = [0.14914934 0.15361097 0.12438705 0.11003227 0.19133556 0.1498558
 0.12162898], best_act=1, best_val=0.154
2025-01-16 05:21:13,525 - DEBUG - Low Q-value (0.154), using MCTS.
2025-01-16 05:21:13,526 - INFO - Running MCTS with 126 simulations using 6 processes.
2025-01-16 05:21:16,367 - DEBUG - Aggregated action counts: {0: 5, 2: 1}
2025-01-16 05:21:16,367 - DEBUG - Chose best action 0
2025-01-16 05:21:16,400 - DEBUG - Q-vals = [0.13620813 0.16299352 0.09489998 0.04337982 0.2637793  0.22601803
 0.07272128], best_act=5, best_val=0.226
2025-01-16 05:21:16,400 - DEBUG - Low Q-value (0.226), using MCTS.
2025-01-16 05:21:16,400 - INFO - Running MCTS with 126 simulations using 6 processes.
2025-01-16 05:21:19,185 - DEBUG - Aggregated action counts: {1: 2, 0: 2, 3: 1, 2: 1}
2025-01-16 05:21:19,185 - DEBUG - Chose best action 1
2025-01-16 05:21:19,260 - INFO - Episode 2923/98900: Winner=2, Reward=32.70, EPSILON=0.974, (W=855,D=5,L=0)
2025-01-16 05:21:19,484 - INFO - Episode 2924/98900: Winner=2, Reward=-8.40, EPSILON=0.974, (W=856,D=5,L=0)
2025-01-16 05:21:19,783 - INFO - Episode 2925/98900: Winner=2, Reward=-11.45, EPSILON=0.974, (W=857,D=5,L=0)
2025-01-16 05:21:19,946 - DEBUG - Q-vals = [0.1950634  0.13189024 0.14578785 0.19280775 0.12743911 0.070297
 0.13671479], best_act=0, best_val=0.195
2025-01-16 05:21:19,946 - DEBUG - Low Q-value (0.195), using MCTS.
2025-01-16 05:21:19,961 - INFO - Running MCTS with 127 simulations using 6 processes.
2025-01-16 05:21:22,737 - DEBUG - Aggregated action counts: {2: 3, 6: 1, 0: 1, 5: 2}
2025-01-16 05:21:22,737 - DEBUG - Chose best action 2
2025-01-16 05:21:22,811 - INFO - Episode 2926/98900: Winner=2, Reward=-8.95, EPSILON=0.974, (W=858,D=5,L=0)
2025-01-16 05:21:23,028 - INFO - Episode 2927/98900: Winner=2, Reward=-10.65, EPSILON=0.974, (W=859,D=5,L=0)
2025-01-16 05:21:23,178 - DEBUG - Q-vals = [0.16376859 0.11004364 0.17573275 0.20839682 0.1011314  0.06307426
 0.17785256], best_act=3, best_val=0.208
2025-01-16 05:21:23,178 - DEBUG - Low Q-value (0.208), using MCTS.
2025-01-16 05:21:23,179 - INFO - Running MCTS with 127 simulations using 6 processes.
2025-01-16 05:21:25,930 - DEBUG - Aggregated action counts: {1: 2, 6: 1, 5: 1, 3: 2, 0: 1}
2025-01-16 05:21:25,930 - DEBUG - Chose best action 1
2025-01-16 05:21:26,159 - INFO - Episode 2928/98900: Winner=2, Reward=-33.10, EPSILON=0.974, (W=860,D=5,L=0)
2025-01-16 05:21:26,364 - DEBUG - Q-vals = [0.11710512 0.13615689 0.23860139 0.2334034  0.12222636 0.06311102
 0.08939586], best_act=2, best_val=0.239
2025-01-16 05:21:26,364 - DEBUG - Low Q-value (0.239), using MCTS.
2025-01-16 05:21:26,365 - INFO - Running MCTS with 127 simulations using 6 processes.
2025-01-16 05:21:29,995 - DEBUG - Aggregated action counts: {3: 3, 0: 2, 4: 1, 1: 1}
2025-01-16 05:21:29,995 - DEBUG - Chose best action 3
2025-01-16 05:21:30,112 - INFO - Episode 2929/98900: Winner=2, Reward=-27.90, EPSILON=0.974, (W=860,D=5,L=0)
2025-01-16 05:21:30,317 - INFO - Episode 2930/98900: Winner=2, Reward=-12.70, EPSILON=0.974, (W=861,D=5,L=0)
2025-01-16 05:21:30,494 - INFO - Episode 2931/98900: Winner=2, Reward=14.50, EPSILON=0.974, (W=861,D=5,L=0)
2025-01-16 05:21:30,551 - DEBUG - Q-vals = [0.10914258 0.06055792 0.13683832 0.02812746 0.25895253 0.14917678
 0.25720435], best_act=4, best_val=0.259
2025-01-16 05:21:30,551 - DEBUG - Low Q-value (0.259), using MCTS.
2025-01-16 05:21:30,552 - INFO - Running MCTS with 127 simulations using 6 processes.
2025-01-16 05:21:33,531 - DEBUG - Aggregated action counts: {2: 1, 1: 1, 6: 1, 0: 2, 5: 1, 3: 1}
2025-01-16 05:21:33,531 - DEBUG - Chose best action 0
2025-01-16 05:21:33,765 - INFO - Episode 2932/98900: Winner=2, Reward=-22.60, EPSILON=0.974, (W=862,D=5,L=0)
2025-01-16 05:21:33,953 - INFO - Episode 2933/98900: Winner=2, Reward=-1.60, EPSILON=0.974, (W=862,D=5,L=0)
2025-01-16 05:21:34,276 - DEBUG - Q-vals = [0.10370424 0.16938755 0.08391724 0.33224747 0.23337057 0.04070383
 0.03666898], best_act=1, best_val=0.169
2025-01-16 05:21:34,276 - DEBUG - Low Q-value (0.169), using MCTS.
2025-01-16 05:21:34,287 - INFO - Episode 2934/98900: Winner=2, Reward=-21.25, EPSILON=0.974, (W=863,D=5,L=0)
2025-01-16 05:21:34,402 - INFO - Episode 2935/98900: Winner=2, Reward=-0.95, EPSILON=0.974, (W=864,D=5,L=0)
2025-01-16 05:21:34,686 - INFO - Episode 2936/98900: Winner=2, Reward=-20.10, EPSILON=0.974, (W=864,D=5,L=0)
2025-01-16 05:21:35,068 - DEBUG - Q-vals = [0.11873607 0.22573914 0.14665107 0.25425208 0.15994425 0.06045873
 0.03421869], best_act=3, best_val=0.254
2025-01-16 05:21:35,068 - DEBUG - Low Q-value (0.254), using MCTS.
2025-01-16 05:21:35,068 - INFO - Running MCTS with 127 simulations using 6 processes.
2025-01-16 05:21:37,748 - DEBUG - Aggregated action counts: {0: 4, 2: 2, 3: 1}
2025-01-16 05:21:37,748 - DEBUG - Chose best action 0
2025-01-16 05:21:37,818 - INFO - Episode 2937/98900: Winner=2, Reward=-98.95, EPSILON=0.974, (W=864,D=5,L=0)
2025-01-16 05:21:37,938 - INFO - Episode 2938/98900: Winner=2, Reward=-11.30, EPSILON=0.974, (W=865,D=5,L=0)
2025-01-16 05:21:38,059 - INFO - Episode 2939/98900: Winner=2, Reward=-12.90, EPSILON=0.974, (W=866,D=5,L=0)
2025-01-16 05:21:38,213 - INFO - Episode 2940/98900: Winner=2, Reward=-1.00, EPSILON=0.974, (W=866,D=5,L=0)
2025-01-16 05:21:38,275 - DEBUG - Q-vals = [0.14429352 0.06181256 0.13375565 0.0738417  0.19091216 0.16153364
 0.2338508 ], best_act=6, best_val=0.234
2025-01-16 05:21:38,275 - DEBUG - Low Q-value (0.234), using MCTS.
2025-01-16 05:21:38,276 - INFO - Running MCTS with 127 simulations using 6 processes.
2025-01-16 05:21:41,532 - DEBUG - Aggregated action counts: {1: 1, 3: 1, 4: 2, 6: 1, 2: 1, 0: 1}
2025-01-16 05:21:41,532 - DEBUG - Chose best action 4
2025-01-16 05:21:41,579 - DEBUG - Q-vals = [0.18555023 0.12466928 0.10459711 0.12037102 0.09332659 0.141307
 0.23017883], best_act=6, best_val=0.230
2025-01-16 05:21:41,579 - DEBUG - Low Q-value (0.230), using MCTS.
2025-01-16 05:21:41,579 - INFO - Running MCTS with 127 simulations using 6 processes.
2025-01-16 05:21:44,617 - DEBUG - Aggregated action counts: {1: 2, 2: 3, 5: 1, 4: 1}
2025-01-16 05:21:44,617 - DEBUG - Chose best action 2
2025-01-16 05:21:44,684 - INFO - Episode 2941/98900: Winner=2, Reward=5.95, EPSILON=0.974, (W=866,D=5,L=0)
2025-01-16 05:21:44,802 - DEBUG - Q-vals = [0.16600616 0.07896004 0.15454319 0.12610501 0.17631821 0.10263298
 0.1954345 ], best_act=6, best_val=0.195
2025-01-16 05:21:44,802 - DEBUG - Low Q-value (0.195), using MCTS.
2025-01-16 05:21:44,803 - INFO - Running MCTS with 127 simulations using 6 processes.
2025-01-16 05:21:47,737 - DEBUG - Aggregated action counts: {1: 2, 3: 1, 2: 2, 4: 1, 0: 1}
2025-01-16 05:21:47,737 - DEBUG - Chose best action 1
2025-01-16 05:21:47,818 - INFO - Episode 2942/98900: Winner=2, Reward=-8.70, EPSILON=0.974, (W=866,D=5,L=0)
2025-01-16 05:21:47,997 - DEBUG - Q-vals = [0.11659857 0.0828865  0.13369787 0.34363332 0.10047255 0.06625275
 0.15645853], best_act=3, best_val=0.344
2025-01-16 05:21:47,997 - DEBUG - Low Q-value (0.344), using MCTS.
2025-01-16 05:21:47,997 - INFO - Running MCTS with 127 simulations using 6 processes.
2025-01-16 05:21:50,939 - DEBUG - Aggregated action counts: {0: 1, 3: 4, 1: 2}
2025-01-16 05:21:50,939 - DEBUG - Chose best action 3
2025-01-16 05:21:50,970 - INFO - Episode 2943/98900: Winner=2, Reward=-12.85, EPSILON=0.974, (W=867,D=5,L=0)
2025-01-16 05:21:51,337 - INFO - Episode 2944/98900: Winner=2, Reward=-25.55, EPSILON=0.974, (W=868,D=5,L=0)
2025-01-16 05:21:51,621 - INFO - Episode 2945/98900: Winner=2, Reward=-11.30, EPSILON=0.974, (W=868,D=5,L=0)
2025-01-16 05:21:51,798 - DEBUG - Q-vals = [0.23078969 0.21066855 0.03987268 0.04515888 0.09628125 0.31793654
 0.05929244], best_act=5, best_val=0.318
2025-01-16 05:21:51,798 - DEBUG - Low Q-value (0.318), using MCTS.
2025-01-16 05:21:51,813 - INFO - Episode 2946/98900: Winner=2, Reward=-17.00, EPSILON=0.974, (W=869,D=5,L=0)
2025-01-16 05:21:51,985 - INFO - Episode 2947/98900: Winner=2, Reward=-6.45, EPSILON=0.974, (W=869,D=5,L=0)
2025-01-16 05:21:52,256 - INFO - Episode 2948/98900: Winner=2, Reward=-29.45, EPSILON=0.974, (W=870,D=5,L=0)
2025-01-16 05:21:52,475 - INFO - Episode 2949/98900: Winner=2, Reward=-3.75, EPSILON=0.974, (W=870,D=5,L=0)
2025-01-16 05:21:52,522 - DEBUG - Q-vals = [2.6986601e-02 8.5041746e-03 1.3897195e-04 9.6436179e-01 1.0226793e-06
 5.1893558e-06 2.3067630e-06], best_act=3, best_val=0.964
2025-01-16 05:21:52,522 - DEBUG - Low Q-value (0.964), using MCTS.
2025-01-16 05:21:52,522 - INFO - Running MCTS with 128 simulations using 6 processes.
2025-01-16 05:21:55,306 - DEBUG - Aggregated action counts: {1: 2, 5: 2, 3: 1, 6: 1, 0: 1}
2025-01-16 05:21:55,306 - DEBUG - Chose best action 1
2025-01-16 05:21:55,494 - INFO - Episode 2950/98900: Winner=2, Reward=-1.20, EPSILON=0.974, (W=871,D=5,L=0)
2025-01-16 05:21:55,525 - DEBUG - Q-vals = [0.01332598 0.00284975 0.01941087 0.00370089 0.01960382 0.87128377
 0.06982488], best_act=5, best_val=0.871
2025-01-16 05:21:55,525 - DEBUG - Low Q-value (0.871), using MCTS.
2025-01-16 05:21:55,525 - INFO - Running MCTS with 128 simulations using 6 processes.
2025-01-16 05:21:58,524 - DEBUG - Aggregated action counts: {5: 1, 1: 3, 0: 2, 3: 1}
2025-01-16 05:21:58,524 - DEBUG - Chose best action 1
2025-01-16 05:21:58,719 - INFO - Episode 2951/98900: Winner=2, Reward=-22.85, EPSILON=0.974, (W=872,D=5,L=0)
2025-01-16 05:21:58,781 - DEBUG - Q-vals = [0.20956871 0.12345583 0.08554742 0.12100671 0.09065976 0.18804523
 0.18171628], best_act=0, best_val=0.210
2025-01-16 05:21:58,781 - DEBUG - Low Q-value (0.210), using MCTS.
2025-01-16 05:21:58,781 - INFO - Running MCTS with 128 simulations using 6 processes.
2025-01-16 05:22:01,874 - DEBUG - Aggregated action counts: {5: 2, 4: 1, 2: 2, 0: 2}
2025-01-16 05:22:01,874 - DEBUG - Chose best action 5
2025-01-16 05:22:02,089 - INFO - Episode 2952/98900: Winner=2, Reward=-12.20, EPSILON=0.974, (W=872,D=5,L=0)
2025-01-16 05:22:02,288 - INFO - Episode 2953/98900: Winner=2, Reward=8.95, EPSILON=0.974, (W=872,D=5,L=0)
2025-01-16 05:22:02,567 - INFO - Episode 2954/98900: Winner=2, Reward=-3.35, EPSILON=0.974, (W=873,D=5,L=0)
2025-01-16 05:22:02,713 - DEBUG - Q-vals = [0.19525021 0.13877618 0.10043482 0.13127723 0.09372939 0.1164214
 0.22411078], best_act=6, best_val=0.224
2025-01-16 05:22:02,713 - DEBUG - Low Q-value (0.224), using MCTS.
2025-01-16 05:22:02,714 - INFO - Running MCTS with 128 simulations using 6 processes.
2025-01-16 05:22:05,623 - DEBUG - Aggregated action counts: {3: 2, 0: 2, 4: 1, 2: 2}
2025-01-16 05:22:05,623 - DEBUG - Chose best action 3
2025-01-16 05:22:05,807 - INFO - Episode 2955/98900: Winner=2, Reward=22.85, EPSILON=0.974, (W=873,D=5,L=0)
2025-01-16 05:22:06,136 - DEBUG - Q-vals = [0.01386498 0.01364393 0.08881481 0.7945096  0.00241928 0.07076816
 0.01597917], best_act=2, best_val=0.089
2025-01-16 05:22:06,136 - DEBUG - Low Q-value (0.089), using MCTS.
2025-01-16 05:22:06,152 - INFO - Episode 2956/98900: Winner=2, Reward=-12.05, EPSILON=0.974, (W=874,D=5,L=0)
2025-01-16 05:22:06,307 - DEBUG - Q-vals = [0.24414696 0.14512739 0.06407089 0.31279367 0.02556763 0.04841385
 0.15987964], best_act=3, best_val=0.313
2025-01-16 05:22:06,307 - DEBUG - Low Q-value (0.313), using MCTS.
2025-01-16 05:22:06,307 - INFO - Episode 2957/98900: Winner=2, Reward=-7.95, EPSILON=0.974, (W=875,D=5,L=0)
2025-01-16 05:22:06,609 - INFO - Episode 2958/98900: Winner=2, Reward=8.75, EPSILON=0.974, (W=875,D=5,L=0)
2025-01-16 05:22:06,772 - INFO - Episode 2959/98900: Winner=2, Reward=-3.35, EPSILON=0.974, (W=875,D=5,L=0)
2025-01-16 05:22:06,850 - INFO - Episode 2960/98900: Winner=2, Reward=8.25, EPSILON=0.974, (W=875,D=5,L=0)
2025-01-16 05:22:06,928 - INFO - Episode 2961/98900: Winner=2, Reward=15.95, EPSILON=0.974, (W=875,D=5,L=0)
2025-01-16 05:22:07,053 - INFO - Episode 2962/98900: Winner=2, Reward=1.70, EPSILON=0.974, (W=876,D=5,L=0)
2025-01-16 05:22:07,172 - INFO - Episode 2963/98900: Winner=2, Reward=7.15, EPSILON=0.974, (W=876,D=5,L=0)
2025-01-16 05:22:07,485 - INFO - Episode 2964/98900: Winner=2, Reward=-5.45, EPSILON=0.974, (W=876,D=5,L=0)
2025-01-16 05:22:07,672 - INFO - Episode 2965/98900: Winner=2, Reward=-4.20, EPSILON=0.974, (W=877,D=5,L=0)
2025-01-16 05:22:07,844 - INFO - Episode 2966/98900: Winner=2, Reward=-3.25, EPSILON=0.974, (W=877,D=5,L=0)
2025-01-16 05:22:08,031 - INFO - Episode 2967/98900: Winner=2, Reward=-13.45, EPSILON=0.974, (W=878,D=5,L=0)
2025-01-16 05:22:08,281 - INFO - Episode 2968/98900: Winner=2, Reward=-3.45, EPSILON=0.974, (W=879,D=5,L=0)
2025-01-16 05:22:08,516 - INFO - Episode 2969/98900: Winner=2, Reward=15.80, EPSILON=0.974, (W=879,D=5,L=0)
2025-01-16 05:22:08,773 - INFO - Episode 2970/98900: Winner=2, Reward=14.65, EPSILON=0.974, (W=879,D=5,L=0)
2025-01-16 05:22:08,924 - INFO - Episode 2971/98900: Winner=2, Reward=-10.70, EPSILON=0.974, (W=880,D=5,L=0)
2025-01-16 05:22:09,262 - INFO - Episode 2972/98900: Winner=2, Reward=-8.05, EPSILON=0.974, (W=880,D=5,L=0)
2025-01-16 05:22:09,403 - DEBUG - Q-vals = [0.16677856 0.12998244 0.15417452 0.18545768 0.11618413 0.09140982
 0.15601285], best_act=3, best_val=0.185
2025-01-16 05:22:09,403 - DEBUG - Low Q-value (0.185), using MCTS.
2025-01-16 05:22:09,419 - INFO - Running MCTS with 128 simulations using 6 processes.
2025-01-16 05:22:13,291 - DEBUG - Aggregated action counts: {4: 4, 1: 2, 0: 1}
2025-01-16 05:22:13,291 - DEBUG - Chose best action 4
2025-01-16 05:22:13,391 - INFO - Episode 2973/98900: Winner=2, Reward=-4.25, EPSILON=0.974, (W=881,D=5,L=0)
2025-01-16 05:22:13,597 - INFO - Episode 2974/98900: Winner=2, Reward=-10.65, EPSILON=0.974, (W=882,D=5,L=0)
2025-01-16 05:22:13,830 - INFO - Episode 2975/98900: Winner=2, Reward=-19.00, EPSILON=0.974, (W=882,D=5,L=0)
2025-01-16 05:22:14,258 - INFO - Episode 2976/98900: Winner=2, Reward=-53.60, EPSILON=0.974, (W=882,D=5,L=0)
2025-01-16 05:22:14,485 - INFO - Episode 2977/98900: Winner=2, Reward=0.40, EPSILON=0.974, (W=882,D=5,L=0)
2025-01-16 05:22:14,874 - INFO - Episode 2978/98900: Winner=2, Reward=-23.65, EPSILON=0.974, (W=883,D=5,L=0)
2025-01-16 05:22:14,984 - DEBUG - Q-vals = [0.1548249  0.12191608 0.13983566 0.14510462 0.12978277 0.13164262
 0.17689338], best_act=6, best_val=0.177
2025-01-16 05:22:14,984 - DEBUG - Low Q-value (0.177), using MCTS.
2025-01-16 05:22:14,984 - INFO - Running MCTS with 129 simulations using 6 processes.
2025-01-16 05:22:18,280 - DEBUG - Aggregated action counts: {5: 1, 4: 1, 0: 5}
2025-01-16 05:22:18,281 - DEBUG - Chose best action 0
2025-01-16 05:22:18,385 - INFO - Episode 2979/98900: Winner=2, Reward=-4.75, EPSILON=0.974, (W=883,D=5,L=0)
2025-01-16 05:22:18,498 - DEBUG - Q-vals = [0.14859928 0.11494692 0.16325583 0.1662897  0.09411334 0.11182233
 0.20097262], best_act=6, best_val=0.201
2025-01-16 05:22:18,498 - DEBUG - Low Q-value (0.201), using MCTS.
2025-01-16 05:22:18,498 - INFO - Running MCTS with 129 simulations using 6 processes.
2025-01-16 05:22:21,695 - DEBUG - Aggregated action counts: {6: 1, 0: 2, 4: 2, 2: 1, 3: 1}
2025-01-16 05:22:21,696 - DEBUG - Chose best action 0
2025-01-16 05:22:21,842 - INFO - Episode 2980/98900: Winner=2, Reward=13.25, EPSILON=0.974, (W=883,D=5,L=0)
2025-01-16 05:22:22,009 - INFO - Episode 2981/98900: Winner=2, Reward=-11.60, EPSILON=0.974, (W=884,D=5,L=0)
2025-01-16 05:22:22,275 - DEBUG - Q-vals = [0.05981685 0.10156342 0.13147971 0.09940353 0.10308256 0.44179747
 0.06285645], best_act=5, best_val=0.442
2025-01-16 05:22:22,275 - DEBUG - Low Q-value (0.442), using MCTS.
2025-01-16 05:22:22,285 - INFO - Episode 2982/98900: Winner=2, Reward=-36.50, EPSILON=0.974, (W=885,D=5,L=0)
2025-01-16 05:22:22,710 - INFO - Episode 2983/98900: Winner=2, Reward=-48.05, EPSILON=0.974, (W=886,D=5,L=0)
2025-01-16 05:22:22,814 - INFO - Episode 2984/98900: Winner=2, Reward=0.45, EPSILON=0.974, (W=886,D=5,L=0)
2025-01-16 05:22:23,005 - INFO - Episode 2985/98900: Winner=2, Reward=-15.35, EPSILON=0.973, (W=887,D=5,L=0)
2025-01-16 05:22:23,229 - INFO - Episode 2986/98900: Winner=2, Reward=8.20, EPSILON=0.973, (W=887,D=5,L=0)
2025-01-16 05:22:23,416 - DEBUG - Q-vals = [0.27837294 0.25889668 0.05982086 0.14366382 0.0228837  0.09122784
 0.14513414], best_act=0, best_val=0.278
2025-01-16 05:22:23,416 - DEBUG - Low Q-value (0.278), using MCTS.
2025-01-16 05:22:23,432 - INFO - Episode 2987/98900: Winner=2, Reward=-2.65, EPSILON=0.973, (W=888,D=5,L=0)
2025-01-16 05:22:23,557 - INFO - Episode 2988/98900: Winner=2, Reward=15.45, EPSILON=0.973, (W=888,D=5,L=0)
2025-01-16 05:22:23,807 - INFO - Episode 2989/98900: Winner=2, Reward=1.85, EPSILON=0.973, (W=888,D=5,L=0)
2025-01-16 05:22:24,182 - INFO - Episode 2990/98900: Winner=2, Reward=-34.10, EPSILON=0.973, (W=889,D=5,L=0)
2025-01-16 05:22:24,353 - INFO - Episode 2991/98900: Winner=2, Reward=22.65, EPSILON=0.973, (W=889,D=5,L=0)
2025-01-16 05:22:24,416 - DEBUG - Q-vals = [0.07078933 0.03085451 0.09200829 0.11988796 0.08958348 0.39435947
 0.202517  ], best_act=5, best_val=0.394
2025-01-16 05:22:24,416 - DEBUG - Low Q-value (0.394), using MCTS.
2025-01-16 05:22:24,416 - INFO - Running MCTS with 129 simulations using 6 processes.
2025-01-16 05:22:27,291 - DEBUG - Aggregated action counts: {3: 1, 5: 1, 2: 2, 4: 1, 1: 1, 0: 1}
2025-01-16 05:22:27,291 - DEBUG - Chose best action 2
2025-01-16 05:22:27,353 - INFO - Episode 2992/98900: Winner=2, Reward=1.65, EPSILON=0.973, (W=889,D=5,L=0)
2025-01-16 05:22:27,463 - INFO - Episode 2993/98900: Winner=2, Reward=-7.35, EPSILON=0.973, (W=890,D=5,L=0)
2025-01-16 05:22:27,713 - INFO - Episode 2994/98900: Winner=2, Reward=-21.75, EPSILON=0.973, (W=891,D=5,L=0)
2025-01-16 05:22:27,996 - INFO - Episode 2995/98900: Winner=2, Reward=-22.90, EPSILON=0.973, (W=891,D=5,L=0)
2025-01-16 05:22:28,190 - INFO - Episode 2996/98900: Winner=2, Reward=-7.55, EPSILON=0.973, (W=891,D=5,L=0)
2025-01-16 05:22:28,368 - INFO - Episode 2997/98900: Winner=2, Reward=17.65, EPSILON=0.973, (W=891,D=5,L=0)
2025-01-16 05:22:28,655 - INFO - Episode 2998/98900: Winner=2, Reward=-6.60, EPSILON=0.973, (W=892,D=5,L=0)
2025-01-16 05:22:28,999 - INFO - Episode 2999/98900: Winner=2, Reward=-36.65, EPSILON=0.973, (W=892,D=5,L=0)
2025-01-16 05:22:29,374 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3000.
2025-01-16 05:22:29,374 - INFO - Models saved at episode 3000
2025-01-16 05:22:29,376 - INFO - Target networks updated
2025-01-16 05:22:29,445 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3000.
2025-01-16 05:22:29,445 - INFO - Episode 3000/98900: Winner=2, Reward=-29.65, EPSILON=0.973, (W=893,D=5,L=0)
2025-01-16 05:22:29,789 - INFO - Episode 3001/98900: Winner=2, Reward=-56.75, EPSILON=0.973, (W=894,D=5,L=0)
2025-01-16 05:22:30,186 - INFO - Episode 3002/98900: Winner=2, Reward=-51.05, EPSILON=0.973, (W=894,D=5,L=0)
2025-01-16 05:22:30,225 - DEBUG - Q-vals = [0.01858343 0.0013504  0.03988359 0.00163912 0.00322587 0.92907345
 0.00624411], best_act=5, best_val=0.929
2025-01-16 05:22:30,225 - DEBUG - Low Q-value (0.929), using MCTS.
2025-01-16 05:22:30,226 - INFO - Running MCTS with 130 simulations using 6 processes.
2025-01-16 05:22:33,586 - DEBUG - Aggregated action counts: {3: 3, 6: 1, 4: 1, 2: 1, 0: 1}
2025-01-16 05:22:33,586 - DEBUG - Chose best action 3
2025-01-16 05:22:33,800 - INFO - Episode 3003/98900: Winner=2, Reward=-27.30, EPSILON=0.973, (W=895,D=5,L=0)
2025-01-16 05:22:34,022 - INFO - Episode 3004/98900: Winner=2, Reward=-11.90, EPSILON=0.973, (W=896,D=5,L=0)
2025-01-16 05:22:34,077 - DEBUG - Q-vals = [0.17126171 0.10655805 0.13133466 0.12998475 0.14502944 0.15587609
 0.15995526], best_act=0, best_val=0.171
2025-01-16 05:22:34,077 - DEBUG - Low Q-value (0.171), using MCTS.
2025-01-16 05:22:34,077 - INFO - Running MCTS with 130 simulations using 6 processes.
2025-01-16 05:22:37,209 - DEBUG - Aggregated action counts: {3: 1, 5: 1, 0: 3, 6: 1, 4: 1}
2025-01-16 05:22:37,209 - DEBUG - Chose best action 0
2025-01-16 05:22:37,289 - INFO - Episode 3005/98900: Winner=2, Reward=4.55, EPSILON=0.973, (W=896,D=5,L=0)
2025-01-16 05:22:37,428 - INFO - Episode 3006/98900: Winner=2, Reward=-8.05, EPSILON=0.973, (W=897,D=5,L=0)
2025-01-16 05:22:37,594 - INFO - Episode 3007/98900: Winner=2, Reward=0.75, EPSILON=0.973, (W=897,D=5,L=0)
2025-01-16 05:22:37,661 - INFO - Episode 3008/98900: Winner=2, Reward=8.20, EPSILON=0.973, (W=897,D=5,L=0)
2025-01-16 05:22:37,766 - DEBUG - Q-vals = [0.20933516 0.15560424 0.10012905 0.10084299 0.10842645 0.09992714
 0.2257349 ], best_act=6, best_val=0.226
2025-01-16 05:22:37,766 - DEBUG - Low Q-value (0.226), using MCTS.
2025-01-16 05:22:37,767 - INFO - Running MCTS with 130 simulations using 6 processes.
2025-01-16 05:22:41,152 - DEBUG - Aggregated action counts: {1: 3, 4: 2, 3: 1, 0: 1}
2025-01-16 05:22:41,152 - DEBUG - Chose best action 1
2025-01-16 05:22:41,261 - INFO - Episode 3009/98900: Winner=2, Reward=-12.65, EPSILON=0.973, (W=898,D=5,L=0)
2025-01-16 05:22:41,620 - DEBUG - Q-vals = [0.03589207 0.04431665 0.06517624 0.45382327 0.04848404 0.05885388
 0.29345384], best_act=3, best_val=0.454
2025-01-16 05:22:41,620 - DEBUG - Low Q-value (0.454), using MCTS.
2025-01-16 05:22:41,620 - INFO - Running MCTS with 130 simulations using 6 processes.
2025-01-16 05:22:45,105 - DEBUG - Aggregated action counts: {5: 1, 3: 5, 0: 1}
2025-01-16 05:22:45,105 - DEBUG - Chose best action 3
2025-01-16 05:22:45,136 - INFO - Episode 3010/98900: Winner=2, Reward=-33.30, EPSILON=0.973, (W=898,D=5,L=0)
2025-01-16 05:22:45,464 - INFO - Episode 3011/98900: Winner=2, Reward=-30.75, EPSILON=0.973, (W=899,D=5,L=0)
2025-01-16 05:22:45,776 - INFO - Episode 3012/98900: Winner=2, Reward=-15.05, EPSILON=0.973, (W=900,D=5,L=0)
2025-01-16 05:22:45,977 - INFO - Episode 3013/98900: Winner=2, Reward=-9.00, EPSILON=0.973, (W=900,D=5,L=0)
2025-01-16 05:22:46,171 - INFO - Episode 3014/98900: Winner=2, Reward=1.75, EPSILON=0.973, (W=900,D=5,L=0)
2025-01-16 05:22:46,233 - DEBUG - Q-vals = [0.17180578 0.07535988 0.11629942 0.18912475 0.11443846 0.16966526
 0.16330644], best_act=3, best_val=0.189
2025-01-16 05:22:46,233 - DEBUG - Low Q-value (0.189), using MCTS.
2025-01-16 05:22:46,233 - INFO - Running MCTS with 130 simulations using 6 processes.
2025-01-16 05:22:49,274 - DEBUG - Aggregated action counts: {2: 1, 4: 2, 0: 3, 3: 1}
2025-01-16 05:22:49,274 - DEBUG - Chose best action 0
2025-01-16 05:22:49,565 - INFO - Episode 3015/98900: Winner=2, Reward=-39.20, EPSILON=0.973, (W=901,D=5,L=0)
2025-01-16 05:22:49,750 - DEBUG - Q-vals = [0.08480423 0.02871905 0.37546387 0.20269616 0.15329872 0.05561635
 0.09940153], best_act=2, best_val=0.375
2025-01-16 05:22:49,750 - DEBUG - Low Q-value (0.375), using MCTS.
2025-01-16 05:22:49,751 - INFO - Running MCTS with 130 simulations using 6 processes.
2025-01-16 05:22:52,567 - DEBUG - Aggregated action counts: {2: 3, 1: 1, 5: 1, 4: 1, 0: 1}
2025-01-16 05:22:52,567 - DEBUG - Chose best action 2
2025-01-16 05:22:52,708 - INFO - Episode 3016/98900: Winner=2, Reward=-24.90, EPSILON=0.973, (W=902,D=5,L=0)
2025-01-16 05:22:52,723 - DEBUG - Q-vals = [0.21913393 0.0638149  0.08068358 0.20384507 0.17848317 0.127151
 0.12688832], best_act=0, best_val=0.219
2025-01-16 05:22:52,723 - DEBUG - Low Q-value (0.219), using MCTS.
2025-01-16 05:22:52,723 - INFO - Running MCTS with 130 simulations using 6 processes.
2025-01-16 05:22:55,662 - DEBUG - Aggregated action counts: {4: 1, 0: 2, 5: 1, 1: 1, 6: 1, 3: 1}
2025-01-16 05:22:55,662 - DEBUG - Chose best action 0
2025-01-16 05:22:55,924 - INFO - Episode 3017/98900: Winner=2, Reward=-5.60, EPSILON=0.973, (W=903,D=5,L=0)
2025-01-16 05:22:56,189 - INFO - Episode 3018/98900: Winner=2, Reward=-23.25, EPSILON=0.973, (W=903,D=5,L=0)
2025-01-16 05:22:56,254 - INFO - Episode 3019/98900: Winner=2, Reward=7.80, EPSILON=0.973, (W=903,D=5,L=0)
2025-01-16 05:22:56,452 - INFO - Episode 3020/98900: Winner=2, Reward=-13.45, EPSILON=0.973, (W=903,D=5,L=0)
2025-01-16 05:22:56,697 - INFO - Episode 3021/98900: Winner=2, Reward=30.70, EPSILON=0.973, (W=903,D=5,L=0)
2025-01-16 05:22:56,786 - INFO - Episode 3022/98900: Winner=2, Reward=-0.60, EPSILON=0.973, (W=903,D=5,L=0)
2025-01-16 05:22:56,915 - INFO - Episode 3023/98900: Winner=2, Reward=-5.20, EPSILON=0.973, (W=904,D=5,L=0)
2025-01-16 05:22:57,095 - INFO - Episode 3024/98900: Winner=2, Reward=-0.95, EPSILON=0.973, (W=904,D=5,L=0)
2025-01-16 05:22:57,197 - INFO - Episode 3025/98900: Winner=2, Reward=0.50, EPSILON=0.973, (W=904,D=5,L=0)
2025-01-16 05:22:57,452 - INFO - Episode 3026/98900: Winner=2, Reward=24.25, EPSILON=0.973, (W=904,D=5,L=0)
2025-01-16 05:22:57,610 - INFO - Episode 3027/98900: Winner=2, Reward=-11.45, EPSILON=0.973, (W=905,D=5,L=0)
2025-01-16 05:22:57,678 - INFO - Episode 3028/98900: Winner=2, Reward=0.00, EPSILON=0.973, (W=905,D=5,L=0)
2025-01-16 05:22:57,860 - INFO - Episode 3029/98900: Winner=2, Reward=-16.25, EPSILON=0.973, (W=906,D=5,L=0)
2025-01-16 05:22:57,996 - INFO - Episode 3030/98900: Winner=2, Reward=-12.25, EPSILON=0.973, (W=907,D=5,L=0)
2025-01-16 05:22:58,341 - INFO - Episode 3031/98900: Winner=2, Reward=-19.55, EPSILON=0.973, (W=908,D=5,L=0)
2025-01-16 05:22:58,647 - INFO - Episode 3032/98900: Winner=2, Reward=-24.85, EPSILON=0.973, (W=908,D=5,L=0)
2025-01-16 05:22:58,918 - INFO - Episode 3033/98900: Winner=2, Reward=-7.10, EPSILON=0.973, (W=908,D=5,L=0)
2025-01-16 05:22:59,276 - INFO - Episode 3034/98900: Winner=2, Reward=-78.15, EPSILON=0.973, (W=909,D=5,L=0)
2025-01-16 05:22:59,493 - DEBUG - Q-vals = [0.19177538 0.18820013 0.03649456 0.20030895 0.02213174 0.09081569
 0.27027363], best_act=6, best_val=0.270
2025-01-16 05:22:59,493 - DEBUG - Low Q-value (0.270), using MCTS.
2025-01-16 05:22:59,493 - INFO - Running MCTS with 131 simulations using 6 processes.
2025-01-16 05:23:02,464 - DEBUG - Aggregated action counts: {4: 1, 3: 3, 2: 2, 1: 1}
2025-01-16 05:23:02,464 - DEBUG - Chose best action 3
2025-01-16 05:23:02,647 - DEBUG - Q-vals = [0.14869593 0.09500217 0.32220083 0.28901237 0.05956706 0.01713439
 0.06838718], best_act=2, best_val=0.322
2025-01-16 05:23:02,647 - DEBUG - Low Q-value (0.322), using MCTS.
2025-01-16 05:23:02,647 - INFO - Running MCTS with 131 simulations using 6 processes.
2025-01-16 05:23:05,477 - DEBUG - Aggregated action counts: {4: 2, 1: 3, 5: 1, 2: 1}
2025-01-16 05:23:05,477 - DEBUG - Chose best action 1
2025-01-16 05:23:05,555 - INFO - Episode 3035/98900: Winner=2, Reward=-80.05, EPSILON=0.973, (W=910,D=5,L=0)
2025-01-16 05:23:05,758 - DEBUG - Q-vals = [0.21253994 0.15909065 0.10231259 0.11031885 0.16172594 0.08483176
 0.16918018], best_act=0, best_val=0.213
2025-01-16 05:23:05,758 - DEBUG - Low Q-value (0.213), using MCTS.
2025-01-16 05:23:05,758 - INFO - Episode 3036/98900: Winner=2, Reward=-11.85, EPSILON=0.973, (W=911,D=5,L=0)
2025-01-16 05:23:05,908 - DEBUG - Q-vals = [0.33282143 0.24946626 0.0907812  0.16425534 0.0507389  0.05347257
 0.05846439], best_act=0, best_val=0.333
2025-01-16 05:23:05,908 - DEBUG - Low Q-value (0.333), using MCTS.
2025-01-16 05:23:05,929 - INFO - Episode 3037/98900: Winner=2, Reward=-14.40, EPSILON=0.973, (W=912,D=5,L=0)
2025-01-16 05:23:06,095 - INFO - Episode 3038/98900: Winner=2, Reward=-5.00, EPSILON=0.973, (W=913,D=5,L=0)
2025-01-16 05:23:06,283 - INFO - Episode 3039/98900: Winner=2, Reward=-12.65, EPSILON=0.973, (W=914,D=5,L=0)
2025-01-16 05:23:06,520 - INFO - Episode 3040/98900: Winner=2, Reward=-19.20, EPSILON=0.973, (W=915,D=5,L=0)
2025-01-16 05:23:06,677 - INFO - Episode 3041/98900: Winner=2, Reward=-11.25, EPSILON=0.973, (W=916,D=5,L=0)
2025-01-16 05:23:06,723 - DEBUG - Q-vals = [0.22336735 0.10412787 0.10133613 0.11446273 0.08454076 0.10900411
 0.26316106], best_act=6, best_val=0.263
2025-01-16 05:23:06,723 - DEBUG - Low Q-value (0.263), using MCTS.
2025-01-16 05:23:06,739 - INFO - Running MCTS with 131 simulations using 6 processes.
2025-01-16 05:23:09,452 - DEBUG - Aggregated action counts: {2: 2, 0: 4, 4: 1}
2025-01-16 05:23:09,452 - DEBUG - Chose best action 0
2025-01-16 05:23:09,563 - INFO - Episode 3042/98900: Winner=2, Reward=1.55, EPSILON=0.973, (W=916,D=5,L=0)
2025-01-16 05:23:09,719 - INFO - Episode 3043/98900: Winner=2, Reward=-15.50, EPSILON=0.973, (W=917,D=5,L=0)
2025-01-16 05:23:09,844 - INFO - Episode 3044/98900: Winner=2, Reward=7.30, EPSILON=0.973, (W=917,D=5,L=0)
2025-01-16 05:23:10,125 - INFO - Episode 3045/98900: Winner=2, Reward=2.00, EPSILON=0.973, (W=917,D=5,L=0)
2025-01-16 05:23:10,278 - DEBUG - Q-vals = [0.10582076 0.08294418 0.24973105 0.09278851 0.2117143  0.12711261
 0.12988858], best_act=2, best_val=0.250
2025-01-16 05:23:10,278 - DEBUG - Low Q-value (0.250), using MCTS.
2025-01-16 05:23:10,293 - INFO - Episode 3046/98900: Winner=2, Reward=-9.55, EPSILON=0.973, (W=918,D=5,L=0)
2025-01-16 05:23:10,590 - INFO - Episode 3047/98900: Winner=2, Reward=1.70, EPSILON=0.973, (W=918,D=5,L=0)
2025-01-16 05:23:10,889 - INFO - Episode 3048/98900: Winner=2, Reward=-25.05, EPSILON=0.973, (W=919,D=5,L=0)
2025-01-16 05:23:10,936 - DEBUG - Q-vals = [0.15241656 0.06675069 0.11509348 0.03131901 0.08167077 0.3702361
 0.18251343], best_act=5, best_val=0.370
2025-01-16 05:23:10,936 - DEBUG - Low Q-value (0.370), using MCTS.
2025-01-16 05:23:10,936 - INFO - Running MCTS with 131 simulations using 6 processes.
2025-01-16 05:23:13,937 - DEBUG - Aggregated action counts: {0: 4, 3: 1, 5: 1, 2: 1}
2025-01-16 05:23:13,937 - DEBUG - Chose best action 0
2025-01-16 05:23:14,015 - INFO - Episode 3049/98900: Winner=2, Reward=4.90, EPSILON=0.973, (W=919,D=5,L=0)
2025-01-16 05:23:14,373 - INFO - Episode 3050/98900: Winner=2, Reward=-19.15, EPSILON=0.973, (W=920,D=5,L=0)
2025-01-16 05:23:14,404 - DEBUG - Q-vals = [0.1938349  0.07027759 0.15686253 0.1634566  0.09904643 0.2058773
 0.11064468], best_act=5, best_val=0.206
2025-01-16 05:23:14,404 - DEBUG - Low Q-value (0.206), using MCTS.
2025-01-16 05:23:14,420 - INFO - Running MCTS with 132 simulations using 6 processes.
2025-01-16 05:23:17,157 - DEBUG - Aggregated action counts: {2: 2, 1: 1, 3: 1, 5: 1, 0: 1}
2025-01-16 05:23:17,157 - DEBUG - Chose best action 2
2025-01-16 05:23:17,360 - INFO - Episode 3051/98900: Winner=2, Reward=16.55, EPSILON=0.973, (W=920,D=5,L=0)
2025-01-16 05:23:17,548 - INFO - Episode 3052/98900: Winner=2, Reward=-1.20, EPSILON=0.973, (W=920,D=5,L=0)
2025-01-16 05:23:17,689 - INFO - Episode 3053/98900: Winner=2, Reward=2.80, EPSILON=0.973, (W=921,D=5,L=0)
2025-01-16 05:23:17,961 - INFO - Episode 3054/98900: Winner=2, Reward=-8.65, EPSILON=0.973, (W=921,D=5,L=0)
2025-01-16 05:23:18,101 - INFO - Episode 3055/98900: Winner=2, Reward=-0.65, EPSILON=0.973, (W=921,D=5,L=0)
2025-01-16 05:23:18,292 - INFO - Episode 3056/98900: Winner=2, Reward=-6.55, EPSILON=0.973, (W=921,D=5,L=0)
2025-01-16 05:23:18,497 - DEBUG - Q-vals = [0.10991192 0.05255457 0.23439088 0.0695168  0.24441229 0.08286481
 0.20634878], best_act=4, best_val=0.244
2025-01-16 05:23:18,497 - DEBUG - Low Q-value (0.244), using MCTS.
2025-01-16 05:23:18,513 - INFO - Episode 3057/98900: Winner=2, Reward=-1.55, EPSILON=0.973, (W=922,D=5,L=0)
2025-01-16 05:23:18,675 - INFO - Episode 3058/98900: Winner=2, Reward=0.05, EPSILON=0.973, (W=922,D=5,L=0)
2025-01-16 05:23:19,050 - INFO - Episode 3059/98900: Winner=2, Reward=-12.50, EPSILON=0.973, (W=923,D=5,L=0)
2025-01-16 05:23:19,131 - INFO - Episode 3060/98900: Winner=2, Reward=8.25, EPSILON=0.973, (W=923,D=5,L=0)
2025-01-16 05:23:19,412 - INFO - Episode 3061/98900: Winner=2, Reward=-30.05, EPSILON=0.973, (W=924,D=5,L=0)
2025-01-16 05:23:19,631 - INFO - Episode 3062/98900: Winner=2, Reward=-20.30, EPSILON=0.973, (W=924,D=5,L=0)
2025-01-16 05:23:19,782 - INFO - Episode 3063/98900: Winner=2, Reward=7.55, EPSILON=0.973, (W=924,D=5,L=0)
2025-01-16 05:23:20,032 - INFO - Episode 3064/98900: Winner=2, Reward=10.45, EPSILON=0.973, (W=924,D=5,L=0)
2025-01-16 05:23:20,141 - DEBUG - Q-vals = [0.06230082 0.01796053 0.23812729 0.02789748 0.13638696 0.38396606
 0.13336082], best_act=5, best_val=0.384
2025-01-16 05:23:20,141 - DEBUG - Low Q-value (0.384), using MCTS.
2025-01-16 05:23:20,141 - INFO - Episode 3065/98900: Winner=2, Reward=-9.50, EPSILON=0.973, (W=925,D=5,L=0)
2025-01-16 05:23:20,428 - INFO - Episode 3066/98900: Winner=2, Reward=-16.60, EPSILON=0.973, (W=926,D=5,L=0)
2025-01-16 05:23:20,615 - INFO - Episode 3067/98900: Winner=2, Reward=-4.00, EPSILON=0.973, (W=926,D=5,L=0)
2025-01-16 05:23:20,756 - DEBUG - Q-vals = [0.15646474 0.10640469 0.10809692 0.13684058 0.17259693 0.16546455
 0.15413155], best_act=4, best_val=0.173
2025-01-16 05:23:20,756 - DEBUG - Low Q-value (0.173), using MCTS.
2025-01-16 05:23:20,756 - INFO - Running MCTS with 132 simulations using 6 processes.
2025-01-16 05:23:23,505 - DEBUG - Aggregated action counts: {1: 3, 2: 1, 0: 1, 3: 1}
2025-01-16 05:23:23,506 - DEBUG - Chose best action 1
2025-01-16 05:23:23,594 - INFO - Episode 3068/98900: Winner=2, Reward=-13.65, EPSILON=0.973, (W=927,D=5,L=0)
2025-01-16 05:23:23,715 - INFO - Episode 3069/98900: Winner=2, Reward=9.75, EPSILON=0.973, (W=927,D=5,L=0)
2025-01-16 05:23:23,948 - INFO - Episode 3070/98900: Winner=2, Reward=-30.55, EPSILON=0.973, (W=928,D=5,L=0)
2025-01-16 05:23:24,245 - INFO - Episode 3071/98900: Winner=2, Reward=-43.15, EPSILON=0.973, (W=929,D=5,L=0)
2025-01-16 05:23:24,430 - INFO - Episode 3072/98900: Winner=2, Reward=-6.35, EPSILON=0.973, (W=929,D=5,L=0)
2025-01-16 05:23:24,699 - INFO - Episode 3073/98900: Winner=2, Reward=-5.45, EPSILON=0.973, (W=929,D=5,L=0)
2025-01-16 05:23:24,921 - DEBUG - Q-vals = [0.10251462 0.10523111 0.2151408  0.2919891  0.19739757 0.0387261
 0.04900062], best_act=3, best_val=0.292
2025-01-16 05:23:24,921 - DEBUG - Low Q-value (0.292), using MCTS.
2025-01-16 05:23:24,945 - INFO - Episode 3074/98900: Winner=2, Reward=-6.95, EPSILON=0.973, (W=930,D=5,L=0)
2025-01-16 05:23:25,266 - INFO - Episode 3075/98900: Winner=2, Reward=-8.70, EPSILON=0.973, (W=931,D=5,L=0)
2025-01-16 05:23:25,506 - INFO - Episode 3076/98900: Winner=2, Reward=-14.55, EPSILON=0.973, (W=931,D=5,L=0)
2025-01-16 05:23:25,740 - DEBUG - Q-vals = [0.10348073 0.08382907 0.2290445  0.21716002 0.12109412 0.12094778
 0.12444386], best_act=2, best_val=0.229
2025-01-16 05:23:25,740 - DEBUG - Low Q-value (0.229), using MCTS.
2025-01-16 05:23:25,751 - INFO - Episode 3077/98900: Winner=2, Reward=-20.35, EPSILON=0.973, (W=932,D=5,L=0)
2025-01-16 05:23:25,884 - DEBUG - Q-vals = [0.23241556 0.14265707 0.09444954 0.09872419 0.09667823 0.22171454
 0.11336085], best_act=0, best_val=0.232
2025-01-16 05:23:25,884 - DEBUG - Low Q-value (0.232), using MCTS.
2025-01-16 05:23:25,896 - INFO - Episode 3078/98900: Winner=2, Reward=-11.95, EPSILON=0.973, (W=933,D=5,L=0)
2025-01-16 05:23:26,147 - INFO - Episode 3079/98900: Winner=2, Reward=3.35, EPSILON=0.973, (W=933,D=5,L=0)
2025-01-16 05:23:26,236 - DEBUG - Q-vals = [0.1743535  0.11197717 0.11342923 0.11509241 0.14777474 0.16243471
 0.17493823], best_act=6, best_val=0.175
2025-01-16 05:23:26,236 - DEBUG - Low Q-value (0.175), using MCTS.
2025-01-16 05:23:26,237 - INFO - Running MCTS with 133 simulations using 6 processes.
2025-01-16 05:23:29,156 - DEBUG - Aggregated action counts: {0: 1, 6: 2, 4: 1, 3: 1, 2: 2}
2025-01-16 05:23:29,156 - DEBUG - Chose best action 6
2025-01-16 05:23:29,328 - INFO - Episode 3080/98900: Winner=2, Reward=0.50, EPSILON=0.973, (W=933,D=5,L=0)
2025-01-16 05:23:29,469 - INFO - Episode 3081/98900: Winner=2, Reward=-7.15, EPSILON=0.973, (W=934,D=5,L=0)
2025-01-16 05:23:29,579 - INFO - Episode 3082/98900: Winner=2, Reward=0.00, EPSILON=0.973, (W=934,D=5,L=0)
2025-01-16 05:23:29,936 - INFO - Episode 3083/98900: Winner=2, Reward=-20.55, EPSILON=0.973, (W=935,D=5,L=0)
2025-01-16 05:23:30,156 - INFO - Episode 3084/98900: Winner=2, Reward=-16.30, EPSILON=0.973, (W=936,D=5,L=0)
2025-01-16 05:23:30,282 - DEBUG - Q-vals = [0.17631042 0.09170574 0.13579676 0.1472498  0.13621211 0.1234351
 0.18929008], best_act=6, best_val=0.189
2025-01-16 05:23:30,282 - DEBUG - Low Q-value (0.189), using MCTS.
2025-01-16 05:23:30,282 - INFO - Episode 3085/98900: Winner=2, Reward=-4.00, EPSILON=0.973, (W=937,D=5,L=0)
2025-01-16 05:23:30,645 - INFO - Episode 3086/98900: Winner=2, Reward=-58.55, EPSILON=0.973, (W=937,D=5,L=0)
2025-01-16 05:23:30,865 - INFO - Episode 3087/98900: Winner=2, Reward=-15.80, EPSILON=0.973, (W=938,D=5,L=0)
2025-01-16 05:23:31,090 - INFO - Episode 3088/98900: Winner=2, Reward=29.55, EPSILON=0.973, (W=938,D=5,L=0)
2025-01-16 05:23:31,211 - DEBUG - Q-vals = [0.17129007 0.10605954 0.1542563  0.15607849 0.1007425  0.11484934
 0.1967238 ], best_act=6, best_val=0.197
2025-01-16 05:23:31,211 - DEBUG - Low Q-value (0.197), using MCTS.
2025-01-16 05:23:31,211 - INFO - Running MCTS with 133 simulations using 6 processes.
2025-01-16 05:23:34,408 - DEBUG - Aggregated action counts: {0: 1, 4: 2, 3: 2, 6: 1, 1: 1}
2025-01-16 05:23:34,408 - DEBUG - Chose best action 4
2025-01-16 05:23:34,643 - INFO - Episode 3089/98900: Winner=2, Reward=-47.65, EPSILON=0.973, (W=938,D=5,L=0)
2025-01-16 05:23:34,744 - DEBUG - Q-vals = [0.22236006 0.12570654 0.11412374 0.11568785 0.11579906 0.14335267
 0.16297014], best_act=0, best_val=0.222
2025-01-16 05:23:34,744 - DEBUG - Low Q-value (0.222), using MCTS.
2025-01-16 05:23:34,745 - INFO - Running MCTS with 133 simulations using 6 processes.
2025-01-16 05:23:37,810 - DEBUG - Aggregated action counts: {4: 2, 2: 2, 5: 1, 0: 2}
2025-01-16 05:23:37,810 - DEBUG - Chose best action 4
2025-01-16 05:23:38,072 - INFO - Episode 3090/98900: Winner=2, Reward=-57.80, EPSILON=0.973, (W=939,D=5,L=0)
2025-01-16 05:23:38,258 - INFO - Episode 3091/98900: Winner=2, Reward=-1.90, EPSILON=0.973, (W=939,D=5,L=0)
2025-01-16 05:23:38,425 - DEBUG - Q-vals = [0.16916026 0.10100385 0.11161937 0.17638743 0.1315892  0.11350089
 0.19673902], best_act=6, best_val=0.197
2025-01-16 05:23:38,425 - DEBUG - Low Q-value (0.197), using MCTS.
2025-01-16 05:23:38,443 - INFO - Episode 3092/98900: Winner=2, Reward=-7.45, EPSILON=0.973, (W=940,D=5,L=0)
2025-01-16 05:23:38,459 - DEBUG - Q-vals = [0.27912098 0.0690642  0.07342611 0.1987788  0.01073795 0.05572382
 0.3131482 ], best_act=6, best_val=0.313
2025-01-16 05:23:38,459 - DEBUG - Low Q-value (0.313), using MCTS.
2025-01-16 05:23:38,459 - INFO - Running MCTS with 133 simulations using 6 processes.
2025-01-16 05:23:41,482 - DEBUG - Aggregated action counts: {2: 1, 0: 1, 5: 2, 3: 1, 4: 1, 1: 1}
2025-01-16 05:23:41,482 - DEBUG - Chose best action 5
2025-01-16 05:23:41,600 - INFO - Episode 3093/98900: Winner=2, Reward=-4.15, EPSILON=0.973, (W=940,D=5,L=0)
2025-01-16 05:23:41,905 - INFO - Episode 3094/98900: Winner=2, Reward=-7.15, EPSILON=0.973, (W=941,D=5,L=0)
2025-01-16 05:23:41,952 - DEBUG - Q-vals = [0.30041096 0.07464759 0.06040734 0.23803419 0.09863595 0.10672063
 0.12114329], best_act=0, best_val=0.300
2025-01-16 05:23:41,952 - DEBUG - Low Q-value (0.300), using MCTS.
2025-01-16 05:23:41,952 - INFO - Running MCTS with 133 simulations using 6 processes.
2025-01-16 05:23:44,884 - DEBUG - Aggregated action counts: {3: 1, 4: 1, 0: 2, 1: 1, 2: 1, 5: 1}
2025-01-16 05:23:44,884 - DEBUG - Chose best action 0
2025-01-16 05:23:44,915 - DEBUG - Q-vals = [0.37543845 0.12328319 0.03265164 0.07185833 0.13708985 0.13491876
 0.12475981], best_act=0, best_val=0.375
2025-01-16 05:23:44,915 - DEBUG - Low Q-value (0.375), using MCTS.
2025-01-16 05:23:44,915 - INFO - Running MCTS with 133 simulations using 6 processes.
2025-01-16 05:23:47,900 - DEBUG - Aggregated action counts: {3: 1, 0: 2, 4: 1, 1: 3}
2025-01-16 05:23:47,900 - DEBUG - Chose best action 1
2025-01-16 05:23:47,994 - DEBUG - Q-vals = [0.11305997 0.07187406 0.1806657  0.11020883 0.21600594 0.12662527
 0.18156022], best_act=4, best_val=0.216
2025-01-16 05:23:47,994 - DEBUG - Low Q-value (0.216), using MCTS.
2025-01-16 05:23:47,994 - INFO - Running MCTS with 133 simulations using 6 processes.
2025-01-16 05:23:50,930 - DEBUG - Aggregated action counts: {4: 2, 2: 2, 0: 2, 6: 1}
2025-01-16 05:23:50,930 - DEBUG - Chose best action 4
2025-01-16 05:23:51,055 - INFO - Episode 3095/98900: Winner=2, Reward=-28.60, EPSILON=0.973, (W=942,D=5,L=0)
2025-01-16 05:23:51,196 - INFO - Episode 3096/98900: Winner=2, Reward=9.20, EPSILON=0.973, (W=942,D=5,L=0)
2025-01-16 05:23:51,399 - INFO - Episode 3097/98900: Winner=2, Reward=18.15, EPSILON=0.973, (W=942,D=5,L=0)
2025-01-16 05:23:51,665 - INFO - Episode 3098/98900: Winner=2, Reward=34.50, EPSILON=0.973, (W=942,D=5,L=0)
2025-01-16 05:23:51,711 - DEBUG - Q-vals = [0.15357164 0.03075972 0.1568593  0.03526775 0.3385338  0.15203288
 0.13297491], best_act=4, best_val=0.339
2025-01-16 05:23:51,711 - DEBUG - Low Q-value (0.339), using MCTS.
2025-01-16 05:23:51,711 - INFO - Running MCTS with 133 simulations using 6 processes.
2025-01-16 05:23:54,696 - DEBUG - Aggregated action counts: {5: 4, 6: 1, 2: 1, 4: 1}
2025-01-16 05:23:54,696 - DEBUG - Chose best action 5
2025-01-16 05:23:54,946 - INFO - Episode 3099/98900: Winner=2, Reward=-28.90, EPSILON=0.972, (W=943,D=5,L=0)
2025-01-16 05:23:55,087 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3100.
2025-01-16 05:23:55,087 - INFO - Models saved at episode 3100
2025-01-16 05:23:55,103 - INFO - Target networks updated
2025-01-16 05:23:55,150 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3100.
2025-01-16 05:23:55,150 - INFO - Episode 3100/98900: Winner=2, Reward=3.55, EPSILON=0.972, (W=943,D=5,L=0)
2025-01-16 05:23:55,290 - INFO - Episode 3101/98900: Winner=2, Reward=-0.15, EPSILON=0.972, (W=943,D=5,L=0)
2025-01-16 05:23:55,594 - INFO - Episode 3102/98900: Winner=2, Reward=-29.20, EPSILON=0.972, (W=944,D=5,L=0)
2025-01-16 05:23:55,687 - DEBUG - Q-vals = [0.16617861 0.10658027 0.12058058 0.15865739 0.12917699 0.13214107
 0.18668504], best_act=6, best_val=0.187
2025-01-16 05:23:55,687 - DEBUG - Low Q-value (0.187), using MCTS.
2025-01-16 05:23:55,703 - INFO - Running MCTS with 134 simulations using 6 processes.
2025-01-16 05:23:58,695 - DEBUG - Aggregated action counts: {2: 3, 5: 1, 3: 1, 0: 2}
2025-01-16 05:23:58,696 - DEBUG - Chose best action 2
2025-01-16 05:23:59,020 - INFO - Episode 3103/98900: Winner=2, Reward=-70.10, EPSILON=0.972, (W=944,D=5,L=0)
2025-01-16 05:23:59,247 - INFO - Episode 3104/98900: Winner=2, Reward=-5.95, EPSILON=0.972, (W=944,D=5,L=0)
2025-01-16 05:23:59,530 - INFO - Episode 3105/98900: Winner=2, Reward=-27.80, EPSILON=0.972, (W=945,D=5,L=0)
2025-01-16 05:23:59,702 - DEBUG - Q-vals = [0.10238558 0.05169781 0.08922873 0.02579949 0.2752709  0.20643477
 0.24918272], best_act=4, best_val=0.275
2025-01-16 05:23:59,702 - DEBUG - Low Q-value (0.275), using MCTS.
2025-01-16 05:23:59,702 - INFO - Running MCTS with 134 simulations using 6 processes.
2025-01-16 05:24:02,624 - DEBUG - Aggregated action counts: {3: 2, 4: 3, 5: 1, 0: 1}
2025-01-16 05:24:02,624 - DEBUG - Chose best action 4
2025-01-16 05:24:02,671 - INFO - Episode 3106/98900: Winner=2, Reward=-7.10, EPSILON=0.972, (W=945,D=5,L=0)
2025-01-16 05:24:02,811 - DEBUG - Q-vals = [0.24693628 0.15759988 0.06387225 0.14444122 0.15995978 0.12992638
 0.09726416], best_act=0, best_val=0.247
2025-01-16 05:24:02,811 - DEBUG - Low Q-value (0.247), using MCTS.
2025-01-16 05:24:02,811 - INFO - Running MCTS with 134 simulations using 6 processes.
2025-01-16 05:24:05,698 - DEBUG - Aggregated action counts: {1: 1, 4: 2, 0: 4}
2025-01-16 05:24:05,698 - DEBUG - Chose best action 0
2025-01-16 05:24:05,870 - INFO - Episode 3107/98900: Winner=2, Reward=-23.20, EPSILON=0.972, (W=945,D=5,L=0)
2025-01-16 05:24:06,151 - INFO - Episode 3108/98900: Winner=2, Reward=-12.95, EPSILON=0.972, (W=946,D=5,L=0)
2025-01-16 05:24:06,385 - INFO - Episode 3109/98900: Winner=2, Reward=-26.55, EPSILON=0.972, (W=947,D=5,L=0)
2025-01-16 05:24:06,729 - INFO - Episode 3110/98900: Winner=2, Reward=-46.90, EPSILON=0.972, (W=948,D=5,L=0)
2025-01-16 05:24:07,010 - INFO - Episode 3111/98900: Winner=2, Reward=5.45, EPSILON=0.972, (W=948,D=5,L=0)
2025-01-16 05:24:07,073 - INFO - Episode 3112/98900: Winner=2, Reward=1.05, EPSILON=0.972, (W=948,D=5,L=0)
2025-01-16 05:24:07,323 - INFO - Episode 3113/98900: Winner=2, Reward=-1.20, EPSILON=0.972, (W=948,D=5,L=0)
2025-01-16 05:24:07,464 - INFO - Episode 3114/98900: Winner=2, Reward=-11.40, EPSILON=0.972, (W=949,D=5,L=0)
2025-01-16 05:24:07,526 - DEBUG - Q-vals = [0.1784708  0.09322383 0.09843599 0.19032504 0.13028704 0.1752956
 0.13396168], best_act=3, best_val=0.190
2025-01-16 05:24:07,526 - DEBUG - Low Q-value (0.190), using MCTS.
2025-01-16 05:24:07,526 - INFO - Running MCTS with 134 simulations using 6 processes.
2025-01-16 05:24:10,510 - DEBUG - Aggregated action counts: {4: 1, 0: 3, 3: 2, 1: 1}
2025-01-16 05:24:10,510 - DEBUG - Chose best action 0
2025-01-16 05:24:10,729 - INFO - Episode 3115/98900: Winner=2, Reward=-6.60, EPSILON=0.972, (W=949,D=5,L=0)
2025-01-16 05:24:10,792 - DEBUG - Q-vals = [0.1482274  0.06277859 0.14172322 0.08496628 0.21289591 0.13389088
 0.21551767], best_act=6, best_val=0.216
2025-01-16 05:24:10,792 - DEBUG - Low Q-value (0.216), using MCTS.
2025-01-16 05:24:10,792 - INFO - Running MCTS with 134 simulations using 6 processes.
2025-01-16 05:24:13,791 - DEBUG - Aggregated action counts: {2: 2, 0: 3, 5: 1, 4: 1}
2025-01-16 05:24:13,791 - DEBUG - Chose best action 0
2025-01-16 05:24:14,275 - INFO - Episode 3116/98900: Winner=2, Reward=-36.15, EPSILON=0.972, (W=949,D=5,L=0)
2025-01-16 05:24:14,551 - INFO - Episode 3117/98900: Winner=2, Reward=-5.60, EPSILON=0.972, (W=950,D=5,L=0)
2025-01-16 05:24:14,740 - DEBUG - Q-vals = [0.16623394 0.09631247 0.04704    0.47023654 0.02148477 0.04911669
 0.14957568], best_act=3, best_val=0.470
2025-01-16 05:24:14,740 - DEBUG - Low Q-value (0.470), using MCTS.
2025-01-16 05:24:14,751 - INFO - Episode 3118/98900: Winner=2, Reward=-8.25, EPSILON=0.972, (W=951,D=5,L=0)
2025-01-16 05:24:14,842 - DEBUG - Q-vals = [0.15895684 0.11167155 0.12878163 0.13287516 0.12080338 0.14801648
 0.19889498], best_act=6, best_val=0.199
2025-01-16 05:24:14,842 - DEBUG - Low Q-value (0.199), using MCTS.
2025-01-16 05:24:14,842 - INFO - Running MCTS with 134 simulations using 6 processes.
2025-01-16 05:24:18,529 - DEBUG - Aggregated action counts: {1: 1, 2: 1, 5: 3, 3: 1, 0: 1}
2025-01-16 05:24:18,529 - DEBUG - Chose best action 5
2025-01-16 05:24:18,855 - INFO - Episode 3119/98900: Winner=2, Reward=-18.35, EPSILON=0.972, (W=952,D=5,L=0)
2025-01-16 05:24:19,262 - INFO - Episode 3120/98900: Winner=2, Reward=-73.00, EPSILON=0.972, (W=953,D=5,L=0)
2025-01-16 05:24:19,444 - INFO - Episode 3121/98900: Winner=2, Reward=-20.50, EPSILON=0.972, (W=954,D=5,L=0)
2025-01-16 05:24:19,788 - INFO - Episode 3122/98900: Winner=2, Reward=-47.05, EPSILON=0.972, (W=954,D=5,L=0)
2025-01-16 05:24:20,108 - INFO - Episode 3123/98900: Winner=2, Reward=-29.80, EPSILON=0.972, (W=955,D=5,L=0)
2025-01-16 05:24:20,469 - DEBUG - Q-vals = [0.10425522 0.11649427 0.09874057 0.50772184 0.07577984 0.05246083
 0.04454739], best_act=1, best_val=0.116
2025-01-16 05:24:20,469 - DEBUG - Low Q-value (0.116), using MCTS.
2025-01-16 05:24:20,481 - INFO - Episode 3124/98900: Winner=2, Reward=-42.75, EPSILON=0.972, (W=956,D=5,L=0)
2025-01-16 05:24:20,956 - INFO - Episode 3125/98900: Winner=-1, Reward=-129.35, EPSILON=0.972, (W=956,D=6,L=0)
2025-01-16 05:24:21,082 - DEBUG - Q-vals = [0.15286611 0.09868075 0.10312345 0.21728687 0.15097672 0.09546313
 0.18160297], best_act=3, best_val=0.217
2025-01-16 05:24:21,082 - DEBUG - Low Q-value (0.217), using MCTS.
2025-01-16 05:24:21,083 - INFO - Running MCTS with 135 simulations using 6 processes.
2025-01-16 05:24:24,352 - DEBUG - Aggregated action counts: {6: 2, 3: 1, 0: 3, 4: 1}
2025-01-16 05:24:24,352 - DEBUG - Chose best action 0
2025-01-16 05:24:24,455 - INFO - Episode 3126/98900: Winner=2, Reward=11.55, EPSILON=0.972, (W=956,D=6,L=0)
2025-01-16 05:24:24,546 - INFO - Episode 3127/98900: Winner=2, Reward=9.15, EPSILON=0.972, (W=956,D=6,L=0)
2025-01-16 05:24:24,758 - INFO - Episode 3128/98900: Winner=2, Reward=22.35, EPSILON=0.972, (W=956,D=6,L=0)
2025-01-16 05:24:24,849 - DEBUG - Q-vals = [0.2658316  0.06359513 0.09564852 0.00482873 0.32864067 0.13513692
 0.10631845], best_act=4, best_val=0.329
2025-01-16 05:24:24,849 - DEBUG - Low Q-value (0.329), using MCTS.
2025-01-16 05:24:24,850 - INFO - Running MCTS with 135 simulations using 6 processes.
2025-01-16 05:24:27,813 - DEBUG - Aggregated action counts: {6: 1, 1: 2, 0: 2, 3: 1, 2: 1}
2025-01-16 05:24:27,813 - DEBUG - Chose best action 1
2025-01-16 05:24:27,955 - INFO - Episode 3129/98900: Winner=2, Reward=-20.95, EPSILON=0.972, (W=957,D=6,L=0)
2025-01-16 05:24:28,107 - INFO - Episode 3130/98900: Winner=2, Reward=-16.30, EPSILON=0.972, (W=958,D=6,L=0)
2025-01-16 05:24:28,261 - INFO - Episode 3131/98900: Winner=2, Reward=-4.05, EPSILON=0.972, (W=959,D=6,L=0)
2025-01-16 05:24:28,409 - DEBUG - Q-vals = [0.2505055  0.14880283 0.09595644 0.11128338 0.14750838 0.11229324
 0.13365021], best_act=0, best_val=0.251
2025-01-16 05:24:28,409 - DEBUG - Low Q-value (0.251), using MCTS.
2025-01-16 05:24:28,410 - INFO - Running MCTS with 135 simulations using 6 processes.
2025-01-16 05:24:31,337 - DEBUG - Aggregated action counts: {2: 2, 3: 3, 1: 1, 0: 1}
2025-01-16 05:24:31,337 - DEBUG - Chose best action 3
2025-01-16 05:24:31,450 - INFO - Episode 3132/98900: Winner=2, Reward=-1.80, EPSILON=0.972, (W=960,D=6,L=0)
2025-01-16 05:24:31,608 - INFO - Episode 3133/98900: Winner=2, Reward=-9.30, EPSILON=0.972, (W=961,D=6,L=0)
2025-01-16 05:24:31,946 - INFO - Episode 3134/98900: Winner=2, Reward=-10.30, EPSILON=0.972, (W=962,D=6,L=0)
2025-01-16 05:24:32,147 - INFO - Episode 3135/98900: Winner=2, Reward=-5.70, EPSILON=0.972, (W=963,D=6,L=0)
2025-01-16 05:24:32,233 - INFO - Episode 3136/98900: Winner=2, Reward=8.55, EPSILON=0.972, (W=963,D=6,L=0)
2025-01-16 05:24:32,388 - INFO - Episode 3137/98900: Winner=2, Reward=-2.60, EPSILON=0.972, (W=963,D=6,L=0)
2025-01-16 05:24:32,425 - DEBUG - Q-vals = [1.6991774e-02 2.9931898e-04 2.4071987e-05 9.8091233e-01 1.2602827e-06
 1.7616751e-03 9.5031710e-06], best_act=3, best_val=0.981
2025-01-16 05:24:32,425 - DEBUG - Low Q-value (0.981), using MCTS.
2025-01-16 05:24:32,425 - INFO - Running MCTS with 135 simulations using 6 processes.
2025-01-16 05:24:35,373 - DEBUG - Aggregated action counts: {0: 2, 5: 2, 3: 2, 4: 1}
2025-01-16 05:24:35,373 - DEBUG - Chose best action 0
2025-01-16 05:24:35,404 - INFO - Episode 3138/98900: Winner=2, Reward=7.75, EPSILON=0.972, (W=963,D=6,L=0)
2025-01-16 05:24:35,638 - INFO - Episode 3139/98900: Winner=2, Reward=-30.25, EPSILON=0.972, (W=964,D=6,L=0)
2025-01-16 05:24:35,878 - INFO - Episode 3140/98900: Winner=2, Reward=-8.20, EPSILON=0.972, (W=964,D=6,L=0)
2025-01-16 05:24:35,956 - DEBUG - Q-vals = [0.16364336 0.12755907 0.11241082 0.15292639 0.10424564 0.17645022
 0.16276449], best_act=5, best_val=0.176
2025-01-16 05:24:35,956 - DEBUG - Low Q-value (0.176), using MCTS.
2025-01-16 05:24:35,956 - INFO - Running MCTS with 135 simulations using 6 processes.
2025-01-16 05:24:38,702 - DEBUG - Aggregated action counts: {6: 2, 0: 3, 3: 1, 5: 1}
2025-01-16 05:24:38,702 - DEBUG - Chose best action 0
2025-01-16 05:24:38,912 - INFO - Episode 3141/98900: Winner=2, Reward=11.30, EPSILON=0.972, (W=965,D=6,L=0)
2025-01-16 05:24:38,990 - INFO - Episode 3142/98900: Winner=2, Reward=0.45, EPSILON=0.972, (W=965,D=6,L=0)
2025-01-16 05:24:39,068 - DEBUG - Q-vals = [0.19192041 0.12673187 0.12839508 0.13328215 0.08428444 0.16028169
 0.17510435], best_act=0, best_val=0.192
2025-01-16 05:24:39,068 - DEBUG - Low Q-value (0.192), using MCTS.
2025-01-16 05:24:39,068 - INFO - Running MCTS with 135 simulations using 6 processes.
2025-01-16 05:24:42,177 - DEBUG - Aggregated action counts: {2: 2, 4: 2, 1: 1, 0: 2}
2025-01-16 05:24:42,177 - DEBUG - Chose best action 2
2025-01-16 05:24:42,321 - INFO - Episode 3143/98900: Winner=2, Reward=-5.35, EPSILON=0.972, (W=965,D=6,L=0)
2025-01-16 05:24:42,591 - INFO - Episode 3144/98900: Winner=2, Reward=-9.35, EPSILON=0.972, (W=966,D=6,L=0)
2025-01-16 05:24:42,814 - INFO - Episode 3145/98900: Winner=2, Reward=4.00, EPSILON=0.972, (W=966,D=6,L=0)
2025-01-16 05:24:43,040 - INFO - Episode 3146/98900: Winner=2, Reward=13.05, EPSILON=0.972, (W=966,D=6,L=0)
2025-01-16 05:24:43,072 - DEBUG - Q-vals = [0.17105582 0.06650337 0.09502797 0.23500764 0.1181394  0.16681093
 0.14745487], best_act=3, best_val=0.235
2025-01-16 05:24:43,072 - DEBUG - Low Q-value (0.235), using MCTS.
2025-01-16 05:24:43,072 - INFO - Running MCTS with 135 simulations using 6 processes.
2025-01-16 05:24:46,294 - DEBUG - Aggregated action counts: {1: 1, 6: 1, 3: 2, 5: 1, 2: 1, 0: 1}
2025-01-16 05:24:46,294 - DEBUG - Chose best action 3
2025-01-16 05:24:46,529 - INFO - Episode 3147/98900: Winner=2, Reward=-19.60, EPSILON=0.972, (W=967,D=6,L=0)
2025-01-16 05:24:46,693 - INFO - Episode 3148/98900: Winner=2, Reward=1.25, EPSILON=0.972, (W=967,D=6,L=0)
2025-01-16 05:24:46,951 - INFO - Episode 3149/98900: Winner=2, Reward=-22.35, EPSILON=0.972, (W=968,D=6,L=0)
2025-01-16 05:24:47,127 - INFO - Episode 3150/98900: Winner=2, Reward=8.45, EPSILON=0.972, (W=968,D=6,L=0)
2025-01-16 05:24:47,356 - INFO - Episode 3151/98900: Winner=2, Reward=-10.85, EPSILON=0.972, (W=969,D=6,L=0)
2025-01-16 05:24:47,613 - INFO - Episode 3152/98900: Winner=2, Reward=-34.65, EPSILON=0.972, (W=969,D=6,L=0)
2025-01-16 05:24:47,696 - DEBUG - Q-vals = [0.14996693 0.08134831 0.12166952 0.09781783 0.21046299 0.11358134
 0.22515304], best_act=6, best_val=0.225
2025-01-16 05:24:47,696 - DEBUG - Low Q-value (0.225), using MCTS.
2025-01-16 05:24:47,696 - INFO - Running MCTS with 136 simulations using 6 processes.
2025-01-16 05:24:50,637 - DEBUG - Aggregated action counts: {3: 5, 0: 2}
2025-01-16 05:24:50,637 - DEBUG - Chose best action 3
2025-01-16 05:24:50,712 - INFO - Episode 3153/98900: Winner=2, Reward=-9.05, EPSILON=0.972, (W=970,D=6,L=0)
2025-01-16 05:24:50,943 - INFO - Episode 3154/98900: Winner=2, Reward=-12.25, EPSILON=0.972, (W=970,D=6,L=0)
2025-01-16 05:24:51,149 - INFO - Episode 3155/98900: Winner=2, Reward=8.75, EPSILON=0.972, (W=970,D=6,L=0)
2025-01-16 05:24:51,260 - INFO - Episode 3156/98900: Winner=2, Reward=8.35, EPSILON=0.972, (W=970,D=6,L=0)
2025-01-16 05:24:51,417 - DEBUG - Q-vals = [0.28295237 0.07593003 0.03702255 0.3745887  0.00654291 0.02448654
 0.19847694], best_act=3, best_val=0.375
2025-01-16 05:24:51,418 - DEBUG - Low Q-value (0.375), using MCTS.
2025-01-16 05:24:51,429 - INFO - Episode 3157/98900: Winner=2, Reward=-19.25, EPSILON=0.972, (W=971,D=6,L=0)
2025-01-16 05:24:51,445 - DEBUG - Q-vals = [4.9353339e-02 1.0628821e-03 3.8911309e-04 9.4841677e-01 4.4448934e-05
 3.1765993e-04 4.1573707e-04], best_act=3, best_val=0.948
2025-01-16 05:24:51,445 - DEBUG - Low Q-value (0.948), using MCTS.
2025-01-16 05:24:51,445 - INFO - Running MCTS with 136 simulations using 6 processes.
2025-01-16 05:24:54,420 - DEBUG - Aggregated action counts: {5: 2, 3: 1, 4: 1, 0: 2, 1: 1}
2025-01-16 05:24:54,420 - DEBUG - Chose best action 5
2025-01-16 05:24:54,651 - INFO - Episode 3158/98900: Winner=2, Reward=-4.05, EPSILON=0.972, (W=971,D=6,L=0)
2025-01-16 05:24:55,008 - INFO - Episode 3159/98900: Winner=2, Reward=-31.95, EPSILON=0.972, (W=972,D=6,L=0)
2025-01-16 05:24:55,276 - INFO - Episode 3160/98900: Winner=2, Reward=-25.30, EPSILON=0.972, (W=973,D=6,L=0)
2025-01-16 05:24:55,407 - INFO - Episode 3161/98900: Winner=2, Reward=0.45, EPSILON=0.972, (W=973,D=6,L=0)
2025-01-16 05:24:55,726 - INFO - Episode 3162/98900: Winner=2, Reward=-6.70, EPSILON=0.972, (W=973,D=6,L=0)
2025-01-16 05:24:56,064 - INFO - Episode 3163/98900: Winner=2, Reward=22.20, EPSILON=0.972, (W=973,D=6,L=0)
2025-01-16 05:24:56,159 - DEBUG - Q-vals = [0.172481   0.08812509 0.1169946  0.10359915 0.21461718 0.11330669
 0.19087628], best_act=4, best_val=0.215
2025-01-16 05:24:56,159 - DEBUG - Low Q-value (0.215), using MCTS.
2025-01-16 05:24:56,159 - INFO - Running MCTS with 136 simulations using 6 processes.
2025-01-16 05:24:59,398 - DEBUG - Aggregated action counts: {5: 3, 2: 1, 1: 1, 3: 1, 0: 1}
2025-01-16 05:24:59,398 - DEBUG - Chose best action 5
2025-01-16 05:24:59,512 - INFO - Episode 3164/98900: Winner=2, Reward=-2.90, EPSILON=0.972, (W=973,D=6,L=0)
2025-01-16 05:24:59,682 - DEBUG - Q-vals = [0.3187175  0.12435788 0.09143199 0.1410985  0.02586349 0.11642985
 0.1821008 ], best_act=0, best_val=0.319
2025-01-16 05:24:59,682 - DEBUG - Low Q-value (0.319), using MCTS.
2025-01-16 05:24:59,683 - INFO - Running MCTS with 136 simulations using 6 processes.
2025-01-16 05:25:02,650 - DEBUG - Aggregated action counts: {6: 1, 5: 1, 0: 3, 1: 1, 4: 1}
2025-01-16 05:25:02,650 - DEBUG - Chose best action 0
2025-01-16 05:25:02,755 - INFO - Episode 3165/98900: Winner=2, Reward=-27.30, EPSILON=0.972, (W=974,D=6,L=0)
2025-01-16 05:25:02,921 - INFO - Episode 3166/98900: Winner=2, Reward=2.55, EPSILON=0.972, (W=974,D=6,L=0)
2025-01-16 05:25:03,111 - INFO - Episode 3167/98900: Winner=2, Reward=5.20, EPSILON=0.972, (W=974,D=6,L=0)
2025-01-16 05:25:03,322 - INFO - Episode 3168/98900: Winner=2, Reward=10.30, EPSILON=0.972, (W=974,D=6,L=0)
2025-01-16 05:25:03,567 - INFO - Episode 3169/98900: Winner=2, Reward=-1.00, EPSILON=0.972, (W=974,D=6,L=0)
2025-01-16 05:25:03,703 - INFO - Episode 3170/98900: Winner=2, Reward=14.35, EPSILON=0.972, (W=974,D=6,L=0)
2025-01-16 05:25:03,943 - INFO - Episode 3171/98900: Winner=2, Reward=12.55, EPSILON=0.972, (W=974,D=6,L=0)
2025-01-16 05:25:04,194 - INFO - Episode 3172/98900: Winner=2, Reward=-15.10, EPSILON=0.972, (W=975,D=6,L=0)
2025-01-16 05:25:04,307 - INFO - Episode 3173/98900: Winner=2, Reward=1.90, EPSILON=0.972, (W=975,D=6,L=0)
2025-01-16 05:25:04,604 - INFO - Episode 3174/98900: Winner=2, Reward=-2.20, EPSILON=0.972, (W=975,D=6,L=0)
2025-01-16 05:25:04,845 - INFO - Episode 3175/98900: Winner=2, Reward=-10.45, EPSILON=0.972, (W=976,D=6,L=0)
2025-01-16 05:25:05,073 - INFO - Episode 3176/98900: Winner=2, Reward=-10.75, EPSILON=0.972, (W=977,D=6,L=0)
2025-01-16 05:25:05,290 - INFO - Episode 3177/98900: Winner=2, Reward=-4.55, EPSILON=0.972, (W=977,D=6,L=0)
2025-01-16 05:25:05,525 - INFO - Episode 3178/98900: Winner=2, Reward=-2.95, EPSILON=0.972, (W=978,D=6,L=0)
2025-01-16 05:25:05,631 - DEBUG - Q-vals = [0.14522578 0.08192416 0.21957621 0.15713897 0.07094653 0.11654039
 0.20864797], best_act=2, best_val=0.220
2025-01-16 05:25:05,631 - DEBUG - Low Q-value (0.220), using MCTS.
2025-01-16 05:25:05,632 - INFO - Running MCTS with 137 simulations using 6 processes.
2025-01-16 05:25:08,649 - DEBUG - Aggregated action counts: {3: 3, 2: 1, 0: 2, 5: 1}
2025-01-16 05:25:08,649 - DEBUG - Chose best action 3
2025-01-16 05:25:08,680 - INFO - Episode 3179/98900: Winner=2, Reward=-5.25, EPSILON=0.972, (W=979,D=6,L=0)
2025-01-16 05:25:08,889 - DEBUG - Q-vals = [0.16574366 0.14093526 0.07489685 0.21121447 0.16010895 0.18787308
 0.05922772], best_act=3, best_val=0.211
2025-01-16 05:25:08,889 - DEBUG - Low Q-value (0.211), using MCTS.
2025-01-16 05:25:08,905 - INFO - Episode 3180/98900: Winner=2, Reward=-17.90, EPSILON=0.972, (W=980,D=6,L=0)
2025-01-16 05:25:09,063 - INFO - Episode 3181/98900: Winner=2, Reward=-10.10, EPSILON=0.972, (W=980,D=6,L=0)
2025-01-16 05:25:09,122 - DEBUG - Q-vals = [0.15571195 0.09092235 0.13875249 0.15567951 0.14047797 0.1482197
 0.17023604], best_act=6, best_val=0.170
2025-01-16 05:25:09,122 - DEBUG - Low Q-value (0.170), using MCTS.
2025-01-16 05:25:09,122 - INFO - Running MCTS with 137 simulations using 6 processes.
2025-01-16 05:25:12,308 - DEBUG - Aggregated action counts: {0: 2, 1: 2, 6: 1, 3: 1, 2: 1}
2025-01-16 05:25:12,308 - DEBUG - Chose best action 0
2025-01-16 05:25:12,509 - INFO - Episode 3182/98900: Winner=2, Reward=-19.25, EPSILON=0.972, (W=980,D=6,L=0)
2025-01-16 05:25:12,740 - INFO - Episode 3183/98900: Winner=2, Reward=-29.05, EPSILON=0.972, (W=980,D=6,L=0)
2025-01-16 05:25:13,023 - INFO - Episode 3184/98900: Winner=2, Reward=28.35, EPSILON=0.972, (W=980,D=6,L=0)
2025-01-16 05:25:13,336 - INFO - Episode 3185/98900: Winner=2, Reward=-19.85, EPSILON=0.972, (W=981,D=6,L=0)
2025-01-16 05:25:13,373 - DEBUG - Q-vals = [1.7674153e-03 1.7465551e-04 7.8533172e-05 4.5800437e-03 1.7630593e-04
 9.9298251e-01 2.4048802e-04], best_act=5, best_val=0.993
2025-01-16 05:25:13,373 - DEBUG - Low Q-value (0.993), using MCTS.
2025-01-16 05:25:13,374 - INFO - Running MCTS with 137 simulations using 6 processes.
2025-01-16 05:25:16,395 - DEBUG - Aggregated action counts: {4: 1, 1: 2, 3: 2, 5: 1, 0: 1}
2025-01-16 05:25:16,395 - DEBUG - Chose best action 1
2025-01-16 05:25:16,599 - INFO - Episode 3186/98900: Winner=2, Reward=-1.25, EPSILON=0.972, (W=981,D=6,L=0)
2025-01-16 05:25:16,721 - INFO - Episode 3187/98900: Winner=2, Reward=25.35, EPSILON=0.972, (W=981,D=6,L=0)
2025-01-16 05:25:16,909 - INFO - Episode 3188/98900: Winner=2, Reward=-2.35, EPSILON=0.972, (W=981,D=6,L=0)
2025-01-16 05:25:17,257 - INFO - Episode 3189/98900: Winner=2, Reward=-44.65, EPSILON=0.972, (W=981,D=6,L=0)
2025-01-16 05:25:17,577 - INFO - Episode 3190/98900: Winner=2, Reward=-10.80, EPSILON=0.972, (W=982,D=6,L=0)
2025-01-16 05:25:17,674 - INFO - Episode 3191/98900: Winner=2, Reward=1.60, EPSILON=0.972, (W=982,D=6,L=0)
2025-01-16 05:25:17,907 - INFO - Episode 3192/98900: Winner=2, Reward=7.55, EPSILON=0.972, (W=982,D=6,L=0)
2025-01-16 05:25:18,105 - INFO - Episode 3193/98900: Winner=2, Reward=3.95, EPSILON=0.972, (W=982,D=6,L=0)
2025-01-16 05:25:18,209 - INFO - Episode 3194/98900: Winner=2, Reward=-4.65, EPSILON=0.972, (W=982,D=6,L=0)
2025-01-16 05:25:18,438 - INFO - Episode 3195/98900: Winner=2, Reward=4.50, EPSILON=0.972, (W=982,D=6,L=0)
2025-01-16 05:25:18,593 - INFO - Episode 3196/98900: Winner=2, Reward=3.20, EPSILON=0.972, (W=982,D=6,L=0)
2025-01-16 05:25:18,717 - DEBUG - Q-vals = [0.18343128 0.1338174  0.08481327 0.08673146 0.19793035 0.16701418
 0.14626203], best_act=4, best_val=0.198
2025-01-16 05:25:18,717 - DEBUG - Low Q-value (0.198), using MCTS.
2025-01-16 05:25:18,717 - INFO - Running MCTS with 137 simulations using 6 processes.
2025-01-16 05:25:21,946 - DEBUG - Aggregated action counts: {2: 4, 0: 3}
2025-01-16 05:25:21,947 - DEBUG - Chose best action 2
2025-01-16 05:25:22,231 - INFO - Episode 3197/98900: Winner=2, Reward=-24.00, EPSILON=0.972, (W=982,D=6,L=0)
2025-01-16 05:25:22,491 - INFO - Episode 3198/98900: Winner=2, Reward=-33.65, EPSILON=0.972, (W=983,D=6,L=0)
2025-01-16 05:25:22,630 - INFO - Episode 3199/98900: Winner=2, Reward=-9.25, EPSILON=0.972, (W=984,D=6,L=0)
2025-01-16 05:25:22,806 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3200.
2025-01-16 05:25:22,806 - INFO - Models saved at episode 3200
2025-01-16 05:25:22,808 - INFO - Target networks updated
2025-01-16 05:25:22,894 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3200.
2025-01-16 05:25:22,894 - INFO - Episode 3200/98900: Winner=2, Reward=-7.05, EPSILON=0.972, (W=985,D=6,L=0)
2025-01-16 05:25:23,207 - INFO - Episode 3201/98900: Winner=2, Reward=18.05, EPSILON=0.972, (W=985,D=6,L=0)
2025-01-16 05:25:23,445 - INFO - Episode 3202/98900: Winner=2, Reward=23.15, EPSILON=0.972, (W=985,D=6,L=0)
2025-01-16 05:25:23,503 - DEBUG - Q-vals = [0.24221268 0.06736638 0.05773677 0.2055821  0.10061153 0.16070296
 0.16578762], best_act=0, best_val=0.242
2025-01-16 05:25:23,504 - DEBUG - Low Q-value (0.242), using MCTS.
2025-01-16 05:25:23,504 - INFO - Running MCTS with 138 simulations using 6 processes.
2025-01-16 05:25:26,600 - DEBUG - Aggregated action counts: {0: 5, 5: 1}
2025-01-16 05:25:26,600 - DEBUG - Chose best action 0
2025-01-16 05:25:26,800 - INFO - Episode 3203/98900: Winner=2, Reward=-5.25, EPSILON=0.972, (W=985,D=6,L=0)
2025-01-16 05:25:27,011 - INFO - Episode 3204/98900: Winner=2, Reward=-5.45, EPSILON=0.972, (W=985,D=6,L=0)
2025-01-16 05:25:27,307 - INFO - Episode 3205/98900: Winner=2, Reward=-3.60, EPSILON=0.972, (W=985,D=6,L=0)
2025-01-16 05:25:27,533 - INFO - Episode 3206/98900: Winner=2, Reward=-8.45, EPSILON=0.972, (W=985,D=6,L=0)
2025-01-16 05:25:27,639 - DEBUG - Q-vals = [0.19466105 0.03782428 0.26415768 0.12249317 0.0663548  0.03746998
 0.277039  ], best_act=6, best_val=0.277
2025-01-16 05:25:27,639 - DEBUG - Low Q-value (0.277), using MCTS.
2025-01-16 05:25:27,640 - INFO - Running MCTS with 138 simulations using 6 processes.
2025-01-16 05:25:30,714 - DEBUG - Aggregated action counts: {3: 3, 1: 3}
2025-01-16 05:25:30,714 - DEBUG - Chose best action 3
2025-01-16 05:25:30,777 - INFO - Episode 3207/98900: Winner=2, Reward=-9.25, EPSILON=0.972, (W=986,D=6,L=0)
2025-01-16 05:25:31,121 - INFO - Episode 3208/98900: Winner=2, Reward=-42.05, EPSILON=0.972, (W=986,D=6,L=0)
2025-01-16 05:25:31,433 - INFO - Episode 3209/98900: Winner=2, Reward=-24.55, EPSILON=0.972, (W=986,D=6,L=0)
2025-01-16 05:25:31,824 - INFO - Episode 3210/98900: Winner=2, Reward=-89.85, EPSILON=0.972, (W=987,D=6,L=0)
2025-01-16 05:25:31,949 - INFO - Episode 3211/98900: Winner=2, Reward=-12.05, EPSILON=0.972, (W=988,D=6,L=0)
2025-01-16 05:25:32,308 - INFO - Episode 3212/98900: Winner=2, Reward=-53.50, EPSILON=0.972, (W=989,D=6,L=0)
2025-01-16 05:25:32,620 - INFO - Episode 3213/98900: Winner=2, Reward=-15.05, EPSILON=0.971, (W=990,D=6,L=0)
2025-01-16 05:25:32,964 - INFO - Episode 3214/98900: Winner=2, Reward=-28.65, EPSILON=0.971, (W=990,D=6,L=0)
2025-01-16 05:25:33,183 - INFO - Episode 3215/98900: Winner=2, Reward=8.45, EPSILON=0.971, (W=990,D=6,L=0)
2025-01-16 05:25:33,386 - INFO - Episode 3216/98900: Winner=2, Reward=-8.80, EPSILON=0.971, (W=991,D=6,L=0)
2025-01-16 05:25:33,667 - INFO - Episode 3217/98900: Winner=2, Reward=-1.15, EPSILON=0.971, (W=992,D=6,L=0)
2025-01-16 05:25:33,839 - DEBUG - Q-vals = [0.19960512 0.13974075 0.1329823  0.13694151 0.07291228 0.17235844
 0.1454596 ], best_act=0, best_val=0.200
2025-01-16 05:25:33,839 - DEBUG - Low Q-value (0.200), using MCTS.
2025-01-16 05:25:33,839 - INFO - Running MCTS with 138 simulations using 6 processes.
2025-01-16 05:25:37,190 - DEBUG - Aggregated action counts: {2: 3, 5: 1, 3: 2}
2025-01-16 05:25:37,190 - DEBUG - Chose best action 2
2025-01-16 05:25:37,312 - INFO - Episode 3218/98900: Winner=2, Reward=-22.30, EPSILON=0.971, (W=993,D=6,L=0)
2025-01-16 05:25:37,640 - INFO - Episode 3219/98900: Winner=2, Reward=-34.55, EPSILON=0.971, (W=993,D=6,L=0)
2025-01-16 05:25:37,845 - INFO - Episode 3220/98900: Winner=2, Reward=-0.50, EPSILON=0.971, (W=993,D=6,L=0)
2025-01-16 05:25:38,083 - DEBUG - Q-vals = [0.08485345 0.13088775 0.09646235 0.11876371 0.14808178 0.3286027
 0.0923482 ], best_act=5, best_val=0.329
2025-01-16 05:25:38,083 - DEBUG - Low Q-value (0.329), using MCTS.
2025-01-16 05:25:38,093 - INFO - Episode 3221/98900: Winner=2, Reward=-11.90, EPSILON=0.971, (W=994,D=6,L=0)
2025-01-16 05:25:38,438 - INFO - Episode 3222/98900: Winner=2, Reward=2.15, EPSILON=0.971, (W=994,D=6,L=0)
2025-01-16 05:25:38,611 - INFO - Episode 3223/98900: Winner=2, Reward=9.10, EPSILON=0.971, (W=994,D=6,L=0)
2025-01-16 05:25:38,743 - INFO - Episode 3224/98900: Winner=2, Reward=-2.05, EPSILON=0.971, (W=994,D=6,L=0)
2025-01-16 05:25:38,823 - DEBUG - Q-vals = [0.12436188 0.05222572 0.09896053 0.04789415 0.4060956  0.07951602
 0.19094609], best_act=4, best_val=0.406
2025-01-16 05:25:38,823 - DEBUG - Low Q-value (0.406), using MCTS.
2025-01-16 05:25:38,824 - INFO - Running MCTS with 139 simulations using 6 processes.
2025-01-16 05:25:41,810 - DEBUG - Aggregated action counts: {1: 1, 5: 1, 2: 2, 4: 1, 3: 1, 6: 1}
2025-01-16 05:25:41,810 - DEBUG - Chose best action 2
2025-01-16 05:25:41,877 - DEBUG - Q-vals = [0.12648556 0.08391681 0.32076362 0.19505364 0.12644178 0.03858184
 0.10875676], best_act=2, best_val=0.321
2025-01-16 05:25:41,878 - DEBUG - Low Q-value (0.321), using MCTS.
2025-01-16 05:25:41,878 - INFO - Running MCTS with 139 simulations using 6 processes.
2025-01-16 05:25:44,986 - DEBUG - Aggregated action counts: {0: 1, 5: 1, 1: 3, 6: 2}
2025-01-16 05:25:44,986 - DEBUG - Chose best action 1
2025-01-16 05:25:45,096 - INFO - Episode 3225/98900: Winner=2, Reward=-10.65, EPSILON=0.971, (W=994,D=6,L=0)
2025-01-16 05:25:45,269 - INFO - Episode 3226/98900: Winner=2, Reward=-9.85, EPSILON=0.971, (W=995,D=6,L=0)
2025-01-16 05:25:45,499 - INFO - Episode 3227/98900: Winner=2, Reward=-14.20, EPSILON=0.971, (W=996,D=6,L=0)
2025-01-16 05:25:45,913 - INFO - Episode 3228/98900: Winner=2, Reward=-51.15, EPSILON=0.971, (W=996,D=6,L=0)
2025-01-16 05:25:46,170 - INFO - Episode 3229/98900: Winner=2, Reward=-16.50, EPSILON=0.971, (W=997,D=6,L=0)
2025-01-16 05:25:46,261 - INFO - Episode 3230/98900: Winner=2, Reward=1.05, EPSILON=0.971, (W=997,D=6,L=0)
2025-01-16 05:25:46,465 - INFO - Episode 3231/98900: Winner=2, Reward=0.55, EPSILON=0.971, (W=997,D=6,L=0)
2025-01-16 05:25:46,482 - DEBUG - Q-vals = [5.2940369e-01 1.2344082e-02 1.6753970e-03 4.5238355e-01 1.3943034e-04
 3.1610660e-03 8.9287636e-04], best_act=0, best_val=0.529
2025-01-16 05:25:46,482 - DEBUG - Low Q-value (0.529), using MCTS.
2025-01-16 05:25:46,482 - INFO - Running MCTS with 139 simulations using 6 processes.
2025-01-16 05:25:49,892 - DEBUG - Aggregated action counts: {5: 1, 1: 2, 6: 2, 3: 2}
2025-01-16 05:25:49,892 - DEBUG - Chose best action 1
2025-01-16 05:25:50,158 - DEBUG - Q-vals = [0.12195771 0.05379115 0.09006965 0.20248054 0.2748742  0.10307586
 0.15375082], best_act=4, best_val=0.275
2025-01-16 05:25:50,158 - DEBUG - Low Q-value (0.275), using MCTS.
2025-01-16 05:25:50,173 - INFO - Episode 3232/98900: Winner=2, Reward=0.30, EPSILON=0.971, (W=998,D=6,L=0)
2025-01-16 05:25:50,408 - INFO - Episode 3233/98900: Winner=2, Reward=1.70, EPSILON=0.971, (W=998,D=6,L=0)
2025-01-16 05:25:50,517 - DEBUG - Q-vals = [0.2050928  0.07622084 0.10626683 0.20377368 0.07951291 0.0881631
 0.2409698 ], best_act=6, best_val=0.241
2025-01-16 05:25:50,517 - DEBUG - Low Q-value (0.241), using MCTS.
2025-01-16 05:25:50,517 - INFO - Running MCTS with 139 simulations using 6 processes.
2025-01-16 05:25:53,830 - DEBUG - Aggregated action counts: {3: 3, 2: 3, 4: 1}
2025-01-16 05:25:53,830 - DEBUG - Chose best action 3
2025-01-16 05:25:53,861 - INFO - Episode 3234/98900: Winner=2, Reward=1.40, EPSILON=0.971, (W=998,D=6,L=0)
2025-01-16 05:25:54,127 - INFO - Episode 3235/98900: Winner=2, Reward=-18.10, EPSILON=0.971, (W=999,D=6,L=0)
2025-01-16 05:25:54,361 - INFO - Episode 3236/98900: Winner=2, Reward=19.95, EPSILON=0.971, (W=999,D=6,L=0)
2025-01-16 05:25:54,423 - DEBUG - Q-vals = [0.27060482 0.05571163 0.08422752 0.09050761 0.17896308 0.10877386
 0.21121143], best_act=0, best_val=0.271
2025-01-16 05:25:54,423 - DEBUG - Low Q-value (0.271), using MCTS.
2025-01-16 05:25:54,423 - INFO - Running MCTS with 139 simulations using 6 processes.
2025-01-16 05:25:57,173 - DEBUG - Aggregated action counts: {5: 1, 6: 1, 3: 2, 2: 1, 4: 1, 1: 1}
2025-01-16 05:25:57,173 - DEBUG - Chose best action 3
2025-01-16 05:25:57,298 - INFO - Episode 3237/98900: Winner=2, Reward=17.75, EPSILON=0.971, (W=999,D=6,L=0)
2025-01-16 05:25:57,454 - INFO - Episode 3238/98900: Winner=2, Reward=-1.95, EPSILON=0.971, (W=999,D=6,L=0)
2025-01-16 05:25:57,611 - DEBUG - Q-vals = [0.14720249 0.0741813  0.13720283 0.1734003  0.07802782 0.05481055
 0.33517465], best_act=6, best_val=0.335
2025-01-16 05:25:57,611 - DEBUG - Low Q-value (0.335), using MCTS.
2025-01-16 05:25:57,611 - INFO - Running MCTS with 139 simulations using 6 processes.
2025-01-16 05:26:00,392 - DEBUG - Aggregated action counts: {5: 2, 6: 1, 0: 1, 1: 1, 3: 1, 4: 1}
2025-01-16 05:26:00,392 - DEBUG - Chose best action 5
2025-01-16 05:26:00,408 - INFO - Episode 3239/98900: Winner=2, Reward=28.75, EPSILON=0.971, (W=999,D=6,L=0)
2025-01-16 05:26:00,751 - INFO - Episode 3240/98900: Winner=2, Reward=-15.70, EPSILON=0.971, (W=999,D=6,L=0)
2025-01-16 05:26:01,095 - INFO - Episode 3241/98900: Winner=2, Reward=-8.75, EPSILON=0.971, (W=999,D=6,L=0)
2025-01-16 05:26:01,314 - INFO - Episode 3242/98900: Winner=2, Reward=8.55, EPSILON=0.971, (W=999,D=6,L=0)
2025-01-16 05:26:01,345 - DEBUG - Q-vals = [1.4683552e-04 3.6284928e-06 2.6976813e-02 3.2187086e-03 1.6391149e-03
 9.6373171e-01 4.2831167e-03], best_act=5, best_val=0.964
2025-01-16 05:26:01,345 - DEBUG - Low Q-value (0.964), using MCTS.
2025-01-16 05:26:01,345 - INFO - Running MCTS with 139 simulations using 6 processes.
2025-01-16 05:26:04,388 - DEBUG - Aggregated action counts: {6: 3, 1: 3, 3: 1}
2025-01-16 05:26:04,388 - DEBUG - Chose best action 6
2025-01-16 05:26:04,653 - INFO - Episode 3243/98900: Winner=2, Reward=-0.75, EPSILON=0.971, (W=999,D=6,L=0)
2025-01-16 05:26:04,906 - DEBUG - Q-vals = [0.13896443 0.22571345 0.08614044 0.08297803 0.18523951 0.16770464
 0.11325948], best_act=1, best_val=0.226
2025-01-16 05:26:04,906 - DEBUG - Low Q-value (0.226), using MCTS.
2025-01-16 05:26:04,922 - INFO - Episode 3244/98900: Winner=2, Reward=-20.45, EPSILON=0.971, (W=1000,D=6,L=0)
2025-01-16 05:26:05,295 - DEBUG - Q-vals = [0.08110536 0.03291661 0.25005233 0.5374499  0.03441469 0.00512726
 0.05893392], best_act=3, best_val=0.537
2025-01-16 05:26:05,295 - DEBUG - Low Q-value (0.537), using MCTS.
2025-01-16 05:26:05,311 - INFO - Episode 3245/98900: Winner=2, Reward=-21.30, EPSILON=0.971, (W=1001,D=6,L=0)
2025-01-16 05:26:05,476 - INFO - Episode 3246/98900: Winner=2, Reward=12.50, EPSILON=0.971, (W=1001,D=6,L=0)
2025-01-16 05:26:05,722 - INFO - Episode 3247/98900: Winner=2, Reward=0.85, EPSILON=0.971, (W=1001,D=6,L=0)
2025-01-16 05:26:05,984 - INFO - Episode 3248/98900: Winner=2, Reward=0.90, EPSILON=0.971, (W=1001,D=6,L=0)
2025-01-16 05:26:06,305 - INFO - Episode 3249/98900: Winner=2, Reward=-11.55, EPSILON=0.971, (W=1002,D=6,L=0)
2025-01-16 05:26:06,461 - INFO - Episode 3250/98900: Winner=2, Reward=8.55, EPSILON=0.971, (W=1002,D=6,L=0)
2025-01-16 05:26:06,654 - INFO - Episode 3251/98900: Winner=2, Reward=-8.50, EPSILON=0.971, (W=1003,D=6,L=0)
2025-01-16 05:26:06,938 - INFO - Episode 3252/98900: Winner=2, Reward=-10.80, EPSILON=0.971, (W=1003,D=6,L=0)
2025-01-16 05:26:07,139 - INFO - Episode 3253/98900: Winner=2, Reward=-9.65, EPSILON=0.971, (W=1004,D=6,L=0)
2025-01-16 05:26:07,296 - DEBUG - Q-vals = [0.17556486 0.11540483 0.10779063 0.07842832 0.28676757 0.12342639
 0.11261747], best_act=4, best_val=0.287
2025-01-16 05:26:07,296 - DEBUG - Low Q-value (0.287), using MCTS.
2025-01-16 05:26:07,311 - INFO - Episode 3254/98900: Winner=2, Reward=-4.35, EPSILON=0.971, (W=1005,D=6,L=0)
2025-01-16 05:26:07,343 - DEBUG - Q-vals = [0.28624377 0.08457392 0.05640562 0.12200218 0.15151355 0.12726693
 0.17199405], best_act=0, best_val=0.286
2025-01-16 05:26:07,343 - DEBUG - Low Q-value (0.286), using MCTS.
2025-01-16 05:26:07,343 - INFO - Running MCTS with 140 simulations using 6 processes.
2025-01-16 05:26:10,285 - DEBUG - Aggregated action counts: {1: 3, 3: 1, 2: 1, 6: 1, 0: 1}
2025-01-16 05:26:10,285 - DEBUG - Chose best action 1
2025-01-16 05:26:10,467 - INFO - Episode 3255/98900: Winner=2, Reward=-14.75, EPSILON=0.971, (W=1006,D=6,L=0)
2025-01-16 05:26:10,601 - INFO - Episode 3256/98900: Winner=2, Reward=-0.35, EPSILON=0.971, (W=1006,D=6,L=0)
2025-01-16 05:26:11,001 - INFO - Episode 3257/98900: Winner=2, Reward=-58.10, EPSILON=0.971, (W=1006,D=6,L=0)
2025-01-16 05:26:11,112 - INFO - Episode 3258/98900: Winner=2, Reward=-12.05, EPSILON=0.971, (W=1007,D=6,L=0)
2025-01-16 05:26:11,213 - DEBUG - Q-vals = [0.16285652 0.11050905 0.17524543 0.11927883 0.18505901 0.11453694
 0.13251415], best_act=4, best_val=0.185
2025-01-16 05:26:11,213 - DEBUG - Low Q-value (0.185), using MCTS.
2025-01-16 05:26:11,213 - INFO - Episode 3259/98900: Winner=2, Reward=-9.85, EPSILON=0.971, (W=1008,D=6,L=0)
2025-01-16 05:26:11,444 - INFO - Episode 3260/98900: Winner=2, Reward=5.55, EPSILON=0.971, (W=1009,D=6,L=0)
2025-01-16 05:26:11,555 - INFO - Episode 3261/98900: Winner=2, Reward=0.20, EPSILON=0.971, (W=1009,D=6,L=0)
2025-01-16 05:26:11,995 - INFO - Episode 3262/98900: Winner=2, Reward=-42.15, EPSILON=0.971, (W=1009,D=6,L=0)
2025-01-16 05:26:12,077 - DEBUG - Q-vals = [0.1802348  0.14410089 0.16778608 0.09526527 0.1069199  0.13019006
 0.17550294], best_act=0, best_val=0.180
2025-01-16 05:26:12,077 - DEBUG - Low Q-value (0.180), using MCTS.
2025-01-16 05:26:12,077 - INFO - Running MCTS with 140 simulations using 6 processes.
2025-01-16 05:26:15,260 - DEBUG - Aggregated action counts: {2: 2, 1: 2, 0: 2, 4: 1}
2025-01-16 05:26:15,260 - DEBUG - Chose best action 2
2025-01-16 05:26:15,484 - INFO - Episode 3263/98900: Winner=2, Reward=-41.90, EPSILON=0.971, (W=1010,D=6,L=0)
2025-01-16 05:26:15,925 - INFO - Episode 3264/98900: Winner=2, Reward=-82.80, EPSILON=0.971, (W=1011,D=6,L=0)
2025-01-16 05:26:16,126 - INFO - Episode 3265/98900: Winner=2, Reward=-18.10, EPSILON=0.971, (W=1012,D=6,L=0)
2025-01-16 05:26:16,276 - DEBUG - Q-vals = [0.21501249 0.18118322 0.11748938 0.22056483 0.08838168 0.09567782
 0.08169052], best_act=3, best_val=0.221
2025-01-16 05:26:16,276 - DEBUG - Low Q-value (0.221), using MCTS.
2025-01-16 05:26:16,277 - INFO - Running MCTS with 140 simulations using 6 processes.
2025-01-16 05:26:19,149 - DEBUG - Aggregated action counts: {2: 4, 0: 3}
2025-01-16 05:26:19,149 - DEBUG - Chose best action 2
2025-01-16 05:26:19,180 - INFO - Episode 3266/98900: Winner=2, Reward=0.45, EPSILON=0.971, (W=1012,D=6,L=0)
2025-01-16 05:26:19,356 - DEBUG - Q-vals = [0.18890856 0.20892173 0.08284583 0.10071319 0.15477373 0.20369901
 0.0601379 ], best_act=1, best_val=0.209
2025-01-16 05:26:19,356 - DEBUG - Low Q-value (0.209), using MCTS.
2025-01-16 05:26:19,357 - INFO - Running MCTS with 140 simulations using 6 processes.
2025-01-16 05:26:22,451 - DEBUG - Aggregated action counts: {0: 2, 5: 2, 3: 2, 1: 1}
2025-01-16 05:26:22,451 - DEBUG - Chose best action 0
2025-01-16 05:26:22,451 - INFO - Episode 3267/98900: Winner=2, Reward=-3.25, EPSILON=0.971, (W=1012,D=6,L=0)
2025-01-16 05:26:22,571 - INFO - Episode 3268/98900: Winner=2, Reward=-7.45, EPSILON=0.971, (W=1013,D=6,L=0)
2025-01-16 05:26:22,742 - DEBUG - Q-vals = [0.16651587 0.09519864 0.13015859 0.150737   0.09984546 0.14203982
 0.2155046 ], best_act=6, best_val=0.216
2025-01-16 05:26:22,742 - DEBUG - Low Q-value (0.216), using MCTS.
2025-01-16 05:26:22,753 - INFO - Episode 3269/98900: Winner=2, Reward=-11.25, EPSILON=0.971, (W=1014,D=6,L=0)
2025-01-16 05:26:22,886 - INFO - Episode 3270/98900: Winner=2, Reward=0.85, EPSILON=0.971, (W=1014,D=6,L=0)
2025-01-16 05:26:23,129 - INFO - Episode 3271/98900: Winner=2, Reward=-0.85, EPSILON=0.971, (W=1014,D=6,L=0)
2025-01-16 05:26:23,283 - DEBUG - Q-vals = [0.23460981 0.12852265 0.10071762 0.07206175 0.13630721 0.16124342
 0.16653748], best_act=0, best_val=0.235
2025-01-16 05:26:23,283 - DEBUG - Low Q-value (0.235), using MCTS.
2025-01-16 05:26:23,299 - INFO - Episode 3272/98900: Winner=2, Reward=-10.25, EPSILON=0.971, (W=1015,D=6,L=0)
2025-01-16 05:26:23,393 - INFO - Episode 3273/98900: Winner=2, Reward=8.60, EPSILON=0.971, (W=1015,D=6,L=0)
2025-01-16 05:26:23,455 - INFO - Episode 3274/98900: Winner=2, Reward=8.25, EPSILON=0.971, (W=1015,D=6,L=0)
2025-01-16 05:26:23,752 - INFO - Episode 3275/98900: Winner=2, Reward=25.35, EPSILON=0.971, (W=1015,D=6,L=0)
2025-01-16 05:26:23,924 - INFO - Episode 3276/98900: Winner=2, Reward=6.65, EPSILON=0.971, (W=1015,D=6,L=0)
2025-01-16 05:26:24,080 - INFO - Episode 3277/98900: Winner=2, Reward=-1.65, EPSILON=0.971, (W=1015,D=6,L=0)
2025-01-16 05:26:24,315 - INFO - Episode 3278/98900: Winner=2, Reward=-8.20, EPSILON=0.971, (W=1016,D=6,L=0)
2025-01-16 05:26:24,565 - INFO - Episode 3279/98900: Winner=2, Reward=5.70, EPSILON=0.971, (W=1016,D=6,L=0)
2025-01-16 05:26:24,658 - DEBUG - Q-vals = [0.25843227 0.13028345 0.09758625 0.1187401  0.14172497 0.11668023
 0.13655274], best_act=0, best_val=0.258
2025-01-16 05:26:24,658 - DEBUG - Low Q-value (0.258), using MCTS.
2025-01-16 05:26:24,658 - INFO - Running MCTS with 141 simulations using 6 processes.
2025-01-16 05:26:27,830 - DEBUG - Aggregated action counts: {2: 2, 3: 2, 0: 2, 6: 1}
2025-01-16 05:26:27,830 - DEBUG - Chose best action 2
2025-01-16 05:26:28,033 - INFO - Episode 3280/98900: Winner=2, Reward=-56.35, EPSILON=0.971, (W=1017,D=6,L=0)
2025-01-16 05:26:28,380 - INFO - Episode 3281/98900: Winner=2, Reward=-4.85, EPSILON=0.971, (W=1018,D=6,L=0)
2025-01-16 05:26:28,526 - DEBUG - Q-vals = [0.28779668 0.20010388 0.06347052 0.06313932 0.18818288 0.08049829
 0.11680842], best_act=0, best_val=0.288
2025-01-16 05:26:28,526 - DEBUG - Low Q-value (0.288), using MCTS.
2025-01-16 05:26:28,537 - INFO - Episode 3282/98900: Winner=2, Reward=-9.20, EPSILON=0.971, (W=1019,D=6,L=0)
2025-01-16 05:26:28,819 - INFO - Episode 3283/98900: Winner=2, Reward=3.30, EPSILON=0.971, (W=1019,D=6,L=0)
2025-01-16 05:26:29,131 - INFO - Episode 3284/98900: Winner=2, Reward=-23.50, EPSILON=0.971, (W=1019,D=6,L=0)
2025-01-16 05:26:29,145 - DEBUG - Q-vals = [0.7611123  0.03251394 0.01539147 0.015314   0.12806147 0.02537915
 0.0222277 ], best_act=0, best_val=0.761
2025-01-16 05:26:29,145 - DEBUG - Low Q-value (0.761), using MCTS.
2025-01-16 05:26:29,145 - INFO - Running MCTS with 141 simulations using 6 processes.
2025-01-16 05:26:32,397 - DEBUG - Aggregated action counts: {1: 2, 3: 1, 5: 1, 0: 3}
2025-01-16 05:26:32,397 - DEBUG - Chose best action 0
2025-01-16 05:26:32,917 - DEBUG - Q-vals = [0.13361834 0.05109271 0.18902998 0.52294093 0.03707936 0.00530392
 0.06093481], best_act=3, best_val=0.523
2025-01-16 05:26:32,918 - DEBUG - Low Q-value (0.523), using MCTS.
2025-01-16 05:26:32,928 - INFO - Episode 3285/98900: Winner=2, Reward=-15.85, EPSILON=0.971, (W=1020,D=6,L=0)
2025-01-16 05:26:33,082 - INFO - Episode 3286/98900: Winner=2, Reward=-6.75, EPSILON=0.971, (W=1021,D=6,L=0)
2025-01-16 05:26:33,286 - INFO - Episode 3287/98900: Winner=2, Reward=11.95, EPSILON=0.971, (W=1021,D=6,L=0)
2025-01-16 05:26:33,709 - INFO - Episode 3288/98900: Winner=2, Reward=-70.45, EPSILON=0.971, (W=1022,D=6,L=0)
2025-01-16 05:26:33,874 - INFO - Episode 3289/98900: Winner=2, Reward=-14.40, EPSILON=0.971, (W=1023,D=6,L=0)
2025-01-16 05:26:34,143 - INFO - Episode 3290/98900: Winner=2, Reward=-13.20, EPSILON=0.971, (W=1024,D=6,L=0)
2025-01-16 05:26:34,419 - INFO - Episode 3291/98900: Winner=2, Reward=-0.20, EPSILON=0.971, (W=1024,D=6,L=0)
2025-01-16 05:26:34,458 - DEBUG - Q-vals = [0.2949617  0.01396446 0.02773632 0.06223622 0.382418   0.1106684
 0.10801485], best_act=4, best_val=0.382
2025-01-16 05:26:34,458 - DEBUG - Low Q-value (0.382), using MCTS.
2025-01-16 05:26:34,459 - INFO - Running MCTS with 141 simulations using 6 processes.
2025-01-16 05:26:37,750 - DEBUG - Aggregated action counts: {4: 3, 2: 2, 1: 1, 0: 1}
2025-01-16 05:26:37,750 - DEBUG - Chose best action 4
2025-01-16 05:26:37,782 - DEBUG - Q-vals = [0.11327908 0.00695384 0.07697479 0.02718584 0.00624974 0.6853097
 0.08404701], best_act=5, best_val=0.685
2025-01-16 05:26:37,782 - DEBUG - Low Q-value (0.685), using MCTS.
2025-01-16 05:26:37,782 - INFO - Running MCTS with 141 simulations using 6 processes.
2025-01-16 05:26:40,937 - DEBUG - Aggregated action counts: {1: 3, 3: 1, 5: 1, 4: 1, 0: 1}
2025-01-16 05:26:40,937 - DEBUG - Chose best action 1
2025-01-16 05:26:41,109 - INFO - Episode 3292/98900: Winner=2, Reward=-12.75, EPSILON=0.971, (W=1024,D=6,L=0)
2025-01-16 05:26:41,390 - INFO - Episode 3293/98900: Winner=2, Reward=-22.85, EPSILON=0.971, (W=1024,D=6,L=0)
2025-01-16 05:26:41,484 - INFO - Episode 3294/98900: Winner=2, Reward=8.75, EPSILON=0.971, (W=1024,D=6,L=0)
2025-01-16 05:26:41,640 - DEBUG - Q-vals = [0.16559093 0.1770142  0.13088918 0.10662182 0.23783024 0.07421769
 0.10783605], best_act=4, best_val=0.238
2025-01-16 05:26:41,640 - DEBUG - Low Q-value (0.238), using MCTS.
2025-01-16 05:26:41,656 - INFO - Episode 3295/98900: Winner=2, Reward=-12.00, EPSILON=0.971, (W=1025,D=6,L=0)
2025-01-16 05:26:41,781 - INFO - Episode 3296/98900: Winner=2, Reward=-6.90, EPSILON=0.971, (W=1026,D=6,L=0)
2025-01-16 05:26:41,859 - DEBUG - Q-vals = [0.17675084 0.1075905  0.12437738 0.1538817  0.13438717 0.1458032
 0.15720919], best_act=0, best_val=0.177
2025-01-16 05:26:41,859 - DEBUG - Low Q-value (0.177), using MCTS.
2025-01-16 05:26:41,859 - INFO - Running MCTS with 141 simulations using 6 processes.
2025-01-16 05:26:44,655 - DEBUG - Aggregated action counts: {5: 1, 4: 1, 1: 1, 3: 1, 6: 2, 0: 1}
2025-01-16 05:26:44,655 - DEBUG - Chose best action 6
2025-01-16 05:26:44,780 - INFO - Episode 3297/98900: Winner=2, Reward=11.25, EPSILON=0.971, (W=1026,D=6,L=0)
2025-01-16 05:26:44,937 - INFO - Episode 3298/98900: Winner=2, Reward=-0.55, EPSILON=0.971, (W=1026,D=6,L=0)
2025-01-16 05:26:45,077 - INFO - Episode 3299/98900: Winner=2, Reward=4.85, EPSILON=0.971, (W=1026,D=6,L=0)
2025-01-16 05:26:45,499 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3300.
2025-01-16 05:26:45,499 - INFO - Models saved at episode 3300
2025-01-16 05:26:45,499 - INFO - Target networks updated
2025-01-16 05:26:45,561 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3300.
2025-01-16 05:26:45,561 - INFO - Episode 3300/98900: Winner=2, Reward=-34.85, EPSILON=0.971, (W=1027,D=6,L=0)
2025-01-16 05:26:45,874 - DEBUG - Q-vals = [0.07676617 0.05570363 0.13704562 0.55135924 0.05001667 0.03931946
 0.08978916], best_act=6, best_val=0.090
2025-01-16 05:26:45,874 - DEBUG - Low Q-value (0.090), using MCTS.
2025-01-16 05:26:45,889 - INFO - Episode 3301/98900: Winner=2, Reward=-21.10, EPSILON=0.971, (W=1028,D=6,L=0)
2025-01-16 05:26:46,186 - INFO - Episode 3302/98900: Winner=2, Reward=-6.85, EPSILON=0.971, (W=1028,D=6,L=0)
2025-01-16 05:26:46,545 - INFO - Episode 3303/98900: Winner=2, Reward=-14.90, EPSILON=0.971, (W=1029,D=6,L=0)
2025-01-16 05:26:46,670 - INFO - Episode 3304/98900: Winner=2, Reward=-2.35, EPSILON=0.971, (W=1029,D=6,L=0)
2025-01-16 05:26:46,780 - DEBUG - Q-vals = [0.2369924  0.11799759 0.13638625 0.18674949 0.10393111 0.10943494
 0.10850823], best_act=0, best_val=0.237
2025-01-16 05:26:46,780 - DEBUG - Low Q-value (0.237), using MCTS.
2025-01-16 05:26:46,780 - INFO - Episode 3305/98900: Winner=2, Reward=-7.35, EPSILON=0.971, (W=1030,D=6,L=0)
2025-01-16 05:26:47,045 - INFO - Episode 3306/98900: Winner=2, Reward=-15.30, EPSILON=0.971, (W=1030,D=6,L=0)
2025-01-16 05:26:47,123 - DEBUG - Q-vals = [0.16397871 0.12923029 0.12745592 0.12447236 0.14526738 0.15761586
 0.15197946], best_act=0, best_val=0.164
2025-01-16 05:26:47,123 - DEBUG - Low Q-value (0.164), using MCTS.
2025-01-16 05:26:47,123 - INFO - Running MCTS with 142 simulations using 6 processes.
2025-01-16 05:26:49,920 - DEBUG - Aggregated action counts: {2: 3, 5: 2, 1: 1, 0: 1}
2025-01-16 05:26:49,920 - DEBUG - Chose best action 2
2025-01-16 05:26:50,060 - INFO - Episode 3307/98900: Winner=2, Reward=-2.65, EPSILON=0.971, (W=1030,D=6,L=0)
2025-01-16 05:26:50,310 - INFO - Episode 3308/98900: Winner=2, Reward=-30.60, EPSILON=0.971, (W=1031,D=6,L=0)
2025-01-16 05:26:50,435 - INFO - Episode 3309/98900: Winner=2, Reward=-9.85, EPSILON=0.971, (W=1032,D=6,L=0)
2025-01-16 05:26:50,685 - DEBUG - Q-vals = [0.05919087 0.10521828 0.1311157  0.21283926 0.25872156 0.12388878
 0.10902556], best_act=4, best_val=0.259
2025-01-16 05:26:50,685 - DEBUG - Low Q-value (0.259), using MCTS.
2025-01-16 05:26:50,685 - INFO - Running MCTS with 142 simulations using 6 processes.
2025-01-16 05:26:53,632 - DEBUG - Aggregated action counts: {2: 2, 1: 1, 3: 1, 6: 1, 0: 2}
2025-01-16 05:26:53,632 - DEBUG - Chose best action 2
2025-01-16 05:26:53,694 - DEBUG - Q-vals = [0.03418603 0.02257745 0.39203694 0.37778124 0.0961111  0.03194497
 0.04536236], best_act=3, best_val=0.378
2025-01-16 05:26:53,694 - DEBUG - Low Q-value (0.378), using MCTS.
2025-01-16 05:26:53,694 - INFO - Running MCTS with 142 simulations using 6 processes.
2025-01-16 05:26:56,438 - DEBUG - Aggregated action counts: {1: 2, 6: 1, 0: 3, 3: 1}
2025-01-16 05:26:56,438 - DEBUG - Chose best action 0
2025-01-16 05:26:56,501 - INFO - Episode 3310/98900: Winner=2, Reward=-14.55, EPSILON=0.971, (W=1032,D=6,L=0)
2025-01-16 05:26:56,760 - DEBUG - Q-vals = [0.15591882 0.15453352 0.06705728 0.23421861 0.03317406 0.19207041
 0.16302732], best_act=3, best_val=0.234
2025-01-16 05:26:56,761 - DEBUG - Low Q-value (0.234), using MCTS.
2025-01-16 05:26:56,771 - INFO - Episode 3311/98900: Winner=2, Reward=-35.80, EPSILON=0.971, (W=1033,D=6,L=0)
2025-01-16 05:26:56,978 - INFO - Episode 3312/98900: Winner=2, Reward=0.55, EPSILON=0.971, (W=1034,D=6,L=0)
2025-01-16 05:26:57,086 - INFO - Episode 3313/98900: Winner=2, Reward=15.40, EPSILON=0.971, (W=1034,D=6,L=0)
2025-01-16 05:26:57,250 - INFO - Episode 3314/98900: Winner=2, Reward=-12.65, EPSILON=0.971, (W=1035,D=6,L=0)
2025-01-16 05:26:57,437 - INFO - Episode 3315/98900: Winner=2, Reward=7.65, EPSILON=0.971, (W=1035,D=6,L=0)
2025-01-16 05:26:57,737 - INFO - Episode 3316/98900: Winner=2, Reward=-23.25, EPSILON=0.971, (W=1036,D=6,L=0)
2025-01-16 05:26:57,862 - INFO - Episode 3317/98900: Winner=2, Reward=24.25, EPSILON=0.971, (W=1036,D=6,L=0)
2025-01-16 05:26:58,182 - INFO - Episode 3318/98900: Winner=2, Reward=-25.65, EPSILON=0.971, (W=1036,D=6,L=0)
2025-01-16 05:26:58,404 - INFO - Episode 3319/98900: Winner=2, Reward=-18.85, EPSILON=0.971, (W=1037,D=6,L=0)
2025-01-16 05:26:58,564 - INFO - Episode 3320/98900: Winner=2, Reward=24.70, EPSILON=0.971, (W=1037,D=6,L=0)
2025-01-16 05:26:58,635 - DEBUG - Q-vals = [0.16497569 0.11765569 0.12475228 0.12037996 0.1347628  0.17238347
 0.1650901 ], best_act=5, best_val=0.172
2025-01-16 05:26:58,635 - DEBUG - Low Q-value (0.172), using MCTS.
2025-01-16 05:26:58,637 - INFO - Running MCTS with 142 simulations using 6 processes.
2025-01-16 05:27:01,395 - DEBUG - Aggregated action counts: {5: 1, 2: 2, 0: 3, 1: 1}
2025-01-16 05:27:01,395 - DEBUG - Chose best action 0
2025-01-16 05:27:01,442 - DEBUG - Q-vals = [0.15266483 0.10721258 0.11322891 0.14092398 0.15921828 0.14877443
 0.17797709], best_act=6, best_val=0.178
2025-01-16 05:27:01,442 - DEBUG - Low Q-value (0.178), using MCTS.
2025-01-16 05:27:01,442 - INFO - Running MCTS with 142 simulations using 6 processes.
2025-01-16 05:27:04,131 - DEBUG - Aggregated action counts: {3: 3, 4: 1, 2: 1, 5: 1, 0: 1}
2025-01-16 05:27:04,131 - DEBUG - Chose best action 3
2025-01-16 05:27:04,147 - DEBUG - Q-vals = [0.16432373 0.10826109 0.10362631 0.1307111  0.17507264 0.12830612
 0.18969896], best_act=6, best_val=0.190
2025-01-16 05:27:04,147 - DEBUG - Low Q-value (0.190), using MCTS.
2025-01-16 05:27:04,147 - INFO - Running MCTS with 142 simulations using 6 processes.
2025-01-16 05:27:06,855 - DEBUG - Aggregated action counts: {1: 3, 2: 1, 4: 1, 6: 1, 0: 1}
2025-01-16 05:27:06,855 - DEBUG - Chose best action 1
2025-01-16 05:27:07,121 - INFO - Episode 3321/98900: Winner=2, Reward=-46.10, EPSILON=0.971, (W=1037,D=6,L=0)
2025-01-16 05:27:07,386 - INFO - Episode 3322/98900: Winner=2, Reward=4.40, EPSILON=0.971, (W=1037,D=6,L=0)
2025-01-16 05:27:07,486 - INFO - Episode 3323/98900: Winner=2, Reward=1.55, EPSILON=0.971, (W=1037,D=6,L=0)
2025-01-16 05:27:07,683 - INFO - Episode 3324/98900: Winner=2, Reward=-0.80, EPSILON=0.971, (W=1037,D=6,L=0)
2025-01-16 05:27:07,907 - INFO - Episode 3325/98900: Winner=2, Reward=-16.25, EPSILON=0.971, (W=1038,D=6,L=0)
2025-01-16 05:27:07,922 - DEBUG - Q-vals = [0.40856773 0.03664919 0.06722554 0.15166363 0.01614786 0.00826649
 0.3114795 ], best_act=0, best_val=0.409
2025-01-16 05:27:07,922 - DEBUG - Low Q-value (0.409), using MCTS.
2025-01-16 05:27:07,922 - INFO - Running MCTS with 143 simulations using 6 processes.
2025-01-16 05:27:10,632 - DEBUG - Aggregated action counts: {3: 2, 1: 2, 6: 1, 0: 2}
2025-01-16 05:27:10,632 - DEBUG - Chose best action 3
2025-01-16 05:27:10,679 - DEBUG - Q-vals = [0.15024768 0.09593477 0.13816287 0.10004077 0.1969181  0.12370063
 0.19499514], best_act=4, best_val=0.197
2025-01-16 05:27:10,679 - DEBUG - Low Q-value (0.197), using MCTS.
2025-01-16 05:27:10,679 - INFO - Running MCTS with 143 simulations using 6 processes.
2025-01-16 05:27:13,504 - DEBUG - Aggregated action counts: {2: 1, 0: 2, 1: 2, 3: 2}
2025-01-16 05:27:13,504 - DEBUG - Chose best action 0
2025-01-16 05:27:13,536 - DEBUG - Q-vals = [0.15730867 0.12719586 0.13007396 0.11599255 0.13827077 0.15949307
 0.1716651 ], best_act=6, best_val=0.172
2025-01-16 05:27:13,536 - DEBUG - Low Q-value (0.172), using MCTS.
2025-01-16 05:27:13,536 - INFO - Running MCTS with 143 simulations using 6 processes.
2025-01-16 05:27:16,382 - DEBUG - Aggregated action counts: {6: 2, 4: 1, 5: 1, 1: 2, 0: 1}
2025-01-16 05:27:16,382 - DEBUG - Chose best action 6
2025-01-16 05:27:16,605 - INFO - Episode 3326/98900: Winner=2, Reward=-15.10, EPSILON=0.971, (W=1039,D=6,L=0)
2025-01-16 05:27:16,841 - INFO - Episode 3327/98900: Winner=2, Reward=-7.40, EPSILON=0.971, (W=1039,D=6,L=0)
2025-01-16 05:27:16,963 - DEBUG - Q-vals = [0.19930834 0.13916525 0.09706461 0.06357808 0.21579994 0.11246657
 0.17261723], best_act=4, best_val=0.216
2025-01-16 05:27:16,963 - DEBUG - Low Q-value (0.216), using MCTS.
2025-01-16 05:27:16,974 - INFO - Episode 3328/98900: Winner=2, Reward=-11.95, EPSILON=0.970, (W=1040,D=6,L=0)
2025-01-16 05:27:17,059 - INFO - Episode 3329/98900: Winner=2, Reward=8.30, EPSILON=0.970, (W=1040,D=6,L=0)
2025-01-16 05:27:17,340 - INFO - Episode 3330/98900: Winner=2, Reward=-20.05, EPSILON=0.970, (W=1041,D=6,L=0)
2025-01-16 05:27:17,617 - INFO - Episode 3331/98900: Winner=2, Reward=-26.15, EPSILON=0.970, (W=1042,D=6,L=0)
2025-01-16 05:27:17,806 - INFO - Episode 3332/98900: Winner=2, Reward=6.15, EPSILON=0.970, (W=1042,D=6,L=0)
2025-01-16 05:27:17,996 - INFO - Episode 3333/98900: Winner=2, Reward=-11.40, EPSILON=0.970, (W=1043,D=6,L=0)
2025-01-16 05:27:18,230 - INFO - Episode 3334/98900: Winner=2, Reward=11.45, EPSILON=0.970, (W=1043,D=6,L=0)
2025-01-16 05:27:18,356 - INFO - Episode 3335/98900: Winner=2, Reward=21.10, EPSILON=0.970, (W=1043,D=6,L=0)
2025-01-16 05:27:18,467 - DEBUG - Q-vals = [0.20630953 0.11221176 0.08047876 0.13410729 0.12947115 0.16762972
 0.1697918 ], best_act=0, best_val=0.206
2025-01-16 05:27:18,467 - DEBUG - Low Q-value (0.206), using MCTS.
2025-01-16 05:27:18,479 - INFO - Episode 3336/98900: Winner=2, Reward=-7.85, EPSILON=0.970, (W=1044,D=6,L=0)
2025-01-16 05:27:18,752 - INFO - Episode 3337/98900: Winner=2, Reward=20.65, EPSILON=0.970, (W=1044,D=6,L=0)
2025-01-16 05:27:18,900 - INFO - Episode 3338/98900: Winner=2, Reward=14.45, EPSILON=0.970, (W=1045,D=6,L=0)
2025-01-16 05:27:19,061 - INFO - Episode 3339/98900: Winner=2, Reward=-6.35, EPSILON=0.970, (W=1046,D=6,L=0)
2025-01-16 05:27:19,480 - INFO - Episode 3340/98900: Winner=2, Reward=-48.95, EPSILON=0.970, (W=1047,D=6,L=0)
2025-01-16 05:27:19,636 - INFO - Episode 3341/98900: Winner=2, Reward=-2.50, EPSILON=0.970, (W=1047,D=6,L=0)
2025-01-16 05:27:20,031 - INFO - Episode 3342/98900: Winner=2, Reward=-52.00, EPSILON=0.970, (W=1048,D=6,L=0)
2025-01-16 05:27:20,288 - INFO - Episode 3343/98900: Winner=2, Reward=-14.85, EPSILON=0.970, (W=1049,D=6,L=0)
2025-01-16 05:27:20,468 - INFO - Episode 3344/98900: Winner=2, Reward=12.10, EPSILON=0.970, (W=1049,D=6,L=0)
2025-01-16 05:27:20,806 - INFO - Episode 3345/98900: Winner=2, Reward=-7.20, EPSILON=0.970, (W=1049,D=6,L=0)
2025-01-16 05:27:21,007 - INFO - Episode 3346/98900: Winner=2, Reward=-20.15, EPSILON=0.970, (W=1050,D=6,L=0)
2025-01-16 05:27:21,096 - INFO - Episode 3347/98900: Winner=2, Reward=0.80, EPSILON=0.970, (W=1050,D=6,L=0)
2025-01-16 05:27:21,209 - INFO - Episode 3348/98900: Winner=2, Reward=5.50, EPSILON=0.970, (W=1050,D=6,L=0)
2025-01-16 05:27:21,522 - INFO - Episode 3349/98900: Winner=2, Reward=-8.80, EPSILON=0.970, (W=1050,D=6,L=0)
2025-01-16 05:27:21,580 - DEBUG - Q-vals = [0.43575406 0.14734218 0.05310675 0.06445919 0.10943211 0.12037823
 0.06952753], best_act=0, best_val=0.436
2025-01-16 05:27:21,580 - DEBUG - Low Q-value (0.436), using MCTS.
2025-01-16 05:27:21,580 - INFO - Running MCTS with 144 simulations using 6 processes.
2025-01-16 05:27:24,736 - DEBUG - Aggregated action counts: {2: 6}
2025-01-16 05:27:24,736 - DEBUG - Chose best action 2
2025-01-16 05:27:25,159 - INFO - Episode 3350/98900: Winner=2, Reward=-17.85, EPSILON=0.970, (W=1051,D=6,L=0)
2025-01-16 05:27:25,305 - INFO - Episode 3351/98900: Winner=2, Reward=7.50, EPSILON=0.970, (W=1051,D=6,L=0)
2025-01-16 05:27:25,505 - INFO - Episode 3352/98900: Winner=2, Reward=0.70, EPSILON=0.970, (W=1051,D=6,L=0)
2025-01-16 05:27:25,693 - DEBUG - Q-vals = [0.12136954 0.07760224 0.14137872 0.05128251 0.23949012 0.08987872
 0.2789981 ], best_act=6, best_val=0.279
2025-01-16 05:27:25,693 - DEBUG - Low Q-value (0.279), using MCTS.
2025-01-16 05:27:25,694 - INFO - Running MCTS with 144 simulations using 6 processes.
2025-01-16 05:27:28,552 - DEBUG - Aggregated action counts: {6: 1, 0: 2, 3: 1, 2: 2}
2025-01-16 05:27:28,552 - DEBUG - Chose best action 0
2025-01-16 05:27:28,623 - INFO - Episode 3353/98900: Winner=2, Reward=-23.65, EPSILON=0.970, (W=1052,D=6,L=0)
2025-01-16 05:27:28,986 - INFO - Episode 3354/98900: Winner=2, Reward=-8.45, EPSILON=0.970, (W=1052,D=6,L=0)
2025-01-16 05:27:29,190 - INFO - Episode 3355/98900: Winner=2, Reward=-8.05, EPSILON=0.970, (W=1052,D=6,L=0)
2025-01-16 05:27:29,473 - INFO - Episode 3356/98900: Winner=2, Reward=-23.10, EPSILON=0.970, (W=1053,D=6,L=0)
2025-01-16 05:27:29,847 - INFO - Episode 3357/98900: Winner=2, Reward=-61.65, EPSILON=0.970, (W=1054,D=6,L=0)
2025-01-16 05:27:30,078 - DEBUG - Q-vals = [0.17292364 0.31642273 0.03791108 0.06185029 0.04787759 0.31213382
 0.05088083], best_act=1, best_val=0.316
2025-01-16 05:27:30,078 - DEBUG - Low Q-value (0.316), using MCTS.
2025-01-16 05:27:30,080 - INFO - Running MCTS with 144 simulations using 6 processes.
2025-01-16 05:27:33,016 - DEBUG - Aggregated action counts: {2: 3, 3: 1, 1: 1, 4: 1}
2025-01-16 05:27:33,016 - DEBUG - Chose best action 2
2025-01-16 05:27:33,097 - INFO - Episode 3358/98900: Winner=2, Reward=8.00, EPSILON=0.970, (W=1055,D=6,L=0)
2025-01-16 05:27:33,473 - INFO - Episode 3359/98900: Winner=2, Reward=-12.30, EPSILON=0.970, (W=1055,D=6,L=0)
2025-01-16 05:27:33,616 - INFO - Episode 3360/98900: Winner=2, Reward=-12.55, EPSILON=0.970, (W=1056,D=6,L=0)
2025-01-16 05:27:33,804 - INFO - Episode 3361/98900: Winner=2, Reward=1.20, EPSILON=0.970, (W=1056,D=6,L=0)
2025-01-16 05:27:34,072 - INFO - Episode 3362/98900: Winner=2, Reward=-28.10, EPSILON=0.970, (W=1057,D=6,L=0)
2025-01-16 05:27:34,325 - INFO - Episode 3363/98900: Winner=2, Reward=-9.45, EPSILON=0.970, (W=1057,D=6,L=0)
2025-01-16 05:27:34,648 - INFO - Episode 3364/98900: Winner=2, Reward=-47.30, EPSILON=0.970, (W=1058,D=6,L=0)
2025-01-16 05:27:34,949 - INFO - Episode 3365/98900: Winner=2, Reward=-7.20, EPSILON=0.970, (W=1059,D=6,L=0)
2025-01-16 05:27:35,054 - INFO - Episode 3366/98900: Winner=2, Reward=2.35, EPSILON=0.970, (W=1059,D=6,L=0)
2025-01-16 05:27:35,254 - INFO - Episode 3367/98900: Winner=2, Reward=-1.05, EPSILON=0.970, (W=1059,D=6,L=0)
2025-01-16 05:27:35,597 - INFO - Episode 3368/98900: Winner=2, Reward=-48.85, EPSILON=0.970, (W=1060,D=6,L=0)
2025-01-16 05:27:35,963 - INFO - Episode 3369/98900: Winner=2, Reward=-25.65, EPSILON=0.970, (W=1060,D=6,L=0)
2025-01-16 05:27:36,048 - INFO - Episode 3370/98900: Winner=2, Reward=0.15, EPSILON=0.970, (W=1060,D=6,L=0)
2025-01-16 05:27:36,165 - DEBUG - Q-vals = [0.15366475 0.02081805 0.05409654 0.0089929  0.6230185  0.02124188
 0.11816735], best_act=4, best_val=0.623
2025-01-16 05:27:36,165 - DEBUG - Low Q-value (0.623), using MCTS.
2025-01-16 05:27:36,167 - INFO - Running MCTS with 144 simulations using 6 processes.
2025-01-16 05:27:39,429 - DEBUG - Aggregated action counts: {1: 2, 0: 1, 4: 2, 2: 1}
2025-01-16 05:27:39,429 - DEBUG - Chose best action 1
2025-01-16 05:27:39,601 - INFO - Episode 3371/98900: Winner=2, Reward=11.75, EPSILON=0.970, (W=1060,D=6,L=0)
2025-01-16 05:27:39,647 - DEBUG - Q-vals = [0.22916655 0.14658755 0.09402914 0.03795785 0.09311869 0.26633078
 0.13280942], best_act=5, best_val=0.266
2025-01-16 05:27:39,647 - DEBUG - Low Q-value (0.266), using MCTS.
2025-01-16 05:27:39,647 - INFO - Running MCTS with 144 simulations using 6 processes.
2025-01-16 05:27:42,673 - DEBUG - Aggregated action counts: {1: 2, 0: 1, 6: 1, 3: 2}
2025-01-16 05:27:42,673 - DEBUG - Chose best action 1
2025-01-16 05:27:42,751 - INFO - Episode 3372/98900: Winner=2, Reward=-5.40, EPSILON=0.970, (W=1061,D=6,L=0)
2025-01-16 05:27:42,829 - DEBUG - Q-vals = [0.18603866 0.0833202  0.12570253 0.07678653 0.24740964 0.12610412
 0.1546384 ], best_act=4, best_val=0.247
2025-01-16 05:27:42,829 - DEBUG - Low Q-value (0.247), using MCTS.
2025-01-16 05:27:42,829 - INFO - Running MCTS with 144 simulations using 6 processes.
2025-01-16 05:27:45,720 - DEBUG - Aggregated action counts: {1: 1, 4: 1, 3: 1, 0: 1, 5: 2}
2025-01-16 05:27:45,720 - DEBUG - Chose best action 5
2025-01-16 05:27:45,863 - INFO - Episode 3373/98900: Winner=2, Reward=-7.35, EPSILON=0.970, (W=1062,D=6,L=0)
2025-01-16 05:27:46,016 - INFO - Episode 3374/98900: Winner=2, Reward=-7.95, EPSILON=0.970, (W=1063,D=6,L=0)
2025-01-16 05:27:46,192 - INFO - Episode 3375/98900: Winner=2, Reward=-12.85, EPSILON=0.970, (W=1064,D=6,L=0)
2025-01-16 05:27:46,255 - DEBUG - Q-vals = [0.25969306 0.07576808 0.06601527 0.14603214 0.20327236 0.11481937
 0.13439971], best_act=0, best_val=0.260
2025-01-16 05:27:46,255 - DEBUG - Low Q-value (0.260), using MCTS.
2025-01-16 05:27:46,255 - INFO - Running MCTS with 145 simulations using 6 processes.
2025-01-16 05:27:49,088 - DEBUG - Aggregated action counts: {2: 2, 4: 1, 6: 1, 3: 2, 1: 1}
2025-01-16 05:27:49,088 - DEBUG - Chose best action 2
2025-01-16 05:27:49,255 - INFO - Episode 3376/98900: Winner=2, Reward=-3.50, EPSILON=0.970, (W=1064,D=6,L=0)
2025-01-16 05:27:49,388 - INFO - Episode 3377/98900: Winner=2, Reward=3.85, EPSILON=0.970, (W=1064,D=6,L=0)
2025-01-16 05:27:49,768 - INFO - Episode 3378/98900: Winner=2, Reward=-53.20, EPSILON=0.970, (W=1065,D=6,L=0)
2025-01-16 05:27:49,983 - INFO - Episode 3379/98900: Winner=2, Reward=8.50, EPSILON=0.970, (W=1065,D=6,L=0)
2025-01-16 05:27:50,142 - DEBUG - Q-vals = [0.14040406 0.19352731 0.0779192  0.13940112 0.11868214 0.17244436
 0.15762179], best_act=1, best_val=0.194
2025-01-16 05:27:50,142 - DEBUG - Low Q-value (0.194), using MCTS.
2025-01-16 05:27:50,142 - INFO - Running MCTS with 145 simulations using 6 processes.
2025-01-16 05:27:53,183 - DEBUG - Aggregated action counts: {2: 3, 3: 2, 0: 1, 6: 1}
2025-01-16 05:27:53,183 - DEBUG - Chose best action 2
2025-01-16 05:27:53,292 - DEBUG - Q-vals = [0.11276811 0.1369571  0.11186771 0.2338761  0.26085588 0.06827037
 0.0754047 ], best_act=4, best_val=0.261
2025-01-16 05:27:53,292 - DEBUG - Low Q-value (0.261), using MCTS.
2025-01-16 05:27:53,292 - INFO - Running MCTS with 145 simulations using 6 processes.
2025-01-16 05:27:56,413 - DEBUG - Aggregated action counts: {3: 5, 4: 1, 2: 1}
2025-01-16 05:27:56,413 - DEBUG - Chose best action 3
2025-01-16 05:27:56,480 - INFO - Episode 3380/98900: Winner=2, Reward=6.15, EPSILON=0.970, (W=1065,D=6,L=0)
2025-01-16 05:27:56,794 - INFO - Episode 3381/98900: Winner=2, Reward=-19.90, EPSILON=0.970, (W=1066,D=6,L=0)
2025-01-16 05:27:57,016 - INFO - Episode 3382/98900: Winner=2, Reward=-6.55, EPSILON=0.970, (W=1067,D=6,L=0)
2025-01-16 05:27:57,292 - INFO - Episode 3383/98900: Winner=2, Reward=-0.95, EPSILON=0.970, (W=1068,D=6,L=0)
2025-01-16 05:27:57,587 - INFO - Episode 3384/98900: Winner=2, Reward=-3.70, EPSILON=0.970, (W=1068,D=6,L=0)
2025-01-16 05:27:57,805 - INFO - Episode 3385/98900: Winner=2, Reward=-10.45, EPSILON=0.970, (W=1069,D=6,L=0)
2025-01-16 05:27:58,047 - DEBUG - Q-vals = [0.11036391 0.1220888  0.36851454 0.2185274  0.11406688 0.02162755
 0.04481089], best_act=2, best_val=0.369
2025-01-16 05:27:58,047 - DEBUG - Low Q-value (0.369), using MCTS.
2025-01-16 05:27:58,057 - INFO - Episode 3386/98900: Winner=2, Reward=-42.30, EPSILON=0.970, (W=1070,D=6,L=0)
2025-01-16 05:27:58,174 - INFO - Episode 3387/98900: Winner=2, Reward=-7.65, EPSILON=0.970, (W=1071,D=6,L=0)
2025-01-16 05:27:58,189 - DEBUG - Q-vals = [0.4275129  0.01945117 0.01663275 0.01865338 0.46287104 0.01961144
 0.03526735], best_act=4, best_val=0.463
2025-01-16 05:27:58,189 - DEBUG - Low Q-value (0.463), using MCTS.
2025-01-16 05:27:58,189 - INFO - Running MCTS with 145 simulations using 6 processes.
2025-01-16 05:28:01,458 - DEBUG - Aggregated action counts: {1: 4, 5: 1, 2: 1, 0: 1}
2025-01-16 05:28:01,458 - DEBUG - Chose best action 1
2025-01-16 05:28:01,818 - INFO - Episode 3388/98900: Winner=2, Reward=-13.45, EPSILON=0.970, (W=1071,D=6,L=0)
2025-01-16 05:28:02,069 - INFO - Episode 3389/98900: Winner=2, Reward=-14.45, EPSILON=0.970, (W=1072,D=6,L=0)
2025-01-16 05:28:02,362 - INFO - Episode 3390/98900: Winner=2, Reward=-10.75, EPSILON=0.970, (W=1072,D=6,L=0)
2025-01-16 05:28:02,594 - INFO - Episode 3391/98900: Winner=2, Reward=-16.40, EPSILON=0.970, (W=1073,D=6,L=0)
2025-01-16 05:28:02,632 - DEBUG - Q-vals = [0.22018467 0.09300876 0.1300188  0.05512502 0.2236163  0.15754752
 0.12049894], best_act=4, best_val=0.224
2025-01-16 05:28:02,632 - DEBUG - Low Q-value (0.224), using MCTS.
2025-01-16 05:28:02,633 - INFO - Running MCTS with 145 simulations using 6 processes.
2025-01-16 05:28:05,884 - DEBUG - Aggregated action counts: {0: 2, 3: 3, 4: 1, 2: 1}
2025-01-16 05:28:05,884 - DEBUG - Chose best action 3
2025-01-16 05:28:06,150 - INFO - Episode 3392/98900: Winner=2, Reward=-36.25, EPSILON=0.970, (W=1073,D=6,L=0)
2025-01-16 05:28:06,353 - INFO - Episode 3393/98900: Winner=2, Reward=5.95, EPSILON=0.970, (W=1073,D=6,L=0)
2025-01-16 05:28:06,431 - DEBUG - Q-vals = [0.16507922 0.10100807 0.12795138 0.10510368 0.20292634 0.10732305
 0.19060825], best_act=4, best_val=0.203
2025-01-16 05:28:06,431 - DEBUG - Low Q-value (0.203), using MCTS.
2025-01-16 05:28:06,431 - INFO - Running MCTS with 145 simulations using 6 processes.
2025-01-16 05:28:09,783 - DEBUG - Aggregated action counts: {3: 4, 5: 1, 1: 2}
2025-01-16 05:28:09,783 - DEBUG - Chose best action 3
2025-01-16 05:28:10,032 - INFO - Episode 3394/98900: Winner=2, Reward=-23.05, EPSILON=0.970, (W=1074,D=6,L=0)
2025-01-16 05:28:10,345 - INFO - Episode 3395/98900: Winner=2, Reward=-32.60, EPSILON=0.970, (W=1075,D=6,L=0)
2025-01-16 05:28:10,470 - DEBUG - Q-vals = [0.12091501 0.08212918 0.13915215 0.12470248 0.08996809 0.08057258
 0.36256054], best_act=6, best_val=0.363
2025-01-16 05:28:10,470 - DEBUG - Low Q-value (0.363), using MCTS.
2025-01-16 05:28:10,470 - INFO - Running MCTS with 145 simulations using 6 processes.
2025-01-16 05:28:13,579 - DEBUG - Aggregated action counts: {4: 2, 0: 3, 5: 2}
2025-01-16 05:28:13,579 - DEBUG - Chose best action 0
2025-01-16 05:28:13,673 - INFO - Episode 3396/98900: Winner=2, Reward=2.60, EPSILON=0.970, (W=1075,D=6,L=0)
2025-01-16 05:28:13,985 - INFO - Episode 3397/98900: Winner=2, Reward=-9.25, EPSILON=0.970, (W=1075,D=6,L=0)
2025-01-16 05:28:14,048 - DEBUG - Q-vals = [0.17095384 0.1068967  0.14691123 0.09791635 0.18441445 0.1171822
 0.17572524], best_act=4, best_val=0.184
2025-01-16 05:28:14,048 - DEBUG - Low Q-value (0.184), using MCTS.
2025-01-16 05:28:14,048 - INFO - Running MCTS with 145 simulations using 6 processes.
2025-01-16 05:28:17,235 - DEBUG - Aggregated action counts: {5: 1, 0: 2, 1: 2, 2: 2}
2025-01-16 05:28:17,235 - DEBUG - Chose best action 0
2025-01-16 05:28:17,439 - DEBUG - Q-vals = [0.11112301 0.1636382  0.0697924  0.05026948 0.17045955 0.36124095
 0.07347641], best_act=5, best_val=0.361
2025-01-16 05:28:17,439 - DEBUG - Low Q-value (0.361), using MCTS.
2025-01-16 05:28:17,439 - INFO - Episode 3398/98900: Winner=2, Reward=-16.60, EPSILON=0.970, (W=1076,D=6,L=0)
2025-01-16 05:28:17,564 - INFO - Episode 3399/98900: Winner=2, Reward=7.10, EPSILON=0.970, (W=1076,D=6,L=0)
2025-01-16 05:28:17,923 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3400.
2025-01-16 05:28:17,923 - INFO - Models saved at episode 3400
2025-01-16 05:28:17,923 - INFO - Target networks updated
2025-01-16 05:28:17,985 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3400.
2025-01-16 05:28:17,985 - INFO - Episode 3400/98900: Winner=2, Reward=-8.95, EPSILON=0.970, (W=1077,D=6,L=0)
2025-01-16 05:28:18,157 - INFO - Episode 3401/98900: Winner=2, Reward=6.80, EPSILON=0.970, (W=1077,D=6,L=0)
2025-01-16 05:28:18,313 - INFO - Episode 3402/98900: Winner=2, Reward=3.75, EPSILON=0.970, (W=1078,D=6,L=0)
2025-01-16 05:28:18,517 - INFO - Episode 3403/98900: Winner=2, Reward=11.20, EPSILON=0.970, (W=1078,D=6,L=0)
2025-01-16 05:28:18,688 - INFO - Episode 3404/98900: Winner=2, Reward=-7.50, EPSILON=0.970, (W=1079,D=6,L=0)
2025-01-16 05:28:19,001 - INFO - Episode 3405/98900: Winner=2, Reward=-21.55, EPSILON=0.970, (W=1080,D=6,L=0)
2025-01-16 05:28:19,266 - INFO - Episode 3406/98900: Winner=2, Reward=23.70, EPSILON=0.970, (W=1081,D=6,L=0)
2025-01-16 05:28:19,594 - INFO - Episode 3407/98900: Winner=2, Reward=-44.60, EPSILON=0.970, (W=1082,D=6,L=0)
2025-01-16 05:28:19,610 - DEBUG - Q-vals = [7.01672286e-02 3.01080197e-01 5.44316310e-04 1.17194395e-05
 2.05675997e-06 6.28186405e-01 8.08981076e-06], best_act=5, best_val=0.628
2025-01-16 05:28:19,610 - DEBUG - Low Q-value (0.628), using MCTS.
2025-01-16 05:28:19,610 - INFO - Running MCTS with 146 simulations using 6 processes.
2025-01-16 05:28:22,672 - DEBUG - Aggregated action counts: {6: 1, 2: 2, 0: 3, 5: 1}
2025-01-16 05:28:22,672 - DEBUG - Chose best action 0
2025-01-16 05:28:22,953 - INFO - Episode 3408/98900: Winner=2, Reward=-5.65, EPSILON=0.970, (W=1083,D=6,L=0)
2025-01-16 05:28:23,109 - DEBUG - Q-vals = [0.07455117 0.03502447 0.2760711  0.31887758 0.05395386 0.01759278
 0.22392894], best_act=3, best_val=0.319
2025-01-16 05:28:23,109 - DEBUG - Low Q-value (0.319), using MCTS.
2025-01-16 05:28:23,109 - INFO - Running MCTS with 146 simulations using 6 processes.
2025-01-16 05:28:26,140 - DEBUG - Aggregated action counts: {4: 1, 2: 1, 1: 1, 6: 1, 3: 1, 0: 2}
2025-01-16 05:28:26,140 - DEBUG - Chose best action 0
2025-01-16 05:28:26,155 - INFO - Episode 3409/98900: Winner=2, Reward=16.55, EPSILON=0.970, (W=1083,D=6,L=0)
2025-01-16 05:28:26,327 - DEBUG - Q-vals = [0.1581115  0.21524993 0.05944831 0.05087983 0.18166095 0.20452467
 0.13012485], best_act=1, best_val=0.215
2025-01-16 05:28:26,327 - DEBUG - Low Q-value (0.215), using MCTS.
2025-01-16 05:28:26,327 - INFO - Running MCTS with 146 simulations using 6 processes.
2025-01-16 05:28:29,452 - DEBUG - Aggregated action counts: {3: 3, 1: 1, 4: 1, 2: 1, 0: 1}
2025-01-16 05:28:29,452 - DEBUG - Chose best action 3
2025-01-16 05:28:29,483 - DEBUG - Q-vals = [0.13296212 0.09183162 0.21938187 0.19394217 0.19407058 0.03857977
 0.12923191], best_act=2, best_val=0.219
2025-01-16 05:28:29,483 - DEBUG - Low Q-value (0.219), using MCTS.
2025-01-16 05:28:29,483 - INFO - Running MCTS with 146 simulations using 6 processes.
2025-01-16 05:28:32,560 - DEBUG - Aggregated action counts: {5: 4, 3: 2, 0: 1}
2025-01-16 05:28:32,560 - DEBUG - Chose best action 5
2025-01-16 05:28:32,639 - INFO - Episode 3410/98900: Winner=2, Reward=-25.80, EPSILON=0.970, (W=1083,D=6,L=0)
2025-01-16 05:28:32,982 - INFO - Episode 3411/98900: Winner=2, Reward=-36.45, EPSILON=0.970, (W=1084,D=6,L=0)
2025-01-16 05:28:33,170 - INFO - Episode 3412/98900: Winner=2, Reward=-26.90, EPSILON=0.970, (W=1085,D=6,L=0)
2025-01-16 05:28:33,529 - INFO - Episode 3413/98900: Winner=2, Reward=-71.70, EPSILON=0.970, (W=1086,D=6,L=0)
2025-01-16 05:28:33,732 - INFO - Episode 3414/98900: Winner=2, Reward=12.25, EPSILON=0.970, (W=1086,D=6,L=0)
2025-01-16 05:28:33,904 - INFO - Episode 3415/98900: Winner=2, Reward=-11.70, EPSILON=0.970, (W=1087,D=6,L=0)
2025-01-16 05:28:34,060 - INFO - Episode 3416/98900: Winner=2, Reward=5.85, EPSILON=0.970, (W=1087,D=6,L=0)
2025-01-16 05:28:34,373 - INFO - Episode 3417/98900: Winner=2, Reward=-23.50, EPSILON=0.970, (W=1087,D=6,L=0)
2025-01-16 05:28:34,513 - INFO - Episode 3418/98900: Winner=2, Reward=5.80, EPSILON=0.970, (W=1087,D=6,L=0)
2025-01-16 05:28:34,576 - INFO - Episode 3419/98900: Winner=2, Reward=0.55, EPSILON=0.970, (W=1087,D=6,L=0)
2025-01-16 05:28:34,607 - DEBUG - Q-vals = [0.1853427  0.0928709  0.05876533 0.06806174 0.16632794 0.2910082
 0.13762315], best_act=5, best_val=0.291
2025-01-16 05:28:34,607 - DEBUG - Low Q-value (0.291), using MCTS.
2025-01-16 05:28:34,607 - INFO - Running MCTS with 146 simulations using 6 processes.
2025-01-16 05:28:37,419 - DEBUG - Aggregated action counts: {3: 3, 1: 1, 2: 2, 0: 1}
2025-01-16 05:28:37,419 - DEBUG - Chose best action 3
2025-01-16 05:28:37,684 - INFO - Episode 3420/98900: Winner=2, Reward=-27.65, EPSILON=0.970, (W=1088,D=6,L=0)
2025-01-16 05:28:37,950 - INFO - Episode 3421/98900: Winner=2, Reward=-12.90, EPSILON=0.970, (W=1089,D=6,L=0)
2025-01-16 05:28:38,122 - INFO - Episode 3422/98900: Winner=2, Reward=-12.10, EPSILON=0.970, (W=1090,D=6,L=0)
2025-01-16 05:28:38,403 - INFO - Episode 3423/98900: Winner=2, Reward=-12.25, EPSILON=0.970, (W=1090,D=6,L=0)
2025-01-16 05:28:38,653 - INFO - Episode 3424/98900: Winner=2, Reward=-11.50, EPSILON=0.970, (W=1091,D=6,L=0)
2025-01-16 05:28:38,809 - INFO - Episode 3425/98900: Winner=2, Reward=-14.45, EPSILON=0.970, (W=1092,D=6,L=0)
2025-01-16 05:28:39,012 - INFO - Episode 3426/98900: Winner=2, Reward=-24.45, EPSILON=0.970, (W=1093,D=6,L=0)
2025-01-16 05:28:39,168 - INFO - Episode 3427/98900: Winner=2, Reward=13.20, EPSILON=0.970, (W=1093,D=6,L=0)
2025-01-16 05:28:39,356 - INFO - Episode 3428/98900: Winner=2, Reward=-1.35, EPSILON=0.970, (W=1093,D=6,L=0)
2025-01-16 05:28:39,606 - INFO - Episode 3429/98900: Winner=2, Reward=9.20, EPSILON=0.970, (W=1093,D=6,L=0)
2025-01-16 05:28:39,684 - DEBUG - Q-vals = [0.18483667 0.11970097 0.13634573 0.14809541 0.13257557 0.11534926
 0.1630964 ], best_act=0, best_val=0.185
2025-01-16 05:28:39,684 - DEBUG - Low Q-value (0.185), using MCTS.
2025-01-16 05:28:39,684 - INFO - Running MCTS with 147 simulations using 6 processes.
2025-01-16 05:28:42,512 - DEBUG - Aggregated action counts: {2: 2, 4: 1, 3: 2, 0: 2}
2025-01-16 05:28:42,512 - DEBUG - Chose best action 2
2025-01-16 05:28:42,543 - INFO - Episode 3430/98900: Winner=2, Reward=2.75, EPSILON=0.970, (W=1093,D=6,L=0)
2025-01-16 05:28:42,793 - DEBUG - Q-vals = [0.12976174 0.05988252 0.38071287 0.3517092  0.02911946 0.03979658
 0.00901771], best_act=2, best_val=0.381
2025-01-16 05:28:42,793 - DEBUG - Low Q-value (0.381), using MCTS.
2025-01-16 05:28:42,793 - INFO - Running MCTS with 147 simulations using 6 processes.
2025-01-16 05:28:45,589 - DEBUG - Aggregated action counts: {0: 2, 1: 2, 4: 1, 3: 1, 2: 1}
2025-01-16 05:28:45,589 - DEBUG - Chose best action 0
2025-01-16 05:28:45,684 - INFO - Episode 3431/98900: Winner=2, Reward=-27.00, EPSILON=0.970, (W=1094,D=6,L=0)
2025-01-16 05:28:45,980 - INFO - Episode 3432/98900: Winner=2, Reward=13.85, EPSILON=0.970, (W=1094,D=6,L=0)
2025-01-16 05:28:46,152 - INFO - Episode 3433/98900: Winner=2, Reward=11.30, EPSILON=0.970, (W=1094,D=6,L=0)
2025-01-16 05:28:46,308 - DEBUG - Q-vals = [0.23437098 0.21440125 0.08374195 0.16079104 0.08695834 0.11944703
 0.10028947], best_act=0, best_val=0.234
2025-01-16 05:28:46,308 - DEBUG - Low Q-value (0.234), using MCTS.
2025-01-16 05:28:46,308 - INFO - Episode 3434/98900: Winner=2, Reward=-7.80, EPSILON=0.970, (W=1095,D=6,L=0)
2025-01-16 05:28:46,433 - DEBUG - Q-vals = [0.16895565 0.13691244 0.11667433 0.12747216 0.16166896 0.12947068
 0.1588459 ], best_act=0, best_val=0.169
2025-01-16 05:28:46,433 - DEBUG - Low Q-value (0.169), using MCTS.
2025-01-16 05:28:46,433 - INFO - Running MCTS with 147 simulations using 6 processes.
2025-01-16 05:28:49,214 - DEBUG - Aggregated action counts: {1: 1, 0: 2, 2: 3, 6: 1}
2025-01-16 05:28:49,214 - DEBUG - Chose best action 2
2025-01-16 05:28:49,276 - INFO - Episode 3435/98900: Winner=2, Reward=-10.55, EPSILON=0.970, (W=1096,D=6,L=0)
2025-01-16 05:28:49,480 - DEBUG - Q-vals = [0.13776994 0.19295797 0.03467516 0.07868242 0.02490504 0.3403844
 0.19062504], best_act=5, best_val=0.340
2025-01-16 05:28:49,480 - DEBUG - Low Q-value (0.340), using MCTS.
2025-01-16 05:28:49,480 - INFO - Running MCTS with 147 simulations using 6 processes.
2025-01-16 05:28:52,229 - DEBUG - Aggregated action counts: {0: 3, 2: 1, 1: 3}
2025-01-16 05:28:52,229 - DEBUG - Chose best action 0
2025-01-16 05:28:52,307 - INFO - Episode 3436/98900: Winner=2, Reward=-34.10, EPSILON=0.970, (W=1097,D=6,L=0)
2025-01-16 05:28:52,635 - INFO - Episode 3437/98900: Winner=2, Reward=-16.85, EPSILON=0.970, (W=1097,D=6,L=0)
2025-01-16 05:28:52,854 - INFO - Episode 3438/98900: Winner=2, Reward=-2.65, EPSILON=0.970, (W=1098,D=6,L=0)
2025-01-16 05:28:53,042 - INFO - Episode 3439/98900: Winner=2, Reward=-0.35, EPSILON=0.970, (W=1098,D=6,L=0)
2025-01-16 05:28:53,167 - INFO - Episode 3440/98900: Winner=2, Reward=-3.00, EPSILON=0.970, (W=1098,D=6,L=0)
2025-01-16 05:28:53,276 - INFO - Episode 3441/98900: Winner=2, Reward=0.70, EPSILON=0.970, (W=1098,D=6,L=0)
2025-01-16 05:28:53,463 - INFO - Episode 3442/98900: Winner=2, Reward=-5.95, EPSILON=0.969, (W=1098,D=6,L=0)
2025-01-16 05:28:53,620 - INFO - Episode 3443/98900: Winner=2, Reward=8.45, EPSILON=0.969, (W=1098,D=6,L=0)
2025-01-16 05:28:53,823 - INFO - Episode 3444/98900: Winner=2, Reward=-14.60, EPSILON=0.969, (W=1099,D=6,L=0)
2025-01-16 05:28:54,073 - INFO - Episode 3445/98900: Winner=2, Reward=-19.95, EPSILON=0.969, (W=1100,D=6,L=0)
2025-01-16 05:28:54,260 - DEBUG - Q-vals = [0.14839916 0.16686653 0.1011429  0.2402635  0.12644103 0.12585443
 0.09103247], best_act=3, best_val=0.240
2025-01-16 05:28:54,260 - DEBUG - Low Q-value (0.240), using MCTS.
2025-01-16 05:28:54,276 - INFO - Episode 3446/98900: Winner=2, Reward=-7.25, EPSILON=0.969, (W=1101,D=6,L=0)
2025-01-16 05:28:54,463 - INFO - Episode 3447/98900: Winner=2, Reward=-22.55, EPSILON=0.969, (W=1102,D=6,L=0)
2025-01-16 05:28:54,682 - INFO - Episode 3448/98900: Winner=2, Reward=21.50, EPSILON=0.969, (W=1102,D=6,L=0)
2025-01-16 05:28:54,744 - DEBUG - Q-vals = [0.15565617 0.11260817 0.26237175 0.10092866 0.07681448 0.11376293
 0.17785786], best_act=2, best_val=0.262
2025-01-16 05:28:54,744 - DEBUG - Low Q-value (0.262), using MCTS.
2025-01-16 05:28:54,744 - INFO - Running MCTS with 147 simulations using 6 processes.
2025-01-16 05:28:57,494 - DEBUG - Aggregated action counts: {3: 2, 1: 1, 4: 2, 2: 1, 0: 1}
2025-01-16 05:28:57,494 - DEBUG - Chose best action 3
2025-01-16 05:28:57,525 - INFO - Episode 3449/98900: Winner=2, Reward=-0.55, EPSILON=0.969, (W=1102,D=6,L=0)
2025-01-16 05:28:57,650 - INFO - Episode 3450/98900: Winner=2, Reward=0.05, EPSILON=0.969, (W=1102,D=6,L=0)
2025-01-16 05:28:57,775 - DEBUG - Q-vals = [0.17519556 0.11376185 0.12475221 0.12301081 0.17619334 0.10166929
 0.1854169 ], best_act=6, best_val=0.185
2025-01-16 05:28:57,775 - DEBUG - Low Q-value (0.185), using MCTS.
2025-01-16 05:28:57,775 - INFO - Running MCTS with 148 simulations using 6 processes.
2025-01-16 05:29:00,552 - DEBUG - Aggregated action counts: {4: 1, 5: 1, 1: 1, 0: 2, 2: 1, 6: 1}
2025-01-16 05:29:00,552 - DEBUG - Chose best action 0
2025-01-16 05:29:00,677 - DEBUG - Q-vals = [0.05046455 0.04535821 0.17783828 0.18880934 0.0488386  0.03616251
 0.4525285 ], best_act=6, best_val=0.453
2025-01-16 05:29:00,677 - DEBUG - Low Q-value (0.453), using MCTS.
2025-01-16 05:29:00,677 - INFO - Running MCTS with 148 simulations using 6 processes.
2025-01-16 05:29:03,489 - DEBUG - Aggregated action counts: {3: 1, 1: 3, 2: 1, 4: 1, 5: 1}
2025-01-16 05:29:03,489 - DEBUG - Chose best action 1
2025-01-16 05:29:03,646 - INFO - Episode 3451/98900: Winner=2, Reward=-62.95, EPSILON=0.969, (W=1103,D=6,L=0)
2025-01-16 05:29:03,786 - INFO - Episode 3452/98900: Winner=2, Reward=0.10, EPSILON=0.969, (W=1103,D=6,L=0)
2025-01-16 05:29:03,942 - INFO - Episode 3453/98900: Winner=2, Reward=0.00, EPSILON=0.969, (W=1103,D=6,L=0)
2025-01-16 05:29:04,224 - INFO - Episode 3454/98900: Winner=2, Reward=2.55, EPSILON=0.969, (W=1103,D=6,L=0)
2025-01-16 05:29:04,364 - DEBUG - Q-vals = [0.16849141 0.11304973 0.11643244 0.17470323 0.12137753 0.095778
 0.21016774], best_act=6, best_val=0.210
2025-01-16 05:29:04,364 - DEBUG - Low Q-value (0.210), using MCTS.
2025-01-16 05:29:04,364 - INFO - Running MCTS with 148 simulations using 6 processes.
2025-01-16 05:29:07,145 - DEBUG - Aggregated action counts: {1: 3, 5: 1, 0: 2, 6: 1}
2025-01-16 05:29:07,145 - DEBUG - Chose best action 1
2025-01-16 05:29:07,192 - INFO - Episode 3455/98900: Winner=2, Reward=-17.60, EPSILON=0.969, (W=1104,D=6,L=0)
2025-01-16 05:29:07,239 - DEBUG - Q-vals = [0.18948004 0.07342248 0.13860554 0.15909433 0.17927873 0.12513463
 0.13498428], best_act=0, best_val=0.189
2025-01-16 05:29:07,239 - DEBUG - Low Q-value (0.189), using MCTS.
2025-01-16 05:29:07,239 - INFO - Running MCTS with 148 simulations using 6 processes.
2025-01-16 05:29:10,395 - DEBUG - Aggregated action counts: {0: 2, 5: 2, 1: 2, 3: 1}
2025-01-16 05:29:10,395 - DEBUG - Chose best action 0
2025-01-16 05:29:10,505 - DEBUG - Q-vals = [0.15163237 0.22363973 0.06353711 0.13648078 0.1023252  0.19413912
 0.1282457 ], best_act=1, best_val=0.224
2025-01-16 05:29:10,505 - DEBUG - Low Q-value (0.224), using MCTS.
2025-01-16 05:29:10,505 - INFO - Running MCTS with 148 simulations using 6 processes.
2025-01-16 05:29:13,395 - DEBUG - Aggregated action counts: {3: 1, 2: 3, 1: 1, 0: 2}
2025-01-16 05:29:13,395 - DEBUG - Chose best action 2
2025-01-16 05:29:13,473 - INFO - Episode 3456/98900: Winner=2, Reward=-23.05, EPSILON=0.969, (W=1105,D=6,L=0)
2025-01-16 05:29:13,582 - DEBUG - Q-vals = [0.17574428 0.12808949 0.1130754  0.1312606  0.15149136 0.11304451
 0.18729429], best_act=6, best_val=0.187
2025-01-16 05:29:13,582 - DEBUG - Low Q-value (0.187), using MCTS.
2025-01-16 05:29:13,582 - INFO - Running MCTS with 148 simulations using 6 processes.
2025-01-16 05:29:16,394 - DEBUG - Aggregated action counts: {6: 1, 3: 1, 5: 1, 4: 2, 1: 1, 0: 1}
2025-01-16 05:29:16,394 - DEBUG - Chose best action 4
2025-01-16 05:29:16,597 - INFO - Episode 3457/98900: Winner=2, Reward=-9.80, EPSILON=0.969, (W=1106,D=6,L=0)
2025-01-16 05:29:16,691 - INFO - Episode 3458/98900: Winner=2, Reward=0.00, EPSILON=0.969, (W=1106,D=6,L=0)
2025-01-16 05:29:16,754 - DEBUG - Q-vals = [0.11411981 0.0819625  0.18198091 0.06545193 0.18648364 0.1334323
 0.23656894], best_act=6, best_val=0.237
2025-01-16 05:29:16,754 - DEBUG - Low Q-value (0.237), using MCTS.
2025-01-16 05:29:16,754 - INFO - Running MCTS with 148 simulations using 6 processes.
2025-01-16 05:29:19,456 - DEBUG - Aggregated action counts: {0: 2, 5: 3, 3: 1, 1: 1}
2025-01-16 05:29:19,456 - DEBUG - Chose best action 5
2025-01-16 05:29:19,550 - INFO - Episode 3459/98900: Winner=2, Reward=13.85, EPSILON=0.969, (W=1106,D=6,L=0)
2025-01-16 05:29:19,737 - DEBUG - Q-vals = [0.11405782 0.3771373  0.02470949 0.13992313 0.0493446  0.25623247
 0.03859526], best_act=1, best_val=0.377
2025-01-16 05:29:19,737 - DEBUG - Low Q-value (0.377), using MCTS.
2025-01-16 05:29:19,737 - INFO - Running MCTS with 148 simulations using 6 processes.
2025-01-16 05:29:22,502 - DEBUG - Aggregated action counts: {3: 3, 1: 1, 4: 1, 2: 1, 0: 1}
2025-01-16 05:29:22,502 - DEBUG - Chose best action 3
2025-01-16 05:29:22,611 - INFO - Episode 3460/98900: Winner=2, Reward=-13.60, EPSILON=0.969, (W=1107,D=6,L=0)
2025-01-16 05:29:22,705 - INFO - Episode 3461/98900: Winner=2, Reward=7.50, EPSILON=0.969, (W=1107,D=6,L=0)
2025-01-16 05:29:22,924 - DEBUG - Q-vals = [0.10354136 0.12270398 0.0938016  0.26913968 0.13845776 0.15847245
 0.11388312], best_act=3, best_val=0.269
2025-01-16 05:29:22,924 - DEBUG - Low Q-value (0.269), using MCTS.
2025-01-16 05:29:22,924 - INFO - Running MCTS with 148 simulations using 6 processes.
2025-01-16 05:29:25,626 - DEBUG - Aggregated action counts: {1: 4, 0: 2, 3: 1}
2025-01-16 05:29:25,626 - DEBUG - Chose best action 1
2025-01-16 05:29:25,642 - INFO - Episode 3462/98900: Winner=2, Reward=2.85, EPSILON=0.969, (W=1107,D=6,L=0)
2025-01-16 05:29:25,908 - INFO - Episode 3463/98900: Winner=2, Reward=-2.70, EPSILON=0.969, (W=1108,D=6,L=0)
2025-01-16 05:29:26,126 - INFO - Episode 3464/98900: Winner=2, Reward=-10.45, EPSILON=0.969, (W=1108,D=6,L=0)
2025-01-16 05:29:26,329 - INFO - Episode 3465/98900: Winner=2, Reward=3.20, EPSILON=0.969, (W=1108,D=6,L=0)
2025-01-16 05:29:26,517 - INFO - Episode 3466/98900: Winner=2, Reward=20.00, EPSILON=0.969, (W=1108,D=6,L=0)
2025-01-16 05:29:26,532 - DEBUG - Q-vals = [0.39318866 0.5752867  0.01083351 0.00323408 0.00343612 0.00991233
 0.00410863], best_act=1, best_val=0.575
2025-01-16 05:29:26,532 - DEBUG - Low Q-value (0.575), using MCTS.
2025-01-16 05:29:26,532 - INFO - Running MCTS with 148 simulations using 6 processes.
2025-01-16 05:29:29,313 - DEBUG - Aggregated action counts: {1: 2, 0: 2, 3: 2, 4: 1}
2025-01-16 05:29:29,313 - DEBUG - Chose best action 1
2025-01-16 05:29:29,547 - INFO - Episode 3467/98900: Winner=2, Reward=-29.55, EPSILON=0.969, (W=1109,D=6,L=0)
2025-01-16 05:29:29,985 - INFO - Episode 3468/98900: Winner=2, Reward=-44.85, EPSILON=0.969, (W=1109,D=6,L=0)
2025-01-16 05:29:30,297 - INFO - Episode 3469/98900: Winner=2, Reward=-36.65, EPSILON=0.969, (W=1109,D=6,L=0)
2025-01-16 05:29:30,516 - INFO - Episode 3470/98900: Winner=2, Reward=-0.75, EPSILON=0.969, (W=1109,D=6,L=0)
2025-01-16 05:29:30,938 - INFO - Episode 3471/98900: Winner=2, Reward=-85.35, EPSILON=0.969, (W=1110,D=6,L=0)
2025-01-16 05:29:31,156 - INFO - Episode 3472/98900: Winner=2, Reward=8.25, EPSILON=0.969, (W=1110,D=6,L=0)
2025-01-16 05:29:31,359 - DEBUG - Q-vals = [0.13830009 0.09596876 0.1782014  0.17516297 0.14591    0.06297658
 0.20348018], best_act=6, best_val=0.203
2025-01-16 05:29:31,359 - DEBUG - Low Q-value (0.203), using MCTS.
2025-01-16 05:29:31,375 - INFO - Episode 3473/98900: Winner=2, Reward=-14.05, EPSILON=0.969, (W=1111,D=6,L=0)
2025-01-16 05:29:31,672 - INFO - Episode 3474/98900: Winner=2, Reward=-47.95, EPSILON=0.969, (W=1112,D=6,L=0)
2025-01-16 05:29:32,000 - INFO - Episode 3475/98900: Winner=2, Reward=-15.70, EPSILON=0.969, (W=1113,D=6,L=0)
2025-01-16 05:29:32,140 - INFO - Episode 3476/98900: Winner=2, Reward=6.65, EPSILON=0.969, (W=1113,D=6,L=0)
2025-01-16 05:29:32,359 - INFO - Episode 3477/98900: Winner=2, Reward=-1.75, EPSILON=0.969, (W=1113,D=6,L=0)
2025-01-16 05:29:32,469 - INFO - Episode 3478/98900: Winner=2, Reward=7.40, EPSILON=0.969, (W=1113,D=6,L=0)
2025-01-16 05:29:32,765 - INFO - Episode 3479/98900: Winner=2, Reward=-7.55, EPSILON=0.969, (W=1113,D=6,L=0)
2025-01-16 05:29:32,984 - INFO - Episode 3480/98900: Winner=2, Reward=-11.15, EPSILON=0.969, (W=1114,D=6,L=0)
2025-01-16 05:29:33,265 - INFO - Episode 3481/98900: Winner=2, Reward=-43.65, EPSILON=0.969, (W=1115,D=6,L=0)
2025-01-16 05:29:33,531 - INFO - Episode 3482/98900: Winner=2, Reward=-5.50, EPSILON=0.969, (W=1116,D=6,L=0)
2025-01-16 05:29:33,593 - INFO - Episode 3483/98900: Winner=2, Reward=0.30, EPSILON=0.969, (W=1116,D=6,L=0)
2025-01-16 05:29:33,640 - DEBUG - Q-vals = [0.28600082 0.06920429 0.21363725 0.16216138 0.12513147 0.06491404
 0.07895073], best_act=0, best_val=0.286
2025-01-16 05:29:33,640 - DEBUG - Low Q-value (0.286), using MCTS.
2025-01-16 05:29:33,640 - INFO - Running MCTS with 149 simulations using 6 processes.
2025-01-16 05:29:36,730 - DEBUG - Aggregated action counts: {2: 2, 3: 2, 1: 1, 4: 1, 0: 1}
2025-01-16 05:29:36,730 - DEBUG - Chose best action 2
2025-01-16 05:29:37,021 - INFO - Episode 3484/98900: Winner=2, Reward=-41.05, EPSILON=0.969, (W=1117,D=6,L=0)
2025-01-16 05:29:37,349 - DEBUG - Q-vals = [0.14225546 0.07931402 0.13351892 0.2505682  0.19151035 0.08057225
 0.12226076], best_act=4, best_val=0.192
2025-01-16 05:29:37,349 - DEBUG - Low Q-value (0.192), using MCTS.
2025-01-16 05:29:37,365 - INFO - Episode 3485/98900: Winner=2, Reward=-62.05, EPSILON=0.969, (W=1118,D=6,L=0)
2025-01-16 05:29:37,697 - INFO - Episode 3486/98900: Winner=2, Reward=-30.25, EPSILON=0.969, (W=1119,D=6,L=0)
2025-01-16 05:29:37,923 - INFO - Episode 3487/98900: Winner=2, Reward=-7.75, EPSILON=0.969, (W=1119,D=6,L=0)
2025-01-16 05:29:38,064 - INFO - Episode 3488/98900: Winner=2, Reward=-9.85, EPSILON=0.969, (W=1120,D=6,L=0)
2025-01-16 05:29:38,189 - INFO - Episode 3489/98900: Winner=2, Reward=8.00, EPSILON=0.969, (W=1121,D=6,L=0)
2025-01-16 05:29:38,537 - INFO - Episode 3490/98900: Winner=2, Reward=-30.45, EPSILON=0.969, (W=1121,D=6,L=0)
2025-01-16 05:29:38,734 - INFO - Episode 3491/98900: Winner=2, Reward=-7.35, EPSILON=0.969, (W=1122,D=6,L=0)
2025-01-16 05:29:38,890 - DEBUG - Q-vals = [0.29929036 0.24982665 0.04918009 0.14686747 0.03818627 0.10504998
 0.11159915], best_act=0, best_val=0.299
2025-01-16 05:29:38,890 - DEBUG - Low Q-value (0.299), using MCTS.
2025-01-16 05:29:38,890 - INFO - Episode 3492/98900: Winner=2, Reward=-8.70, EPSILON=0.969, (W=1123,D=6,L=0)
2025-01-16 05:29:39,199 - INFO - Episode 3493/98900: Winner=2, Reward=-20.80, EPSILON=0.969, (W=1124,D=6,L=0)
2025-01-16 05:29:39,505 - INFO - Episode 3494/98900: Winner=2, Reward=-17.75, EPSILON=0.969, (W=1125,D=6,L=0)
2025-01-16 05:29:39,797 - INFO - Episode 3495/98900: Winner=2, Reward=-58.55, EPSILON=0.969, (W=1126,D=6,L=0)
2025-01-16 05:29:39,844 - DEBUG - Q-vals = [0.23579493 0.06252916 0.08163988 0.09312315 0.27181152 0.05687408
 0.19822726], best_act=4, best_val=0.272
2025-01-16 05:29:39,844 - DEBUG - Low Q-value (0.272), using MCTS.
2025-01-16 05:29:39,844 - INFO - Running MCTS with 149 simulations using 6 processes.
2025-01-16 05:29:42,642 - DEBUG - Aggregated action counts: {1: 1, 3: 2, 2: 2, 6: 1, 0: 1}
2025-01-16 05:29:42,642 - DEBUG - Chose best action 3
2025-01-16 05:29:42,836 - INFO - Episode 3496/98900: Winner=2, Reward=-3.45, EPSILON=0.969, (W=1126,D=6,L=0)
2025-01-16 05:29:43,242 - INFO - Episode 3497/98900: Winner=2, Reward=-41.80, EPSILON=0.969, (W=1126,D=6,L=0)
2025-01-16 05:29:43,422 - INFO - Episode 3498/98900: Winner=2, Reward=6.65, EPSILON=0.969, (W=1126,D=6,L=0)
2025-01-16 05:29:43,603 - INFO - Episode 3499/98900: Winner=2, Reward=-6.25, EPSILON=0.969, (W=1127,D=6,L=0)
2025-01-16 05:29:43,851 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3500.
2025-01-16 05:29:43,851 - INFO - Models saved at episode 3500
2025-01-16 05:29:43,853 - INFO - Target networks updated
2025-01-16 05:29:43,903 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3500.
2025-01-16 05:29:43,903 - INFO - Episode 3500/98900: Winner=2, Reward=-5.05, EPSILON=0.969, (W=1127,D=6,L=0)
2025-01-16 05:29:44,138 - INFO - Episode 3501/98900: Winner=2, Reward=-6.65, EPSILON=0.969, (W=1128,D=6,L=0)
2025-01-16 05:29:44,348 - INFO - Episode 3502/98900: Winner=2, Reward=1.65, EPSILON=0.969, (W=1128,D=6,L=0)
2025-01-16 05:29:44,500 - INFO - Episode 3503/98900: Winner=2, Reward=-10.55, EPSILON=0.969, (W=1129,D=6,L=0)
2025-01-16 05:29:44,639 - INFO - Episode 3504/98900: Winner=2, Reward=6.45, EPSILON=0.969, (W=1129,D=6,L=0)
2025-01-16 05:29:44,887 - INFO - Episode 3505/98900: Winner=2, Reward=-9.15, EPSILON=0.969, (W=1129,D=6,L=0)
2025-01-16 05:29:45,247 - INFO - Episode 3506/98900: Winner=2, Reward=-38.55, EPSILON=0.969, (W=1130,D=6,L=0)
2025-01-16 05:29:45,422 - INFO - Episode 3507/98900: Winner=2, Reward=-3.35, EPSILON=0.969, (W=1130,D=6,L=0)
2025-01-16 05:29:45,438 - DEBUG - Q-vals = [0.13038953 0.01821605 0.07491508 0.07844051 0.02187432 0.00691214
 0.6692524 ], best_act=6, best_val=0.669
2025-01-16 05:29:45,438 - DEBUG - Low Q-value (0.669), using MCTS.
2025-01-16 05:29:45,438 - INFO - Running MCTS with 150 simulations using 6 processes.
2025-01-16 05:29:48,300 - DEBUG - Aggregated action counts: {3: 1, 0: 3, 1: 1, 6: 1}
2025-01-16 05:29:48,300 - DEBUG - Chose best action 0
2025-01-16 05:29:48,592 - INFO - Episode 3508/98900: Winner=2, Reward=-19.85, EPSILON=0.969, (W=1130,D=6,L=0)
2025-01-16 05:29:48,763 - INFO - Episode 3509/98900: Winner=2, Reward=1.85, EPSILON=0.969, (W=1130,D=6,L=0)
2025-01-16 05:29:48,981 - DEBUG - Q-vals = [0.26634002 0.17338812 0.03643366 0.18263379 0.10889266 0.10504513
 0.12726666], best_act=0, best_val=0.266
2025-01-16 05:29:48,997 - DEBUG - Low Q-value (0.266), using MCTS.
2025-01-16 05:29:48,997 - INFO - Episode 3510/98900: Winner=2, Reward=-8.25, EPSILON=0.969, (W=1131,D=6,L=0)
2025-01-16 05:29:49,121 - DEBUG - Q-vals = [0.2246607  0.09454249 0.09841298 0.0835254  0.26299697 0.05295201
 0.18290941], best_act=4, best_val=0.263
2025-01-16 05:29:49,121 - DEBUG - Low Q-value (0.263), using MCTS.
2025-01-16 05:29:49,121 - INFO - Running MCTS with 150 simulations using 6 processes.
2025-01-16 05:29:52,120 - DEBUG - Aggregated action counts: {3: 2, 4: 3, 0: 1}
2025-01-16 05:29:52,121 - DEBUG - Chose best action 4
2025-01-16 05:29:52,295 - DEBUG - Q-vals = [0.18729942 0.07397179 0.3144789  0.19724229 0.04868476 0.01257545
 0.16574734], best_act=2, best_val=0.314
2025-01-16 05:29:52,295 - DEBUG - Low Q-value (0.314), using MCTS.
2025-01-16 05:29:52,297 - INFO - Running MCTS with 150 simulations using 6 processes.
2025-01-16 05:29:55,304 - DEBUG - Aggregated action counts: {5: 1, 2: 2, 1: 2, 0: 1}
2025-01-16 05:29:55,304 - DEBUG - Chose best action 2
2025-01-16 05:29:55,320 - INFO - Episode 3511/98900: Winner=2, Reward=-25.15, EPSILON=0.969, (W=1131,D=6,L=0)
2025-01-16 05:29:55,554 - DEBUG - Q-vals = [0.11792527 0.0329463  0.1898313  0.39023396 0.08174453 0.00912563
 0.178193  ], best_act=3, best_val=0.390
2025-01-16 05:29:55,554 - DEBUG - Low Q-value (0.390), using MCTS.
2025-01-16 05:29:55,554 - INFO - Running MCTS with 150 simulations using 6 processes.
2025-01-16 05:29:58,554 - DEBUG - Aggregated action counts: {1: 1, 2: 4, 3: 1}
2025-01-16 05:29:58,554 - DEBUG - Chose best action 2
2025-01-16 05:29:58,741 - INFO - Episode 3512/98900: Winner=2, Reward=-1.15, EPSILON=0.969, (W=1131,D=6,L=0)
2025-01-16 05:29:59,054 - INFO - Episode 3513/98900: Winner=2, Reward=-13.25, EPSILON=0.969, (W=1132,D=6,L=0)
2025-01-16 05:29:59,210 - INFO - Episode 3514/98900: Winner=2, Reward=-0.10, EPSILON=0.969, (W=1132,D=6,L=0)
2025-01-16 05:29:59,226 - DEBUG - Q-vals = [1.0703299e-02 4.0769655e-02 8.1557737e-05 1.8655242e-06 2.0848474e-06
 9.4841528e-01 2.6208554e-05], best_act=5, best_val=0.948
2025-01-16 05:29:59,226 - DEBUG - Low Q-value (0.948), using MCTS.
2025-01-16 05:29:59,226 - INFO - Running MCTS with 150 simulations using 6 processes.
2025-01-16 05:30:02,273 - DEBUG - Aggregated action counts: {5: 2, 3: 3, 0: 1}
2025-01-16 05:30:02,273 - DEBUG - Chose best action 3
2025-01-16 05:30:02,554 - INFO - Episode 3515/98900: Winner=2, Reward=-31.55, EPSILON=0.969, (W=1133,D=6,L=0)
2025-01-16 05:30:02,648 - DEBUG - Q-vals = [0.15810134 0.14081141 0.09672282 0.12904896 0.18448003 0.12012905
 0.17070639], best_act=4, best_val=0.184
2025-01-16 05:30:02,648 - DEBUG - Low Q-value (0.184), using MCTS.
2025-01-16 05:30:02,648 - INFO - Running MCTS with 150 simulations using 6 processes.
2025-01-16 05:30:05,850 - DEBUG - Aggregated action counts: {1: 1, 2: 2, 5: 3}
2025-01-16 05:30:05,850 - DEBUG - Chose best action 5
2025-01-16 05:30:06,084 - INFO - Episode 3516/98900: Winner=2, Reward=7.80, EPSILON=0.969, (W=1133,D=6,L=0)
2025-01-16 05:30:06,194 - INFO - Episode 3517/98900: Winner=2, Reward=1.75, EPSILON=0.969, (W=1133,D=6,L=0)
2025-01-16 05:30:06,365 - INFO - Episode 3518/98900: Winner=2, Reward=-14.40, EPSILON=0.969, (W=1134,D=6,L=0)
2025-01-16 05:30:06,756 - INFO - Episode 3519/98900: Winner=2, Reward=-44.05, EPSILON=0.969, (W=1134,D=6,L=0)
2025-01-16 05:30:06,865 - INFO - Episode 3520/98900: Winner=2, Reward=-0.45, EPSILON=0.969, (W=1134,D=6,L=0)
2025-01-16 05:30:07,053 - INFO - Episode 3521/98900: Winner=2, Reward=-16.40, EPSILON=0.969, (W=1135,D=6,L=0)
2025-01-16 05:30:07,240 - INFO - Episode 3522/98900: Winner=2, Reward=5.75, EPSILON=0.969, (W=1135,D=6,L=0)
2025-01-16 05:30:07,256 - DEBUG - Q-vals = [0.32719555 0.01244074 0.01291044 0.01039317 0.5534645  0.01746631
 0.06612933], best_act=4, best_val=0.553
2025-01-16 05:30:07,256 - DEBUG - Low Q-value (0.553), using MCTS.
2025-01-16 05:30:07,256 - INFO - Running MCTS with 150 simulations using 6 processes.
2025-01-16 05:30:10,308 - DEBUG - Aggregated action counts: {5: 1, 3: 3, 1: 1, 6: 1}
2025-01-16 05:30:10,308 - DEBUG - Chose best action 3
2025-01-16 05:30:10,442 - DEBUG - Q-vals = [0.04892377 0.03230516 0.18955988 0.05198219 0.19557314 0.11525183
 0.3664041 ], best_act=6, best_val=0.366
2025-01-16 05:30:10,442 - DEBUG - Low Q-value (0.366), using MCTS.
2025-01-16 05:30:10,442 - INFO - Running MCTS with 150 simulations using 6 processes.
2025-01-16 05:30:13,829 - DEBUG - Aggregated action counts: {0: 2, 4: 1, 2: 1, 5: 1, 3: 1}
2025-01-16 05:30:13,829 - DEBUG - Chose best action 0
2025-01-16 05:30:14,038 - INFO - Episode 3523/98900: Winner=2, Reward=-57.30, EPSILON=0.969, (W=1135,D=6,L=0)
2025-01-16 05:30:14,286 - INFO - Episode 3524/98900: Winner=2, Reward=-18.80, EPSILON=0.969, (W=1136,D=6,L=0)
2025-01-16 05:30:14,411 - DEBUG - Q-vals = [0.18054949 0.13939202 0.12324599 0.16437823 0.16099867 0.10686568
 0.12456994], best_act=0, best_val=0.181
2025-01-16 05:30:14,411 - DEBUG - Low Q-value (0.181), using MCTS.
2025-01-16 05:30:14,412 - INFO - Running MCTS with 151 simulations using 6 processes.
2025-01-16 05:30:17,555 - DEBUG - Aggregated action counts: {2: 4, 6: 1, 3: 1, 4: 1}
2025-01-16 05:30:17,555 - DEBUG - Chose best action 2
2025-01-16 05:30:17,654 - INFO - Episode 3525/98900: Winner=2, Reward=-13.70, EPSILON=0.969, (W=1137,D=6,L=0)
2025-01-16 05:30:17,861 - INFO - Episode 3526/98900: Winner=2, Reward=-12.25, EPSILON=0.969, (W=1137,D=6,L=0)
2025-01-16 05:30:18,073 - INFO - Episode 3527/98900: Winner=2, Reward=2.85, EPSILON=0.969, (W=1137,D=6,L=0)
2025-01-16 05:30:18,350 - INFO - Episode 3528/98900: Winner=2, Reward=-7.95, EPSILON=0.969, (W=1138,D=6,L=0)
2025-01-16 05:30:18,573 - INFO - Episode 3529/98900: Winner=2, Reward=-13.95, EPSILON=0.969, (W=1139,D=6,L=0)
2025-01-16 05:30:18,635 - INFO - Episode 3530/98900: Winner=2, Reward=2.25, EPSILON=0.969, (W=1139,D=6,L=0)
2025-01-16 05:30:18,854 - DEBUG - Q-vals = [0.10012191 0.238277   0.05005014 0.06159391 0.22087497 0.2534922
 0.07558989], best_act=1, best_val=0.238
2025-01-16 05:30:18,854 - DEBUG - Low Q-value (0.238), using MCTS.
2025-01-16 05:30:18,854 - INFO - Running MCTS with 151 simulations using 6 processes.
2025-01-16 05:30:22,043 - DEBUG - Aggregated action counts: {6: 2, 2: 2, 3: 2, 0: 1}
2025-01-16 05:30:22,043 - DEBUG - Chose best action 6
2025-01-16 05:30:22,153 - INFO - Episode 3531/98900: Winner=2, Reward=-53.55, EPSILON=0.969, (W=1139,D=6,L=0)
2025-01-16 05:30:22,364 - INFO - Episode 3532/98900: Winner=2, Reward=-12.70, EPSILON=0.969, (W=1140,D=6,L=0)
2025-01-16 05:30:22,520 - INFO - Episode 3533/98900: Winner=2, Reward=-7.65, EPSILON=0.969, (W=1141,D=6,L=0)
2025-01-16 05:30:22,740 - INFO - Episode 3534/98900: Winner=2, Reward=8.70, EPSILON=0.969, (W=1141,D=6,L=0)
2025-01-16 05:30:23,103 - INFO - Episode 3535/98900: Winner=2, Reward=-52.10, EPSILON=0.969, (W=1142,D=6,L=0)
2025-01-16 05:30:23,448 - INFO - Episode 3536/98900: Winner=2, Reward=-21.95, EPSILON=0.969, (W=1143,D=6,L=0)
2025-01-16 05:30:23,654 - INFO - Episode 3537/98900: Winner=2, Reward=7.95, EPSILON=0.969, (W=1143,D=6,L=0)
2025-01-16 05:30:23,813 - INFO - Episode 3538/98900: Winner=2, Reward=15.80, EPSILON=0.969, (W=1143,D=6,L=0)
2025-01-16 05:30:23,921 - DEBUG - Q-vals = [0.20257457 0.13094161 0.09477263 0.1876312  0.14546078 0.10698269
 0.1316365 ], best_act=0, best_val=0.203
2025-01-16 05:30:23,922 - DEBUG - Low Q-value (0.203), using MCTS.
2025-01-16 05:30:23,922 - INFO - Running MCTS with 151 simulations using 6 processes.
2025-01-16 05:30:27,008 - DEBUG - Aggregated action counts: {1: 2, 4: 2, 0: 2, 6: 1}
2025-01-16 05:30:27,008 - DEBUG - Chose best action 1
2025-01-16 05:30:27,057 - DEBUG - Q-vals = [0.1961457  0.11251643 0.08894053 0.10257407 0.27217308 0.09103459
 0.13661557], best_act=4, best_val=0.272
2025-01-16 05:30:27,057 - DEBUG - Low Q-value (0.272), using MCTS.
2025-01-16 05:30:27,057 - INFO - Running MCTS with 151 simulations using 6 processes.
2025-01-16 05:30:30,216 - DEBUG - Aggregated action counts: {2: 1, 0: 2, 6: 1, 1: 2, 3: 1}
2025-01-16 05:30:30,216 - DEBUG - Chose best action 0
2025-01-16 05:30:30,243 - INFO - Episode 3539/98900: Winner=2, Reward=-13.05, EPSILON=0.969, (W=1143,D=6,L=0)
2025-01-16 05:30:30,368 - INFO - Episode 3540/98900: Winner=2, Reward=22.75, EPSILON=0.969, (W=1143,D=6,L=0)
2025-01-16 05:30:30,563 - INFO - Episode 3541/98900: Winner=2, Reward=7.95, EPSILON=0.969, (W=1143,D=6,L=0)
2025-01-16 05:30:30,821 - INFO - Episode 3542/98900: Winner=2, Reward=-0.25, EPSILON=0.969, (W=1144,D=6,L=0)
2025-01-16 05:30:31,119 - INFO - Episode 3543/98900: Winner=2, Reward=-9.85, EPSILON=0.969, (W=1145,D=6,L=0)
2025-01-16 05:30:31,429 - INFO - Episode 3544/98900: Winner=2, Reward=-22.85, EPSILON=0.969, (W=1145,D=6,L=0)
2025-01-16 05:30:31,724 - INFO - Episode 3545/98900: Winner=2, Reward=-20.75, EPSILON=0.969, (W=1145,D=6,L=0)
2025-01-16 05:30:31,891 - INFO - Episode 3546/98900: Winner=2, Reward=-3.10, EPSILON=0.969, (W=1145,D=6,L=0)
2025-01-16 05:30:31,953 - DEBUG - Q-vals = [0.21625362 0.07831396 0.09097441 0.13137199 0.16641955 0.12614383
 0.1905226 ], best_act=0, best_val=0.216
2025-01-16 05:30:31,953 - DEBUG - Low Q-value (0.216), using MCTS.
2025-01-16 05:30:31,953 - INFO - Running MCTS with 151 simulations using 6 processes.
2025-01-16 05:30:35,050 - DEBUG - Aggregated action counts: {2: 1, 3: 3, 0: 1, 1: 2}
2025-01-16 05:30:35,050 - DEBUG - Chose best action 3
2025-01-16 05:30:35,373 - DEBUG - Q-vals = [0.05160338 0.08772708 0.03965899 0.6318483  0.02650408 0.02607631
 0.13658188], best_act=3, best_val=0.632
2025-01-16 05:30:35,373 - DEBUG - Low Q-value (0.632), using MCTS.
2025-01-16 05:30:35,382 - INFO - Episode 3547/98900: Winner=2, Reward=-64.40, EPSILON=0.969, (W=1146,D=6,L=0)
2025-01-16 05:30:35,678 - INFO - Episode 3548/98900: Winner=2, Reward=-24.85, EPSILON=0.969, (W=1147,D=6,L=0)
2025-01-16 05:30:35,960 - INFO - Episode 3549/98900: Winner=2, Reward=2.85, EPSILON=0.969, (W=1148,D=6,L=0)
2025-01-16 05:30:36,212 - INFO - Episode 3550/98900: Winner=2, Reward=-16.85, EPSILON=0.969, (W=1148,D=6,L=0)
2025-01-16 05:30:36,507 - INFO - Episode 3551/98900: Winner=2, Reward=15.35, EPSILON=0.969, (W=1148,D=6,L=0)
2025-01-16 05:30:36,642 - INFO - Episode 3552/98900: Winner=2, Reward=-9.85, EPSILON=0.969, (W=1149,D=6,L=0)
2025-01-16 05:30:36,863 - INFO - Episode 3553/98900: Winner=2, Reward=-1.35, EPSILON=0.969, (W=1149,D=6,L=0)
2025-01-16 05:30:37,172 - INFO - Episode 3554/98900: Winner=2, Reward=-24.15, EPSILON=0.969, (W=1149,D=6,L=0)
2025-01-16 05:30:37,460 - INFO - Episode 3555/98900: Winner=2, Reward=-13.60, EPSILON=0.969, (W=1150,D=6,L=0)
2025-01-16 05:30:37,710 - INFO - Episode 3556/98900: Winner=2, Reward=-13.60, EPSILON=0.969, (W=1151,D=6,L=0)
2025-01-16 05:30:37,932 - INFO - Episode 3557/98900: Winner=2, Reward=-13.55, EPSILON=0.968, (W=1152,D=6,L=0)
2025-01-16 05:30:38,332 - INFO - Episode 3558/98900: Winner=2, Reward=-47.25, EPSILON=0.968, (W=1152,D=6,L=0)
2025-01-16 05:30:38,554 - INFO - Episode 3559/98900: Winner=2, Reward=-13.15, EPSILON=0.968, (W=1153,D=6,L=0)
2025-01-16 05:30:38,804 - INFO - Episode 3560/98900: Winner=2, Reward=-13.55, EPSILON=0.968, (W=1154,D=6,L=0)
2025-01-16 05:30:39,008 - INFO - Episode 3561/98900: Winner=2, Reward=-14.00, EPSILON=0.968, (W=1155,D=6,L=0)
2025-01-16 05:30:39,254 - DEBUG - Q-vals = [0.1406313  0.1473961  0.06849027 0.11853213 0.26361734 0.13674696
 0.12458602], best_act=4, best_val=0.264
2025-01-16 05:30:39,254 - DEBUG - Low Q-value (0.264), using MCTS.
2025-01-16 05:30:39,255 - INFO - Running MCTS with 152 simulations using 6 processes.
2025-01-16 05:30:42,361 - DEBUG - Aggregated action counts: {0: 4, 4: 1, 3: 1, 1: 1}
2025-01-16 05:30:42,361 - DEBUG - Chose best action 0
2025-01-16 05:30:42,415 - INFO - Episode 3562/98900: Winner=2, Reward=11.50, EPSILON=0.968, (W=1155,D=6,L=0)
2025-01-16 05:30:42,629 - DEBUG - Q-vals = [0.04174421 0.03617743 0.08905797 0.5404986  0.07804679 0.02350319
 0.19097182], best_act=3, best_val=0.540
2025-01-16 05:30:42,629 - DEBUG - Low Q-value (0.540), using MCTS.
2025-01-16 05:30:42,640 - INFO - Episode 3563/98900: Winner=2, Reward=-15.60, EPSILON=0.968, (W=1156,D=6,L=0)
2025-01-16 05:30:42,816 - DEBUG - Q-vals = [0.09026288 0.13674192 0.09990676 0.27723125 0.21210536 0.09380182
 0.08995009], best_act=3, best_val=0.277
2025-01-16 05:30:42,816 - DEBUG - Low Q-value (0.277), using MCTS.
2025-01-16 05:30:42,817 - INFO - Running MCTS with 152 simulations using 6 processes.
2025-01-16 05:30:45,669 - DEBUG - Aggregated action counts: {4: 1, 0: 2, 3: 3, 5: 1}
2025-01-16 05:30:45,670 - DEBUG - Chose best action 3
2025-01-16 05:30:45,722 - INFO - Episode 3564/98900: Winner=2, Reward=2.65, EPSILON=0.968, (W=1157,D=6,L=0)
2025-01-16 05:30:45,878 - INFO - Episode 3565/98900: Winner=2, Reward=10.75, EPSILON=0.968, (W=1157,D=6,L=0)
2025-01-16 05:30:46,150 - INFO - Episode 3566/98900: Winner=2, Reward=-9.85, EPSILON=0.968, (W=1157,D=6,L=0)
2025-01-16 05:30:46,258 - INFO - Episode 3567/98900: Winner=2, Reward=7.25, EPSILON=0.968, (W=1157,D=6,L=0)
2025-01-16 05:30:46,522 - INFO - Episode 3568/98900: Winner=2, Reward=-10.55, EPSILON=0.968, (W=1158,D=6,L=0)
2025-01-16 05:30:46,806 - INFO - Episode 3569/98900: Winner=2, Reward=-34.45, EPSILON=0.968, (W=1158,D=6,L=0)
2025-01-16 05:30:47,025 - INFO - Episode 3570/98900: Winner=2, Reward=17.50, EPSILON=0.968, (W=1158,D=6,L=0)
2025-01-16 05:30:47,225 - INFO - Episode 3571/98900: Winner=2, Reward=-26.15, EPSILON=0.968, (W=1159,D=6,L=0)
2025-01-16 05:30:47,441 - INFO - Episode 3572/98900: Winner=2, Reward=-0.85, EPSILON=0.968, (W=1159,D=6,L=0)
2025-01-16 05:30:47,629 - INFO - Episode 3573/98900: Winner=2, Reward=3.55, EPSILON=0.968, (W=1159,D=6,L=0)
2025-01-16 05:30:47,725 - INFO - Episode 3574/98900: Winner=2, Reward=-10.25, EPSILON=0.968, (W=1160,D=6,L=0)
2025-01-16 05:30:48,031 - INFO - Episode 3575/98900: Winner=2, Reward=-37.80, EPSILON=0.968, (W=1161,D=6,L=0)
2025-01-16 05:30:48,270 - INFO - Episode 3576/98900: Winner=2, Reward=-25.85, EPSILON=0.968, (W=1162,D=6,L=0)
2025-01-16 05:30:48,372 - DEBUG - Q-vals = [0.08921092 0.06433736 0.12454679 0.04559116 0.11020549 0.45127168
 0.1148366 ], best_act=5, best_val=0.451
2025-01-16 05:30:48,372 - DEBUG - Low Q-value (0.451), using MCTS.
2025-01-16 05:30:48,373 - INFO - Running MCTS with 153 simulations using 6 processes.
2025-01-16 05:30:51,115 - DEBUG - Aggregated action counts: {1: 1, 4: 2, 0: 2, 2: 2}
2025-01-16 05:30:51,115 - DEBUG - Chose best action 4
2025-01-16 05:30:51,190 - INFO - Episode 3577/98900: Winner=2, Reward=-0.40, EPSILON=0.968, (W=1163,D=6,L=0)
2025-01-16 05:30:51,251 - DEBUG - Q-vals = [0.1849547  0.10201848 0.13368341 0.1155187  0.16720594 0.11878749
 0.17783122], best_act=0, best_val=0.185
2025-01-16 05:30:51,251 - DEBUG - Low Q-value (0.185), using MCTS.
2025-01-16 05:30:51,252 - INFO - Running MCTS with 153 simulations using 6 processes.
2025-01-16 05:30:54,122 - DEBUG - Aggregated action counts: {0: 3, 1: 2, 5: 1, 2: 1}
2025-01-16 05:30:54,122 - DEBUG - Chose best action 0
2025-01-16 05:30:54,379 - INFO - Episode 3578/98900: Winner=2, Reward=-9.50, EPSILON=0.968, (W=1163,D=6,L=0)
2025-01-16 05:30:54,558 - INFO - Episode 3579/98900: Winner=2, Reward=-6.25, EPSILON=0.968, (W=1164,D=6,L=0)
2025-01-16 05:30:54,766 - DEBUG - Q-vals = [0.14088754 0.18051922 0.1564897  0.08532526 0.16290459 0.10377029
 0.17010336], best_act=6, best_val=0.170
2025-01-16 05:30:54,767 - DEBUG - Low Q-value (0.170), using MCTS.
2025-01-16 05:30:54,768 - INFO - Running MCTS with 153 simulations using 6 processes.
2025-01-16 05:30:57,472 - DEBUG - Aggregated action counts: {2: 2, 3: 2, 0: 3}
2025-01-16 05:30:57,472 - DEBUG - Chose best action 0
2025-01-16 05:30:57,550 - INFO - Episode 3580/98900: Winner=2, Reward=23.75, EPSILON=0.968, (W=1165,D=6,L=0)
2025-01-16 05:30:57,744 - INFO - Episode 3581/98900: Winner=2, Reward=4.05, EPSILON=0.968, (W=1165,D=6,L=0)
2025-01-16 05:30:57,900 - DEBUG - Q-vals = [0.06801307 0.05175198 0.04309655 0.2806603  0.07867384 0.09476573
 0.38303846], best_act=6, best_val=0.383
2025-01-16 05:30:57,900 - DEBUG - Low Q-value (0.383), using MCTS.
2025-01-16 05:30:57,900 - INFO - Running MCTS with 153 simulations using 6 processes.
2025-01-16 05:31:00,742 - DEBUG - Aggregated action counts: {4: 1, 0: 4, 2: 2}
2025-01-16 05:31:00,742 - DEBUG - Chose best action 0
2025-01-16 05:31:00,918 - INFO - Episode 3582/98900: Winner=2, Reward=-29.10, EPSILON=0.968, (W=1165,D=6,L=0)
2025-01-16 05:31:00,955 - DEBUG - Q-vals = [0.06118649 0.03828651 0.43320742 0.00756677 0.1699524  0.17251442
 0.11728597], best_act=2, best_val=0.433
2025-01-16 05:31:00,955 - DEBUG - Low Q-value (0.433), using MCTS.
2025-01-16 05:31:00,955 - INFO - Running MCTS with 153 simulations using 6 processes.
2025-01-16 05:31:03,762 - DEBUG - Aggregated action counts: {0: 2, 3: 1, 2: 1, 1: 1, 6: 2}
2025-01-16 05:31:03,762 - DEBUG - Chose best action 0
2025-01-16 05:31:04,108 - INFO - Episode 3583/98900: Winner=2, Reward=-78.00, EPSILON=0.968, (W=1166,D=6,L=0)
2025-01-16 05:31:04,496 - INFO - Episode 3584/98900: Winner=2, Reward=-38.25, EPSILON=0.968, (W=1167,D=6,L=0)
2025-01-16 05:31:04,664 - DEBUG - Q-vals = [0.19129722 0.16537909 0.0869209  0.12364629 0.20991063 0.09413218
 0.12871374], best_act=4, best_val=0.210
2025-01-16 05:31:04,664 - DEBUG - Low Q-value (0.210), using MCTS.
2025-01-16 05:31:04,665 - INFO - Running MCTS with 153 simulations using 6 processes.
2025-01-16 05:31:07,328 - DEBUG - Aggregated action counts: {1: 3, 2: 1, 5: 1, 0: 2}
2025-01-16 05:31:07,328 - DEBUG - Chose best action 1
2025-01-16 05:31:07,390 - INFO - Episode 3585/98900: Winner=2, Reward=-6.95, EPSILON=0.968, (W=1167,D=6,L=0)
2025-01-16 05:31:07,515 - DEBUG - Q-vals = [0.14221217 0.09177806 0.20189981 0.1919782  0.0883093  0.06471468
 0.21910782], best_act=6, best_val=0.219
2025-01-16 05:31:07,515 - DEBUG - Low Q-value (0.219), using MCTS.
2025-01-16 05:31:07,515 - INFO - Running MCTS with 153 simulations using 6 processes.
2025-01-16 05:31:10,338 - DEBUG - Aggregated action counts: {4: 1, 3: 1, 2: 1, 5: 3, 0: 1}
2025-01-16 05:31:10,338 - DEBUG - Chose best action 5
2025-01-16 05:31:10,478 - INFO - Episode 3586/98900: Winner=2, Reward=-7.70, EPSILON=0.968, (W=1168,D=6,L=0)
2025-01-16 05:31:10,558 - DEBUG - Q-vals = [0.17166439 0.12773404 0.13045578 0.12490474 0.14264102 0.1247993
 0.1778007 ], best_act=6, best_val=0.178
2025-01-16 05:31:10,558 - DEBUG - Low Q-value (0.178), using MCTS.
2025-01-16 05:31:10,559 - INFO - Running MCTS with 153 simulations using 6 processes.
2025-01-16 05:31:13,384 - DEBUG - Aggregated action counts: {1: 1, 6: 1, 2: 2, 4: 1, 0: 2}
2025-01-16 05:31:13,384 - DEBUG - Chose best action 2
2025-01-16 05:31:13,525 - INFO - Episode 3587/98900: Winner=2, Reward=-12.30, EPSILON=0.968, (W=1169,D=6,L=0)
2025-01-16 05:31:13,556 - DEBUG - Q-vals = [0.13440813 0.08238006 0.1413071  0.0514419  0.17398033 0.14302273
 0.2734598 ], best_act=6, best_val=0.273
2025-01-16 05:31:13,556 - DEBUG - Low Q-value (0.273), using MCTS.
2025-01-16 05:31:13,556 - INFO - Running MCTS with 153 simulations using 6 processes.
2025-01-16 05:31:16,522 - DEBUG - Aggregated action counts: {6: 2, 3: 3, 2: 1, 0: 1}
2025-01-16 05:31:16,522 - DEBUG - Chose best action 3
2025-01-16 05:31:16,997 - INFO - Episode 3588/98900: Winner=2, Reward=-15.95, EPSILON=0.968, (W=1169,D=6,L=0)
2025-01-16 05:31:17,303 - INFO - Episode 3589/98900: Winner=2, Reward=2.10, EPSILON=0.968, (W=1169,D=6,L=0)
2025-01-16 05:31:17,451 - DEBUG - Q-vals = [0.15831654 0.26592657 0.06010889 0.09452673 0.09791362 0.1828172
 0.14039041], best_act=1, best_val=0.266
2025-01-16 05:31:17,451 - DEBUG - Low Q-value (0.266), using MCTS.
2025-01-16 05:31:17,452 - INFO - Running MCTS with 153 simulations using 6 processes.
2025-01-16 05:31:20,277 - DEBUG - Aggregated action counts: {3: 1, 5: 1, 1: 2, 4: 2, 0: 1}
2025-01-16 05:31:20,277 - DEBUG - Chose best action 1
2025-01-16 05:31:20,334 - DEBUG - Q-vals = [0.10351001 0.16439168 0.13675706 0.3124459  0.12808724 0.03258112
 0.12222705], best_act=3, best_val=0.312
2025-01-16 05:31:20,334 - DEBUG - Low Q-value (0.312), using MCTS.
2025-01-16 05:31:20,356 - INFO - Episode 3590/98900: Winner=2, Reward=-7.10, EPSILON=0.968, (W=1170,D=6,L=0)
2025-01-16 05:31:20,371 - DEBUG - Q-vals = [0.44415385 0.5270907  0.00758833 0.00302295 0.00366804 0.00827073
 0.00620539], best_act=1, best_val=0.527
2025-01-16 05:31:20,371 - DEBUG - Low Q-value (0.527), using MCTS.
2025-01-16 05:31:20,372 - INFO - Running MCTS with 153 simulations using 6 processes.
2025-01-16 05:31:23,325 - DEBUG - Aggregated action counts: {1: 1, 4: 1, 2: 2, 0: 2, 5: 1}
2025-01-16 05:31:23,325 - DEBUG - Chose best action 2
2025-01-16 05:31:23,650 - INFO - Episode 3591/98900: Winner=2, Reward=-89.15, EPSILON=0.968, (W=1171,D=6,L=0)
2025-01-16 05:31:23,738 - INFO - Episode 3592/98900: Winner=2, Reward=7.80, EPSILON=0.968, (W=1171,D=6,L=0)
2025-01-16 05:31:23,965 - INFO - Episode 3593/98900: Winner=2, Reward=-17.85, EPSILON=0.968, (W=1172,D=6,L=0)
2025-01-16 05:31:24,430 - INFO - Episode 3594/98900: Winner=2, Reward=-92.90, EPSILON=0.968, (W=1173,D=6,L=0)
2025-01-16 05:31:24,610 - INFO - Episode 3595/98900: Winner=2, Reward=12.40, EPSILON=0.968, (W=1173,D=6,L=0)
2025-01-16 05:31:24,726 - INFO - Episode 3596/98900: Winner=2, Reward=1.35, EPSILON=0.968, (W=1173,D=6,L=0)
2025-01-16 05:31:24,853 - DEBUG - Q-vals = [0.09817372 0.07964747 0.11043359 0.23677033 0.15462123 0.09982193
 0.22053179], best_act=3, best_val=0.237
2025-01-16 05:31:24,853 - DEBUG - Low Q-value (0.237), using MCTS.
2025-01-16 05:31:24,854 - INFO - Running MCTS with 153 simulations using 6 processes.
2025-01-16 05:31:27,791 - DEBUG - Aggregated action counts: {6: 3, 1: 1, 2: 1, 0: 2}
2025-01-16 05:31:27,791 - DEBUG - Chose best action 6
2025-01-16 05:31:27,979 - DEBUG - Q-vals = [0.07484964 0.16396256 0.0577595  0.24812327 0.1397133  0.15097825
 0.1646134 ], best_act=3, best_val=0.248
2025-01-16 05:31:27,979 - DEBUG - Low Q-value (0.248), using MCTS.
2025-01-16 05:31:27,997 - INFO - Episode 3597/98900: Winner=2, Reward=-39.95, EPSILON=0.968, (W=1174,D=6,L=0)
2025-01-16 05:31:28,210 - INFO - Episode 3598/98900: Winner=2, Reward=10.65, EPSILON=0.968, (W=1174,D=6,L=0)
2025-01-16 05:31:28,480 - INFO - Episode 3599/98900: Winner=2, Reward=-3.35, EPSILON=0.968, (W=1175,D=6,L=0)
2025-01-16 05:31:28,702 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3600.
2025-01-16 05:31:28,702 - INFO - Models saved at episode 3600
2025-01-16 05:31:28,702 - INFO - Target networks updated
2025-01-16 05:31:28,765 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3600.
2025-01-16 05:31:28,765 - INFO - Episode 3600/98900: Winner=2, Reward=1.65, EPSILON=0.968, (W=1175,D=6,L=0)
2025-01-16 05:31:28,811 - DEBUG - Q-vals = [0.16921325 0.08150596 0.14763127 0.0525634  0.24290147 0.10687868
 0.19930597], best_act=4, best_val=0.243
2025-01-16 05:31:28,811 - DEBUG - Low Q-value (0.243), using MCTS.
2025-01-16 05:31:28,811 - INFO - Running MCTS with 154 simulations using 6 processes.
2025-01-16 05:31:31,846 - DEBUG - Aggregated action counts: {0: 2, 1: 1, 2: 1, 6: 1, 4: 1, 3: 1}
2025-01-16 05:31:31,846 - DEBUG - Chose best action 0
2025-01-16 05:31:32,018 - INFO - Episode 3601/98900: Winner=2, Reward=21.40, EPSILON=0.968, (W=1175,D=6,L=0)
2025-01-16 05:31:32,361 - INFO - Episode 3602/98900: Winner=2, Reward=-49.15, EPSILON=0.968, (W=1175,D=6,L=0)
2025-01-16 05:31:32,549 - INFO - Episode 3603/98900: Winner=2, Reward=-10.70, EPSILON=0.968, (W=1176,D=6,L=0)
2025-01-16 05:31:32,564 - DEBUG - Q-vals = [0.4230063  0.01643863 0.02963168 0.00871243 0.4153109  0.01682705
 0.09007303], best_act=0, best_val=0.423
2025-01-16 05:31:32,564 - DEBUG - Low Q-value (0.423), using MCTS.
2025-01-16 05:31:32,564 - INFO - Running MCTS with 154 simulations using 6 processes.
2025-01-16 05:31:36,076 - DEBUG - Aggregated action counts: {1: 2, 2: 1, 6: 1, 3: 1, 4: 1, 0: 1}
2025-01-16 05:31:36,076 - DEBUG - Chose best action 1
2025-01-16 05:31:36,397 - INFO - Episode 3604/98900: Winner=2, Reward=-45.45, EPSILON=0.968, (W=1177,D=6,L=0)
2025-01-16 05:31:36,463 - INFO - Episode 3605/98900: Winner=2, Reward=0.25, EPSILON=0.968, (W=1177,D=6,L=0)
2025-01-16 05:31:36,514 - DEBUG - Q-vals = [0.30278966 0.05668638 0.12172692 0.20685115 0.0876281  0.04218679
 0.1821311 ], best_act=0, best_val=0.303
2025-01-16 05:31:36,514 - DEBUG - Low Q-value (0.303), using MCTS.
2025-01-16 05:31:36,514 - INFO - Running MCTS with 154 simulations using 6 processes.
2025-01-16 05:31:39,825 - DEBUG - Aggregated action counts: {3: 1, 0: 3, 2: 3}
2025-01-16 05:31:39,825 - DEBUG - Chose best action 0
2025-01-16 05:31:40,083 - INFO - Episode 3606/98900: Winner=2, Reward=13.75, EPSILON=0.968, (W=1177,D=6,L=0)
2025-01-16 05:31:40,469 - INFO - Episode 3607/98900: Winner=2, Reward=-33.85, EPSILON=0.968, (W=1178,D=6,L=0)
2025-01-16 05:31:40,766 - INFO - Episode 3608/98900: Winner=2, Reward=-10.70, EPSILON=0.968, (W=1178,D=6,L=0)
2025-01-16 05:31:41,110 - INFO - Episode 3609/98900: Winner=2, Reward=-42.90, EPSILON=0.968, (W=1179,D=6,L=0)
2025-01-16 05:31:41,313 - INFO - Episode 3610/98900: Winner=2, Reward=-6.45, EPSILON=0.968, (W=1180,D=6,L=0)
2025-01-16 05:31:41,451 - INFO - Episode 3611/98900: Winner=2, Reward=-12.55, EPSILON=0.968, (W=1181,D=6,L=0)
2025-01-16 05:31:41,483 - DEBUG - Q-vals = [0.3006951  0.03478752 0.03516184 0.11242996 0.14099523 0.16044676
 0.2154835 ], best_act=0, best_val=0.301
2025-01-16 05:31:41,483 - DEBUG - Low Q-value (0.301), using MCTS.
2025-01-16 05:31:41,483 - INFO - Running MCTS with 154 simulations using 6 processes.
2025-01-16 05:31:44,530 - DEBUG - Aggregated action counts: {2: 1, 3: 1, 1: 3, 4: 1, 0: 1}
2025-01-16 05:31:44,530 - DEBUG - Chose best action 1
2025-01-16 05:31:44,608 - INFO - Episode 3612/98900: Winner=2, Reward=-5.55, EPSILON=0.968, (W=1182,D=6,L=0)
2025-01-16 05:31:44,858 - INFO - Episode 3613/98900: Winner=2, Reward=-20.25, EPSILON=0.968, (W=1183,D=6,L=0)
2025-01-16 05:31:45,045 - INFO - Episode 3614/98900: Winner=2, Reward=-2.55, EPSILON=0.968, (W=1183,D=6,L=0)
2025-01-16 05:31:45,155 - DEBUG - Q-vals = [0.2198533  0.13819169 0.08927786 0.11824688 0.15214393 0.14340913
 0.1388773 ], best_act=0, best_val=0.220
2025-01-16 05:31:45,155 - DEBUG - Low Q-value (0.220), using MCTS.
2025-01-16 05:31:45,155 - INFO - Running MCTS with 154 simulations using 6 processes.
2025-01-16 05:31:47,951 - DEBUG - Aggregated action counts: {1: 2, 0: 2, 3: 2, 2: 1}
2025-01-16 05:31:47,951 - DEBUG - Chose best action 1
2025-01-16 05:31:48,013 - INFO - Episode 3615/98900: Winner=2, Reward=-1.85, EPSILON=0.968, (W=1183,D=6,L=0)
2025-01-16 05:31:48,154 - INFO - Episode 3616/98900: Winner=2, Reward=12.85, EPSILON=0.968, (W=1183,D=6,L=0)
2025-01-16 05:31:48,388 - INFO - Episode 3617/98900: Winner=2, Reward=-12.70, EPSILON=0.968, (W=1184,D=6,L=0)
2025-01-16 05:31:48,607 - INFO - Episode 3618/98900: Winner=2, Reward=-24.80, EPSILON=0.968, (W=1185,D=6,L=0)
2025-01-16 05:31:48,826 - INFO - Episode 3619/98900: Winner=2, Reward=-28.10, EPSILON=0.968, (W=1185,D=6,L=0)
2025-01-16 05:31:48,888 - INFO - Episode 3620/98900: Winner=2, Reward=0.25, EPSILON=0.968, (W=1185,D=6,L=0)
2025-01-16 05:31:49,029 - DEBUG - Q-vals = [0.13144444 0.10297067 0.11625637 0.25128528 0.11137076 0.10414586
 0.18252666], best_act=3, best_val=0.251
2025-01-16 05:31:49,029 - DEBUG - Low Q-value (0.251), using MCTS.
2025-01-16 05:31:49,029 - INFO - Running MCTS with 154 simulations using 6 processes.
2025-01-16 05:31:51,856 - DEBUG - Aggregated action counts: {0: 4, 5: 1, 4: 1, 3: 1}
2025-01-16 05:31:51,856 - DEBUG - Chose best action 0
2025-01-16 05:31:51,997 - INFO - Episode 3621/98900: Winner=2, Reward=-25.55, EPSILON=0.968, (W=1185,D=6,L=0)
2025-01-16 05:31:52,153 - INFO - Episode 3622/98900: Winner=2, Reward=-1.90, EPSILON=0.968, (W=1185,D=6,L=0)
2025-01-16 05:31:52,278 - DEBUG - Q-vals = [0.11866038 0.09122177 0.09807859 0.30660918 0.0967086  0.09429175
 0.19442967], best_act=3, best_val=0.307
2025-01-16 05:31:52,278 - DEBUG - Low Q-value (0.307), using MCTS.
2025-01-16 05:31:52,278 - INFO - Running MCTS with 154 simulations using 6 processes.
2025-01-16 05:31:55,122 - DEBUG - Aggregated action counts: {6: 1, 2: 2, 3: 2, 1: 1, 0: 1}
2025-01-16 05:31:55,122 - DEBUG - Chose best action 2
2025-01-16 05:31:55,200 - INFO - Episode 3623/98900: Winner=2, Reward=1.45, EPSILON=0.968, (W=1185,D=6,L=0)
2025-01-16 05:31:55,372 - INFO - Episode 3624/98900: Winner=2, Reward=0.65, EPSILON=0.968, (W=1185,D=6,L=0)
2025-01-16 05:31:55,544 - INFO - Episode 3625/98900: Winner=2, Reward=-1.30, EPSILON=0.968, (W=1186,D=6,L=0)
2025-01-16 05:31:55,825 - INFO - Episode 3626/98900: Winner=2, Reward=-12.70, EPSILON=0.968, (W=1186,D=6,L=0)
2025-01-16 05:31:56,121 - INFO - Episode 3627/98900: Winner=2, Reward=-23.30, EPSILON=0.968, (W=1186,D=6,L=0)
2025-01-16 05:31:56,418 - DEBUG - Q-vals = [0.04067584 0.02107066 0.08681163 0.03520603 0.13212751 0.02270356
 0.6614047 ], best_act=6, best_val=0.661
2025-01-16 05:31:56,418 - DEBUG - Low Q-value (0.661), using MCTS.
2025-01-16 05:31:56,418 - INFO - Running MCTS with 155 simulations using 6 processes.
2025-01-16 05:31:59,183 - DEBUG - Aggregated action counts: {1: 4, 4: 1, 5: 1, 2: 1}
2025-01-16 05:31:59,199 - DEBUG - Chose best action 1
2025-01-16 05:31:59,277 - INFO - Episode 3628/98900: Winner=2, Reward=-22.15, EPSILON=0.968, (W=1186,D=6,L=0)
2025-01-16 05:31:59,511 - INFO - Episode 3629/98900: Winner=2, Reward=3.95, EPSILON=0.968, (W=1186,D=6,L=0)
2025-01-16 05:31:59,792 - INFO - Episode 3630/98900: Winner=2, Reward=7.00, EPSILON=0.968, (W=1186,D=6,L=0)
2025-01-16 05:31:59,964 - INFO - Episode 3631/98900: Winner=2, Reward=0.45, EPSILON=0.968, (W=1187,D=6,L=0)
2025-01-16 05:32:00,089 - INFO - Episode 3632/98900: Winner=2, Reward=-6.60, EPSILON=0.968, (W=1188,D=6,L=0)
2025-01-16 05:32:00,230 - DEBUG - Q-vals = [0.15359789 0.15579724 0.09428583 0.13883615 0.19540979 0.08455271
 0.17752035], best_act=4, best_val=0.195
2025-01-16 05:32:00,230 - DEBUG - Low Q-value (0.195), using MCTS.
2025-01-16 05:32:00,246 - INFO - Episode 3633/98900: Winner=2, Reward=-8.35, EPSILON=0.968, (W=1189,D=6,L=0)
2025-01-16 05:32:00,339 - INFO - Episode 3634/98900: Winner=2, Reward=15.20, EPSILON=0.968, (W=1189,D=6,L=0)
2025-01-16 05:32:00,417 - INFO - Episode 3635/98900: Winner=2, Reward=14.25, EPSILON=0.968, (W=1189,D=6,L=0)
2025-01-16 05:32:00,699 - INFO - Episode 3636/98900: Winner=2, Reward=-20.05, EPSILON=0.968, (W=1190,D=6,L=0)
2025-01-16 05:32:01,042 - INFO - Episode 3637/98900: Winner=2, Reward=-44.20, EPSILON=0.968, (W=1191,D=6,L=0)
2025-01-16 05:32:01,214 - INFO - Episode 3638/98900: Winner=2, Reward=15.85, EPSILON=0.968, (W=1191,D=6,L=0)
2025-01-16 05:32:01,448 - INFO - Episode 3639/98900: Winner=2, Reward=-17.60, EPSILON=0.968, (W=1192,D=6,L=0)
2025-01-16 05:32:01,589 - INFO - Episode 3640/98900: Winner=2, Reward=-12.05, EPSILON=0.968, (W=1193,D=6,L=0)
2025-01-16 05:32:01,651 - INFO - Episode 3641/98900: Winner=2, Reward=0.55, EPSILON=0.968, (W=1193,D=6,L=0)
2025-01-16 05:32:01,948 - INFO - Episode 3642/98900: Winner=2, Reward=-29.20, EPSILON=0.968, (W=1194,D=6,L=0)
2025-01-16 05:32:02,292 - INFO - Episode 3643/98900: Winner=2, Reward=-73.90, EPSILON=0.968, (W=1195,D=6,L=0)
2025-01-16 05:32:02,464 - INFO - Episode 3644/98900: Winner=2, Reward=-17.70, EPSILON=0.968, (W=1196,D=6,L=0)
2025-01-16 05:32:02,573 - INFO - Episode 3645/98900: Winner=2, Reward=-11.20, EPSILON=0.968, (W=1197,D=6,L=0)
2025-01-16 05:32:02,854 - INFO - Episode 3646/98900: Winner=2, Reward=4.40, EPSILON=0.968, (W=1197,D=6,L=0)
2025-01-16 05:32:03,120 - INFO - Episode 3647/98900: Winner=2, Reward=-25.30, EPSILON=0.968, (W=1198,D=6,L=0)
2025-01-16 05:32:03,276 - INFO - Episode 3648/98900: Winner=2, Reward=6.95, EPSILON=0.968, (W=1198,D=6,L=0)
2025-01-16 05:32:03,448 - INFO - Episode 3649/98900: Winner=2, Reward=-11.20, EPSILON=0.968, (W=1199,D=6,L=0)
2025-01-16 05:32:03,604 - INFO - Episode 3650/98900: Winner=2, Reward=2.50, EPSILON=0.968, (W=1199,D=6,L=0)
2025-01-16 05:32:03,745 - INFO - Episode 3651/98900: Winner=2, Reward=4.45, EPSILON=0.968, (W=1199,D=6,L=0)
2025-01-16 05:32:04,058 - INFO - Episode 3652/98900: Winner=2, Reward=14.45, EPSILON=0.968, (W=1199,D=6,L=0)
2025-01-16 05:32:04,229 - INFO - Episode 3653/98900: Winner=2, Reward=2.60, EPSILON=0.968, (W=1199,D=6,L=0)
2025-01-16 05:32:04,261 - DEBUG - Q-vals = [0.27331585 0.03261087 0.12988113 0.3826862  0.05532865 0.01208852
 0.1140888 ], best_act=3, best_val=0.383
2025-01-16 05:32:04,261 - DEBUG - Low Q-value (0.383), using MCTS.
2025-01-16 05:32:04,261 - INFO - Running MCTS with 156 simulations using 6 processes.
2025-01-16 05:32:07,072 - DEBUG - Aggregated action counts: {0: 1, 2: 2, 5: 2, 1: 1}
2025-01-16 05:32:07,072 - DEBUG - Chose best action 2
2025-01-16 05:32:07,338 - INFO - Episode 3654/98900: Winner=2, Reward=1.45, EPSILON=0.968, (W=1199,D=6,L=0)
2025-01-16 05:32:07,447 - DEBUG - Q-vals = [0.15723255 0.13459533 0.10728779 0.04583905 0.2626195  0.20076147
 0.0916642 ], best_act=4, best_val=0.263
2025-01-16 05:32:07,447 - DEBUG - Low Q-value (0.263), using MCTS.
2025-01-16 05:32:07,447 - INFO - Running MCTS with 156 simulations using 6 processes.
2025-01-16 05:32:10,353 - DEBUG - Aggregated action counts: {5: 3, 0: 1, 2: 1, 1: 1}
2025-01-16 05:32:10,353 - DEBUG - Chose best action 5
2025-01-16 05:32:10,447 - INFO - Episode 3655/98900: Winner=2, Reward=-3.85, EPSILON=0.968, (W=1199,D=6,L=0)
2025-01-16 05:32:10,541 - INFO - Episode 3656/98900: Winner=2, Reward=0.00, EPSILON=0.968, (W=1199,D=6,L=0)
2025-01-16 05:32:10,697 - INFO - Episode 3657/98900: Winner=2, Reward=-2.55, EPSILON=0.968, (W=1199,D=6,L=0)
2025-01-16 05:32:10,916 - DEBUG - Q-vals = [0.18503653 0.10168476 0.06068164 0.05670117 0.25929415 0.16609359
 0.17050816], best_act=4, best_val=0.259
2025-01-16 05:32:10,916 - DEBUG - Low Q-value (0.259), using MCTS.
2025-01-16 05:32:10,916 - INFO - Running MCTS with 156 simulations using 6 processes.
2025-01-16 05:32:13,660 - DEBUG - Aggregated action counts: {3: 4, 5: 2}
2025-01-16 05:32:13,660 - DEBUG - Chose best action 3
2025-01-16 05:32:13,671 - INFO - Episode 3658/98900: Winner=2, Reward=-0.05, EPSILON=0.968, (W=1199,D=6,L=0)
2025-01-16 05:32:13,815 - INFO - Episode 3659/98900: Winner=2, Reward=-0.60, EPSILON=0.968, (W=1199,D=6,L=0)
2025-01-16 05:32:13,967 - INFO - Episode 3660/98900: Winner=2, Reward=-9.55, EPSILON=0.968, (W=1200,D=6,L=0)
2025-01-16 05:32:14,131 - DEBUG - Q-vals = [0.16375387 0.1156209  0.1927834  0.29886895 0.05680262 0.03552236
 0.13664785], best_act=3, best_val=0.299
2025-01-16 05:32:14,131 - DEBUG - Low Q-value (0.299), using MCTS.
2025-01-16 05:32:14,146 - INFO - Episode 3661/98900: Winner=2, Reward=-15.15, EPSILON=0.968, (W=1201,D=6,L=0)
2025-01-16 05:32:14,287 - DEBUG - Q-vals = [0.26575497 0.28173563 0.04673551 0.08536869 0.1449574  0.08610826
 0.08933952], best_act=1, best_val=0.282
2025-01-16 05:32:14,287 - DEBUG - Low Q-value (0.282), using MCTS.
2025-01-16 05:32:14,287 - INFO - Running MCTS with 156 simulations using 6 processes.
2025-01-16 05:32:17,106 - DEBUG - Aggregated action counts: {2: 1, 4: 1, 1: 1, 0: 3}
2025-01-16 05:32:17,106 - DEBUG - Chose best action 0
2025-01-16 05:32:17,192 - INFO - Episode 3662/98900: Winner=2, Reward=-5.05, EPSILON=0.968, (W=1201,D=6,L=0)
2025-01-16 05:32:17,455 - INFO - Episode 3663/98900: Winner=2, Reward=-12.80, EPSILON=0.968, (W=1202,D=6,L=0)
2025-01-16 05:32:17,788 - INFO - Episode 3664/98900: Winner=2, Reward=-45.95, EPSILON=0.968, (W=1203,D=6,L=0)
2025-01-16 05:32:17,897 - INFO - Episode 3665/98900: Winner=2, Reward=0.95, EPSILON=0.968, (W=1203,D=6,L=0)
2025-01-16 05:32:18,055 - INFO - Episode 3666/98900: Winner=2, Reward=-3.20, EPSILON=0.968, (W=1203,D=6,L=0)
2025-01-16 05:32:18,469 - INFO - Episode 3667/98900: Winner=2, Reward=-50.10, EPSILON=0.968, (W=1204,D=6,L=0)
2025-01-16 05:32:18,747 - INFO - Episode 3668/98900: Winner=2, Reward=-6.85, EPSILON=0.968, (W=1204,D=6,L=0)
2025-01-16 05:32:18,881 - INFO - Episode 3669/98900: Winner=2, Reward=-0.80, EPSILON=0.968, (W=1204,D=6,L=0)
2025-01-16 05:32:19,337 - INFO - Episode 3670/98900: Winner=2, Reward=-78.25, EPSILON=0.968, (W=1205,D=6,L=0)
2025-01-16 05:32:19,618 - INFO - Episode 3671/98900: Winner=2, Reward=-11.85, EPSILON=0.968, (W=1205,D=6,L=0)
2025-01-16 05:32:19,834 - INFO - Episode 3672/98900: Winner=2, Reward=15.15, EPSILON=0.967, (W=1205,D=6,L=0)
2025-01-16 05:32:19,922 - INFO - Episode 3673/98900: Winner=2, Reward=-9.35, EPSILON=0.967, (W=1206,D=6,L=0)
2025-01-16 05:32:20,129 - DEBUG - Q-vals = [0.17738222 0.22528347 0.02563989 0.08797032 0.07083379 0.2881895
 0.12470082], best_act=5, best_val=0.288
2025-01-16 05:32:20,129 - DEBUG - Low Q-value (0.288), using MCTS.
2025-01-16 05:32:20,140 - INFO - Episode 3674/98900: Winner=2, Reward=-16.70, EPSILON=0.967, (W=1207,D=6,L=0)
2025-01-16 05:32:20,249 - INFO - Episode 3675/98900: Winner=2, Reward=-9.85, EPSILON=0.967, (W=1208,D=6,L=0)
2025-01-16 05:32:20,446 - INFO - Episode 3676/98900: Winner=2, Reward=23.85, EPSILON=0.967, (W=1208,D=6,L=0)
2025-01-16 05:32:20,752 - INFO - Episode 3677/98900: Winner=2, Reward=-59.70, EPSILON=0.967, (W=1209,D=6,L=0)
2025-01-16 05:32:20,937 - INFO - Episode 3678/98900: Winner=2, Reward=5.30, EPSILON=0.967, (W=1209,D=6,L=0)
2025-01-16 05:32:21,027 - INFO - Episode 3679/98900: Winner=2, Reward=0.55, EPSILON=0.967, (W=1209,D=6,L=0)
2025-01-16 05:32:21,225 - INFO - Episode 3680/98900: Winner=2, Reward=-12.40, EPSILON=0.967, (W=1210,D=6,L=0)
2025-01-16 05:32:21,302 - DEBUG - Q-vals = [0.14282939 0.15528014 0.11742513 0.09668081 0.13856813 0.19029558
 0.1589209 ], best_act=5, best_val=0.190
2025-01-16 05:32:21,302 - DEBUG - Low Q-value (0.190), using MCTS.
2025-01-16 05:32:21,302 - INFO - Running MCTS with 157 simulations using 6 processes.
2025-01-16 05:32:24,551 - DEBUG - Aggregated action counts: {0: 2, 1: 1, 3: 3, 5: 1}
2025-01-16 05:32:24,551 - DEBUG - Chose best action 3
2025-01-16 05:32:24,701 - INFO - Episode 3681/98900: Winner=2, Reward=-3.20, EPSILON=0.967, (W=1210,D=6,L=0)
2025-01-16 05:32:25,006 - INFO - Episode 3682/98900: Winner=2, Reward=-33.80, EPSILON=0.967, (W=1211,D=6,L=0)
2025-01-16 05:32:25,200 - INFO - Episode 3683/98900: Winner=2, Reward=7.30, EPSILON=0.967, (W=1211,D=6,L=0)
2025-01-16 05:32:25,307 - INFO - Episode 3684/98900: Winner=2, Reward=6.65, EPSILON=0.967, (W=1211,D=6,L=0)
2025-01-16 05:32:25,385 - DEBUG - Q-vals = [0.16440213 0.12217664 0.1262334  0.11567785 0.14756872 0.14009143
 0.18384981], best_act=6, best_val=0.184
2025-01-16 05:32:25,385 - DEBUG - Low Q-value (0.184), using MCTS.
2025-01-16 05:32:25,385 - INFO - Running MCTS with 157 simulations using 6 processes.
2025-01-16 05:32:28,688 - DEBUG - Aggregated action counts: {2: 2, 0: 2, 1: 1, 3: 1, 4: 1}
2025-01-16 05:32:28,688 - DEBUG - Chose best action 2
2025-01-16 05:32:28,808 - INFO - Episode 3685/98900: Winner=2, Reward=8.15, EPSILON=0.967, (W=1211,D=6,L=0)
2025-01-16 05:32:28,955 - INFO - Episode 3686/98900: Winner=2, Reward=-7.35, EPSILON=0.967, (W=1212,D=6,L=0)
2025-01-16 05:32:29,064 - DEBUG - Q-vals = [0.16535388 0.15720868 0.11521558 0.0255063  0.11299002 0.27585313
 0.14787239], best_act=5, best_val=0.276
2025-01-16 05:32:29,064 - DEBUG - Low Q-value (0.276), using MCTS.
2025-01-16 05:32:29,064 - INFO - Running MCTS with 157 simulations using 6 processes.
2025-01-16 05:32:32,318 - DEBUG - Aggregated action counts: {1: 2, 3: 2, 0: 2, 2: 1}
2025-01-16 05:32:32,318 - DEBUG - Chose best action 1
2025-01-16 05:32:32,438 - INFO - Episode 3687/98900: Winner=2, Reward=-14.35, EPSILON=0.967, (W=1212,D=6,L=0)
2025-01-16 05:32:32,709 - INFO - Episode 3688/98900: Winner=2, Reward=-17.05, EPSILON=0.967, (W=1213,D=6,L=0)
2025-01-16 05:32:33,078 - INFO - Episode 3689/98900: Winner=2, Reward=-23.00, EPSILON=0.967, (W=1213,D=6,L=0)
2025-01-16 05:32:33,443 - INFO - Episode 3690/98900: Winner=2, Reward=4.30, EPSILON=0.967, (W=1213,D=6,L=0)
2025-01-16 05:32:33,598 - DEBUG - Q-vals = [0.1958637  0.139295   0.11136874 0.15173197 0.13744506 0.08885248
 0.17544304], best_act=0, best_val=0.196
2025-01-16 05:32:33,598 - DEBUG - Low Q-value (0.196), using MCTS.
2025-01-16 05:32:33,599 - INFO - Running MCTS with 157 simulations using 6 processes.
2025-01-16 05:32:36,415 - DEBUG - Aggregated action counts: {0: 2, 2: 1, 6: 2, 5: 1, 1: 1}
2025-01-16 05:32:36,415 - DEBUG - Chose best action 0
2025-01-16 05:32:36,525 - INFO - Episode 3691/98900: Winner=2, Reward=-10.60, EPSILON=0.967, (W=1214,D=6,L=0)
2025-01-16 05:32:36,634 - INFO - Episode 3692/98900: Winner=2, Reward=0.45, EPSILON=0.967, (W=1214,D=6,L=0)
2025-01-16 05:32:36,822 - INFO - Episode 3693/98900: Winner=2, Reward=-11.25, EPSILON=0.967, (W=1215,D=6,L=0)
2025-01-16 05:32:37,103 - INFO - Episode 3694/98900: Winner=2, Reward=-4.55, EPSILON=0.967, (W=1215,D=6,L=0)
2025-01-16 05:32:37,212 - INFO - Episode 3695/98900: Winner=2, Reward=1.20, EPSILON=0.967, (W=1215,D=6,L=0)
2025-01-16 05:32:37,431 - INFO - Episode 3696/98900: Winner=2, Reward=0.45, EPSILON=0.967, (W=1215,D=6,L=0)
2025-01-16 05:32:37,697 - DEBUG - Q-vals = [0.10005698 0.09087556 0.10234832 0.24478953 0.15129822 0.07461032
 0.23602098], best_act=3, best_val=0.245
2025-01-16 05:32:37,697 - DEBUG - Low Q-value (0.245), using MCTS.
2025-01-16 05:32:37,712 - INFO - Episode 3697/98900: Winner=2, Reward=-21.95, EPSILON=0.967, (W=1216,D=6,L=0)
2025-01-16 05:32:37,994 - DEBUG - Q-vals = [0.06495455 0.05358375 0.09636001 0.27093992 0.14704977 0.05270956
 0.31440252], best_act=6, best_val=0.314
2025-01-16 05:32:37,994 - DEBUG - Low Q-value (0.314), using MCTS.
2025-01-16 05:32:38,009 - INFO - Episode 3698/98900: Winner=2, Reward=-29.60, EPSILON=0.967, (W=1217,D=6,L=0)
2025-01-16 05:32:38,259 - INFO - Episode 3699/98900: Winner=2, Reward=28.65, EPSILON=0.967, (W=1217,D=6,L=0)
2025-01-16 05:32:38,431 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3700.
2025-01-16 05:32:38,431 - INFO - Models saved at episode 3700
2025-01-16 05:32:38,431 - INFO - Target networks updated
2025-01-16 05:32:38,494 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3700.
2025-01-16 05:32:38,494 - INFO - Episode 3700/98900: Winner=2, Reward=2.75, EPSILON=0.967, (W=1217,D=6,L=0)
2025-01-16 05:32:38,634 - DEBUG - Q-vals = [0.15400457 0.08951648 0.09072433 0.13597818 0.20871283 0.12728414
 0.19377942], best_act=4, best_val=0.209
2025-01-16 05:32:38,634 - DEBUG - Low Q-value (0.209), using MCTS.
2025-01-16 05:32:38,634 - INFO - Running MCTS with 158 simulations using 6 processes.
2025-01-16 05:32:41,446 - DEBUG - Aggregated action counts: {2: 1, 0: 6}
2025-01-16 05:32:41,446 - DEBUG - Chose best action 0
2025-01-16 05:32:41,555 - INFO - Episode 3701/98900: Winner=2, Reward=-11.05, EPSILON=0.967, (W=1218,D=6,L=0)
2025-01-16 05:32:41,696 - INFO - Episode 3702/98900: Winner=2, Reward=15.45, EPSILON=0.967, (W=1218,D=6,L=0)
2025-01-16 05:32:41,946 - DEBUG - Q-vals = [0.11953663 0.05423453 0.14170222 0.4365452  0.06418981 0.01962482
 0.16416675], best_act=3, best_val=0.437
2025-01-16 05:32:41,946 - DEBUG - Low Q-value (0.437), using MCTS.
2025-01-16 05:32:41,946 - INFO - Episode 3703/98900: Winner=2, Reward=6.00, EPSILON=0.967, (W=1219,D=6,L=0)
2025-01-16 05:32:42,180 - INFO - Episode 3704/98900: Winner=2, Reward=-16.55, EPSILON=0.967, (W=1220,D=6,L=0)
2025-01-16 05:32:42,461 - INFO - Episode 3705/98900: Winner=2, Reward=13.70, EPSILON=0.967, (W=1221,D=6,L=0)
2025-01-16 05:32:42,649 - DEBUG - Q-vals = [0.13070245 0.20223078 0.05351433 0.07944063 0.11856175 0.25166157
 0.16388851], best_act=5, best_val=0.252
2025-01-16 05:32:42,649 - DEBUG - Low Q-value (0.252), using MCTS.
2025-01-16 05:32:42,649 - INFO - Running MCTS with 158 simulations using 6 processes.
2025-01-16 05:32:45,586 - DEBUG - Aggregated action counts: {6: 2, 1: 1, 2: 1, 3: 1, 0: 2}
2025-01-16 05:32:45,586 - DEBUG - Chose best action 6
2025-01-16 05:32:45,711 - INFO - Episode 3706/98900: Winner=2, Reward=-6.70, EPSILON=0.967, (W=1221,D=6,L=0)
2025-01-16 05:32:45,836 - INFO - Episode 3707/98900: Winner=2, Reward=0.10, EPSILON=0.967, (W=1221,D=6,L=0)
2025-01-16 05:32:46,148 - INFO - Episode 3708/98900: Winner=2, Reward=-32.30, EPSILON=0.967, (W=1221,D=6,L=0)
2025-01-16 05:32:46,430 - INFO - Episode 3709/98900: Winner=2, Reward=10.60, EPSILON=0.967, (W=1221,D=6,L=0)
2025-01-16 05:32:46,633 - INFO - Episode 3710/98900: Winner=2, Reward=-6.80, EPSILON=0.967, (W=1221,D=6,L=0)
2025-01-16 05:32:46,851 - INFO - Episode 3711/98900: Winner=2, Reward=6.05, EPSILON=0.967, (W=1221,D=6,L=0)
2025-01-16 05:32:47,055 - INFO - Episode 3712/98900: Winner=2, Reward=-15.70, EPSILON=0.967, (W=1222,D=6,L=0)
2025-01-16 05:32:47,226 - INFO - Episode 3713/98900: Winner=2, Reward=-15.35, EPSILON=0.967, (W=1223,D=6,L=0)
2025-01-16 05:32:47,304 - DEBUG - Q-vals = [0.17833903 0.09383223 0.06198375 0.11144457 0.23419856 0.16361135
 0.15659054], best_act=4, best_val=0.234
2025-01-16 05:32:47,304 - DEBUG - Low Q-value (0.234), using MCTS.
2025-01-16 05:32:47,304 - INFO - Running MCTS with 158 simulations using 6 processes.
2025-01-16 05:32:50,038 - DEBUG - Aggregated action counts: {4: 1, 3: 1, 2: 1, 0: 2, 1: 2}
2025-01-16 05:32:50,038 - DEBUG - Chose best action 0
2025-01-16 05:32:50,054 - INFO - Episode 3714/98900: Winner=2, Reward=9.80, EPSILON=0.967, (W=1223,D=6,L=0)
2025-01-16 05:32:50,132 - DEBUG - Q-vals = [0.1752451  0.05495959 0.14632156 0.33305213 0.06950411 0.12555453
 0.09536285], best_act=3, best_val=0.333
2025-01-16 05:32:50,132 - DEBUG - Low Q-value (0.333), using MCTS.
2025-01-16 05:32:50,132 - INFO - Running MCTS with 158 simulations using 6 processes.
2025-01-16 05:32:52,959 - DEBUG - Aggregated action counts: {1: 1, 3: 2, 0: 2, 4: 1, 2: 1}
2025-01-16 05:32:52,959 - DEBUG - Chose best action 3
2025-01-16 05:32:53,241 - INFO - Episode 3715/98900: Winner=2, Reward=-45.00, EPSILON=0.967, (W=1223,D=6,L=0)
2025-01-16 05:32:53,600 - INFO - Episode 3716/98900: Winner=2, Reward=-46.30, EPSILON=0.967, (W=1224,D=6,L=0)
2025-01-16 05:32:53,865 - DEBUG - Q-vals = [0.10794266 0.12171625 0.08737995 0.10262915 0.26222974 0.1570014
 0.16110088], best_act=6, best_val=0.161
2025-01-16 05:32:53,865 - DEBUG - Low Q-value (0.161), using MCTS.
2025-01-16 05:32:53,865 - INFO - Episode 3717/98900: Winner=2, Reward=-26.80, EPSILON=0.967, (W=1225,D=6,L=0)
2025-01-16 05:32:54,022 - DEBUG - Q-vals = [0.02836684 0.02167511 0.19253118 0.07416462 0.1711345  0.11992638
 0.3922014 ], best_act=6, best_val=0.392
2025-01-16 05:32:54,022 - DEBUG - Low Q-value (0.392), using MCTS.
2025-01-16 05:32:54,022 - INFO - Episode 3718/98900: Winner=2, Reward=-3.80, EPSILON=0.967, (W=1226,D=6,L=0)
2025-01-16 05:32:54,115 - DEBUG - Q-vals = [0.27672198 0.18297689 0.08599216 0.13018376 0.10588398 0.100871
 0.11737018], best_act=0, best_val=0.277
2025-01-16 05:32:54,115 - DEBUG - Low Q-value (0.277), using MCTS.
2025-01-16 05:32:54,115 - INFO - Running MCTS with 158 simulations using 6 processes.
2025-01-16 05:32:56,982 - DEBUG - Aggregated action counts: {4: 1, 0: 3, 3: 2, 1: 1}
2025-01-16 05:32:56,982 - DEBUG - Chose best action 0
2025-01-16 05:32:57,153 - INFO - Episode 3719/98900: Winner=2, Reward=18.20, EPSILON=0.967, (W=1226,D=6,L=0)
2025-01-16 05:32:57,263 - INFO - Episode 3720/98900: Winner=2, Reward=5.20, EPSILON=0.967, (W=1226,D=6,L=0)
2025-01-16 05:32:57,341 - DEBUG - Q-vals = [0.15312538 0.12892833 0.13407753 0.177232   0.13409053 0.11305297
 0.15949328], best_act=3, best_val=0.177
2025-01-16 05:32:57,341 - DEBUG - Low Q-value (0.177), using MCTS.
2025-01-16 05:32:57,341 - INFO - Running MCTS with 158 simulations using 6 processes.
2025-01-16 05:33:00,756 - DEBUG - Aggregated action counts: {4: 4, 0: 3}
2025-01-16 05:33:00,756 - DEBUG - Chose best action 4
2025-01-16 05:33:00,865 - INFO - Episode 3721/98900: Winner=2, Reward=2.35, EPSILON=0.967, (W=1227,D=6,L=0)
2025-01-16 05:33:01,240 - INFO - Episode 3722/98900: Winner=2, Reward=-49.90, EPSILON=0.967, (W=1227,D=6,L=0)
2025-01-16 05:33:01,365 - DEBUG - Q-vals = [0.13264324 0.13625409 0.12662768 0.18778728 0.10578827 0.10993213
 0.20096742], best_act=6, best_val=0.201
2025-01-16 05:33:01,365 - DEBUG - Low Q-value (0.201), using MCTS.
2025-01-16 05:33:01,365 - INFO - Episode 3723/98900: Winner=2, Reward=-10.15, EPSILON=0.967, (W=1228,D=6,L=0)
2025-01-16 05:33:01,568 - DEBUG - Q-vals = [0.17274398 0.22555667 0.06853748 0.03540589 0.28651315 0.13953006
 0.07171277], best_act=4, best_val=0.287
2025-01-16 05:33:01,568 - DEBUG - Low Q-value (0.287), using MCTS.
2025-01-16 05:33:01,584 - INFO - Episode 3724/98900: Winner=2, Reward=-10.35, EPSILON=0.967, (W=1229,D=6,L=0)
2025-01-16 05:33:01,787 - INFO - Episode 3725/98900: Winner=2, Reward=10.15, EPSILON=0.967, (W=1229,D=6,L=0)
2025-01-16 05:33:02,052 - INFO - Episode 3726/98900: Winner=2, Reward=-32.85, EPSILON=0.967, (W=1230,D=6,L=0)
2025-01-16 05:33:02,068 - DEBUG - Q-vals = [0.02625025 0.00521086 0.02293169 0.04878347 0.00941275 0.01476034
 0.8726506 ], best_act=6, best_val=0.873
2025-01-16 05:33:02,068 - DEBUG - Low Q-value (0.873), using MCTS.
2025-01-16 05:33:02,068 - INFO - Running MCTS with 159 simulations using 6 processes.
2025-01-16 05:33:05,091 - DEBUG - Aggregated action counts: {1: 2, 0: 2, 3: 1, 2: 2}
2025-01-16 05:33:05,091 - DEBUG - Chose best action 1
2025-01-16 05:33:05,210 - DEBUG - Q-vals = [0.15991066 0.1284506  0.13535663 0.12854527 0.14054736 0.12606047
 0.18112901], best_act=6, best_val=0.181
2025-01-16 05:33:05,210 - DEBUG - Low Q-value (0.181), using MCTS.
2025-01-16 05:33:05,211 - INFO - Running MCTS with 159 simulations using 6 processes.
2025-01-16 05:33:08,156 - DEBUG - Aggregated action counts: {3: 4, 0: 2, 6: 1}
2025-01-16 05:33:08,156 - DEBUG - Chose best action 3
2025-01-16 05:33:08,291 - INFO - Episode 3727/98900: Winner=2, Reward=-25.15, EPSILON=0.967, (W=1231,D=6,L=0)
2025-01-16 05:33:08,669 - DEBUG - Q-vals = [0.16944762 0.09127928 0.08330166 0.24253137 0.2548226  0.06359378
 0.09502358], best_act=4, best_val=0.255
2025-01-16 05:33:08,669 - DEBUG - Low Q-value (0.255), using MCTS.
2025-01-16 05:33:08,671 - INFO - Running MCTS with 159 simulations using 6 processes.
2025-01-16 05:33:11,822 - DEBUG - Aggregated action counts: {2: 7}
2025-01-16 05:33:11,822 - DEBUG - Chose best action 2
2025-01-16 05:33:11,925 - INFO - Episode 3728/98900: Winner=-1, Reward=-102.50, EPSILON=0.967, (W=1231,D=7,L=0)
2025-01-16 05:33:12,063 - INFO - Episode 3729/98900: Winner=2, Reward=-0.95, EPSILON=0.967, (W=1231,D=7,L=0)
2025-01-16 05:33:12,311 - INFO - Episode 3730/98900: Winner=2, Reward=-18.65, EPSILON=0.967, (W=1232,D=7,L=0)
2025-01-16 05:33:12,407 - DEBUG - Q-vals = [0.15775114 0.12056843 0.11968998 0.11803754 0.15195864 0.13900003
 0.19299418], best_act=6, best_val=0.193
2025-01-16 05:33:12,407 - DEBUG - Low Q-value (0.193), using MCTS.
2025-01-16 05:33:12,407 - INFO - Running MCTS with 159 simulations using 6 processes.
2025-01-16 05:33:15,734 - DEBUG - Aggregated action counts: {1: 1, 5: 1, 3: 2, 2: 1, 4: 1, 0: 1}
2025-01-16 05:33:15,734 - DEBUG - Chose best action 3
2025-01-16 05:33:15,859 - INFO - Episode 3731/98900: Winner=2, Reward=-7.05, EPSILON=0.967, (W=1232,D=7,L=0)
2025-01-16 05:33:15,921 - INFO - Episode 3732/98900: Winner=2, Reward=7.35, EPSILON=0.967, (W=1232,D=7,L=0)
2025-01-16 05:33:16,078 - DEBUG - Q-vals = [0.10998681 0.09935011 0.08931841 0.21001472 0.13892938 0.17620467
 0.17619593], best_act=3, best_val=0.210
2025-01-16 05:33:16,078 - DEBUG - Low Q-value (0.210), using MCTS.
2025-01-16 05:33:16,078 - INFO - Running MCTS with 159 simulations using 6 processes.
2025-01-16 05:33:19,289 - DEBUG - Aggregated action counts: {5: 2, 3: 1, 0: 2, 1: 2}
2025-01-16 05:33:19,289 - DEBUG - Chose best action 5
2025-01-16 05:33:19,382 - INFO - Episode 3733/98900: Winner=2, Reward=-4.00, EPSILON=0.967, (W=1232,D=7,L=0)
2025-01-16 05:33:19,492 - INFO - Episode 3734/98900: Winner=2, Reward=2.50, EPSILON=0.967, (W=1232,D=7,L=0)
2025-01-16 05:33:19,648 - INFO - Episode 3735/98900: Winner=2, Reward=-9.45, EPSILON=0.967, (W=1233,D=7,L=0)
2025-01-16 05:33:19,851 - INFO - Episode 3736/98900: Winner=2, Reward=0.25, EPSILON=0.967, (W=1234,D=7,L=0)
2025-01-16 05:33:20,117 - DEBUG - Q-vals = [0.25111023 0.25227246 0.09355746 0.0306715  0.19126427 0.14354134
 0.03758266], best_act=0, best_val=0.251
2025-01-16 05:33:20,117 - DEBUG - Low Q-value (0.251), using MCTS.
2025-01-16 05:33:20,132 - INFO - Episode 3737/98900: Winner=2, Reward=-15.85, EPSILON=0.967, (W=1235,D=7,L=0)
2025-01-16 05:33:20,242 - INFO - Episode 3738/98900: Winner=2, Reward=2.45, EPSILON=0.967, (W=1235,D=7,L=0)
2025-01-16 05:33:20,554 - INFO - Episode 3739/98900: Winner=2, Reward=-24.70, EPSILON=0.967, (W=1235,D=7,L=0)
2025-01-16 05:33:20,773 - INFO - Episode 3740/98900: Winner=2, Reward=15.00, EPSILON=0.967, (W=1235,D=7,L=0)
2025-01-16 05:33:20,898 - INFO - Episode 3741/98900: Winner=2, Reward=0.55, EPSILON=0.967, (W=1235,D=7,L=0)
2025-01-16 05:33:21,023 - INFO - Episode 3742/98900: Winner=2, Reward=-7.70, EPSILON=0.967, (W=1236,D=7,L=0)
2025-01-16 05:33:21,179 - DEBUG - Q-vals = [0.12192084 0.11369827 0.13272472 0.1447195  0.12769929 0.14249396
 0.21674341], best_act=6, best_val=0.217
2025-01-16 05:33:21,179 - DEBUG - Low Q-value (0.217), using MCTS.
2025-01-16 05:33:21,179 - INFO - Running MCTS with 159 simulations using 6 processes.
2025-01-16 05:33:24,178 - DEBUG - Aggregated action counts: {5: 1, 1: 2, 2: 1, 3: 1, 6: 1, 0: 1}
2025-01-16 05:33:24,178 - DEBUG - Chose best action 1
2025-01-16 05:33:24,272 - INFO - Episode 3743/98900: Winner=2, Reward=1.10, EPSILON=0.967, (W=1236,D=7,L=0)
2025-01-16 05:33:24,611 - INFO - Episode 3744/98900: Winner=2, Reward=-23.15, EPSILON=0.967, (W=1236,D=7,L=0)
2025-01-16 05:33:24,859 - INFO - Episode 3745/98900: Winner=2, Reward=12.05, EPSILON=0.967, (W=1236,D=7,L=0)
2025-01-16 05:33:25,096 - DEBUG - Q-vals = [0.05140686 0.03837835 0.108764   0.20727007 0.09099992 0.06936403
 0.43381682], best_act=6, best_val=0.434
2025-01-16 05:33:25,096 - DEBUG - Low Q-value (0.434), using MCTS.
2025-01-16 05:33:25,098 - INFO - Running MCTS with 159 simulations using 6 processes.
2025-01-16 05:33:28,002 - DEBUG - Aggregated action counts: {5: 2, 0: 3, 1: 1, 2: 1}
2025-01-16 05:33:28,002 - DEBUG - Chose best action 0
2025-01-16 05:33:28,060 - INFO - Episode 3746/98900: Winner=2, Reward=-26.05, EPSILON=0.967, (W=1237,D=7,L=0)
2025-01-16 05:33:28,101 - DEBUG - Q-vals = [0.23958044 0.0530336  0.03890973 0.20219879 0.08346429 0.2146111
 0.16820212], best_act=0, best_val=0.240
2025-01-16 05:33:28,101 - DEBUG - Low Q-value (0.240), using MCTS.
2025-01-16 05:33:28,101 - INFO - Running MCTS with 159 simulations using 6 processes.
2025-01-16 05:33:30,944 - DEBUG - Aggregated action counts: {3: 4, 5: 2, 0: 1}
2025-01-16 05:33:30,944 - DEBUG - Chose best action 3
2025-01-16 05:33:31,040 - INFO - Episode 3747/98900: Winner=2, Reward=-10.50, EPSILON=0.967, (W=1238,D=7,L=0)
2025-01-16 05:33:31,080 - DEBUG - Q-vals = [1.7606309e-02 2.9066244e-02 3.1349805e-04 1.1415873e-04 2.9055667e-04
 9.4959337e-01 3.0158649e-03], best_act=5, best_val=0.950
2025-01-16 05:33:31,080 - DEBUG - Low Q-value (0.950), using MCTS.
2025-01-16 05:33:31,081 - INFO - Running MCTS with 159 simulations using 6 processes.
2025-01-16 05:33:33,938 - DEBUG - Aggregated action counts: {3: 1, 4: 1, 0: 2, 1: 2, 2: 1}
2025-01-16 05:33:33,938 - DEBUG - Chose best action 0
2025-01-16 05:33:33,996 - DEBUG - Q-vals = [0.1418336  0.08876143 0.13153416 0.1615351  0.14596264 0.1018218
 0.2285513 ], best_act=6, best_val=0.229
2025-01-16 05:33:33,996 - DEBUG - Low Q-value (0.229), using MCTS.
2025-01-16 05:33:33,996 - INFO - Running MCTS with 159 simulations using 6 processes.
2025-01-16 05:33:37,070 - DEBUG - Aggregated action counts: {1: 1, 3: 3, 4: 1, 2: 1, 0: 1}
2025-01-16 05:33:37,070 - DEBUG - Chose best action 3
2025-01-16 05:33:37,173 - INFO - Episode 3748/98900: Winner=2, Reward=-8.45, EPSILON=0.967, (W=1239,D=7,L=0)
2025-01-16 05:33:37,212 - DEBUG - Q-vals = [0.1806753  0.13047673 0.07468259 0.08665306 0.13676494 0.2331418
 0.1576056 ], best_act=5, best_val=0.233
2025-01-16 05:33:37,212 - DEBUG - Low Q-value (0.233), using MCTS.
2025-01-16 05:33:37,213 - INFO - Running MCTS with 159 simulations using 6 processes.
2025-01-16 05:33:40,523 - DEBUG - Aggregated action counts: {0: 2, 3: 2, 1: 1, 2: 2}
2025-01-16 05:33:40,523 - DEBUG - Chose best action 0
2025-01-16 05:33:40,779 - INFO - Episode 3749/98900: Winner=2, Reward=22.15, EPSILON=0.967, (W=1239,D=7,L=0)
2025-01-16 05:33:41,070 - INFO - Episode 3750/98900: Winner=2, Reward=-1.95, EPSILON=0.967, (W=1239,D=7,L=0)
2025-01-16 05:33:41,231 - INFO - Episode 3751/98900: Winner=2, Reward=12.80, EPSILON=0.967, (W=1239,D=7,L=0)
2025-01-16 05:33:41,323 - INFO - Episode 3752/98900: Winner=2, Reward=0.95, EPSILON=0.967, (W=1239,D=7,L=0)
2025-01-16 05:33:41,338 - DEBUG - Q-vals = [0.32665166 0.01627331 0.00616501 0.02649712 0.5478387  0.00995146
 0.06662276], best_act=4, best_val=0.548
2025-01-16 05:33:41,338 - DEBUG - Low Q-value (0.548), using MCTS.
2025-01-16 05:33:41,339 - INFO - Running MCTS with 160 simulations using 6 processes.
2025-01-16 05:33:44,095 - DEBUG - Aggregated action counts: {2: 3, 3: 1, 4: 1, 6: 1, 0: 1}
2025-01-16 05:33:44,095 - DEBUG - Chose best action 2
2025-01-16 05:33:44,240 - INFO - Episode 3753/98900: Winner=2, Reward=2.90, EPSILON=0.967, (W=1239,D=7,L=0)
2025-01-16 05:33:44,527 - INFO - Episode 3754/98900: Winner=2, Reward=-16.55, EPSILON=0.967, (W=1239,D=7,L=0)
2025-01-16 05:33:44,780 - INFO - Episode 3755/98900: Winner=2, Reward=-15.45, EPSILON=0.967, (W=1240,D=7,L=0)
2025-01-16 05:33:44,840 - DEBUG - Q-vals = [0.16713779 0.11377445 0.13071047 0.15055937 0.13606691 0.12059098
 0.18116006], best_act=6, best_val=0.181
2025-01-16 05:33:44,840 - DEBUG - Low Q-value (0.181), using MCTS.
2025-01-16 05:33:44,840 - INFO - Running MCTS with 160 simulations using 6 processes.
2025-01-16 05:33:47,605 - DEBUG - Aggregated action counts: {2: 2, 3: 1, 5: 2, 4: 1, 0: 1}
2025-01-16 05:33:47,605 - DEBUG - Chose best action 2
2025-01-16 05:33:47,737 - DEBUG - Q-vals = [0.19344062 0.1163943  0.07325406 0.195845   0.13240394 0.13088746
 0.1577746 ], best_act=3, best_val=0.196
2025-01-16 05:33:47,737 - DEBUG - Low Q-value (0.196), using MCTS.
2025-01-16 05:33:47,748 - INFO - Episode 3756/98900: Winner=2, Reward=-17.40, EPSILON=0.967, (W=1241,D=7,L=0)
2025-01-16 05:33:47,915 - INFO - Episode 3757/98900: Winner=2, Reward=14.00, EPSILON=0.967, (W=1241,D=7,L=0)
2025-01-16 05:33:48,195 - INFO - Episode 3758/98900: Winner=2, Reward=-25.35, EPSILON=0.967, (W=1242,D=7,L=0)
2025-01-16 05:33:48,386 - INFO - Episode 3759/98900: Winner=2, Reward=-0.75, EPSILON=0.967, (W=1242,D=7,L=0)
2025-01-16 05:33:48,492 - DEBUG - Q-vals = [0.13287395 0.1054108  0.16058901 0.19768333 0.0305597  0.09302931
 0.27985394], best_act=6, best_val=0.280
2025-01-16 05:33:48,492 - DEBUG - Low Q-value (0.280), using MCTS.
2025-01-16 05:33:48,493 - INFO - Running MCTS with 160 simulations using 6 processes.
2025-01-16 05:33:51,355 - DEBUG - Aggregated action counts: {5: 1, 1: 1, 3: 2, 4: 1, 6: 1, 0: 1}
2025-01-16 05:33:51,355 - DEBUG - Chose best action 3
2025-01-16 05:33:51,408 - INFO - Episode 3760/98900: Winner=2, Reward=0.45, EPSILON=0.967, (W=1242,D=7,L=0)
2025-01-16 05:33:51,606 - INFO - Episode 3761/98900: Winner=2, Reward=-13.15, EPSILON=0.967, (W=1242,D=7,L=0)
2025-01-16 05:33:51,832 - INFO - Episode 3762/98900: Winner=2, Reward=-7.15, EPSILON=0.967, (W=1242,D=7,L=0)
2025-01-16 05:33:51,891 - DEBUG - Q-vals = [0.19101582 0.11742796 0.10850209 0.1424148  0.1376426  0.1329711
 0.17002569], best_act=0, best_val=0.191
2025-01-16 05:33:51,892 - DEBUG - Low Q-value (0.191), using MCTS.
2025-01-16 05:33:51,892 - INFO - Running MCTS with 160 simulations using 6 processes.
2025-01-16 05:33:54,651 - DEBUG - Aggregated action counts: {3: 2, 6: 2, 0: 2, 4: 1}
2025-01-16 05:33:54,651 - DEBUG - Chose best action 3
2025-01-16 05:33:54,896 - INFO - Episode 3763/98900: Winner=2, Reward=-56.65, EPSILON=0.967, (W=1243,D=7,L=0)
2025-01-16 05:33:55,049 - INFO - Episode 3764/98900: Winner=2, Reward=-6.90, EPSILON=0.967, (W=1244,D=7,L=0)
2025-01-16 05:33:55,249 - INFO - Episode 3765/98900: Winner=2, Reward=-23.55, EPSILON=0.967, (W=1245,D=7,L=0)
2025-01-16 05:33:55,495 - INFO - Episode 3766/98900: Winner=2, Reward=-17.20, EPSILON=0.967, (W=1246,D=7,L=0)
2025-01-16 05:33:55,683 - INFO - Episode 3767/98900: Winner=2, Reward=-8.80, EPSILON=0.967, (W=1247,D=7,L=0)
2025-01-16 05:33:55,829 - INFO - Episode 3768/98900: Winner=2, Reward=9.45, EPSILON=0.967, (W=1247,D=7,L=0)
2025-01-16 05:33:55,997 - INFO - Episode 3769/98900: Winner=2, Reward=7.60, EPSILON=0.967, (W=1247,D=7,L=0)
2025-01-16 05:33:56,368 - INFO - Episode 3770/98900: Winner=2, Reward=-26.25, EPSILON=0.967, (W=1248,D=7,L=0)
2025-01-16 05:33:56,716 - INFO - Episode 3771/98900: Winner=2, Reward=-36.15, EPSILON=0.967, (W=1249,D=7,L=0)
2025-01-16 05:33:56,966 - INFO - Episode 3772/98900: Winner=2, Reward=-11.85, EPSILON=0.967, (W=1249,D=7,L=0)
2025-01-16 05:33:57,138 - INFO - Episode 3773/98900: Winner=2, Reward=-11.85, EPSILON=0.967, (W=1250,D=7,L=0)
2025-01-16 05:33:57,294 - DEBUG - Q-vals = [0.16919526 0.17300637 0.10025472 0.11048436 0.14996925 0.12808615
 0.16900392], best_act=1, best_val=0.173
2025-01-16 05:33:57,294 - DEBUG - Low Q-value (0.173), using MCTS.
2025-01-16 05:33:57,294 - INFO - Running MCTS with 160 simulations using 6 processes.
2025-01-16 05:34:00,450 - DEBUG - Aggregated action counts: {2: 2, 3: 4, 0: 1}
2025-01-16 05:34:00,450 - DEBUG - Chose best action 3
2025-01-16 05:34:00,520 - INFO - Episode 3774/98900: Winner=2, Reward=-5.55, EPSILON=0.967, (W=1251,D=7,L=0)
2025-01-16 05:34:00,868 - DEBUG - Q-vals = [0.09430525 0.06232887 0.08481618 0.4509748  0.11240563 0.10200719
 0.09316212], best_act=3, best_val=0.451
2025-01-16 05:34:00,868 - DEBUG - Low Q-value (0.451), using MCTS.
2025-01-16 05:34:00,868 - INFO - Episode 3775/98900: Winner=2, Reward=-34.10, EPSILON=0.967, (W=1252,D=7,L=0)
2025-01-16 05:34:01,118 - INFO - Episode 3776/98900: Winner=2, Reward=-0.65, EPSILON=0.967, (W=1252,D=7,L=0)
2025-01-16 05:34:01,149 - DEBUG - Q-vals = [0.20623694 0.10859063 0.08326788 0.11528333 0.17162858 0.10572757
 0.20926502], best_act=6, best_val=0.209
2025-01-16 05:34:01,149 - DEBUG - Low Q-value (0.209), using MCTS.
2025-01-16 05:34:01,165 - INFO - Running MCTS with 161 simulations using 6 processes.
2025-01-16 05:34:03,975 - DEBUG - Aggregated action counts: {0: 4, 1: 2, 5: 1}
2025-01-16 05:34:03,975 - DEBUG - Chose best action 0
2025-01-16 05:34:04,140 - INFO - Episode 3777/98900: Winner=2, Reward=-11.65, EPSILON=0.967, (W=1252,D=7,L=0)
2025-01-16 05:34:04,297 - INFO - Episode 3778/98900: Winner=2, Reward=15.50, EPSILON=0.967, (W=1252,D=7,L=0)
2025-01-16 05:34:04,640 - INFO - Episode 3779/98900: Winner=2, Reward=-61.20, EPSILON=0.967, (W=1253,D=7,L=0)
2025-01-16 05:34:04,987 - INFO - Episode 3780/98900: Winner=2, Reward=-46.60, EPSILON=0.967, (W=1253,D=7,L=0)
2025-01-16 05:34:05,218 - INFO - Episode 3781/98900: Winner=2, Reward=4.65, EPSILON=0.967, (W=1254,D=7,L=0)
2025-01-16 05:34:05,429 - INFO - Episode 3782/98900: Winner=2, Reward=32.30, EPSILON=0.967, (W=1254,D=7,L=0)
2025-01-16 05:34:05,726 - INFO - Episode 3783/98900: Winner=2, Reward=-17.95, EPSILON=0.967, (W=1254,D=7,L=0)
2025-01-16 05:34:05,866 - INFO - Episode 3784/98900: Winner=2, Reward=25.65, EPSILON=0.967, (W=1254,D=7,L=0)
2025-01-16 05:34:06,085 - INFO - Episode 3785/98900: Winner=2, Reward=14.45, EPSILON=0.967, (W=1254,D=7,L=0)
2025-01-16 05:34:06,304 - INFO - Episode 3786/98900: Winner=2, Reward=-25.80, EPSILON=0.966, (W=1255,D=7,L=0)
2025-01-16 05:34:06,570 - INFO - Episode 3787/98900: Winner=2, Reward=-14.10, EPSILON=0.966, (W=1256,D=7,L=0)
2025-01-16 05:34:06,632 - DEBUG - Q-vals = [0.12747549 0.07965744 0.169761   0.20450404 0.0925658  0.0929236
 0.23311262], best_act=6, best_val=0.233
2025-01-16 05:34:06,632 - DEBUG - Low Q-value (0.233), using MCTS.
2025-01-16 05:34:06,632 - INFO - Running MCTS with 161 simulations using 6 processes.
2025-01-16 05:34:09,492 - DEBUG - Aggregated action counts: {3: 3, 6: 1, 2: 1, 4: 1, 0: 1}
2025-01-16 05:34:09,492 - DEBUG - Chose best action 3
2025-01-16 05:34:09,695 - DEBUG - Q-vals = [0.1450577  0.15699291 0.09396458 0.13244407 0.12519169 0.14201725
 0.20433171], best_act=6, best_val=0.204
2025-01-16 05:34:09,695 - DEBUG - Low Q-value (0.204), using MCTS.
2025-01-16 05:34:09,695 - INFO - Running MCTS with 161 simulations using 6 processes.
2025-01-16 05:34:12,585 - DEBUG - Aggregated action counts: {2: 2, 3: 2, 6: 2, 0: 1}
2025-01-16 05:34:12,585 - DEBUG - Chose best action 2
2025-01-16 05:34:12,616 - INFO - Episode 3788/98900: Winner=2, Reward=-38.35, EPSILON=0.966, (W=1256,D=7,L=0)
2025-01-16 05:34:12,741 - DEBUG - Q-vals = [0.20626049 0.16498305 0.05241018 0.05402082 0.197418   0.23702702
 0.08788043], best_act=5, best_val=0.237
2025-01-16 05:34:12,741 - DEBUG - Low Q-value (0.237), using MCTS.
2025-01-16 05:34:12,741 - INFO - Running MCTS with 161 simulations using 6 processes.
2025-01-16 05:34:15,835 - DEBUG - Aggregated action counts: {3: 1, 0: 5, 5: 1}
2025-01-16 05:34:15,835 - DEBUG - Chose best action 0
2025-01-16 05:34:16,003 - INFO - Episode 3789/98900: Winner=2, Reward=12.35, EPSILON=0.966, (W=1256,D=7,L=0)
2025-01-16 05:34:16,298 - INFO - Episode 3790/98900: Winner=2, Reward=-18.25, EPSILON=0.966, (W=1257,D=7,L=0)
2025-01-16 05:34:16,497 - INFO - Episode 3791/98900: Winner=2, Reward=0.40, EPSILON=0.966, (W=1258,D=7,L=0)
2025-01-16 05:34:16,719 - INFO - Episode 3792/98900: Winner=2, Reward=8.70, EPSILON=0.966, (W=1258,D=7,L=0)
2025-01-16 05:34:16,847 - INFO - Episode 3793/98900: Winner=2, Reward=8.85, EPSILON=0.966, (W=1258,D=7,L=0)
2025-01-16 05:34:17,118 - INFO - Episode 3794/98900: Winner=2, Reward=10.90, EPSILON=0.966, (W=1258,D=7,L=0)
2025-01-16 05:34:17,198 - DEBUG - Q-vals = [0.17836015 0.11577672 0.12515499 0.15700896 0.13872665 0.11332775
 0.17164478], best_act=0, best_val=0.178
2025-01-16 05:34:17,198 - DEBUG - Low Q-value (0.178), using MCTS.
2025-01-16 05:34:17,198 - INFO - Running MCTS with 161 simulations using 6 processes.
2025-01-16 05:34:20,459 - DEBUG - Aggregated action counts: {6: 1, 0: 3, 1: 1, 4: 2}
2025-01-16 05:34:20,459 - DEBUG - Chose best action 0
2025-01-16 05:34:20,521 - DEBUG - Q-vals = [0.19573759 0.11809999 0.10189645 0.14401436 0.13231365 0.1591047
 0.14883333], best_act=0, best_val=0.196
2025-01-16 05:34:20,521 - DEBUG - Low Q-value (0.196), using MCTS.
2025-01-16 05:34:20,537 - INFO - Running MCTS with 161 simulations using 6 processes.
2025-01-16 05:34:23,427 - DEBUG - Aggregated action counts: {1: 2, 4: 2, 3: 1, 2: 1, 0: 1}
2025-01-16 05:34:23,427 - DEBUG - Chose best action 1
2025-01-16 05:34:23,489 - INFO - Episode 3795/98900: Winner=2, Reward=-16.65, EPSILON=0.966, (W=1259,D=7,L=0)
2025-01-16 05:34:23,724 - DEBUG - Q-vals = [0.1969238  0.06174462 0.06357727 0.05432148 0.14574273 0.33845088
 0.13923922], best_act=5, best_val=0.338
2025-01-16 05:34:23,724 - DEBUG - Low Q-value (0.338), using MCTS.
2025-01-16 05:34:23,724 - INFO - Running MCTS with 161 simulations using 6 processes.
2025-01-16 05:34:26,692 - DEBUG - Aggregated action counts: {0: 2, 6: 3, 4: 1, 5: 1}
2025-01-16 05:34:26,692 - DEBUG - Chose best action 6
2025-01-16 05:34:26,879 - INFO - Episode 3796/98900: Winner=2, Reward=-12.65, EPSILON=0.966, (W=1260,D=7,L=0)
2025-01-16 05:34:27,129 - INFO - Episode 3797/98900: Winner=2, Reward=-13.45, EPSILON=0.966, (W=1261,D=7,L=0)
2025-01-16 05:34:27,301 - INFO - Episode 3798/98900: Winner=2, Reward=-6.55, EPSILON=0.966, (W=1262,D=7,L=0)
2025-01-16 05:34:27,519 - INFO - Episode 3799/98900: Winner=2, Reward=-22.90, EPSILON=0.966, (W=1263,D=7,L=0)
2025-01-16 05:34:27,769 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3800.
2025-01-16 05:34:27,769 - INFO - Models saved at episode 3800
2025-01-16 05:34:27,769 - INFO - Target networks updated
2025-01-16 05:34:27,816 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 3800.
2025-01-16 05:34:27,816 - INFO - Episode 3800/98900: Winner=2, Reward=-5.40, EPSILON=0.966, (W=1263,D=7,L=0)
2025-01-16 05:34:27,879 - DEBUG - Q-vals = [0.19454971 0.1130524  0.1226316  0.08451489 0.20795742 0.10674977
 0.17054419], best_act=4, best_val=0.208
2025-01-16 05:34:27,879 - DEBUG - Low Q-value (0.208), using MCTS.
2025-01-16 05:34:27,879 - INFO - Running MCTS with 162 simulations using 6 processes.
2025-01-16 05:34:30,629 - DEBUG - Aggregated action counts: {4: 2, 5: 3, 1: 1}
2025-01-16 05:34:30,629 - DEBUG - Chose best action 5
2025-01-16 05:34:30,691 - DEBUG - Q-vals = [0.1904327  0.07379784 0.111793   0.07832635 0.28177378 0.11746863
 0.14640763], best_act=4, best_val=0.282
2025-01-16 05:34:30,691 - DEBUG - Low Q-value (0.282), using MCTS.
2025-01-16 05:34:30,691 - INFO - Running MCTS with 162 simulations using 6 processes.
2025-01-16 05:34:33,504 - DEBUG - Aggregated action counts: {3: 2, 1: 1, 5: 1, 4: 2}
2025-01-16 05:34:33,504 - DEBUG - Chose best action 3
2025-01-16 05:34:33,691 - INFO - Episode 3801/98900: Winner=2, Reward=-36.65, EPSILON=0.966, (W=1264,D=7,L=0)
2025-01-16 05:34:34,175 - INFO - Episode 3802/98900: Winner=2, Reward=-109.75, EPSILON=0.966, (W=1265,D=7,L=0)
2025-01-16 05:34:34,347 - INFO - Episode 3803/98900: Winner=2, Reward=14.50, EPSILON=0.966, (W=1265,D=7,L=0)
2025-01-16 05:34:34,566 - DEBUG - Q-vals = [0.18853396 0.09904447 0.10590512 0.13329199 0.21954413 0.08470455
 0.16897577], best_act=4, best_val=0.220
2025-01-16 05:34:34,566 - DEBUG - Low Q-value (0.220), using MCTS.
2025-01-16 05:34:34,566 - INFO - Running MCTS with 162 simulations using 6 processes.
2025-01-16 05:34:37,410 - DEBUG - Aggregated action counts: {0: 2, 1: 2, 2: 1, 4: 1}
2025-01-16 05:34:37,410 - DEBUG - Chose best action 0
2025-01-16 05:34:37,503 - INFO - Episode 3804/98900: Winner=2, Reward=-19.70, EPSILON=0.966, (W=1265,D=7,L=0)
2025-01-16 05:34:37,550 - DEBUG - Q-vals = [0.17619555 0.11299215 0.0963392  0.12072347 0.14313184 0.12519357
 0.22542424], best_act=6, best_val=0.225
2025-01-16 05:34:37,550 - DEBUG - Low Q-value (0.225), using MCTS.
2025-01-16 05:34:37,550 - INFO - Running MCTS with 162 simulations using 6 processes.
2025-01-16 05:34:40,362 - DEBUG - Aggregated action counts: {4: 1, 6: 3, 3: 1, 2: 1}
2025-01-16 05:34:40,362 - DEBUG - Chose best action 6
2025-01-16 05:34:40,675 - DEBUG - Q-vals = [0.09723006 0.06099351 0.03454475 0.55899024 0.05920654 0.02314779
 0.16588709], best_act=3, best_val=0.559
2025-01-16 05:34:40,675 - DEBUG - Low Q-value (0.559), using MCTS.
2025-01-16 05:34:40,675 - INFO - Episode 3805/98900: Winner=2, Reward=-44.40, EPSILON=0.966, (W=1266,D=7,L=0)
2025-01-16 05:34:40,737 - DEBUG - Q-vals = [0.18481515 0.09865868 0.12971519 0.11134233 0.20118552 0.10223597
 0.17204714], best_act=4, best_val=0.201
2025-01-16 05:34:40,737 - DEBUG - Low Q-value (0.201), using MCTS.
2025-01-16 05:34:40,737 - INFO - Running MCTS with 162 simulations using 6 processes.
2025-01-16 05:34:43,643 - DEBUG - Aggregated action counts: {0: 3, 5: 1, 4: 2}
2025-01-16 05:34:43,643 - DEBUG - Chose best action 0
2025-01-16 05:34:43,924 - DEBUG - Q-vals = [0.08132517 0.03344818 0.14944415 0.5483404  0.07324856 0.01372197
 0.10047166], best_act=2, best_val=0.149
2025-01-16 05:34:43,924 - DEBUG - Low Q-value (0.149), using MCTS.
2025-01-16 05:34:43,940 - INFO - Episode 3806/98900: Winner=2, Reward=-33.95, EPSILON=0.966, (W=1267,D=7,L=0)
2025-01-16 05:34:44,299 - INFO - Episode 3807/98900: Winner=2, Reward=-38.55, EPSILON=0.966, (W=1268,D=7,L=0)
2025-01-16 05:34:44,549 - INFO - Episode 3808/98900: Winner=2, Reward=-21.70, EPSILON=0.966, (W=1268,D=7,L=0)
2025-01-16 05:34:44,768 - INFO - Episode 3809/98900: Winner=2, Reward=-12.45, EPSILON=0.966, (W=1268,D=7,L=0)
2025-01-16 05:34:44,924 - INFO - Episode 3810/98900: Winner=2, Reward=-12.00, EPSILON=0.966, (W=1269,D=7,L=0)
2025-01-16 05:34:45,065 - INFO - Episode 3811/98900: Winner=2, Reward=-8.95, EPSILON=0.966, (W=1270,D=7,L=0)
2025-01-16 05:34:45,143 - INFO - Episode 3812/98900: Winner=2, Reward=-10.40, EPSILON=0.966, (W=1271,D=7,L=0)
2025-01-16 05:34:45,471 - INFO - Episode 3813/98900: Winner=2, Reward=-2.45, EPSILON=0.966, (W=1271,D=7,L=0)
2025-01-16 05:34:45,689 - INFO - Episode 3814/98900: Winner=2, Reward=0.50, EPSILON=0.966, (W=1271,D=7,L=0)
2025-01-16 05:34:45,830 - DEBUG - Q-vals = [0.10486555 0.07735302 0.07775894 0.05181171 0.30656597 0.2390826
 0.14256221], best_act=4, best_val=0.307
2025-01-16 05:34:45,830 - DEBUG - Low Q-value (0.307), using MCTS.
2025-01-16 05:34:45,830 - INFO - Running MCTS with 162 simulations using 6 processes.
