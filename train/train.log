2025-01-16 11:33:17,096 - INFO - Policy network initialized.
2025-01-16 11:33:17,127 - INFO - Target network initialized.
2025-01-16 11:33:17,127 - INFO - Optimizer initialized.
2025-01-16 11:33:17,158 - INFO - Replay buffer initialized.
2025-01-16 11:33:17,158 - WARNING - Checkpoint file Connect4_Agent_Model.pth does not exist. Starting fresh.
2025-01-16 11:33:17,158 - INFO - TOTAL_EPISODES adjusted to 100000 after subtracting 0.
2025-01-16 11:33:17,158 - INFO - Current Epsilon adjusted to 1.0.
2025-01-16 11:33:17,158 - INFO - Episode 1/100000: Winner=2, Reward=-10.80, EPSILON=1.000, (W=1,D=0,L=0)
2025-01-16 11:33:17,424 - INFO - Episode 2/100000: Winner=2, Reward=-4.40, EPSILON=1.000, (W=2,D=0,L=0)
2025-01-16 11:33:17,596 - INFO - Episode 3/100000: Winner=2, Reward=21.95, EPSILON=1.000, (W=3,D=0,L=0)
2025-01-16 11:33:17,736 - INFO - Episode 4/100000: Winner=2, Reward=4.75, EPSILON=1.000, (W=4,D=0,L=0)
2025-01-16 11:33:17,971 - INFO - Episode 5/100000: Winner=2, Reward=3.95, EPSILON=1.000, (W=5,D=0,L=0)
2025-01-16 11:33:18,252 - INFO - Episode 6/100000: Winner=2, Reward=-2.55, EPSILON=1.000, (W=6,D=0,L=0)
2025-01-16 11:33:18,439 - INFO - Episode 7/100000: Winner=2, Reward=1.05, EPSILON=1.000, (W=7,D=0,L=0)
2025-01-16 11:33:18,689 - INFO - Episode 8/100000: Winner=2, Reward=24.40, EPSILON=1.000, (W=8,D=0,L=0)
2025-01-16 11:33:19,017 - INFO - Episode 9/100000: Winner=2, Reward=-9.60, EPSILON=1.000, (W=9,D=0,L=0)
2025-01-16 11:33:19,330 - INFO - Episode 10/100000: Winner=2, Reward=-0.80, EPSILON=1.000, (W=10,D=0,L=0)
2025-01-16 11:33:19,502 - INFO - Episode 11/100000: Winner=2, Reward=-5.95, EPSILON=1.000, (W=11,D=0,L=0)
2025-01-16 11:33:19,736 - INFO - Episode 12/100000: Winner=2, Reward=9.70, EPSILON=1.000, (W=12,D=0,L=0)
2025-01-16 11:33:20,033 - INFO - Episode 13/100000: Winner=2, Reward=14.55, EPSILON=1.000, (W=13,D=0,L=0)
2025-01-16 11:33:20,190 - INFO - Episode 14/100000: Winner=2, Reward=14.05, EPSILON=1.000, (W=14,D=0,L=0)
2025-01-16 11:33:20,314 - INFO - Episode 15/100000: Winner=2, Reward=-9.20, EPSILON=1.000, (W=15,D=0,L=0)
2025-01-16 11:33:20,502 - INFO - Episode 16/100000: Winner=2, Reward=2.80, EPSILON=1.000, (W=16,D=0,L=0)
2025-01-16 11:33:20,752 - INFO - Episode 17/100000: Winner=2, Reward=28.40, EPSILON=1.000, (W=17,D=0,L=0)
2025-01-16 11:33:20,877 - INFO - Episode 18/100000: Winner=2, Reward=0.30, EPSILON=1.000, (W=18,D=0,L=0)
2025-01-16 11:33:21,096 - INFO - Episode 19/100000: Winner=2, Reward=0.60, EPSILON=1.000, (W=19,D=0,L=0)
2025-01-16 11:33:21,345 - INFO - Episode 20/100000: Winner=2, Reward=27.40, EPSILON=1.000, (W=20,D=0,L=0)
2025-01-16 11:33:21,580 - INFO - Episode 21/100000: Winner=2, Reward=-7.90, EPSILON=1.000, (W=21,D=0,L=0)
2025-01-16 11:33:21,830 - INFO - Episode 22/100000: Winner=2, Reward=7.35, EPSILON=1.000, (W=22,D=0,L=0)
2025-01-16 11:33:22,048 - INFO - Episode 23/100000: Winner=2, Reward=26.35, EPSILON=1.000, (W=23,D=0,L=0)
2025-01-16 11:33:22,251 - INFO - Episode 24/100000: Winner=2, Reward=6.20, EPSILON=1.000, (W=24,D=0,L=0)
2025-01-16 11:33:22,455 - INFO - Episode 25/100000: Winner=2, Reward=-8.30, EPSILON=1.000, (W=25,D=0,L=0)
2025-01-16 11:33:22,580 - INFO - Episode 26/100000: Winner=2, Reward=-6.95, EPSILON=1.000, (W=26,D=0,L=0)
2025-01-16 11:33:22,876 - INFO - Episode 27/100000: Winner=2, Reward=-10.80, EPSILON=1.000, (W=27,D=0,L=0)
2025-01-16 11:33:23,033 - INFO - Episode 28/100000: Winner=2, Reward=2.20, EPSILON=1.000, (W=28,D=0,L=0)
2025-01-16 11:33:23,236 - INFO - Episode 29/100000: Winner=2, Reward=15.90, EPSILON=1.000, (W=29,D=0,L=0)
2025-01-16 11:33:23,361 - INFO - Episode 30/100000: Winner=2, Reward=8.35, EPSILON=1.000, (W=30,D=0,L=0)
2025-01-16 11:33:23,611 - INFO - Episode 31/100000: Winner=2, Reward=-15.40, EPSILON=1.000, (W=31,D=0,L=0)
2025-01-16 11:33:23,736 - INFO - Episode 32/100000: Winner=2, Reward=-5.45, EPSILON=1.000, (W=32,D=0,L=0)
2025-01-16 11:33:23,954 - INFO - Episode 33/100000: Winner=2, Reward=21.60, EPSILON=1.000, (W=33,D=0,L=0)
2025-01-16 11:33:24,173 - INFO - Episode 34/100000: Winner=2, Reward=13.45, EPSILON=1.000, (W=34,D=0,L=0)
2025-01-16 11:33:24,282 - INFO - Episode 35/100000: Winner=2, Reward=-4.20, EPSILON=1.000, (W=35,D=0,L=0)
2025-01-16 11:33:24,532 - INFO - Episode 36/100000: Winner=2, Reward=10.20, EPSILON=1.000, (W=36,D=0,L=0)
2025-01-16 11:33:24,704 - INFO - Episode 37/100000: Winner=2, Reward=-5.40, EPSILON=1.000, (W=37,D=0,L=0)
2025-01-16 11:33:24,938 - INFO - Episode 38/100000: Winner=2, Reward=-3.95, EPSILON=1.000, (W=38,D=0,L=0)
2025-01-16 11:33:25,242 - INFO - Episode 39/100000: Winner=2, Reward=-15.20, EPSILON=1.000, (W=39,D=0,L=0)
2025-01-16 11:33:25,618 - INFO - Episode 40/100000: Winner=2, Reward=-13.90, EPSILON=1.000, (W=40,D=0,L=0)
2025-01-16 11:33:25,871 - INFO - Episode 41/100000: Winner=2, Reward=2.20, EPSILON=1.000, (W=41,D=0,L=0)
2025-01-16 11:33:26,186 - INFO - Episode 42/100000: Winner=2, Reward=16.15, EPSILON=1.000, (W=42,D=0,L=0)
2025-01-16 11:33:26,330 - INFO - Episode 43/100000: Winner=2, Reward=7.75, EPSILON=1.000, (W=43,D=0,L=0)
2025-01-16 11:33:26,473 - INFO - Episode 44/100000: Winner=2, Reward=7.45, EPSILON=1.000, (W=44,D=0,L=0)
2025-01-16 11:33:26,710 - INFO - Episode 45/100000: Winner=2, Reward=17.95, EPSILON=1.000, (W=45,D=0,L=0)
2025-01-16 11:33:26,862 - INFO - Episode 46/100000: Winner=2, Reward=-9.80, EPSILON=1.000, (W=46,D=0,L=0)
2025-01-16 11:33:26,990 - INFO - Episode 47/100000: Winner=2, Reward=5.10, EPSILON=1.000, (W=47,D=0,L=0)
2025-01-16 11:33:27,193 - INFO - Episode 48/100000: Winner=2, Reward=-1.85, EPSILON=1.000, (W=48,D=0,L=0)
2025-01-16 11:33:27,561 - INFO - Episode 49/100000: Winner=2, Reward=-17.10, EPSILON=1.000, (W=49,D=0,L=0)
2025-01-16 11:33:27,821 - INFO - Episode 50/100000: Winner=2, Reward=11.45, EPSILON=1.000, (W=50,D=0,L=0)
2025-01-16 11:33:28,090 - INFO - Episode 51/100000: Winner=2, Reward=-7.65, EPSILON=1.000, (W=51,D=0,L=0)
2025-01-16 11:33:28,212 - INFO - Episode 52/100000: Winner=2, Reward=1.25, EPSILON=1.000, (W=52,D=0,L=0)
2025-01-16 11:33:28,457 - INFO - Episode 53/100000: Winner=2, Reward=6.10, EPSILON=1.000, (W=53,D=0,L=0)
2025-01-16 11:33:28,773 - INFO - Episode 54/100000: Winner=2, Reward=6.70, EPSILON=1.000, (W=54,D=0,L=0)
2025-01-16 11:33:28,933 - INFO - Episode 55/100000: Winner=2, Reward=9.15, EPSILON=1.000, (W=55,D=0,L=0)
2025-01-16 11:33:29,175 - INFO - Episode 56/100000: Winner=2, Reward=-0.20, EPSILON=0.999, (W=56,D=0,L=0)
2025-01-16 11:33:29,345 - INFO - Episode 57/100000: Winner=2, Reward=5.60, EPSILON=0.999, (W=57,D=0,L=0)
2025-01-16 11:33:29,509 - INFO - Episode 58/100000: Winner=2, Reward=1.70, EPSILON=0.999, (W=58,D=0,L=0)
2025-01-16 11:33:29,663 - INFO - Episode 59/100000: Winner=2, Reward=-0.60, EPSILON=0.999, (W=59,D=0,L=0)
2025-01-16 11:33:29,735 - INFO - Episode 60/100000: Winner=2, Reward=0.75, EPSILON=0.999, (W=60,D=0,L=0)
2025-01-16 11:33:30,034 - INFO - Episode 61/100000: Winner=2, Reward=-5.45, EPSILON=0.999, (W=61,D=0,L=0)
2025-01-16 11:33:30,138 - INFO - Episode 62/100000: Winner=2, Reward=-6.60, EPSILON=0.999, (W=62,D=0,L=0)
2025-01-16 11:33:30,429 - INFO - Episode 63/100000: Winner=2, Reward=-0.45, EPSILON=0.999, (W=63,D=0,L=0)
2025-01-16 11:33:30,591 - INFO - Episode 64/100000: Winner=2, Reward=6.35, EPSILON=0.999, (W=64,D=0,L=0)
2025-01-16 11:33:30,797 - INFO - Episode 65/100000: Winner=2, Reward=-6.25, EPSILON=0.999, (W=65,D=0,L=0)
2025-01-16 11:33:31,081 - INFO - Episode 66/100000: Winner=2, Reward=11.75, EPSILON=0.999, (W=66,D=0,L=0)
2025-01-16 11:33:31,359 - INFO - Episode 67/100000: Winner=2, Reward=10.35, EPSILON=0.999, (W=67,D=0,L=0)
2025-01-16 11:33:31,517 - INFO - Episode 68/100000: Winner=2, Reward=12.55, EPSILON=0.999, (W=68,D=0,L=0)
2025-01-16 11:33:31,801 - INFO - Episode 69/100000: Winner=2, Reward=42.05, EPSILON=0.999, (W=69,D=0,L=0)
2025-01-16 11:33:31,934 - INFO - Episode 70/100000: Winner=2, Reward=-8.55, EPSILON=0.999, (W=70,D=0,L=0)
2025-01-16 11:33:32,045 - INFO - Episode 71/100000: Winner=2, Reward=0.55, EPSILON=0.999, (W=71,D=0,L=0)
2025-01-16 11:33:32,177 - DEBUG - Q-vals = [0.12347103 0.10479511 0.14089079 0.11943243 0.14743067 0.18969333
 0.17428662], best_act=5, best_val=0.190
2025-01-16 11:33:32,177 - DEBUG - Low Q-value (0.190), using MCTS.
2025-01-16 11:33:32,182 - INFO - Episode 72/100000: Winner=2, Reward=-3.95, EPSILON=0.999, (W=72,D=0,L=0)
2025-01-16 11:33:32,406 - INFO - Episode 73/100000: Winner=2, Reward=-11.80, EPSILON=0.999, (W=73,D=0,L=0)
2025-01-16 11:33:32,667 - INFO - Episode 74/100000: Winner=2, Reward=17.65, EPSILON=0.999, (W=74,D=0,L=0)
2025-01-16 11:33:32,849 - INFO - Episode 75/100000: Winner=2, Reward=1.70, EPSILON=0.999, (W=75,D=0,L=0)
2025-01-16 11:33:33,149 - INFO - Episode 76/100000: Winner=2, Reward=-21.55, EPSILON=0.999, (W=76,D=0,L=0)
2025-01-16 11:33:33,268 - INFO - Episode 77/100000: Winner=2, Reward=-3.90, EPSILON=0.999, (W=77,D=0,L=0)
2025-01-16 11:33:33,447 - INFO - Episode 78/100000: Winner=2, Reward=31.10, EPSILON=0.999, (W=78,D=0,L=0)
2025-01-16 11:33:33,656 - INFO - Episode 79/100000: Winner=2, Reward=-3.65, EPSILON=0.999, (W=79,D=0,L=0)
2025-01-16 11:33:33,808 - INFO - Episode 80/100000: Winner=2, Reward=11.75, EPSILON=0.999, (W=80,D=0,L=0)
2025-01-16 11:33:34,009 - INFO - Episode 81/100000: Winner=2, Reward=-9.05, EPSILON=0.999, (W=81,D=0,L=0)
2025-01-16 11:33:34,113 - INFO - Episode 82/100000: Winner=2, Reward=-6.30, EPSILON=0.999, (W=82,D=0,L=0)
2025-01-16 11:33:34,290 - INFO - Episode 83/100000: Winner=2, Reward=18.80, EPSILON=0.999, (W=83,D=0,L=0)
2025-01-16 11:33:34,461 - INFO - Episode 84/100000: Winner=2, Reward=-1.90, EPSILON=0.999, (W=84,D=0,L=0)
2025-01-16 11:33:34,645 - INFO - Episode 85/100000: Winner=2, Reward=-4.10, EPSILON=0.999, (W=85,D=0,L=0)
2025-01-16 11:33:34,819 - INFO - Episode 86/100000: Winner=2, Reward=19.90, EPSILON=0.999, (W=86,D=0,L=0)
2025-01-16 11:33:34,946 - INFO - Episode 87/100000: Winner=2, Reward=9.40, EPSILON=0.999, (W=87,D=0,L=0)
2025-01-16 11:33:35,125 - INFO - Episode 88/100000: Winner=2, Reward=11.45, EPSILON=0.999, (W=88,D=0,L=0)
2025-01-16 11:33:35,326 - INFO - Episode 89/100000: Winner=2, Reward=3.80, EPSILON=0.999, (W=89,D=0,L=0)
2025-01-16 11:33:35,617 - INFO - Episode 90/100000: Winner=2, Reward=-6.45, EPSILON=0.999, (W=90,D=0,L=0)
2025-01-16 11:33:35,843 - INFO - Episode 91/100000: Winner=2, Reward=-9.30, EPSILON=0.999, (W=91,D=0,L=0)
2025-01-16 11:33:36,178 - INFO - Episode 92/100000: Winner=2, Reward=-4.00, EPSILON=0.999, (W=92,D=0,L=0)
2025-01-16 11:33:36,364 - INFO - Episode 93/100000: Winner=2, Reward=2.15, EPSILON=0.999, (W=93,D=0,L=0)
2025-01-16 11:33:36,636 - INFO - Episode 94/100000: Winner=2, Reward=-2.50, EPSILON=0.999, (W=94,D=0,L=0)
2025-01-16 11:33:36,792 - INFO - Episode 95/100000: Winner=2, Reward=24.10, EPSILON=0.999, (W=95,D=0,L=0)
2025-01-16 11:33:37,019 - INFO - Episode 96/100000: Winner=2, Reward=-13.50, EPSILON=0.999, (W=96,D=0,L=0)
2025-01-16 11:33:37,152 - INFO - Episode 97/100000: Winner=2, Reward=13.20, EPSILON=0.999, (W=97,D=0,L=0)
2025-01-16 11:33:37,308 - INFO - Episode 98/100000: Winner=2, Reward=16.75, EPSILON=0.999, (W=98,D=0,L=0)
2025-01-16 11:33:37,472 - INFO - Episode 99/100000: Winner=2, Reward=-5.80, EPSILON=0.999, (W=99,D=0,L=0)
2025-01-16 11:33:37,636 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 100.
2025-01-16 11:33:37,636 - INFO - Models saved at episode 100
2025-01-16 11:33:37,637 - INFO - Target networks updated
2025-01-16 11:33:37,698 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 100.
2025-01-16 11:33:37,698 - INFO - Episode 100/100000: Winner=2, Reward=9.10, EPSILON=0.999, (W=100,D=0,L=0)
2025-01-16 11:33:37,968 - INFO - Episode 101/100000: Winner=2, Reward=13.65, EPSILON=0.999, (W=101,D=0,L=0)
2025-01-16 11:33:38,218 - INFO - Episode 102/100000: Winner=2, Reward=-12.45, EPSILON=0.999, (W=102,D=0,L=0)
2025-01-16 11:33:38,452 - INFO - Episode 103/100000: Winner=2, Reward=30.30, EPSILON=0.999, (W=103,D=0,L=0)
2025-01-16 11:33:38,577 - INFO - Episode 104/100000: Winner=2, Reward=29.75, EPSILON=0.999, (W=104,D=0,L=0)
2025-01-16 11:33:38,836 - INFO - Episode 105/100000: Winner=2, Reward=7.85, EPSILON=0.999, (W=105,D=0,L=0)
2025-01-16 11:33:39,047 - INFO - Episode 106/100000: Winner=2, Reward=22.55, EPSILON=0.999, (W=106,D=0,L=0)
2025-01-16 11:33:39,274 - INFO - Episode 107/100000: Winner=2, Reward=3.10, EPSILON=0.999, (W=107,D=0,L=0)
2025-01-16 11:33:39,461 - INFO - Episode 108/100000: Winner=2, Reward=14.55, EPSILON=0.999, (W=108,D=0,L=0)
2025-01-16 11:33:39,727 - INFO - Episode 109/100000: Winner=2, Reward=9.15, EPSILON=0.999, (W=109,D=0,L=0)
2025-01-16 11:33:39,930 - INFO - Episode 110/100000: Winner=2, Reward=10.80, EPSILON=0.999, (W=110,D=0,L=0)
2025-01-16 11:33:40,133 - INFO - Episode 111/100000: Winner=2, Reward=5.10, EPSILON=0.999, (W=111,D=0,L=0)
2025-01-16 11:33:40,336 - INFO - Episode 112/100000: Winner=2, Reward=9.95, EPSILON=0.999, (W=112,D=0,L=0)
2025-01-16 11:33:40,430 - INFO - Episode 113/100000: Winner=2, Reward=16.90, EPSILON=0.999, (W=113,D=0,L=0)
2025-01-16 11:33:40,617 - INFO - Episode 114/100000: Winner=2, Reward=-3.15, EPSILON=0.999, (W=114,D=0,L=0)
2025-01-16 11:33:40,758 - INFO - Episode 115/100000: Winner=2, Reward=3.15, EPSILON=0.999, (W=115,D=0,L=0)
2025-01-16 11:33:40,976 - INFO - Episode 116/100000: Winner=2, Reward=3.45, EPSILON=0.999, (W=116,D=0,L=0)
2025-01-16 11:33:41,133 - INFO - Episode 117/100000: Winner=2, Reward=10.35, EPSILON=0.999, (W=117,D=0,L=0)
2025-01-16 11:33:41,367 - INFO - Episode 118/100000: Winner=2, Reward=12.75, EPSILON=0.999, (W=118,D=0,L=0)
2025-01-16 11:33:41,601 - INFO - Episode 119/100000: Winner=2, Reward=25.35, EPSILON=0.999, (W=119,D=0,L=0)
2025-01-16 11:33:41,789 - INFO - Episode 120/100000: Winner=2, Reward=-9.15, EPSILON=0.999, (W=120,D=0,L=0)
2025-01-16 11:33:42,117 - INFO - Episode 121/100000: Winner=2, Reward=-11.80, EPSILON=0.999, (W=121,D=0,L=0)
2025-01-16 11:33:42,335 - INFO - Episode 122/100000: Winner=2, Reward=0.50, EPSILON=0.999, (W=122,D=0,L=0)
2025-01-16 11:33:42,632 - INFO - Episode 123/100000: Winner=2, Reward=-6.10, EPSILON=0.999, (W=123,D=0,L=0)
2025-01-16 11:33:42,835 - INFO - Episode 124/100000: Winner=2, Reward=24.45, EPSILON=0.999, (W=124,D=0,L=0)
2025-01-16 11:33:43,054 - INFO - Episode 125/100000: Winner=2, Reward=6.00, EPSILON=0.999, (W=125,D=0,L=0)
2025-01-16 11:33:43,257 - INFO - Episode 126/100000: Winner=2, Reward=0.65, EPSILON=0.999, (W=126,D=0,L=0)
2025-01-16 11:33:43,351 - INFO - Episode 127/100000: Winner=2, Reward=-7.25, EPSILON=0.999, (W=127,D=0,L=0)
2025-01-16 11:33:43,601 - INFO - Episode 128/100000: Winner=2, Reward=2.45, EPSILON=0.999, (W=128,D=0,L=0)
2025-01-16 11:33:43,773 - INFO - Episode 129/100000: Winner=2, Reward=25.35, EPSILON=0.999, (W=129,D=0,L=0)
2025-01-16 11:33:43,929 - INFO - Episode 130/100000: Winner=2, Reward=-7.35, EPSILON=0.999, (W=130,D=0,L=0)
2025-01-16 11:33:44,116 - INFO - Episode 131/100000: Winner=2, Reward=3.10, EPSILON=0.999, (W=131,D=0,L=0)
2025-01-16 11:33:44,304 - INFO - Episode 132/100000: Winner=2, Reward=9.00, EPSILON=0.999, (W=132,D=0,L=0)
2025-01-16 11:33:44,444 - INFO - Episode 133/100000: Winner=2, Reward=8.40, EPSILON=0.999, (W=133,D=0,L=0)
2025-01-16 11:33:44,632 - INFO - Episode 134/100000: Winner=2, Reward=0.35, EPSILON=0.999, (W=134,D=0,L=0)
2025-01-16 11:33:44,757 - INFO - Episode 135/100000: Winner=2, Reward=9.75, EPSILON=0.999, (W=135,D=0,L=0)
2025-01-16 11:33:45,054 - INFO - Episode 136/100000: Winner=2, Reward=30.85, EPSILON=0.999, (W=136,D=0,L=0)
2025-01-16 11:33:45,225 - INFO - Episode 137/100000: Winner=2, Reward=-5.15, EPSILON=0.999, (W=137,D=0,L=0)
2025-01-16 11:33:45,350 - INFO - Episode 138/100000: Winner=2, Reward=5.30, EPSILON=0.999, (W=138,D=0,L=0)
2025-01-16 11:33:45,507 - INFO - Episode 139/100000: Winner=2, Reward=18.30, EPSILON=0.999, (W=139,D=0,L=0)
2025-01-16 11:33:45,757 - INFO - Episode 140/100000: Winner=2, Reward=7.55, EPSILON=0.999, (W=140,D=0,L=0)
2025-01-16 11:33:45,944 - INFO - Episode 141/100000: Winner=2, Reward=6.80, EPSILON=0.999, (W=141,D=0,L=0)
2025-01-16 11:33:46,147 - INFO - Episode 142/100000: Winner=2, Reward=-4.80, EPSILON=0.999, (W=142,D=0,L=0)
2025-01-16 11:33:46,350 - INFO - Episode 143/100000: Winner=2, Reward=13.60, EPSILON=0.999, (W=143,D=0,L=0)
2025-01-16 11:33:46,600 - INFO - Episode 144/100000: Winner=2, Reward=10.70, EPSILON=0.999, (W=144,D=0,L=0)
2025-01-16 11:33:46,834 - INFO - Episode 145/100000: Winner=2, Reward=27.30, EPSILON=0.999, (W=145,D=0,L=0)
2025-01-16 11:33:47,053 - INFO - Episode 146/100000: Winner=2, Reward=3.50, EPSILON=0.999, (W=146,D=0,L=0)
2025-01-16 11:33:47,225 - INFO - Episode 147/100000: Winner=2, Reward=-9.50, EPSILON=0.999, (W=147,D=0,L=0)
2025-01-16 11:33:47,412 - INFO - Episode 148/100000: Winner=2, Reward=2.30, EPSILON=0.999, (W=148,D=0,L=0)
2025-01-16 11:33:47,553 - INFO - Episode 149/100000: Winner=2, Reward=20.25, EPSILON=0.999, (W=149,D=0,L=0)
2025-01-16 11:33:47,647 - INFO - Episode 150/100000: Winner=2, Reward=8.40, EPSILON=0.999, (W=150,D=0,L=0)
2025-01-16 11:33:47,819 - INFO - Episode 151/100000: Winner=2, Reward=13.30, EPSILON=0.999, (W=151,D=0,L=0)
2025-01-16 11:33:48,037 - INFO - Episode 152/100000: Winner=2, Reward=2.35, EPSILON=0.999, (W=152,D=0,L=0)
2025-01-16 11:33:48,162 - INFO - Episode 153/100000: Winner=2, Reward=8.60, EPSILON=0.999, (W=153,D=0,L=0)
2025-01-16 11:33:48,334 - INFO - Episode 154/100000: Winner=2, Reward=5.70, EPSILON=0.999, (W=154,D=0,L=0)
2025-01-16 11:33:48,635 - INFO - Episode 155/100000: Winner=2, Reward=4.05, EPSILON=0.999, (W=155,D=0,L=0)
2025-01-16 11:33:48,763 - INFO - Episode 156/100000: Winner=2, Reward=9.55, EPSILON=0.999, (W=156,D=0,L=0)
2025-01-16 11:33:48,884 - INFO - Episode 157/100000: Winner=2, Reward=0.30, EPSILON=0.999, (W=157,D=0,L=0)
2025-01-16 11:33:49,113 - INFO - Episode 158/100000: Winner=2, Reward=3.20, EPSILON=0.999, (W=158,D=0,L=0)
2025-01-16 11:33:49,392 - INFO - Episode 159/100000: Winner=2, Reward=14.15, EPSILON=0.999, (W=159,D=0,L=0)
2025-01-16 11:33:49,603 - INFO - Episode 160/100000: Winner=2, Reward=0.90, EPSILON=0.999, (W=160,D=0,L=0)
2025-01-16 11:33:49,853 - INFO - Episode 161/100000: Winner=2, Reward=23.80, EPSILON=0.999, (W=161,D=0,L=0)
2025-01-16 11:33:50,095 - INFO - Episode 162/100000: Winner=2, Reward=7.40, EPSILON=0.999, (W=162,D=0,L=0)
2025-01-16 11:33:50,341 - INFO - Episode 163/100000: Winner=2, Reward=15.05, EPSILON=0.999, (W=163,D=0,L=0)
2025-01-16 11:33:50,498 - INFO - Episode 164/100000: Winner=2, Reward=-7.10, EPSILON=0.999, (W=164,D=0,L=0)
2025-01-16 11:33:50,712 - INFO - Episode 165/100000: Winner=2, Reward=-7.40, EPSILON=0.999, (W=165,D=0,L=0)
2025-01-16 11:33:50,868 - INFO - Episode 166/100000: Winner=2, Reward=-1.75, EPSILON=0.999, (W=166,D=0,L=0)
2025-01-16 11:33:51,024 - INFO - Episode 167/100000: Winner=2, Reward=-1.10, EPSILON=0.998, (W=167,D=0,L=0)
2025-01-16 11:33:51,196 - INFO - Episode 168/100000: Winner=2, Reward=4.85, EPSILON=0.998, (W=168,D=0,L=0)
2025-01-16 11:33:51,321 - INFO - Episode 169/100000: Winner=2, Reward=1.65, EPSILON=0.998, (W=169,D=0,L=0)
2025-01-16 11:33:51,430 - DEBUG - Q-vals = [0.15662973 0.11080054 0.15571915 0.20798935 0.14855036 0.14542824
 0.07488266], best_act=3, best_val=0.208
2025-01-16 11:33:51,430 - DEBUG - Low Q-value (0.208), using MCTS.
2025-01-16 11:33:51,430 - INFO - Running MCTS with 16 simulations using 6 processes.
2025-01-16 11:33:54,195 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:33:54,195 - DEBUG - Chose best action 0
2025-01-16 11:33:54,242 - INFO - Episode 170/100000: Winner=2, Reward=1.10, EPSILON=0.998, (W=170,D=0,L=0)
2025-01-16 11:33:54,351 - INFO - Episode 171/100000: Winner=2, Reward=2.40, EPSILON=0.998, (W=171,D=0,L=0)
2025-01-16 11:33:54,586 - INFO - Episode 172/100000: Winner=2, Reward=6.50, EPSILON=0.998, (W=172,D=0,L=0)
2025-01-16 11:33:54,867 - INFO - Episode 173/100000: Winner=2, Reward=-6.40, EPSILON=0.998, (W=173,D=0,L=0)
2025-01-16 11:33:55,117 - INFO - Episode 174/100000: Winner=2, Reward=5.55, EPSILON=0.998, (W=174,D=0,L=0)
2025-01-16 11:33:55,351 - INFO - Episode 175/100000: Winner=2, Reward=3.60, EPSILON=0.998, (W=175,D=0,L=0)
2025-01-16 11:33:55,523 - INFO - Episode 176/100000: Winner=2, Reward=-4.15, EPSILON=0.998, (W=176,D=0,L=0)
2025-01-16 11:33:55,836 - INFO - Episode 177/100000: Winner=2, Reward=0.10, EPSILON=0.998, (W=177,D=0,L=0)
2025-01-16 11:33:55,914 - INFO - Episode 178/100000: Winner=2, Reward=-6.55, EPSILON=0.998, (W=178,D=0,L=0)
2025-01-16 11:33:56,007 - INFO - Episode 179/100000: Winner=2, Reward=-4.55, EPSILON=0.998, (W=179,D=0,L=0)
2025-01-16 11:33:56,132 - INFO - Episode 180/100000: Winner=2, Reward=3.95, EPSILON=0.998, (W=180,D=0,L=0)
2025-01-16 11:33:56,304 - INFO - Episode 181/100000: Winner=2, Reward=-4.75, EPSILON=0.998, (W=181,D=0,L=0)
2025-01-16 11:33:56,460 - INFO - Episode 182/100000: Winner=2, Reward=2.75, EPSILON=0.998, (W=182,D=0,L=0)
2025-01-16 11:33:56,570 - INFO - Episode 183/100000: Winner=2, Reward=4.35, EPSILON=0.998, (W=183,D=0,L=0)
2025-01-16 11:33:56,788 - INFO - Episode 184/100000: Winner=2, Reward=13.85, EPSILON=0.998, (W=184,D=0,L=0)
2025-01-16 11:33:56,976 - INFO - Episode 185/100000: Winner=2, Reward=12.75, EPSILON=0.998, (W=185,D=0,L=0)
2025-01-16 11:33:57,101 - INFO - Episode 186/100000: Winner=2, Reward=-3.50, EPSILON=0.998, (W=186,D=0,L=0)
2025-01-16 11:33:57,210 - INFO - Episode 187/100000: Winner=2, Reward=-5.65, EPSILON=0.998, (W=187,D=0,L=0)
2025-01-16 11:33:57,476 - INFO - Episode 188/100000: Winner=2, Reward=2.85, EPSILON=0.998, (W=188,D=0,L=0)
2025-01-16 11:33:57,601 - INFO - Episode 189/100000: Winner=2, Reward=17.00, EPSILON=0.998, (W=189,D=0,L=0)
2025-01-16 11:33:57,773 - INFO - Episode 190/100000: Winner=2, Reward=-10.00, EPSILON=0.998, (W=190,D=0,L=0)
2025-01-16 11:33:57,882 - INFO - Episode 191/100000: Winner=2, Reward=13.20, EPSILON=0.998, (W=191,D=0,L=0)
2025-01-16 11:33:58,226 - INFO - Episode 192/100000: Winner=2, Reward=21.95, EPSILON=0.998, (W=192,D=0,L=0)
2025-01-16 11:33:58,476 - INFO - Episode 193/100000: Winner=2, Reward=3.30, EPSILON=0.998, (W=193,D=0,L=0)
2025-01-16 11:33:58,632 - INFO - Episode 194/100000: Winner=2, Reward=31.55, EPSILON=0.998, (W=194,D=0,L=0)
2025-01-16 11:33:58,791 - INFO - Episode 195/100000: Winner=2, Reward=-3.55, EPSILON=0.998, (W=195,D=0,L=0)
2025-01-16 11:33:59,107 - INFO - Episode 196/100000: Winner=2, Reward=-21.35, EPSILON=0.998, (W=196,D=0,L=0)
2025-01-16 11:33:59,234 - INFO - Episode 197/100000: Winner=2, Reward=-7.05, EPSILON=0.998, (W=197,D=0,L=0)
2025-01-16 11:33:59,291 - INFO - Episode 198/100000: Winner=2, Reward=0.60, EPSILON=0.998, (W=198,D=0,L=0)
2025-01-16 11:33:59,594 - INFO - Episode 199/100000: Winner=2, Reward=38.05, EPSILON=0.998, (W=199,D=0,L=0)
2025-01-16 11:33:59,835 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 200.
2025-01-16 11:33:59,835 - INFO - Models saved at episode 200
2025-01-16 11:33:59,836 - INFO - Target networks updated
2025-01-16 11:33:59,907 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 200.
2025-01-16 11:33:59,907 - INFO - Episode 200/100000: Winner=2, Reward=-4.40, EPSILON=0.998, (W=200,D=0,L=0)
2025-01-16 11:34:00,083 - INFO - Episode 201/100000: Winner=2, Reward=-7.05, EPSILON=0.998, (W=201,D=0,L=0)
2025-01-16 11:34:00,363 - INFO - Episode 202/100000: Winner=2, Reward=7.75, EPSILON=0.998, (W=202,D=0,L=0)
2025-01-16 11:34:00,605 - INFO - Episode 203/100000: Winner=2, Reward=10.75, EPSILON=0.998, (W=203,D=0,L=0)
2025-01-16 11:34:00,775 - INFO - Episode 204/100000: Winner=2, Reward=-9.90, EPSILON=0.998, (W=204,D=0,L=0)
2025-01-16 11:34:00,962 - INFO - Episode 205/100000: Winner=2, Reward=29.85, EPSILON=0.998, (W=205,D=0,L=0)
2025-01-16 11:34:01,040 - INFO - Episode 206/100000: Winner=2, Reward=8.40, EPSILON=0.998, (W=206,D=0,L=0)
2025-01-16 11:34:01,118 - INFO - Episode 207/100000: Winner=2, Reward=0.10, EPSILON=0.998, (W=207,D=0,L=0)
2025-01-16 11:34:01,368 - INFO - Episode 208/100000: Winner=2, Reward=11.05, EPSILON=0.998, (W=208,D=0,L=0)
2025-01-16 11:34:01,540 - INFO - Episode 209/100000: Winner=2, Reward=14.50, EPSILON=0.998, (W=209,D=0,L=0)
2025-01-16 11:34:01,868 - INFO - Episode 210/100000: Winner=2, Reward=-1.55, EPSILON=0.998, (W=210,D=0,L=0)
2025-01-16 11:34:01,993 - INFO - Episode 211/100000: Winner=2, Reward=6.80, EPSILON=0.998, (W=211,D=0,L=0)
2025-01-16 11:34:02,280 - INFO - Episode 212/100000: Winner=2, Reward=-8.30, EPSILON=0.998, (W=212,D=0,L=0)
2025-01-16 11:34:02,561 - INFO - Episode 213/100000: Winner=2, Reward=-9.45, EPSILON=0.998, (W=213,D=0,L=0)
2025-01-16 11:34:02,690 - INFO - Episode 214/100000: Winner=2, Reward=6.00, EPSILON=0.998, (W=214,D=0,L=0)
2025-01-16 11:34:02,765 - DEBUG - Q-vals = [0.09722593 0.01437562 0.02857725 0.01533764 0.0022485  0.56458426
 0.2776508 ], best_act=5, best_val=0.565
2025-01-16 11:34:02,765 - DEBUG - Low Q-value (0.565), using MCTS.
2025-01-16 11:34:02,766 - INFO - Running MCTS with 18 simulations using 6 processes.
2025-01-16 11:34:05,773 - DEBUG - Aggregated action counts: {0: 6}
2025-01-16 11:34:05,773 - DEBUG - Chose best action 0
2025-01-16 11:34:06,034 - INFO - Episode 215/100000: Winner=2, Reward=8.40, EPSILON=0.998, (W=215,D=0,L=0)
2025-01-16 11:34:06,275 - INFO - Episode 216/100000: Winner=2, Reward=-13.05, EPSILON=0.998, (W=216,D=0,L=0)
2025-01-16 11:34:06,401 - INFO - Episode 217/100000: Winner=2, Reward=1.55, EPSILON=0.998, (W=217,D=0,L=0)
2025-01-16 11:34:06,541 - INFO - Episode 218/100000: Winner=2, Reward=-3.90, EPSILON=0.998, (W=218,D=0,L=0)
2025-01-16 11:34:06,741 - INFO - Episode 219/100000: Winner=2, Reward=2.70, EPSILON=0.998, (W=219,D=0,L=0)
2025-01-16 11:34:06,947 - INFO - Episode 220/100000: Winner=2, Reward=-3.35, EPSILON=0.998, (W=220,D=0,L=0)
2025-01-16 11:34:07,157 - INFO - Episode 221/100000: Winner=2, Reward=3.00, EPSILON=0.998, (W=221,D=0,L=0)
2025-01-16 11:34:07,321 - INFO - Episode 222/100000: Winner=2, Reward=12.05, EPSILON=0.998, (W=222,D=0,L=0)
2025-01-16 11:34:07,496 - INFO - Episode 223/100000: Winner=2, Reward=-5.80, EPSILON=0.998, (W=223,D=0,L=0)
2025-01-16 11:34:07,640 - INFO - Episode 224/100000: Winner=2, Reward=-6.40, EPSILON=0.998, (W=224,D=0,L=0)
2025-01-16 11:34:07,930 - INFO - Episode 225/100000: Winner=2, Reward=7.40, EPSILON=0.998, (W=225,D=0,L=0)
2025-01-16 11:34:08,176 - INFO - Episode 226/100000: Winner=2, Reward=7.45, EPSILON=0.998, (W=226,D=0,L=0)
2025-01-16 11:34:08,340 - INFO - Episode 227/100000: Winner=2, Reward=5.70, EPSILON=0.998, (W=227,D=0,L=0)
2025-01-16 11:34:08,568 - INFO - Episode 228/100000: Winner=2, Reward=21.55, EPSILON=0.998, (W=228,D=0,L=0)
2025-01-16 11:34:08,690 - INFO - Episode 229/100000: Winner=2, Reward=4.60, EPSILON=0.998, (W=229,D=0,L=0)
2025-01-16 11:34:09,077 - INFO - Episode 230/100000: Winner=2, Reward=14.20, EPSILON=0.998, (W=230,D=0,L=0)
2025-01-16 11:34:09,211 - INFO - Episode 231/100000: Winner=2, Reward=-7.95, EPSILON=0.998, (W=231,D=0,L=0)
2025-01-16 11:34:09,327 - INFO - Episode 232/100000: Winner=2, Reward=-4.30, EPSILON=0.998, (W=232,D=0,L=0)
2025-01-16 11:34:09,559 - INFO - Episode 233/100000: Winner=2, Reward=10.30, EPSILON=0.998, (W=233,D=0,L=0)
2025-01-16 11:34:09,842 - INFO - Episode 234/100000: Winner=2, Reward=-8.55, EPSILON=0.998, (W=234,D=0,L=0)
2025-01-16 11:34:10,061 - INFO - Episode 235/100000: Winner=2, Reward=-17.15, EPSILON=0.998, (W=235,D=0,L=0)
2025-01-16 11:34:10,287 - INFO - Episode 236/100000: Winner=2, Reward=14.00, EPSILON=0.998, (W=236,D=0,L=0)
2025-01-16 11:34:10,441 - INFO - Episode 237/100000: Winner=2, Reward=-6.55, EPSILON=0.998, (W=237,D=0,L=0)
2025-01-16 11:34:10,566 - INFO - Episode 238/100000: Winner=2, Reward=15.05, EPSILON=0.998, (W=238,D=0,L=0)
2025-01-16 11:34:10,676 - INFO - Episode 239/100000: Winner=2, Reward=9.00, EPSILON=0.998, (W=239,D=0,L=0)
2025-01-16 11:34:10,836 - INFO - Episode 240/100000: Winner=2, Reward=-2.95, EPSILON=0.998, (W=240,D=0,L=0)
2025-01-16 11:34:11,006 - INFO - Episode 241/100000: Winner=2, Reward=-3.05, EPSILON=0.998, (W=241,D=0,L=0)
2025-01-16 11:34:11,226 - INFO - Episode 242/100000: Winner=2, Reward=-7.70, EPSILON=0.998, (W=242,D=0,L=0)
2025-01-16 11:34:11,504 - INFO - Episode 243/100000: Winner=2, Reward=0.65, EPSILON=0.998, (W=243,D=0,L=0)
2025-01-16 11:34:11,743 - INFO - Episode 244/100000: Winner=2, Reward=-4.75, EPSILON=0.998, (W=244,D=0,L=0)
2025-01-16 11:34:12,010 - INFO - Episode 245/100000: Winner=2, Reward=-12.25, EPSILON=0.998, (W=245,D=0,L=0)
2025-01-16 11:34:12,103 - INFO - Episode 246/100000: Winner=2, Reward=0.15, EPSILON=0.998, (W=246,D=0,L=0)
2025-01-16 11:34:12,285 - INFO - Episode 247/100000: Winner=2, Reward=-6.80, EPSILON=0.998, (W=247,D=0,L=0)
2025-01-16 11:34:12,363 - INFO - Episode 248/100000: Winner=2, Reward=2.70, EPSILON=0.998, (W=248,D=0,L=0)
2025-01-16 11:34:12,457 - INFO - Episode 249/100000: Winner=2, Reward=8.90, EPSILON=0.998, (W=249,D=0,L=0)
2025-01-16 11:34:12,658 - INFO - Episode 250/100000: Winner=2, Reward=34.05, EPSILON=0.998, (W=250,D=0,L=0)
2025-01-16 11:34:12,887 - INFO - Episode 251/100000: Winner=2, Reward=10.75, EPSILON=0.998, (W=251,D=0,L=0)
2025-01-16 11:34:13,045 - INFO - Episode 252/100000: Winner=2, Reward=10.50, EPSILON=0.998, (W=252,D=0,L=0)
2025-01-16 11:34:13,187 - INFO - Episode 253/100000: Winner=2, Reward=-1.80, EPSILON=0.998, (W=253,D=0,L=0)
2025-01-16 11:34:13,312 - INFO - Episode 254/100000: Winner=2, Reward=1.75, EPSILON=0.998, (W=254,D=0,L=0)
2025-01-16 11:34:13,461 - INFO - Episode 255/100000: Winner=2, Reward=-3.65, EPSILON=0.998, (W=255,D=0,L=0)
2025-01-16 11:34:13,678 - INFO - Episode 256/100000: Winner=2, Reward=24.45, EPSILON=0.998, (W=256,D=0,L=0)
2025-01-16 11:34:13,777 - INFO - Episode 257/100000: Winner=2, Reward=1.60, EPSILON=0.998, (W=257,D=0,L=0)
2025-01-16 11:34:13,915 - INFO - Episode 258/100000: Winner=2, Reward=-5.75, EPSILON=0.998, (W=258,D=0,L=0)
2025-01-16 11:34:13,980 - INFO - Episode 259/100000: Winner=2, Reward=8.40, EPSILON=0.998, (W=259,D=0,L=0)
2025-01-16 11:34:14,125 - INFO - Episode 260/100000: Winner=2, Reward=7.95, EPSILON=0.998, (W=260,D=0,L=0)
2025-01-16 11:34:14,374 - INFO - Episode 261/100000: Winner=2, Reward=4.65, EPSILON=0.998, (W=261,D=0,L=0)
2025-01-16 11:34:14,626 - INFO - Episode 262/100000: Winner=2, Reward=5.75, EPSILON=0.998, (W=262,D=0,L=0)
2025-01-16 11:34:14,696 - INFO - Episode 263/100000: Winner=2, Reward=1.20, EPSILON=0.998, (W=263,D=0,L=0)
2025-01-16 11:34:14,894 - INFO - Episode 264/100000: Winner=2, Reward=-2.90, EPSILON=0.998, (W=264,D=0,L=0)
2025-01-16 11:34:15,060 - INFO - Episode 265/100000: Winner=2, Reward=-1.65, EPSILON=0.998, (W=265,D=0,L=0)
2025-01-16 11:34:15,135 - INFO - Episode 266/100000: Winner=2, Reward=-6.35, EPSILON=0.998, (W=266,D=0,L=0)
2025-01-16 11:34:15,292 - INFO - Episode 267/100000: Winner=2, Reward=16.25, EPSILON=0.998, (W=267,D=0,L=0)
2025-01-16 11:34:15,526 - INFO - Episode 268/100000: Winner=2, Reward=17.05, EPSILON=0.998, (W=268,D=0,L=0)
2025-01-16 11:34:15,730 - INFO - Episode 269/100000: Winner=2, Reward=30.55, EPSILON=0.998, (W=269,D=0,L=0)
2025-01-16 11:34:15,812 - INFO - Episode 270/100000: Winner=2, Reward=1.85, EPSILON=0.998, (W=270,D=0,L=0)
2025-01-16 11:34:16,105 - INFO - Episode 271/100000: Winner=2, Reward=3.70, EPSILON=0.998, (W=271,D=0,L=0)
2025-01-16 11:34:16,444 - INFO - Episode 272/100000: Winner=2, Reward=-23.60, EPSILON=0.998, (W=272,D=0,L=0)
2025-01-16 11:34:16,659 - INFO - Episode 273/100000: Winner=2, Reward=-0.25, EPSILON=0.998, (W=273,D=0,L=0)
2025-01-16 11:34:16,782 - INFO - Episode 274/100000: Winner=2, Reward=2.05, EPSILON=0.998, (W=274,D=0,L=0)
2025-01-16 11:34:17,053 - INFO - Episode 275/100000: Winner=2, Reward=8.80, EPSILON=0.998, (W=275,D=0,L=0)
2025-01-16 11:34:17,267 - INFO - Episode 276/100000: Winner=2, Reward=4.85, EPSILON=0.998, (W=276,D=0,L=0)
2025-01-16 11:34:17,439 - INFO - Episode 277/100000: Winner=2, Reward=0.45, EPSILON=0.998, (W=277,D=0,L=0)
2025-01-16 11:34:17,707 - INFO - Episode 278/100000: Winner=2, Reward=-5.70, EPSILON=0.998, (W=278,D=0,L=0)
2025-01-16 11:34:17,847 - INFO - Episode 279/100000: Winner=2, Reward=9.90, EPSILON=0.997, (W=279,D=0,L=0)
2025-01-16 11:34:18,176 - INFO - Episode 280/100000: Winner=2, Reward=-3.65, EPSILON=0.997, (W=280,D=0,L=0)
2025-01-16 11:34:18,309 - INFO - Episode 281/100000: Winner=2, Reward=16.35, EPSILON=0.997, (W=281,D=0,L=0)
2025-01-16 11:34:18,482 - INFO - Episode 282/100000: Winner=2, Reward=16.65, EPSILON=0.997, (W=282,D=0,L=0)
2025-01-16 11:34:18,669 - INFO - Episode 283/100000: Winner=2, Reward=4.60, EPSILON=0.997, (W=283,D=0,L=0)
2025-01-16 11:34:18,864 - INFO - Episode 284/100000: Winner=2, Reward=30.95, EPSILON=0.997, (W=284,D=0,L=0)
2025-01-16 11:34:19,094 - INFO - Episode 285/100000: Winner=2, Reward=8.25, EPSILON=0.997, (W=285,D=0,L=0)
2025-01-16 11:34:19,284 - INFO - Episode 286/100000: Winner=2, Reward=5.90, EPSILON=0.997, (W=286,D=0,L=0)
2025-01-16 11:34:19,536 - DEBUG - Q-vals = [3.3877585e-02 6.0136449e-03 9.0720326e-01 1.3689348e-04 1.4686387e-02
 2.5817072e-03 3.5500541e-02], best_act=2, best_val=0.907
2025-01-16 11:34:19,536 - DEBUG - Low Q-value (0.907), using MCTS.
2025-01-16 11:34:19,537 - INFO - Running MCTS with 21 simulations using 6 processes.
2025-01-16 11:34:22,408 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:34:22,408 - DEBUG - Chose best action 0
2025-01-16 11:34:22,470 - INFO - Episode 287/100000: Winner=2, Reward=3.55, EPSILON=0.997, (W=287,D=0,L=0)
2025-01-16 11:34:22,611 - INFO - Episode 288/100000: Winner=2, Reward=7.25, EPSILON=0.997, (W=288,D=0,L=0)
2025-01-16 11:34:22,799 - INFO - Episode 289/100000: Winner=2, Reward=-7.85, EPSILON=0.997, (W=289,D=0,L=0)
2025-01-16 11:34:23,080 - INFO - Episode 290/100000: Winner=2, Reward=2.60, EPSILON=0.997, (W=290,D=0,L=0)
2025-01-16 11:34:23,221 - INFO - Episode 291/100000: Winner=2, Reward=20.00, EPSILON=0.997, (W=291,D=0,L=0)
2025-01-16 11:34:23,455 - INFO - Episode 292/100000: Winner=2, Reward=24.95, EPSILON=0.997, (W=292,D=0,L=0)
2025-01-16 11:34:23,752 - INFO - Episode 293/100000: Winner=2, Reward=-10.50, EPSILON=0.997, (W=293,D=0,L=0)
2025-01-16 11:34:23,939 - INFO - Episode 294/100000: Winner=2, Reward=16.55, EPSILON=0.997, (W=294,D=0,L=0)
2025-01-16 11:34:24,064 - INFO - Episode 295/100000: Winner=2, Reward=0.45, EPSILON=0.997, (W=295,D=0,L=0)
2025-01-16 11:34:24,408 - INFO - Episode 296/100000: Winner=2, Reward=-7.10, EPSILON=0.997, (W=296,D=0,L=0)
2025-01-16 11:34:24,705 - INFO - Episode 297/100000: Winner=2, Reward=-16.80, EPSILON=0.997, (W=297,D=0,L=0)
2025-01-16 11:34:24,892 - DEBUG - Q-vals = [0.0321183  0.63546586 0.02311395 0.01053109 0.01209751 0.13073228
 0.15594102], best_act=1, best_val=0.635
2025-01-16 11:34:24,892 - DEBUG - Low Q-value (0.635), using MCTS.
2025-01-16 11:34:24,908 - INFO - Episode 298/100000: Winner=2, Reward=-5.40, EPSILON=0.997, (W=298,D=0,L=0)
2025-01-16 11:34:25,017 - INFO - Episode 299/100000: Winner=2, Reward=0.80, EPSILON=0.997, (W=299,D=0,L=0)
2025-01-16 11:34:25,377 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 300.
2025-01-16 11:34:25,377 - INFO - Models saved at episode 300
2025-01-16 11:34:25,377 - INFO - Target networks updated
2025-01-16 11:34:25,439 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 300.
2025-01-16 11:34:25,439 - INFO - Episode 300/100000: Winner=2, Reward=-26.75, EPSILON=0.997, (W=300,D=0,L=0)
2025-01-16 11:34:25,627 - INFO - Episode 301/100000: Winner=2, Reward=17.45, EPSILON=0.997, (W=301,D=0,L=0)
2025-01-16 11:34:25,736 - INFO - Episode 302/100000: Winner=2, Reward=-4.45, EPSILON=0.997, (W=302,D=0,L=0)
2025-01-16 11:34:25,923 - INFO - Episode 303/100000: Winner=2, Reward=10.25, EPSILON=0.997, (W=303,D=0,L=0)
2025-01-16 11:34:26,173 - INFO - Episode 304/100000: Winner=2, Reward=21.70, EPSILON=0.997, (W=304,D=0,L=0)
2025-01-16 11:34:26,423 - INFO - Episode 305/100000: Winner=2, Reward=6.05, EPSILON=0.997, (W=305,D=0,L=0)
2025-01-16 11:34:26,689 - INFO - Episode 306/100000: Winner=2, Reward=18.85, EPSILON=0.997, (W=306,D=0,L=0)
2025-01-16 11:34:26,876 - INFO - Episode 307/100000: Winner=2, Reward=18.00, EPSILON=0.997, (W=307,D=0,L=0)
2025-01-16 11:34:27,001 - INFO - Episode 308/100000: Winner=2, Reward=1.05, EPSILON=0.997, (W=308,D=0,L=0)
2025-01-16 11:34:27,267 - INFO - Episode 309/100000: Winner=2, Reward=26.70, EPSILON=0.997, (W=309,D=0,L=0)
2025-01-16 11:34:27,470 - INFO - Episode 310/100000: Winner=2, Reward=13.25, EPSILON=0.997, (W=310,D=0,L=0)
2025-01-16 11:34:27,720 - INFO - Episode 311/100000: Winner=2, Reward=26.05, EPSILON=0.997, (W=311,D=0,L=0)
2025-01-16 11:34:27,892 - INFO - Episode 312/100000: Winner=2, Reward=19.30, EPSILON=0.997, (W=312,D=0,L=0)
2025-01-16 11:34:28,001 - INFO - Episode 313/100000: Winner=2, Reward=16.30, EPSILON=0.997, (W=313,D=0,L=0)
2025-01-16 11:34:28,267 - INFO - Episode 314/100000: Winner=2, Reward=-3.85, EPSILON=0.997, (W=314,D=0,L=0)
2025-01-16 11:34:28,485 - INFO - Episode 315/100000: Winner=2, Reward=8.40, EPSILON=0.997, (W=315,D=0,L=0)
2025-01-16 11:34:28,704 - INFO - Episode 316/100000: Winner=2, Reward=-5.85, EPSILON=0.997, (W=316,D=0,L=0)
2025-01-16 11:34:28,969 - INFO - Episode 317/100000: Winner=2, Reward=-11.50, EPSILON=0.997, (W=317,D=0,L=0)
2025-01-16 11:34:29,141 - INFO - Episode 318/100000: Winner=2, Reward=15.40, EPSILON=0.997, (W=318,D=0,L=0)
2025-01-16 11:34:29,376 - INFO - Episode 319/100000: Winner=2, Reward=-4.40, EPSILON=0.997, (W=319,D=0,L=0)
2025-01-16 11:34:29,547 - INFO - Episode 320/100000: Winner=2, Reward=24.05, EPSILON=0.997, (W=320,D=0,L=0)
2025-01-16 11:34:29,719 - INFO - Episode 321/100000: Winner=2, Reward=16.40, EPSILON=0.997, (W=321,D=0,L=0)
2025-01-16 11:34:29,782 - INFO - Episode 322/100000: Winner=2, Reward=-6.90, EPSILON=0.997, (W=322,D=0,L=0)
2025-01-16 11:34:30,079 - INFO - Episode 323/100000: Winner=2, Reward=16.50, EPSILON=0.997, (W=323,D=0,L=0)
2025-01-16 11:34:30,204 - INFO - Episode 324/100000: Winner=2, Reward=-10.90, EPSILON=0.997, (W=324,D=0,L=0)
2025-01-16 11:34:30,282 - INFO - Episode 325/100000: Winner=2, Reward=-5.85, EPSILON=0.997, (W=325,D=0,L=0)
2025-01-16 11:34:30,438 - INFO - Episode 326/100000: Winner=2, Reward=1.25, EPSILON=0.997, (W=326,D=0,L=0)
2025-01-16 11:34:30,563 - INFO - Episode 327/100000: Winner=2, Reward=23.25, EPSILON=0.997, (W=327,D=0,L=0)
2025-01-16 11:34:30,719 - INFO - Episode 328/100000: Winner=2, Reward=16.25, EPSILON=0.997, (W=328,D=0,L=0)
2025-01-16 11:34:30,828 - INFO - Episode 329/100000: Winner=2, Reward=17.35, EPSILON=0.997, (W=329,D=0,L=0)
2025-01-16 11:34:31,172 - INFO - Episode 330/100000: Winner=2, Reward=-24.60, EPSILON=0.997, (W=330,D=0,L=0)
2025-01-16 11:34:31,297 - INFO - Episode 331/100000: Winner=2, Reward=-4.40, EPSILON=0.997, (W=331,D=0,L=0)
2025-01-16 11:34:31,547 - INFO - Episode 332/100000: Winner=2, Reward=18.40, EPSILON=0.997, (W=332,D=0,L=0)
2025-01-16 11:34:31,781 - INFO - Episode 333/100000: Winner=2, Reward=-8.65, EPSILON=0.997, (W=333,D=0,L=0)
2025-01-16 11:34:31,969 - INFO - Episode 334/100000: Winner=2, Reward=-7.60, EPSILON=0.997, (W=334,D=0,L=0)
2025-01-16 11:34:32,234 - INFO - Episode 335/100000: Winner=2, Reward=10.75, EPSILON=0.997, (W=335,D=0,L=0)
2025-01-16 11:34:32,313 - INFO - Episode 336/100000: Winner=2, Reward=1.10, EPSILON=0.997, (W=336,D=0,L=0)
2025-01-16 11:34:32,469 - INFO - Episode 337/100000: Winner=2, Reward=-5.80, EPSILON=0.997, (W=337,D=0,L=0)
2025-01-16 11:34:32,625 - INFO - Episode 338/100000: Winner=2, Reward=-5.65, EPSILON=0.997, (W=338,D=0,L=0)
2025-01-16 11:34:32,828 - INFO - Episode 339/100000: Winner=2, Reward=19.70, EPSILON=0.997, (W=339,D=0,L=0)
2025-01-16 11:34:33,063 - INFO - Episode 340/100000: Winner=2, Reward=5.50, EPSILON=0.997, (W=340,D=0,L=0)
2025-01-16 11:34:33,344 - INFO - Episode 341/100000: Winner=2, Reward=3.30, EPSILON=0.997, (W=341,D=0,L=0)
2025-01-16 11:34:33,562 - INFO - Episode 342/100000: Winner=2, Reward=7.40, EPSILON=0.997, (W=342,D=0,L=0)
2025-01-16 11:34:33,797 - INFO - Episode 343/100000: Winner=2, Reward=49.15, EPSILON=0.997, (W=343,D=0,L=0)
2025-01-16 11:34:33,922 - INFO - Episode 344/100000: Winner=2, Reward=11.20, EPSILON=0.997, (W=344,D=0,L=0)
2025-01-16 11:34:34,172 - INFO - Episode 345/100000: Winner=2, Reward=-0.60, EPSILON=0.997, (W=345,D=0,L=0)
2025-01-16 11:34:34,281 - INFO - Episode 346/100000: Winner=2, Reward=-6.30, EPSILON=0.997, (W=346,D=0,L=0)
2025-01-16 11:34:34,547 - INFO - Episode 347/100000: Winner=2, Reward=21.45, EPSILON=0.997, (W=347,D=0,L=0)
2025-01-16 11:34:34,718 - INFO - Episode 348/100000: Winner=2, Reward=6.95, EPSILON=0.997, (W=348,D=0,L=0)
2025-01-16 11:34:34,984 - INFO - Episode 349/100000: Winner=2, Reward=-8.65, EPSILON=0.997, (W=349,D=0,L=0)
2025-01-16 11:34:35,125 - INFO - Episode 350/100000: Winner=2, Reward=1.35, EPSILON=0.997, (W=350,D=0,L=0)
2025-01-16 11:34:35,250 - INFO - Episode 351/100000: Winner=2, Reward=24.10, EPSILON=0.997, (W=351,D=0,L=0)
2025-01-16 11:34:35,437 - INFO - Episode 352/100000: Winner=2, Reward=-4.30, EPSILON=0.997, (W=352,D=0,L=0)
2025-01-16 11:34:35,640 - DEBUG - Q-vals = [0.73127776 0.01310993 0.03168685 0.0749352  0.01870537 0.12059175
 0.00969319], best_act=0, best_val=0.731
2025-01-16 11:34:35,640 - DEBUG - Low Q-value (0.731), using MCTS.
2025-01-16 11:34:35,656 - INFO - Running MCTS with 24 simulations using 6 processes.
2025-01-16 11:34:38,311 - DEBUG - Aggregated action counts: {0: 6}
2025-01-16 11:34:38,311 - DEBUG - Chose best action 0
2025-01-16 11:34:38,452 - INFO - Episode 353/100000: Winner=2, Reward=-19.95, EPSILON=0.997, (W=353,D=0,L=0)
2025-01-16 11:34:38,624 - INFO - Episode 354/100000: Winner=2, Reward=20.10, EPSILON=0.997, (W=354,D=0,L=0)
2025-01-16 11:34:38,780 - INFO - Episode 355/100000: Winner=2, Reward=14.50, EPSILON=0.997, (W=355,D=0,L=0)
2025-01-16 11:34:39,108 - INFO - Episode 356/100000: Winner=2, Reward=-12.60, EPSILON=0.997, (W=356,D=0,L=0)
2025-01-16 11:34:39,280 - INFO - Episode 357/100000: Winner=2, Reward=17.70, EPSILON=0.997, (W=357,D=0,L=0)
2025-01-16 11:34:39,436 - INFO - Episode 358/100000: Winner=2, Reward=5.25, EPSILON=0.997, (W=358,D=0,L=0)
2025-01-16 11:34:39,655 - INFO - Episode 359/100000: Winner=2, Reward=25.35, EPSILON=0.997, (W=359,D=0,L=0)
2025-01-16 11:34:39,780 - INFO - Episode 360/100000: Winner=2, Reward=-6.00, EPSILON=0.997, (W=360,D=0,L=0)
2025-01-16 11:34:40,123 - INFO - Episode 361/100000: Winner=2, Reward=12.20, EPSILON=0.997, (W=361,D=0,L=0)
2025-01-16 11:34:40,373 - INFO - Episode 362/100000: Winner=2, Reward=6.35, EPSILON=0.997, (W=362,D=0,L=0)
2025-01-16 11:34:40,616 - DEBUG - Q-vals = [0.04673927 0.10477217 0.07438409 0.00407094 0.27915126 0.21382771
 0.27705458], best_act=4, best_val=0.279
2025-01-16 11:34:40,631 - DEBUG - Low Q-value (0.279), using MCTS.
2025-01-16 11:34:40,631 - INFO - Running MCTS with 24 simulations using 6 processes.
2025-01-16 11:34:43,674 - DEBUG - Aggregated action counts: {0: 6}
2025-01-16 11:34:43,674 - DEBUG - Chose best action 0
2025-01-16 11:34:43,770 - INFO - Episode 363/100000: Winner=2, Reward=1.80, EPSILON=0.997, (W=363,D=0,L=0)
2025-01-16 11:34:43,982 - INFO - Episode 364/100000: Winner=2, Reward=-14.10, EPSILON=0.997, (W=364,D=0,L=0)
2025-01-16 11:34:44,215 - INFO - Episode 365/100000: Winner=2, Reward=47.35, EPSILON=0.997, (W=365,D=0,L=0)
2025-01-16 11:34:44,423 - INFO - Episode 366/100000: Winner=2, Reward=7.50, EPSILON=0.997, (W=366,D=0,L=0)
2025-01-16 11:34:44,570 - INFO - Episode 367/100000: Winner=2, Reward=12.20, EPSILON=0.997, (W=367,D=0,L=0)
2025-01-16 11:34:44,746 - INFO - Episode 368/100000: Winner=2, Reward=2.20, EPSILON=0.997, (W=368,D=0,L=0)
2025-01-16 11:34:44,824 - INFO - Episode 369/100000: Winner=2, Reward=0.90, EPSILON=0.997, (W=369,D=0,L=0)
2025-01-16 11:34:45,059 - INFO - Episode 370/100000: Winner=2, Reward=-7.95, EPSILON=0.997, (W=370,D=0,L=0)
2025-01-16 11:34:45,121 - DEBUG - Q-vals = [0.09167612 0.16763988 0.08526197 0.18906479 0.16015163 0.14535412
 0.16085146], best_act=3, best_val=0.189
2025-01-16 11:34:45,121 - DEBUG - Low Q-value (0.189), using MCTS.
2025-01-16 11:34:45,121 - INFO - Running MCTS with 24 simulations using 6 processes.
2025-01-16 11:34:47,834 - DEBUG - Aggregated action counts: {0: 6}
2025-01-16 11:34:47,834 - DEBUG - Chose best action 0
2025-01-16 11:34:47,925 - INFO - Episode 371/100000: Winner=2, Reward=16.10, EPSILON=0.997, (W=371,D=0,L=0)
2025-01-16 11:34:48,171 - INFO - Episode 372/100000: Winner=2, Reward=20.10, EPSILON=0.997, (W=372,D=0,L=0)
2025-01-16 11:34:48,374 - INFO - Episode 373/100000: Winner=2, Reward=-4.00, EPSILON=0.997, (W=373,D=0,L=0)
2025-01-16 11:34:48,533 - INFO - Episode 374/100000: Winner=2, Reward=1.25, EPSILON=0.997, (W=374,D=0,L=0)
2025-01-16 11:34:48,720 - INFO - Episode 375/100000: Winner=2, Reward=7.90, EPSILON=0.997, (W=375,D=0,L=0)
2025-01-16 11:34:49,014 - INFO - Episode 376/100000: Winner=2, Reward=14.00, EPSILON=0.997, (W=376,D=0,L=0)
2025-01-16 11:34:49,221 - INFO - Episode 377/100000: Winner=2, Reward=-2.50, EPSILON=0.997, (W=377,D=0,L=0)
2025-01-16 11:34:49,354 - INFO - Episode 378/100000: Winner=2, Reward=-5.15, EPSILON=0.997, (W=378,D=0,L=0)
2025-01-16 11:34:49,590 - INFO - Episode 379/100000: Winner=2, Reward=1.80, EPSILON=0.997, (W=379,D=0,L=0)
2025-01-16 11:34:49,680 - INFO - Episode 380/100000: Winner=2, Reward=1.60, EPSILON=0.997, (W=380,D=0,L=0)
2025-01-16 11:34:49,906 - INFO - Episode 381/100000: Winner=2, Reward=18.55, EPSILON=0.997, (W=381,D=0,L=0)
2025-01-16 11:34:50,220 - INFO - Episode 382/100000: Winner=2, Reward=2.60, EPSILON=0.997, (W=382,D=0,L=0)
2025-01-16 11:34:50,449 - INFO - Episode 383/100000: Winner=2, Reward=29.45, EPSILON=0.997, (W=383,D=0,L=0)
2025-01-16 11:34:50,632 - INFO - Episode 384/100000: Winner=2, Reward=22.90, EPSILON=0.997, (W=384,D=0,L=0)
2025-01-16 11:34:50,819 - INFO - Episode 385/100000: Winner=2, Reward=2.85, EPSILON=0.997, (W=385,D=0,L=0)
2025-01-16 11:34:50,914 - INFO - Episode 386/100000: Winner=2, Reward=-4.35, EPSILON=0.997, (W=386,D=0,L=0)
2025-01-16 11:34:51,164 - INFO - Episode 387/100000: Winner=2, Reward=-7.60, EPSILON=0.997, (W=387,D=0,L=0)
2025-01-16 11:34:51,340 - INFO - Episode 388/100000: Winner=2, Reward=17.35, EPSILON=0.997, (W=388,D=0,L=0)
2025-01-16 11:34:51,468 - DEBUG - Q-vals = [0.0026833  0.03729693 0.01522449 0.5534122  0.09693712 0.06568545
 0.22876057], best_act=3, best_val=0.553
2025-01-16 11:34:51,468 - DEBUG - Low Q-value (0.553), using MCTS.
2025-01-16 11:34:51,469 - INFO - Running MCTS with 25 simulations using 6 processes.
2025-01-16 11:34:54,211 - DEBUG - Aggregated action counts: {0: 6, 5: 1}
2025-01-16 11:34:54,211 - DEBUG - Chose best action 0
2025-01-16 11:34:54,595 - INFO - Episode 389/100000: Winner=2, Reward=-32.10, EPSILON=0.997, (W=389,D=0,L=0)
2025-01-16 11:34:54,859 - INFO - Episode 390/100000: Winner=2, Reward=16.00, EPSILON=0.996, (W=390,D=0,L=0)
2025-01-16 11:34:55,077 - INFO - Episode 391/100000: Winner=2, Reward=18.15, EPSILON=0.996, (W=391,D=0,L=0)
2025-01-16 11:34:55,243 - INFO - Episode 392/100000: Winner=2, Reward=-9.45, EPSILON=0.996, (W=392,D=0,L=0)
2025-01-16 11:34:55,461 - INFO - Episode 393/100000: Winner=2, Reward=3.50, EPSILON=0.996, (W=393,D=0,L=0)
2025-01-16 11:34:55,623 - INFO - Episode 394/100000: Winner=2, Reward=13.75, EPSILON=0.996, (W=394,D=0,L=0)
2025-01-16 11:34:55,850 - INFO - Episode 395/100000: Winner=2, Reward=3.55, EPSILON=0.996, (W=395,D=0,L=0)
2025-01-16 11:34:55,954 - INFO - Episode 396/100000: Winner=2, Reward=-6.05, EPSILON=0.996, (W=396,D=0,L=0)
2025-01-16 11:34:56,124 - INFO - Episode 397/100000: Winner=2, Reward=4.30, EPSILON=0.996, (W=397,D=0,L=0)
2025-01-16 11:34:56,248 - INFO - Episode 398/100000: Winner=2, Reward=6.80, EPSILON=0.996, (W=398,D=0,L=0)
2025-01-16 11:34:56,516 - INFO - Episode 399/100000: Winner=2, Reward=15.65, EPSILON=0.996, (W=399,D=0,L=0)
2025-01-16 11:34:56,784 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 400.
2025-01-16 11:34:56,784 - INFO - Models saved at episode 400
2025-01-16 11:34:56,784 - INFO - Target networks updated
2025-01-16 11:34:56,855 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 400.
2025-01-16 11:34:56,856 - INFO - Episode 400/100000: Winner=2, Reward=8.65, EPSILON=0.996, (W=400,D=0,L=0)
2025-01-16 11:34:57,069 - INFO - Episode 401/100000: Winner=2, Reward=42.00, EPSILON=0.996, (W=401,D=0,L=0)
2025-01-16 11:34:57,266 - INFO - Episode 402/100000: Winner=2, Reward=7.80, EPSILON=0.996, (W=402,D=0,L=0)
2025-01-16 11:34:57,422 - INFO - Episode 403/100000: Winner=2, Reward=-7.40, EPSILON=0.996, (W=403,D=0,L=0)
2025-01-16 11:34:57,715 - INFO - Episode 404/100000: Winner=2, Reward=2.40, EPSILON=0.996, (W=404,D=0,L=0)
2025-01-16 11:34:57,965 - INFO - Episode 405/100000: Winner=2, Reward=-5.65, EPSILON=0.996, (W=405,D=0,L=0)
2025-01-16 11:34:58,177 - INFO - Episode 406/100000: Winner=2, Reward=-6.85, EPSILON=0.996, (W=406,D=0,L=0)
2025-01-16 11:34:58,408 - INFO - Episode 407/100000: Winner=2, Reward=6.20, EPSILON=0.996, (W=407,D=0,L=0)
2025-01-16 11:34:58,592 - INFO - Episode 408/100000: Winner=2, Reward=5.70, EPSILON=0.996, (W=408,D=0,L=0)
2025-01-16 11:34:58,701 - INFO - Episode 409/100000: Winner=2, Reward=9.70, EPSILON=0.996, (W=409,D=0,L=0)
2025-01-16 11:34:58,896 - INFO - Episode 410/100000: Winner=2, Reward=16.35, EPSILON=0.996, (W=410,D=0,L=0)
2025-01-16 11:34:59,084 - INFO - Episode 411/100000: Winner=2, Reward=5.35, EPSILON=0.996, (W=411,D=0,L=0)
2025-01-16 11:34:59,365 - INFO - Episode 412/100000: Winner=2, Reward=19.15, EPSILON=0.996, (W=412,D=0,L=0)
2025-01-16 11:34:59,599 - INFO - Episode 413/100000: Winner=2, Reward=-24.10, EPSILON=0.996, (W=413,D=0,L=0)
2025-01-16 11:34:59,667 - INFO - Episode 414/100000: Winner=2, Reward=-7.15, EPSILON=0.996, (W=414,D=0,L=0)
2025-01-16 11:34:59,873 - INFO - Episode 415/100000: Winner=2, Reward=8.25, EPSILON=0.996, (W=415,D=0,L=0)
2025-01-16 11:35:00,110 - INFO - Episode 416/100000: Winner=2, Reward=0.25, EPSILON=0.996, (W=416,D=0,L=0)
2025-01-16 11:35:00,289 - INFO - Episode 417/100000: Winner=2, Reward=-8.25, EPSILON=0.996, (W=417,D=0,L=0)
2025-01-16 11:35:00,607 - INFO - Episode 418/100000: Winner=2, Reward=4.35, EPSILON=0.996, (W=418,D=0,L=0)
2025-01-16 11:35:00,944 - INFO - Episode 419/100000: Winner=2, Reward=2.65, EPSILON=0.996, (W=419,D=0,L=0)
2025-01-16 11:35:01,168 - INFO - Episode 420/100000: Winner=2, Reward=13.20, EPSILON=0.996, (W=420,D=0,L=0)
2025-01-16 11:35:01,380 - INFO - Episode 421/100000: Winner=2, Reward=9.85, EPSILON=0.996, (W=421,D=0,L=0)
2025-01-16 11:35:01,519 - INFO - Episode 422/100000: Winner=2, Reward=2.40, EPSILON=0.996, (W=422,D=0,L=0)
2025-01-16 11:35:01,772 - INFO - Episode 423/100000: Winner=2, Reward=12.45, EPSILON=0.996, (W=423,D=0,L=0)
2025-01-16 11:35:02,040 - INFO - Episode 424/100000: Winner=2, Reward=23.85, EPSILON=0.996, (W=424,D=0,L=0)
2025-01-16 11:35:02,315 - INFO - Episode 425/100000: Winner=2, Reward=-6.80, EPSILON=0.996, (W=425,D=0,L=0)
2025-01-16 11:35:02,498 - INFO - Episode 426/100000: Winner=2, Reward=-0.30, EPSILON=0.996, (W=426,D=0,L=0)
2025-01-16 11:35:02,694 - INFO - Episode 427/100000: Winner=2, Reward=-2.25, EPSILON=0.996, (W=427,D=0,L=0)
2025-01-16 11:35:02,865 - INFO - Episode 428/100000: Winner=2, Reward=23.90, EPSILON=0.996, (W=428,D=0,L=0)
2025-01-16 11:35:03,073 - INFO - Episode 429/100000: Winner=2, Reward=0.40, EPSILON=0.996, (W=429,D=0,L=0)
2025-01-16 11:35:03,146 - INFO - Episode 430/100000: Winner=2, Reward=0.75, EPSILON=0.996, (W=430,D=0,L=0)
2025-01-16 11:35:03,380 - INFO - Episode 431/100000: Winner=2, Reward=2.30, EPSILON=0.996, (W=431,D=0,L=0)
2025-01-16 11:35:03,568 - INFO - Episode 432/100000: Winner=2, Reward=-8.80, EPSILON=0.996, (W=432,D=0,L=0)
2025-01-16 11:35:03,713 - INFO - Episode 433/100000: Winner=2, Reward=1.40, EPSILON=0.996, (W=433,D=0,L=0)
2025-01-16 11:35:03,744 - DEBUG - Q-vals = [0.03817941 0.0738415  0.2556816  0.1052293  0.3283978  0.10670726
 0.09196308], best_act=4, best_val=0.328
2025-01-16 11:35:03,744 - DEBUG - Low Q-value (0.328), using MCTS.
2025-01-16 11:35:03,744 - INFO - Running MCTS with 27 simulations using 6 processes.
2025-01-16 11:35:06,379 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:35:06,379 - DEBUG - Chose best action 0
2025-01-16 11:35:06,480 - INFO - Episode 434/100000: Winner=2, Reward=-4.60, EPSILON=0.996, (W=434,D=0,L=0)
2025-01-16 11:35:06,614 - INFO - Episode 435/100000: Winner=2, Reward=-5.65, EPSILON=0.996, (W=435,D=0,L=0)
2025-01-16 11:35:06,759 - INFO - Episode 436/100000: Winner=2, Reward=19.65, EPSILON=0.996, (W=436,D=0,L=0)
2025-01-16 11:35:06,913 - INFO - Episode 437/100000: Winner=2, Reward=0.10, EPSILON=0.996, (W=437,D=0,L=0)
2025-01-16 11:35:07,193 - INFO - Episode 438/100000: Winner=2, Reward=6.70, EPSILON=0.996, (W=438,D=0,L=0)
2025-01-16 11:35:07,487 - INFO - Episode 439/100000: Winner=2, Reward=18.40, EPSILON=0.996, (W=439,D=0,L=0)
2025-01-16 11:35:07,612 - INFO - Episode 440/100000: Winner=2, Reward=-1.00, EPSILON=0.996, (W=440,D=0,L=0)
2025-01-16 11:35:07,860 - INFO - Episode 441/100000: Winner=2, Reward=-10.85, EPSILON=0.996, (W=441,D=0,L=0)
2025-01-16 11:35:08,008 - INFO - Episode 442/100000: Winner=2, Reward=-8.65, EPSILON=0.996, (W=442,D=0,L=0)
2025-01-16 11:35:08,211 - INFO - Episode 443/100000: Winner=2, Reward=1.80, EPSILON=0.996, (W=443,D=0,L=0)
2025-01-16 11:35:08,326 - INFO - Episode 444/100000: Winner=2, Reward=17.55, EPSILON=0.996, (W=444,D=0,L=0)
2025-01-16 11:35:08,564 - INFO - Episode 445/100000: Winner=2, Reward=11.25, EPSILON=0.996, (W=445,D=0,L=0)
2025-01-16 11:35:08,633 - INFO - Episode 446/100000: Winner=2, Reward=8.40, EPSILON=0.996, (W=446,D=0,L=0)
2025-01-16 11:35:08,782 - INFO - Episode 447/100000: Winner=2, Reward=-8.85, EPSILON=0.996, (W=447,D=0,L=0)
2025-01-16 11:35:09,016 - INFO - Episode 448/100000: Winner=2, Reward=-19.65, EPSILON=0.996, (W=448,D=0,L=0)
2025-01-16 11:35:09,188 - INFO - Episode 449/100000: Winner=2, Reward=6.05, EPSILON=0.996, (W=449,D=0,L=0)
2025-01-16 11:35:09,383 - INFO - Episode 450/100000: Winner=2, Reward=5.05, EPSILON=0.996, (W=450,D=0,L=0)
2025-01-16 11:35:09,570 - INFO - Episode 451/100000: Winner=2, Reward=4.90, EPSILON=0.996, (W=451,D=0,L=0)
2025-01-16 11:35:09,899 - INFO - Episode 452/100000: Winner=2, Reward=-9.70, EPSILON=0.996, (W=452,D=0,L=0)
2025-01-16 11:35:10,153 - INFO - Episode 453/100000: Winner=2, Reward=2.80, EPSILON=0.996, (W=453,D=0,L=0)
2025-01-16 11:35:10,464 - INFO - Episode 454/100000: Winner=2, Reward=-32.30, EPSILON=0.996, (W=454,D=0,L=0)
2025-01-16 11:35:10,564 - INFO - Episode 455/100000: Winner=2, Reward=8.50, EPSILON=0.996, (W=455,D=0,L=0)
2025-01-16 11:35:10,736 - INFO - Episode 456/100000: Winner=2, Reward=7.90, EPSILON=0.996, (W=456,D=0,L=0)
2025-01-16 11:35:10,923 - INFO - Episode 457/100000: Winner=2, Reward=27.20, EPSILON=0.996, (W=457,D=0,L=0)
2025-01-16 11:35:11,079 - INFO - Episode 458/100000: Winner=2, Reward=2.30, EPSILON=0.996, (W=458,D=0,L=0)
2025-01-16 11:35:11,229 - INFO - Episode 459/100000: Winner=2, Reward=7.50, EPSILON=0.996, (W=459,D=0,L=0)
2025-01-16 11:35:11,339 - INFO - Episode 460/100000: Winner=2, Reward=17.60, EPSILON=0.996, (W=460,D=0,L=0)
2025-01-16 11:35:11,499 - INFO - Episode 461/100000: Winner=2, Reward=12.15, EPSILON=0.996, (W=461,D=0,L=0)
2025-01-16 11:35:11,681 - INFO - Episode 462/100000: Winner=2, Reward=24.50, EPSILON=0.996, (W=462,D=0,L=0)
2025-01-16 11:35:11,806 - INFO - Episode 463/100000: Winner=2, Reward=-4.55, EPSILON=0.996, (W=463,D=0,L=0)
2025-01-16 11:35:12,025 - INFO - Episode 464/100000: Winner=2, Reward=27.85, EPSILON=0.996, (W=464,D=0,L=0)
2025-01-16 11:35:12,212 - INFO - Episode 465/100000: Winner=2, Reward=-11.10, EPSILON=0.996, (W=465,D=0,L=0)
2025-01-16 11:35:12,396 - INFO - Episode 466/100000: Winner=2, Reward=-6.40, EPSILON=0.996, (W=466,D=0,L=0)
2025-01-16 11:35:12,583 - INFO - Episode 467/100000: Winner=2, Reward=4.60, EPSILON=0.996, (W=467,D=0,L=0)
2025-01-16 11:35:12,744 - INFO - Episode 468/100000: Winner=2, Reward=-5.40, EPSILON=0.996, (W=468,D=0,L=0)
2025-01-16 11:35:12,926 - INFO - Episode 469/100000: Winner=2, Reward=6.90, EPSILON=0.996, (W=469,D=0,L=0)
2025-01-16 11:35:13,058 - INFO - Episode 470/100000: Winner=2, Reward=-6.85, EPSILON=0.996, (W=470,D=0,L=0)
2025-01-16 11:35:13,204 - INFO - Episode 471/100000: Winner=2, Reward=8.75, EPSILON=0.996, (W=471,D=0,L=0)
2025-01-16 11:35:13,429 - INFO - Episode 472/100000: Winner=2, Reward=6.10, EPSILON=0.996, (W=472,D=0,L=0)
2025-01-16 11:35:13,641 - INFO - Episode 473/100000: Winner=2, Reward=22.30, EPSILON=0.996, (W=473,D=0,L=0)
2025-01-16 11:35:13,795 - INFO - Episode 474/100000: Winner=2, Reward=8.95, EPSILON=0.996, (W=474,D=0,L=0)
2025-01-16 11:35:14,017 - INFO - Episode 475/100000: Winner=2, Reward=17.55, EPSILON=0.996, (W=475,D=0,L=0)
2025-01-16 11:35:14,101 - INFO - Episode 476/100000: Winner=2, Reward=7.10, EPSILON=0.996, (W=476,D=0,L=0)
2025-01-16 11:35:14,367 - INFO - Episode 477/100000: Winner=2, Reward=30.10, EPSILON=0.996, (W=477,D=0,L=0)
2025-01-16 11:35:14,568 - INFO - Episode 478/100000: Winner=2, Reward=1.10, EPSILON=0.996, (W=478,D=0,L=0)
2025-01-16 11:35:14,734 - INFO - Episode 479/100000: Winner=2, Reward=-1.10, EPSILON=0.996, (W=479,D=0,L=0)
2025-01-16 11:35:14,934 - INFO - Episode 480/100000: Winner=2, Reward=22.85, EPSILON=0.996, (W=480,D=0,L=0)
2025-01-16 11:35:15,200 - INFO - Episode 481/100000: Winner=2, Reward=7.50, EPSILON=0.996, (W=481,D=0,L=0)
2025-01-16 11:35:15,434 - INFO - Episode 482/100000: Winner=2, Reward=-6.20, EPSILON=0.996, (W=482,D=0,L=0)
2025-01-16 11:35:15,498 - INFO - Episode 483/100000: Winner=2, Reward=8.40, EPSILON=0.996, (W=483,D=0,L=0)
2025-01-16 11:35:15,801 - INFO - Episode 484/100000: Winner=2, Reward=-25.55, EPSILON=0.996, (W=484,D=0,L=0)
2025-01-16 11:35:15,984 - INFO - Episode 485/100000: Winner=2, Reward=-6.15, EPSILON=0.996, (W=485,D=0,L=0)
2025-01-16 11:35:16,083 - INFO - Episode 486/100000: Winner=2, Reward=-7.75, EPSILON=0.996, (W=486,D=0,L=0)
2025-01-16 11:35:16,217 - INFO - Episode 487/100000: Winner=2, Reward=-4.60, EPSILON=0.996, (W=487,D=0,L=0)
2025-01-16 11:35:16,484 - INFO - Episode 488/100000: Winner=2, Reward=21.85, EPSILON=0.996, (W=488,D=0,L=0)
2025-01-16 11:35:16,568 - INFO - Episode 489/100000: Winner=2, Reward=8.55, EPSILON=0.996, (W=489,D=0,L=0)
2025-01-16 11:35:16,751 - INFO - Episode 490/100000: Winner=2, Reward=17.00, EPSILON=0.996, (W=490,D=0,L=0)
2025-01-16 11:35:17,001 - INFO - Episode 491/100000: Winner=2, Reward=31.85, EPSILON=0.996, (W=491,D=0,L=0)
2025-01-16 11:35:17,216 - INFO - Episode 492/100000: Winner=2, Reward=-4.75, EPSILON=0.996, (W=492,D=0,L=0)
2025-01-16 11:35:17,437 - INFO - Episode 493/100000: Winner=2, Reward=-5.70, EPSILON=0.996, (W=493,D=0,L=0)
2025-01-16 11:35:17,667 - INFO - Episode 494/100000: Winner=2, Reward=-12.45, EPSILON=0.996, (W=494,D=0,L=0)
2025-01-16 11:35:17,968 - INFO - Episode 495/100000: Winner=2, Reward=-25.95, EPSILON=0.996, (W=495,D=0,L=0)
2025-01-16 11:35:18,151 - INFO - Episode 496/100000: Winner=2, Reward=-10.00, EPSILON=0.996, (W=496,D=0,L=0)
2025-01-16 11:35:18,483 - INFO - Episode 497/100000: Winner=2, Reward=-7.95, EPSILON=0.996, (W=497,D=0,L=0)
2025-01-16 11:35:18,606 - DEBUG - Q-vals = [0.56116354 0.07510906 0.23471908 0.00158761 0.08099569 0.04087193
 0.00555302], best_act=0, best_val=0.561
2025-01-16 11:35:18,606 - DEBUG - Low Q-value (0.561), using MCTS.
2025-01-16 11:35:18,606 - INFO - Running MCTS with 29 simulations using 6 processes.
2025-01-16 11:35:21,352 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:35:21,353 - DEBUG - Chose best action 0
2025-01-16 11:35:21,421 - INFO - Episode 498/100000: Winner=2, Reward=5.00, EPSILON=0.996, (W=498,D=0,L=0)
2025-01-16 11:35:21,675 - INFO - Episode 499/100000: Winner=2, Reward=-11.15, EPSILON=0.996, (W=499,D=0,L=0)
2025-01-16 11:35:21,938 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 500.
2025-01-16 11:35:21,938 - INFO - Models saved at episode 500
2025-01-16 11:35:21,940 - INFO - Target networks updated
2025-01-16 11:35:21,998 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 500.
2025-01-16 11:35:21,998 - INFO - Episode 500/100000: Winner=2, Reward=8.30, EPSILON=0.996, (W=500,D=0,L=0)
2025-01-16 11:35:22,256 - INFO - Episode 501/100000: Winner=2, Reward=31.25, EPSILON=0.996, (W=501,D=0,L=0)
2025-01-16 11:35:22,501 - INFO - Episode 502/100000: Winner=2, Reward=29.20, EPSILON=0.995, (W=502,D=0,L=0)
2025-01-16 11:35:22,785 - INFO - Episode 503/100000: Winner=2, Reward=-11.40, EPSILON=0.995, (W=503,D=0,L=0)
2025-01-16 11:35:22,974 - INFO - Episode 504/100000: Winner=2, Reward=-5.30, EPSILON=0.995, (W=504,D=0,L=0)
2025-01-16 11:35:23,010 - DEBUG - Q-vals = [0.03703171 0.02982491 0.38392904 0.16924088 0.09819613 0.21836191
 0.06341536], best_act=2, best_val=0.384
2025-01-16 11:35:23,010 - DEBUG - Low Q-value (0.384), using MCTS.
2025-01-16 11:35:23,011 - INFO - Running MCTS with 30 simulations using 6 processes.
2025-01-16 11:35:25,804 - DEBUG - Aggregated action counts: {0: 6}
2025-01-16 11:35:25,804 - DEBUG - Chose best action 0
2025-01-16 11:35:26,124 - INFO - Episode 505/100000: Winner=2, Reward=-18.75, EPSILON=0.995, (W=505,D=0,L=0)
2025-01-16 11:35:26,241 - INFO - Episode 506/100000: Winner=2, Reward=1.15, EPSILON=0.995, (W=506,D=0,L=0)
2025-01-16 11:35:26,507 - INFO - Episode 507/100000: Winner=2, Reward=7.60, EPSILON=0.995, (W=507,D=0,L=0)
2025-01-16 11:35:26,699 - INFO - Episode 508/100000: Winner=2, Reward=9.30, EPSILON=0.995, (W=508,D=0,L=0)
2025-01-16 11:35:26,733 - DEBUG - Q-vals = [0.25372875 0.10241435 0.01302881 0.33002833 0.14550017 0.08108892
 0.07421067], best_act=3, best_val=0.330
2025-01-16 11:35:26,733 - DEBUG - Low Q-value (0.330), using MCTS.
2025-01-16 11:35:26,734 - INFO - Running MCTS with 30 simulations using 6 processes.
2025-01-16 11:35:29,694 - DEBUG - Aggregated action counts: {0: 6}
2025-01-16 11:35:29,694 - DEBUG - Chose best action 0
2025-01-16 11:35:29,936 - INFO - Episode 509/100000: Winner=2, Reward=-9.75, EPSILON=0.995, (W=509,D=0,L=0)
2025-01-16 11:35:30,170 - INFO - Episode 510/100000: Winner=2, Reward=-7.80, EPSILON=0.995, (W=510,D=0,L=0)
2025-01-16 11:35:30,445 - INFO - Episode 511/100000: Winner=2, Reward=2.30, EPSILON=0.995, (W=511,D=0,L=0)
2025-01-16 11:35:30,774 - INFO - Episode 512/100000: Winner=2, Reward=37.20, EPSILON=0.995, (W=512,D=0,L=0)
2025-01-16 11:35:30,924 - INFO - Episode 513/100000: Winner=2, Reward=3.20, EPSILON=0.995, (W=513,D=0,L=0)
2025-01-16 11:35:31,200 - INFO - Episode 514/100000: Winner=2, Reward=12.80, EPSILON=0.995, (W=514,D=0,L=0)
2025-01-16 11:35:31,455 - INFO - Episode 515/100000: Winner=2, Reward=16.20, EPSILON=0.995, (W=515,D=0,L=0)
2025-01-16 11:35:31,539 - INFO - Episode 516/100000: Winner=2, Reward=2.25, EPSILON=0.995, (W=516,D=0,L=0)
2025-01-16 11:35:31,652 - INFO - Episode 517/100000: Winner=2, Reward=-4.30, EPSILON=0.995, (W=517,D=0,L=0)
2025-01-16 11:35:31,975 - INFO - Episode 518/100000: Winner=2, Reward=-23.15, EPSILON=0.995, (W=518,D=0,L=0)
2025-01-16 11:35:32,118 - INFO - Episode 519/100000: Winner=2, Reward=10.00, EPSILON=0.995, (W=519,D=0,L=0)
2025-01-16 11:35:32,364 - INFO - Episode 520/100000: Winner=2, Reward=12.45, EPSILON=0.995, (W=520,D=0,L=0)
2025-01-16 11:35:32,626 - INFO - Episode 521/100000: Winner=2, Reward=7.40, EPSILON=0.995, (W=521,D=0,L=0)
2025-01-16 11:35:32,820 - INFO - Episode 522/100000: Winner=2, Reward=-10.70, EPSILON=0.995, (W=522,D=0,L=0)
2025-01-16 11:35:32,961 - INFO - Episode 523/100000: Winner=2, Reward=-7.80, EPSILON=0.995, (W=523,D=0,L=0)
2025-01-16 11:35:33,310 - INFO - Episode 524/100000: Winner=2, Reward=-5.95, EPSILON=0.995, (W=524,D=0,L=0)
2025-01-16 11:35:33,567 - INFO - Episode 525/100000: Winner=2, Reward=-7.00, EPSILON=0.995, (W=525,D=0,L=0)
2025-01-16 11:35:33,861 - INFO - Episode 526/100000: Winner=2, Reward=-8.35, EPSILON=0.995, (W=526,D=0,L=0)
2025-01-16 11:35:33,939 - INFO - Episode 527/100000: Winner=2, Reward=0.15, EPSILON=0.995, (W=527,D=0,L=0)
2025-01-16 11:35:34,081 - INFO - Episode 528/100000: Winner=2, Reward=1.55, EPSILON=0.995, (W=528,D=0,L=0)
2025-01-16 11:35:34,332 - INFO - Episode 529/100000: Winner=2, Reward=-9.90, EPSILON=0.995, (W=529,D=0,L=0)
2025-01-16 11:35:34,540 - INFO - Episode 530/100000: Winner=2, Reward=16.95, EPSILON=0.995, (W=530,D=0,L=0)
2025-01-16 11:35:34,654 - INFO - Episode 531/100000: Winner=2, Reward=14.85, EPSILON=0.995, (W=531,D=0,L=0)
2025-01-16 11:35:34,916 - INFO - Episode 532/100000: Winner=2, Reward=-13.55, EPSILON=0.995, (W=532,D=0,L=0)
2025-01-16 11:35:35,154 - INFO - Episode 533/100000: Winner=2, Reward=6.75, EPSILON=0.995, (W=533,D=0,L=0)
2025-01-16 11:35:35,295 - INFO - Episode 534/100000: Winner=2, Reward=17.45, EPSILON=0.995, (W=534,D=0,L=0)
2025-01-16 11:35:35,525 - INFO - Episode 535/100000: Winner=2, Reward=-14.05, EPSILON=0.995, (W=535,D=0,L=0)
2025-01-16 11:35:35,748 - INFO - Episode 536/100000: Winner=2, Reward=20.50, EPSILON=0.995, (W=536,D=0,L=0)
2025-01-16 11:35:35,908 - INFO - Episode 537/100000: Winner=2, Reward=24.15, EPSILON=0.995, (W=537,D=0,L=0)
2025-01-16 11:35:36,269 - INFO - Episode 538/100000: Winner=2, Reward=-11.95, EPSILON=0.995, (W=538,D=0,L=0)
2025-01-16 11:35:36,534 - INFO - Episode 539/100000: Winner=2, Reward=4.20, EPSILON=0.995, (W=539,D=0,L=0)
2025-01-16 11:35:36,656 - INFO - Episode 540/100000: Winner=2, Reward=9.45, EPSILON=0.995, (W=540,D=0,L=0)
2025-01-16 11:35:36,769 - INFO - Episode 541/100000: Winner=2, Reward=-6.15, EPSILON=0.995, (W=541,D=0,L=0)
2025-01-16 11:35:36,852 - INFO - Episode 542/100000: Winner=2, Reward=2.00, EPSILON=0.995, (W=542,D=0,L=0)
2025-01-16 11:35:37,102 - INFO - Episode 543/100000: Winner=2, Reward=13.40, EPSILON=0.995, (W=543,D=0,L=0)
2025-01-16 11:35:37,404 - INFO - Episode 544/100000: Winner=2, Reward=19.40, EPSILON=0.995, (W=544,D=0,L=0)
2025-01-16 11:35:37,625 - INFO - Episode 545/100000: Winner=2, Reward=17.55, EPSILON=0.995, (W=545,D=0,L=0)
2025-01-16 11:35:37,749 - INFO - Episode 546/100000: Winner=2, Reward=-2.25, EPSILON=0.995, (W=546,D=0,L=0)
2025-01-16 11:35:37,928 - INFO - Episode 547/100000: Winner=2, Reward=28.65, EPSILON=0.995, (W=547,D=0,L=0)
2025-01-16 11:35:38,155 - INFO - Episode 548/100000: Winner=2, Reward=17.40, EPSILON=0.995, (W=548,D=0,L=0)
2025-01-16 11:35:38,295 - INFO - Episode 549/100000: Winner=2, Reward=3.75, EPSILON=0.995, (W=549,D=0,L=0)
2025-01-16 11:35:38,452 - INFO - Episode 550/100000: Winner=2, Reward=11.25, EPSILON=0.995, (W=550,D=0,L=0)
2025-01-16 11:35:38,647 - INFO - Episode 551/100000: Winner=2, Reward=18.95, EPSILON=0.995, (W=551,D=0,L=0)
2025-01-16 11:35:38,783 - INFO - Episode 552/100000: Winner=2, Reward=15.90, EPSILON=0.995, (W=552,D=0,L=0)
2025-01-16 11:35:38,909 - INFO - Episode 553/100000: Winner=2, Reward=-4.40, EPSILON=0.995, (W=553,D=0,L=0)
2025-01-16 11:35:39,184 - INFO - Episode 554/100000: Winner=2, Reward=-16.15, EPSILON=0.995, (W=554,D=0,L=0)
2025-01-16 11:35:39,252 - INFO - Episode 555/100000: Winner=2, Reward=-6.55, EPSILON=0.995, (W=555,D=0,L=0)
2025-01-16 11:35:39,580 - INFO - Episode 556/100000: Winner=2, Reward=32.90, EPSILON=0.995, (W=556,D=0,L=0)
2025-01-16 11:35:39,723 - INFO - Episode 557/100000: Winner=2, Reward=2.60, EPSILON=0.995, (W=557,D=0,L=0)
2025-01-16 11:35:40,036 - INFO - Episode 558/100000: Winner=2, Reward=58.65, EPSILON=0.995, (W=558,D=0,L=0)
2025-01-16 11:35:40,273 - INFO - Episode 559/100000: Winner=2, Reward=7.65, EPSILON=0.995, (W=559,D=0,L=0)
2025-01-16 11:35:40,470 - INFO - Episode 560/100000: Winner=2, Reward=-4.45, EPSILON=0.995, (W=560,D=0,L=0)
2025-01-16 11:35:40,772 - INFO - Episode 561/100000: Winner=2, Reward=4.80, EPSILON=0.995, (W=561,D=0,L=0)
2025-01-16 11:35:41,063 - INFO - Episode 562/100000: Winner=2, Reward=23.15, EPSILON=0.995, (W=562,D=0,L=0)
2025-01-16 11:35:41,310 - INFO - Episode 563/100000: Winner=2, Reward=13.65, EPSILON=0.995, (W=563,D=0,L=0)
2025-01-16 11:35:41,498 - INFO - Episode 564/100000: Winner=2, Reward=-8.90, EPSILON=0.995, (W=564,D=0,L=0)
2025-01-16 11:35:41,552 - INFO - Episode 565/100000: Winner=2, Reward=1.20, EPSILON=0.995, (W=565,D=0,L=0)
2025-01-16 11:35:41,656 - INFO - Episode 566/100000: Winner=2, Reward=-2.65, EPSILON=0.995, (W=566,D=0,L=0)
2025-01-16 11:35:41,780 - INFO - Episode 567/100000: Winner=2, Reward=7.80, EPSILON=0.995, (W=567,D=0,L=0)
2025-01-16 11:35:42,065 - INFO - Episode 568/100000: Winner=2, Reward=-14.25, EPSILON=0.995, (W=568,D=0,L=0)
2025-01-16 11:35:42,287 - INFO - Episode 569/100000: Winner=2, Reward=-1.05, EPSILON=0.995, (W=569,D=0,L=0)
2025-01-16 11:35:42,329 - DEBUG - Q-vals = [0.19343863 0.04375997 0.22747876 0.2208514  0.0270253  0.2392304
 0.04821559], best_act=5, best_val=0.239
2025-01-16 11:35:42,329 - DEBUG - Low Q-value (0.239), using MCTS.
2025-01-16 11:35:42,329 - INFO - Running MCTS with 32 simulations using 6 processes.
2025-01-16 11:35:45,123 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:35:45,123 - DEBUG - Chose best action 0
2025-01-16 11:35:45,279 - INFO - Episode 570/100000: Winner=2, Reward=6.65, EPSILON=0.995, (W=570,D=0,L=0)
2025-01-16 11:35:45,498 - INFO - Episode 571/100000: Winner=2, Reward=-6.55, EPSILON=0.995, (W=571,D=0,L=0)
2025-01-16 11:35:45,813 - INFO - Episode 572/100000: Winner=2, Reward=2.35, EPSILON=0.995, (W=572,D=0,L=0)
2025-01-16 11:35:46,077 - INFO - Episode 573/100000: Winner=2, Reward=-1.80, EPSILON=0.995, (W=573,D=0,L=0)
2025-01-16 11:35:46,228 - INFO - Episode 574/100000: Winner=2, Reward=22.35, EPSILON=0.995, (W=574,D=0,L=0)
2025-01-16 11:35:46,420 - INFO - Episode 575/100000: Winner=2, Reward=17.55, EPSILON=0.995, (W=575,D=0,L=0)
2025-01-16 11:35:46,732 - INFO - Episode 576/100000: Winner=2, Reward=-33.35, EPSILON=0.995, (W=576,D=0,L=0)
2025-01-16 11:35:46,890 - INFO - Episode 577/100000: Winner=2, Reward=3.05, EPSILON=0.995, (W=577,D=0,L=0)
2025-01-16 11:35:47,152 - INFO - Episode 578/100000: Winner=2, Reward=-23.30, EPSILON=0.995, (W=578,D=0,L=0)
2025-01-16 11:35:47,237 - INFO - Episode 579/100000: Winner=2, Reward=9.05, EPSILON=0.995, (W=579,D=0,L=0)
2025-01-16 11:35:47,482 - INFO - Episode 580/100000: Winner=2, Reward=-2.60, EPSILON=0.995, (W=580,D=0,L=0)
2025-01-16 11:35:47,632 - INFO - Episode 581/100000: Winner=2, Reward=-2.10, EPSILON=0.995, (W=581,D=0,L=0)
2025-01-16 11:35:47,820 - INFO - Episode 582/100000: Winner=2, Reward=11.25, EPSILON=0.995, (W=582,D=0,L=0)
2025-01-16 11:35:47,991 - INFO - Episode 583/100000: Winner=2, Reward=-9.30, EPSILON=0.995, (W=583,D=0,L=0)
2025-01-16 11:35:48,194 - INFO - Episode 584/100000: Winner=2, Reward=-2.80, EPSILON=0.995, (W=584,D=0,L=0)
2025-01-16 11:35:48,288 - INFO - Episode 585/100000: Winner=2, Reward=-7.45, EPSILON=0.995, (W=585,D=0,L=0)
2025-01-16 11:35:48,473 - DEBUG - Q-vals = [5.9088241e-02 4.7694144e-01 6.7391239e-02 1.0574609e-02 3.5361135e-01
 2.3645192e-05 3.2369476e-02], best_act=1, best_val=0.477
2025-01-16 11:35:48,473 - DEBUG - Low Q-value (0.477), using MCTS.
2025-01-16 11:35:48,475 - INFO - Running MCTS with 33 simulations using 6 processes.
2025-01-16 11:35:51,291 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:35:51,291 - DEBUG - Chose best action 0
2025-01-16 11:35:51,320 - INFO - Episode 586/100000: Winner=2, Reward=-4.90, EPSILON=0.995, (W=586,D=0,L=0)
2025-01-16 11:35:51,586 - INFO - Episode 587/100000: Winner=2, Reward=-17.95, EPSILON=0.995, (W=587,D=0,L=0)
2025-01-16 11:35:51,830 - INFO - Episode 588/100000: Winner=2, Reward=3.30, EPSILON=0.995, (W=588,D=0,L=0)
2025-01-16 11:35:52,030 - INFO - Episode 589/100000: Winner=2, Reward=-8.75, EPSILON=0.995, (W=589,D=0,L=0)
2025-01-16 11:35:52,158 - DEBUG - Q-vals = [0.04495825 0.35849193 0.14224578 0.00576563 0.01929936 0.4285855
 0.00065357], best_act=5, best_val=0.429
2025-01-16 11:35:52,158 - DEBUG - Low Q-value (0.429), using MCTS.
2025-01-16 11:35:52,159 - INFO - Running MCTS with 33 simulations using 6 processes.
2025-01-16 11:35:54,904 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:35:54,904 - DEBUG - Chose best action 0
2025-01-16 11:35:54,988 - INFO - Episode 590/100000: Winner=2, Reward=14.55, EPSILON=0.995, (W=590,D=0,L=0)
2025-01-16 11:35:55,204 - INFO - Episode 591/100000: Winner=2, Reward=26.45, EPSILON=0.995, (W=591,D=0,L=0)
2025-01-16 11:35:55,321 - INFO - Episode 592/100000: Winner=2, Reward=-7.40, EPSILON=0.995, (W=592,D=0,L=0)
2025-01-16 11:35:55,571 - INFO - Episode 593/100000: Winner=2, Reward=-9.10, EPSILON=0.995, (W=593,D=0,L=0)
2025-01-16 11:35:55,688 - INFO - Episode 594/100000: Winner=2, Reward=0.70, EPSILON=0.995, (W=594,D=0,L=0)
2025-01-16 11:35:55,850 - INFO - Episode 595/100000: Winner=2, Reward=-4.60, EPSILON=0.995, (W=595,D=0,L=0)
2025-01-16 11:35:56,055 - INFO - Episode 596/100000: Winner=2, Reward=-8.85, EPSILON=0.995, (W=596,D=0,L=0)
2025-01-16 11:35:56,204 - DEBUG - Q-vals = [0.25671184 0.02782121 0.07197385 0.32420513 0.02652732 0.2175328
 0.07522795], best_act=3, best_val=0.324
2025-01-16 11:35:56,204 - DEBUG - Low Q-value (0.324), using MCTS.
2025-01-16 11:35:56,206 - INFO - Running MCTS with 33 simulations using 6 processes.
2025-01-16 11:35:59,146 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:35:59,146 - DEBUG - Chose best action 0
2025-01-16 11:35:59,212 - INFO - Episode 597/100000: Winner=2, Reward=-13.45, EPSILON=0.995, (W=597,D=0,L=0)
2025-01-16 11:35:59,447 - INFO - Episode 598/100000: Winner=2, Reward=6.65, EPSILON=0.995, (W=598,D=0,L=0)
2025-01-16 11:35:59,581 - INFO - Episode 599/100000: Winner=2, Reward=-7.00, EPSILON=0.995, (W=599,D=0,L=0)
2025-01-16 11:35:59,893 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 600.
2025-01-16 11:35:59,893 - INFO - Models saved at episode 600
2025-01-16 11:35:59,894 - INFO - Target networks updated
2025-01-16 11:35:59,990 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 600.
2025-01-16 11:35:59,990 - INFO - Episode 600/100000: Winner=2, Reward=-5.95, EPSILON=0.995, (W=600,D=0,L=0)
2025-01-16 11:36:00,106 - INFO - Episode 601/100000: Winner=2, Reward=1.85, EPSILON=0.995, (W=601,D=0,L=0)
2025-01-16 11:36:00,327 - INFO - Episode 602/100000: Winner=2, Reward=15.50, EPSILON=0.995, (W=602,D=0,L=0)
2025-01-16 11:36:00,455 - INFO - Episode 603/100000: Winner=2, Reward=22.65, EPSILON=0.995, (W=603,D=0,L=0)
2025-01-16 11:36:00,566 - INFO - Episode 604/100000: Winner=2, Reward=-6.15, EPSILON=0.995, (W=604,D=0,L=0)
2025-01-16 11:36:00,853 - INFO - Episode 605/100000: Winner=2, Reward=-17.55, EPSILON=0.995, (W=605,D=0,L=0)
2025-01-16 11:36:01,025 - INFO - Episode 606/100000: Winner=2, Reward=-0.10, EPSILON=0.995, (W=606,D=0,L=0)
2025-01-16 11:36:01,170 - DEBUG - Q-vals = [4.6943697e-01 1.2892379e-01 1.6998323e-02 9.0807138e-05 3.6385524e-01
 2.6071402e-03 1.8087700e-02], best_act=0, best_val=0.469
2025-01-16 11:36:01,170 - DEBUG - Low Q-value (0.469), using MCTS.
2025-01-16 11:36:01,172 - INFO - Running MCTS with 34 simulations using 6 processes.
2025-01-16 11:36:04,277 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:36:04,277 - DEBUG - Chose best action 0
2025-01-16 11:36:04,399 - INFO - Episode 607/100000: Winner=2, Reward=16.60, EPSILON=0.995, (W=607,D=0,L=0)
2025-01-16 11:36:04,491 - INFO - Episode 608/100000: Winner=2, Reward=15.90, EPSILON=0.995, (W=608,D=0,L=0)
2025-01-16 11:36:04,748 - INFO - Episode 609/100000: Winner=2, Reward=-5.85, EPSILON=0.995, (W=609,D=0,L=0)
2025-01-16 11:36:04,921 - INFO - Episode 610/100000: Winner=2, Reward=9.30, EPSILON=0.995, (W=610,D=0,L=0)
2025-01-16 11:36:05,028 - INFO - Episode 611/100000: Winner=2, Reward=2.30, EPSILON=0.995, (W=611,D=0,L=0)
2025-01-16 11:36:05,043 - DEBUG - Q-vals = [0.2950266  0.06169549 0.1146024  0.27072287 0.01658354 0.15192209
 0.08944707], best_act=0, best_val=0.295
2025-01-16 11:36:05,043 - DEBUG - Low Q-value (0.295), using MCTS.
2025-01-16 11:36:05,044 - INFO - Running MCTS with 34 simulations using 6 processes.
2025-01-16 11:36:08,312 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:36:08,312 - DEBUG - Chose best action 0
2025-01-16 11:36:08,530 - INFO - Episode 612/100000: Winner=2, Reward=-16.05, EPSILON=0.995, (W=612,D=0,L=0)
2025-01-16 11:36:08,564 - DEBUG - Q-vals = [0.18105654 0.03443156 0.14250676 0.22821671 0.14548524 0.182295
 0.0860082 ], best_act=3, best_val=0.228
2025-01-16 11:36:08,564 - DEBUG - Low Q-value (0.228), using MCTS.
2025-01-16 11:36:08,565 - INFO - Running MCTS with 34 simulations using 6 processes.
2025-01-16 11:36:11,777 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:36:11,777 - DEBUG - Chose best action 0
2025-01-16 11:36:11,914 - INFO - Episode 613/100000: Winner=2, Reward=-5.25, EPSILON=0.994, (W=613,D=0,L=0)
2025-01-16 11:36:12,133 - INFO - Episode 614/100000: Winner=2, Reward=16.65, EPSILON=0.994, (W=614,D=0,L=0)
2025-01-16 11:36:12,239 - INFO - Episode 615/100000: Winner=2, Reward=8.15, EPSILON=0.994, (W=615,D=0,L=0)
2025-01-16 11:36:12,476 - INFO - Episode 616/100000: Winner=2, Reward=23.10, EPSILON=0.994, (W=616,D=0,L=0)
2025-01-16 11:36:12,596 - INFO - Episode 617/100000: Winner=2, Reward=0.95, EPSILON=0.994, (W=617,D=0,L=0)
2025-01-16 11:36:12,745 - INFO - Episode 618/100000: Winner=2, Reward=7.75, EPSILON=0.994, (W=618,D=0,L=0)
2025-01-16 11:36:13,106 - INFO - Episode 619/100000: Winner=2, Reward=1.85, EPSILON=0.994, (W=619,D=0,L=0)
2025-01-16 11:36:13,264 - INFO - Episode 620/100000: Winner=2, Reward=-6.70, EPSILON=0.994, (W=620,D=0,L=0)
2025-01-16 11:36:13,478 - INFO - Episode 621/100000: Winner=2, Reward=4.15, EPSILON=0.994, (W=621,D=0,L=0)
2025-01-16 11:36:13,711 - INFO - Episode 622/100000: Winner=2, Reward=-3.00, EPSILON=0.994, (W=622,D=0,L=0)
2025-01-16 11:36:13,845 - INFO - Episode 623/100000: Winner=2, Reward=9.75, EPSILON=0.994, (W=623,D=0,L=0)
2025-01-16 11:36:13,938 - DEBUG - Q-vals = [0.05939288 0.10345829 0.12300145 0.1762257  0.1544937  0.2799971
 0.10343087], best_act=5, best_val=0.280
2025-01-16 11:36:13,938 - DEBUG - Low Q-value (0.280), using MCTS.
2025-01-16 11:36:13,939 - INFO - Running MCTS with 34 simulations using 6 processes.
2025-01-16 11:36:17,190 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:36:17,190 - DEBUG - Chose best action 0
2025-01-16 11:36:17,335 - INFO - Episode 624/100000: Winner=2, Reward=-6.05, EPSILON=0.994, (W=624,D=0,L=0)
2025-01-16 11:36:17,402 - INFO - Episode 625/100000: Winner=2, Reward=8.55, EPSILON=0.994, (W=625,D=0,L=0)
2025-01-16 11:36:17,579 - INFO - Episode 626/100000: Winner=2, Reward=14.05, EPSILON=0.994, (W=626,D=0,L=0)
2025-01-16 11:36:17,825 - INFO - Episode 627/100000: Winner=2, Reward=11.80, EPSILON=0.994, (W=627,D=0,L=0)
2025-01-16 11:36:18,069 - INFO - Episode 628/100000: Winner=2, Reward=12.30, EPSILON=0.994, (W=628,D=0,L=0)
2025-01-16 11:36:18,296 - INFO - Episode 629/100000: Winner=2, Reward=11.45, EPSILON=0.994, (W=629,D=0,L=0)
2025-01-16 11:36:18,549 - INFO - Episode 630/100000: Winner=2, Reward=-1.45, EPSILON=0.994, (W=630,D=0,L=0)
2025-01-16 11:36:18,779 - INFO - Episode 631/100000: Winner=2, Reward=0.00, EPSILON=0.994, (W=631,D=0,L=0)
2025-01-16 11:36:19,010 - INFO - Episode 632/100000: Winner=2, Reward=14.85, EPSILON=0.994, (W=632,D=0,L=0)
2025-01-16 11:36:19,195 - INFO - Episode 633/100000: Winner=2, Reward=1.20, EPSILON=0.994, (W=633,D=0,L=0)
2025-01-16 11:36:19,559 - INFO - Episode 634/100000: Winner=2, Reward=-2.60, EPSILON=0.994, (W=634,D=0,L=0)
2025-01-16 11:36:19,851 - INFO - Episode 635/100000: Winner=2, Reward=2.60, EPSILON=0.994, (W=635,D=0,L=0)
2025-01-16 11:36:19,975 - INFO - Episode 636/100000: Winner=2, Reward=10.30, EPSILON=0.994, (W=636,D=0,L=0)
2025-01-16 11:36:20,306 - INFO - Episode 637/100000: Winner=2, Reward=-5.65, EPSILON=0.994, (W=637,D=0,L=0)
2025-01-16 11:36:20,493 - INFO - Episode 638/100000: Winner=2, Reward=-4.15, EPSILON=0.994, (W=638,D=0,L=0)
2025-01-16 11:36:20,647 - DEBUG - Q-vals = [8.1239891e-01 2.0471716e-02 1.0506802e-03 3.9099182e-06 5.9403531e-04
 1.6452710e-01 9.5364841e-04], best_act=0, best_val=0.812
2025-01-16 11:36:20,647 - DEBUG - Low Q-value (0.812), using MCTS.
2025-01-16 11:36:20,656 - INFO - Episode 639/100000: Winner=2, Reward=-4.45, EPSILON=0.994, (W=639,D=0,L=0)
2025-01-16 11:36:20,847 - INFO - Episode 640/100000: Winner=2, Reward=8.00, EPSILON=0.994, (W=640,D=0,L=0)
2025-01-16 11:36:21,046 - INFO - Episode 641/100000: Winner=2, Reward=12.15, EPSILON=0.994, (W=641,D=0,L=0)
2025-01-16 11:36:21,256 - INFO - Episode 642/100000: Winner=2, Reward=3.95, EPSILON=0.994, (W=642,D=0,L=0)
2025-01-16 11:36:21,414 - INFO - Episode 643/100000: Winner=2, Reward=4.70, EPSILON=0.994, (W=643,D=0,L=0)
2025-01-16 11:36:21,593 - INFO - Episode 644/100000: Winner=2, Reward=-7.20, EPSILON=0.994, (W=644,D=0,L=0)
2025-01-16 11:36:21,888 - INFO - Episode 645/100000: Winner=2, Reward=14.40, EPSILON=0.994, (W=645,D=0,L=0)
2025-01-16 11:36:22,008 - INFO - Episode 646/100000: Winner=2, Reward=-5.10, EPSILON=0.994, (W=646,D=0,L=0)
2025-01-16 11:36:22,227 - INFO - Episode 647/100000: Winner=2, Reward=-4.80, EPSILON=0.994, (W=647,D=0,L=0)
2025-01-16 11:36:22,372 - INFO - Episode 648/100000: Winner=2, Reward=17.60, EPSILON=0.994, (W=648,D=0,L=0)
2025-01-16 11:36:22,580 - INFO - Episode 649/100000: Winner=2, Reward=-10.70, EPSILON=0.994, (W=649,D=0,L=0)
2025-01-16 11:36:22,877 - INFO - Episode 650/100000: Winner=2, Reward=-11.50, EPSILON=0.994, (W=650,D=0,L=0)
2025-01-16 11:36:23,142 - INFO - Episode 651/100000: Winner=2, Reward=2.75, EPSILON=0.994, (W=651,D=0,L=0)
2025-01-16 11:36:23,207 - INFO - Episode 652/100000: Winner=2, Reward=15.90, EPSILON=0.994, (W=652,D=0,L=0)
2025-01-16 11:36:23,327 - INFO - Episode 653/100000: Winner=2, Reward=4.05, EPSILON=0.994, (W=653,D=0,L=0)
2025-01-16 11:36:23,503 - INFO - Episode 654/100000: Winner=2, Reward=11.70, EPSILON=0.994, (W=654,D=0,L=0)
2025-01-16 11:36:23,894 - INFO - Episode 655/100000: Winner=-1, Reward=-1.45, EPSILON=0.994, (W=654,D=1,L=0)
2025-01-16 11:36:24,165 - INFO - Episode 656/100000: Winner=2, Reward=-23.60, EPSILON=0.994, (W=655,D=1,L=0)
2025-01-16 11:36:24,399 - INFO - Episode 657/100000: Winner=2, Reward=8.70, EPSILON=0.994, (W=656,D=1,L=0)
2025-01-16 11:36:24,608 - INFO - Episode 658/100000: Winner=2, Reward=6.95, EPSILON=0.994, (W=657,D=1,L=0)
2025-01-16 11:36:24,821 - INFO - Episode 659/100000: Winner=2, Reward=1.70, EPSILON=0.994, (W=658,D=1,L=0)
2025-01-16 11:36:25,032 - INFO - Episode 660/100000: Winner=2, Reward=4.25, EPSILON=0.994, (W=659,D=1,L=0)
2025-01-16 11:36:25,256 - INFO - Episode 661/100000: Winner=2, Reward=4.80, EPSILON=0.994, (W=660,D=1,L=0)
2025-01-16 11:36:25,508 - INFO - Episode 662/100000: Winner=2, Reward=15.95, EPSILON=0.994, (W=661,D=1,L=0)
2025-01-16 11:36:25,601 - INFO - Episode 663/100000: Winner=2, Reward=10.75, EPSILON=0.994, (W=662,D=1,L=0)
2025-01-16 11:36:25,779 - INFO - Episode 664/100000: Winner=2, Reward=-8.20, EPSILON=0.994, (W=663,D=1,L=0)
2025-01-16 11:36:25,838 - INFO - Episode 665/100000: Winner=2, Reward=-6.75, EPSILON=0.994, (W=664,D=1,L=0)
2025-01-16 11:36:25,973 - DEBUG - Q-vals = [0.01170152 0.37433106 0.0169301  0.31106025 0.04480675 0.20271346
 0.03845672], best_act=1, best_val=0.374
2025-01-16 11:36:25,973 - DEBUG - Low Q-value (0.374), using MCTS.
2025-01-16 11:36:25,973 - INFO - Episode 666/100000: Winner=2, Reward=-2.35, EPSILON=0.994, (W=665,D=1,L=0)
2025-01-16 11:36:26,166 - INFO - Episode 667/100000: Winner=2, Reward=4.30, EPSILON=0.994, (W=666,D=1,L=0)
2025-01-16 11:36:26,404 - INFO - Episode 668/100000: Winner=2, Reward=15.50, EPSILON=0.994, (W=667,D=1,L=0)
2025-01-16 11:36:26,580 - INFO - Episode 669/100000: Winner=2, Reward=2.75, EPSILON=0.994, (W=668,D=1,L=0)
2025-01-16 11:36:26,828 - INFO - Episode 670/100000: Winner=2, Reward=-5.70, EPSILON=0.994, (W=669,D=1,L=0)
2025-01-16 11:36:26,960 - INFO - Episode 671/100000: Winner=2, Reward=-8.60, EPSILON=0.994, (W=670,D=1,L=0)
2025-01-16 11:36:27,125 - INFO - Episode 672/100000: Winner=2, Reward=17.50, EPSILON=0.994, (W=671,D=1,L=0)
2025-01-16 11:36:27,269 - INFO - Episode 673/100000: Winner=2, Reward=11.70, EPSILON=0.994, (W=672,D=1,L=0)
2025-01-16 11:36:27,556 - INFO - Episode 674/100000: Winner=2, Reward=2.85, EPSILON=0.994, (W=673,D=1,L=0)
2025-01-16 11:36:27,756 - INFO - Episode 675/100000: Winner=2, Reward=20.45, EPSILON=0.994, (W=674,D=1,L=0)
2025-01-16 11:36:27,817 - INFO - Episode 676/100000: Winner=2, Reward=0.55, EPSILON=0.994, (W=675,D=1,L=0)
2025-01-16 11:36:28,068 - INFO - Episode 677/100000: Winner=2, Reward=31.20, EPSILON=0.994, (W=676,D=1,L=0)
2025-01-16 11:36:28,258 - INFO - Episode 678/100000: Winner=2, Reward=3.60, EPSILON=0.994, (W=677,D=1,L=0)
2025-01-16 11:36:28,352 - DEBUG - Q-vals = [0.00364353 0.00648736 0.7412618  0.00129362 0.09878618 0.00471277
 0.14381476], best_act=2, best_val=0.741
2025-01-16 11:36:28,352 - DEBUG - Low Q-value (0.741), using MCTS.
2025-01-16 11:36:28,352 - INFO - Running MCTS with 37 simulations using 6 processes.
2025-01-16 11:36:31,494 - DEBUG - Aggregated action counts: {0: 6, 4: 1}
2025-01-16 11:36:31,494 - DEBUG - Chose best action 0
2025-01-16 11:36:31,589 - INFO - Episode 679/100000: Winner=2, Reward=22.20, EPSILON=0.994, (W=678,D=1,L=0)
2025-01-16 11:36:31,823 - INFO - Episode 680/100000: Winner=2, Reward=25.05, EPSILON=0.994, (W=679,D=1,L=0)
2025-01-16 11:36:32,026 - INFO - Episode 681/100000: Winner=2, Reward=12.85, EPSILON=0.994, (W=680,D=1,L=0)
2025-01-16 11:36:32,226 - INFO - Episode 682/100000: Winner=2, Reward=-7.55, EPSILON=0.994, (W=681,D=1,L=0)
2025-01-16 11:36:32,275 - DEBUG - Q-vals = [0.39200982 0.12220786 0.0299839  0.21987452 0.00207245 0.11366511
 0.12018636], best_act=0, best_val=0.392
2025-01-16 11:36:32,275 - DEBUG - Low Q-value (0.392), using MCTS.
2025-01-16 11:36:32,275 - INFO - Running MCTS with 37 simulations using 6 processes.
2025-01-16 11:36:35,176 - DEBUG - Aggregated action counts: {0: 6, 2: 1}
2025-01-16 11:36:35,176 - DEBUG - Chose best action 0
2025-01-16 11:36:35,226 - INFO - Episode 683/100000: Winner=2, Reward=-6.45, EPSILON=0.994, (W=682,D=1,L=0)
2025-01-16 11:36:35,410 - INFO - Episode 684/100000: Winner=2, Reward=7.45, EPSILON=0.994, (W=683,D=1,L=0)
2025-01-16 11:36:35,644 - INFO - Episode 685/100000: Winner=2, Reward=-7.85, EPSILON=0.994, (W=684,D=1,L=0)
2025-01-16 11:36:35,960 - INFO - Episode 686/100000: Winner=2, Reward=-16.45, EPSILON=0.994, (W=685,D=1,L=0)
2025-01-16 11:36:36,269 - INFO - Episode 687/100000: Winner=2, Reward=15.35, EPSILON=0.994, (W=686,D=1,L=0)
2025-01-16 11:36:36,561 - INFO - Episode 688/100000: Winner=2, Reward=-25.95, EPSILON=0.994, (W=687,D=1,L=0)
2025-01-16 11:36:36,840 - INFO - Episode 689/100000: Winner=2, Reward=-20.55, EPSILON=0.994, (W=688,D=1,L=0)
2025-01-16 11:36:37,124 - INFO - Episode 690/100000: Winner=2, Reward=14.65, EPSILON=0.994, (W=689,D=1,L=0)
2025-01-16 11:36:37,267 - INFO - Episode 691/100000: Winner=2, Reward=8.95, EPSILON=0.994, (W=690,D=1,L=0)
2025-01-16 11:36:37,391 - INFO - Episode 692/100000: Winner=2, Reward=10.80, EPSILON=0.994, (W=691,D=1,L=0)
2025-01-16 11:36:37,641 - INFO - Episode 693/100000: Winner=2, Reward=-5.10, EPSILON=0.994, (W=692,D=1,L=0)
2025-01-16 11:36:37,835 - INFO - Episode 694/100000: Winner=2, Reward=11.60, EPSILON=0.994, (W=693,D=1,L=0)
2025-01-16 11:36:37,965 - INFO - Episode 695/100000: Winner=2, Reward=-0.40, EPSILON=0.994, (W=694,D=1,L=0)
2025-01-16 11:36:38,139 - INFO - Episode 696/100000: Winner=2, Reward=-1.35, EPSILON=0.994, (W=695,D=1,L=0)
2025-01-16 11:36:38,325 - INFO - Episode 697/100000: Winner=2, Reward=-6.00, EPSILON=0.994, (W=696,D=1,L=0)
2025-01-16 11:36:38,523 - INFO - Episode 698/100000: Winner=2, Reward=-2.45, EPSILON=0.994, (W=697,D=1,L=0)
2025-01-16 11:36:38,651 - INFO - Episode 699/100000: Winner=2, Reward=2.10, EPSILON=0.994, (W=698,D=1,L=0)
2025-01-16 11:36:38,870 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 700.
2025-01-16 11:36:38,870 - INFO - Models saved at episode 700
2025-01-16 11:36:38,871 - INFO - Target networks updated
2025-01-16 11:36:38,931 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 700.
2025-01-16 11:36:38,931 - INFO - Episode 700/100000: Winner=2, Reward=7.00, EPSILON=0.994, (W=699,D=1,L=0)
2025-01-16 11:36:39,176 - INFO - Episode 701/100000: Winner=2, Reward=21.35, EPSILON=0.994, (W=700,D=1,L=0)
2025-01-16 11:36:39,309 - INFO - Episode 702/100000: Winner=2, Reward=-7.35, EPSILON=0.994, (W=701,D=1,L=0)
2025-01-16 11:36:39,456 - INFO - Episode 703/100000: Winner=2, Reward=-5.80, EPSILON=0.994, (W=702,D=1,L=0)
2025-01-16 11:36:39,656 - INFO - Episode 704/100000: Winner=2, Reward=-4.80, EPSILON=0.994, (W=703,D=1,L=0)
2025-01-16 11:36:39,776 - INFO - Episode 705/100000: Winner=2, Reward=-5.65, EPSILON=0.994, (W=704,D=1,L=0)
2025-01-16 11:36:40,030 - INFO - Episode 706/100000: Winner=2, Reward=-3.85, EPSILON=0.994, (W=705,D=1,L=0)
2025-01-16 11:36:40,270 - INFO - Episode 707/100000: Winner=2, Reward=-3.60, EPSILON=0.994, (W=706,D=1,L=0)
2025-01-16 11:36:40,347 - INFO - Episode 708/100000: Winner=2, Reward=-5.40, EPSILON=0.994, (W=707,D=1,L=0)
2025-01-16 11:36:40,656 - INFO - Episode 709/100000: Winner=2, Reward=-8.40, EPSILON=0.994, (W=708,D=1,L=0)
2025-01-16 11:36:40,843 - INFO - Episode 710/100000: Winner=2, Reward=21.95, EPSILON=0.994, (W=709,D=1,L=0)
2025-01-16 11:36:40,983 - INFO - Episode 711/100000: Winner=2, Reward=3.20, EPSILON=0.994, (W=710,D=1,L=0)
2025-01-16 11:36:41,118 - INFO - Episode 712/100000: Winner=2, Reward=12.60, EPSILON=0.994, (W=711,D=1,L=0)
2025-01-16 11:36:41,362 - INFO - Episode 713/100000: Winner=2, Reward=12.75, EPSILON=0.994, (W=712,D=1,L=0)
2025-01-16 11:36:41,652 - INFO - Episode 714/100000: Winner=2, Reward=13.50, EPSILON=0.994, (W=713,D=1,L=0)
2025-01-16 11:36:42,010 - INFO - Episode 715/100000: Winner=2, Reward=-17.10, EPSILON=0.994, (W=714,D=1,L=0)
2025-01-16 11:36:42,264 - INFO - Episode 716/100000: Winner=2, Reward=25.85, EPSILON=0.994, (W=715,D=1,L=0)
2025-01-16 11:36:42,376 - INFO - Episode 717/100000: Winner=2, Reward=-6.65, EPSILON=0.994, (W=716,D=1,L=0)
2025-01-16 11:36:42,666 - INFO - Episode 718/100000: Winner=2, Reward=-0.60, EPSILON=0.994, (W=717,D=1,L=0)
2025-01-16 11:36:42,911 - INFO - Episode 719/100000: Winner=2, Reward=2.40, EPSILON=0.994, (W=718,D=1,L=0)
2025-01-16 11:36:43,245 - INFO - Episode 720/100000: Winner=2, Reward=15.70, EPSILON=0.994, (W=719,D=1,L=0)
2025-01-16 11:36:43,377 - INFO - Episode 721/100000: Winner=2, Reward=-0.60, EPSILON=0.994, (W=720,D=1,L=0)
2025-01-16 11:36:43,551 - INFO - Episode 722/100000: Winner=2, Reward=-7.60, EPSILON=0.994, (W=721,D=1,L=0)
2025-01-16 11:36:43,794 - INFO - Episode 723/100000: Winner=2, Reward=17.85, EPSILON=0.994, (W=722,D=1,L=0)
2025-01-16 11:36:44,079 - INFO - Episode 724/100000: Winner=2, Reward=0.25, EPSILON=0.994, (W=723,D=1,L=0)
2025-01-16 11:36:44,407 - INFO - Episode 725/100000: Winner=2, Reward=-1.70, EPSILON=0.993, (W=724,D=1,L=0)
2025-01-16 11:36:44,467 - INFO - Episode 726/100000: Winner=2, Reward=1.05, EPSILON=0.993, (W=725,D=1,L=0)
2025-01-16 11:36:44,787 - INFO - Episode 727/100000: Winner=2, Reward=16.90, EPSILON=0.993, (W=726,D=1,L=0)
2025-01-16 11:36:44,944 - INFO - Episode 728/100000: Winner=2, Reward=-4.00, EPSILON=0.993, (W=727,D=1,L=0)
2025-01-16 11:36:45,029 - INFO - Episode 729/100000: Winner=2, Reward=0.90, EPSILON=0.993, (W=728,D=1,L=0)
2025-01-16 11:36:45,238 - INFO - Episode 730/100000: Winner=2, Reward=24.50, EPSILON=0.993, (W=729,D=1,L=0)
2025-01-16 11:36:45,392 - INFO - Episode 731/100000: Winner=2, Reward=-9.45, EPSILON=0.993, (W=730,D=1,L=0)
2025-01-16 11:36:45,636 - INFO - Episode 732/100000: Winner=2, Reward=-12.00, EPSILON=0.993, (W=731,D=1,L=0)
2025-01-16 11:36:45,829 - INFO - Episode 733/100000: Winner=2, Reward=1.05, EPSILON=0.993, (W=732,D=1,L=0)
2025-01-16 11:36:45,984 - INFO - Episode 734/100000: Winner=2, Reward=-10.90, EPSILON=0.993, (W=733,D=1,L=0)
2025-01-16 11:36:46,110 - INFO - Episode 735/100000: Winner=2, Reward=1.05, EPSILON=0.993, (W=734,D=1,L=0)
2025-01-16 11:36:46,341 - INFO - Episode 736/100000: Winner=2, Reward=1.65, EPSILON=0.993, (W=735,D=1,L=0)
2025-01-16 11:36:46,375 - DEBUG - Q-vals = [0.09800453 0.05379549 0.04602123 0.5363682  0.14377405 0.04001133
 0.08202513], best_act=3, best_val=0.536
2025-01-16 11:36:46,375 - DEBUG - Low Q-value (0.536), using MCTS.
2025-01-16 11:36:46,376 - INFO - Running MCTS with 39 simulations using 6 processes.
2025-01-16 11:36:49,721 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:36:49,721 - DEBUG - Chose best action 0
2025-01-16 11:36:49,862 - INFO - Episode 737/100000: Winner=2, Reward=-10.10, EPSILON=0.993, (W=736,D=1,L=0)
2025-01-16 11:36:50,081 - INFO - Episode 738/100000: Winner=2, Reward=11.70, EPSILON=0.993, (W=737,D=1,L=0)
2025-01-16 11:36:50,268 - INFO - Episode 739/100000: Winner=2, Reward=0.50, EPSILON=0.993, (W=738,D=1,L=0)
2025-01-16 11:36:50,409 - INFO - Episode 740/100000: Winner=2, Reward=19.30, EPSILON=0.993, (W=739,D=1,L=0)
2025-01-16 11:36:50,706 - INFO - Episode 741/100000: Winner=2, Reward=26.60, EPSILON=0.993, (W=740,D=1,L=0)
2025-01-16 11:36:50,987 - INFO - Episode 742/100000: Winner=2, Reward=-17.15, EPSILON=0.993, (W=741,D=1,L=0)
2025-01-16 11:36:51,143 - INFO - Episode 743/100000: Winner=2, Reward=10.35, EPSILON=0.993, (W=742,D=1,L=0)
2025-01-16 11:36:51,268 - INFO - Episode 744/100000: Winner=2, Reward=1.45, EPSILON=0.993, (W=743,D=1,L=0)
2025-01-16 11:36:51,580 - INFO - Episode 745/100000: Winner=2, Reward=17.45, EPSILON=0.993, (W=744,D=1,L=0)
2025-01-16 11:36:51,705 - INFO - Episode 746/100000: Winner=2, Reward=7.15, EPSILON=0.993, (W=745,D=1,L=0)
2025-01-16 11:36:51,846 - INFO - Episode 747/100000: Winner=2, Reward=-5.00, EPSILON=0.993, (W=746,D=1,L=0)
2025-01-16 11:36:52,096 - INFO - Episode 748/100000: Winner=2, Reward=8.30, EPSILON=0.993, (W=747,D=1,L=0)
2025-01-16 11:36:52,424 - INFO - Episode 749/100000: Winner=2, Reward=-18.15, EPSILON=0.993, (W=748,D=1,L=0)
2025-01-16 11:36:52,518 - INFO - Episode 750/100000: Winner=2, Reward=-5.15, EPSILON=0.993, (W=749,D=1,L=0)
2025-01-16 11:36:52,611 - DEBUG - Q-vals = [4.9679387e-01 2.8792143e-05 9.5876940e-03 2.8536063e-01 2.0451464e-02
 1.8009625e-01 7.6813255e-03], best_act=0, best_val=0.497
2025-01-16 11:36:52,611 - DEBUG - Low Q-value (0.497), using MCTS.
2025-01-16 11:36:52,611 - INFO - Running MCTS with 40 simulations using 6 processes.
2025-01-16 11:36:55,350 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:36:55,350 - DEBUG - Chose best action 0
2025-01-16 11:36:55,475 - INFO - Episode 751/100000: Winner=2, Reward=4.65, EPSILON=0.993, (W=750,D=1,L=0)
2025-01-16 11:36:55,631 - INFO - Episode 752/100000: Winner=2, Reward=-5.40, EPSILON=0.993, (W=751,D=1,L=0)
2025-01-16 11:36:55,709 - DEBUG - Q-vals = [0.12143931 0.03554989 0.6499648  0.13337931 0.01500599 0.01338303
 0.03127767], best_act=2, best_val=0.650
2025-01-16 11:36:55,709 - DEBUG - Low Q-value (0.650), using MCTS.
2025-01-16 11:36:55,709 - INFO - Running MCTS with 40 simulations using 6 processes.
2025-01-16 11:36:58,380 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:36:58,380 - DEBUG - Chose best action 0
2025-01-16 11:36:58,521 - INFO - Episode 753/100000: Winner=2, Reward=6.05, EPSILON=0.993, (W=752,D=1,L=0)
2025-01-16 11:36:58,614 - INFO - Episode 754/100000: Winner=2, Reward=5.60, EPSILON=0.993, (W=753,D=1,L=0)
2025-01-16 11:36:58,771 - INFO - Episode 755/100000: Winner=2, Reward=-7.55, EPSILON=0.993, (W=754,D=1,L=0)
2025-01-16 11:36:58,880 - INFO - Episode 756/100000: Winner=2, Reward=-5.75, EPSILON=0.993, (W=755,D=1,L=0)
2025-01-16 11:36:59,021 - INFO - Episode 757/100000: Winner=2, Reward=8.45, EPSILON=0.993, (W=756,D=1,L=0)
2025-01-16 11:36:59,177 - DEBUG - Q-vals = [2.8388901e-03 9.7264785e-01 2.0885334e-04 1.8385475e-06 2.2145288e-04
 4.7869170e-03 1.9294200e-02], best_act=1, best_val=0.973
2025-01-16 11:36:59,177 - DEBUG - Low Q-value (0.973), using MCTS.
2025-01-16 11:36:59,177 - INFO - Running MCTS with 40 simulations using 6 processes.
2025-01-16 11:37:01,832 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:37:01,832 - DEBUG - Chose best action 0
2025-01-16 11:37:01,926 - INFO - Episode 758/100000: Winner=2, Reward=-7.95, EPSILON=0.993, (W=757,D=1,L=0)
2025-01-16 11:37:02,051 - INFO - Episode 759/100000: Winner=2, Reward=-4.55, EPSILON=0.993, (W=758,D=1,L=0)
2025-01-16 11:37:02,254 - INFO - Episode 760/100000: Winner=2, Reward=12.80, EPSILON=0.993, (W=759,D=1,L=0)
2025-01-16 11:37:02,395 - INFO - Episode 761/100000: Winner=2, Reward=-1.10, EPSILON=0.993, (W=760,D=1,L=0)
2025-01-16 11:37:02,614 - INFO - Episode 762/100000: Winner=2, Reward=11.35, EPSILON=0.993, (W=761,D=1,L=0)
2025-01-16 11:37:02,848 - INFO - Episode 763/100000: Winner=2, Reward=-6.25, EPSILON=0.993, (W=762,D=1,L=0)
2025-01-16 11:37:03,098 - INFO - Episode 764/100000: Winner=2, Reward=-10.55, EPSILON=0.993, (W=763,D=1,L=0)
2025-01-16 11:37:03,473 - INFO - Episode 765/100000: Winner=2, Reward=-30.20, EPSILON=0.993, (W=764,D=1,L=0)
2025-01-16 11:37:03,660 - INFO - Episode 766/100000: Winner=2, Reward=-9.00, EPSILON=0.993, (W=765,D=1,L=0)
2025-01-16 11:37:03,754 - DEBUG - Q-vals = [0.3095299  0.00553246 0.1150354  0.1802011  0.13833532 0.1708161
 0.08054972], best_act=0, best_val=0.310
2025-01-16 11:37:03,754 - DEBUG - Low Q-value (0.310), using MCTS.
2025-01-16 11:37:03,754 - INFO - Running MCTS with 40 simulations using 6 processes.
2025-01-16 11:37:06,347 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:37:06,347 - DEBUG - Chose best action 0
2025-01-16 11:37:06,394 - INFO - Episode 767/100000: Winner=2, Reward=-6.95, EPSILON=0.993, (W=766,D=1,L=0)
2025-01-16 11:37:06,566 - INFO - Episode 768/100000: Winner=2, Reward=-5.00, EPSILON=0.993, (W=767,D=1,L=0)
2025-01-16 11:37:06,769 - INFO - Episode 769/100000: Winner=2, Reward=3.25, EPSILON=0.993, (W=768,D=1,L=0)
2025-01-16 11:37:06,941 - INFO - Episode 770/100000: Winner=2, Reward=22.05, EPSILON=0.993, (W=769,D=1,L=0)
2025-01-16 11:37:07,113 - INFO - Episode 771/100000: Winner=2, Reward=-4.50, EPSILON=0.993, (W=770,D=1,L=0)
2025-01-16 11:37:07,269 - INFO - Episode 772/100000: Winner=2, Reward=9.10, EPSILON=0.993, (W=771,D=1,L=0)
2025-01-16 11:37:07,347 - INFO - Episode 773/100000: Winner=2, Reward=14.85, EPSILON=0.993, (W=772,D=1,L=0)
2025-01-16 11:37:07,535 - INFO - Episode 774/100000: Winner=2, Reward=-0.05, EPSILON=0.993, (W=773,D=1,L=0)
2025-01-16 11:37:07,769 - INFO - Episode 775/100000: Winner=2, Reward=14.05, EPSILON=0.993, (W=774,D=1,L=0)
2025-01-16 11:37:07,988 - INFO - Episode 776/100000: Winner=2, Reward=-9.10, EPSILON=0.993, (W=775,D=1,L=0)
2025-01-16 11:37:08,144 - INFO - Episode 777/100000: Winner=2, Reward=11.05, EPSILON=0.993, (W=776,D=1,L=0)
2025-01-16 11:37:08,238 - INFO - Episode 778/100000: Winner=2, Reward=-6.40, EPSILON=0.993, (W=777,D=1,L=0)
2025-01-16 11:37:08,534 - INFO - Episode 779/100000: Winner=2, Reward=33.85, EPSILON=0.993, (W=778,D=1,L=0)
2025-01-16 11:37:08,722 - DEBUG - Q-vals = [5.8742691e-02 7.5623378e-02 3.9301686e-02 3.5722192e-02 2.1417072e-01
 8.8198561e-07 5.7643849e-01], best_act=6, best_val=0.576
2025-01-16 11:37:08,722 - DEBUG - Low Q-value (0.576), using MCTS.
2025-01-16 11:37:08,722 - INFO - Episode 780/100000: Winner=2, Reward=-2.95, EPSILON=0.993, (W=779,D=1,L=0)
2025-01-16 11:37:08,925 - INFO - Episode 781/100000: Winner=2, Reward=20.70, EPSILON=0.993, (W=780,D=1,L=0)
2025-01-16 11:37:09,097 - INFO - Episode 782/100000: Winner=2, Reward=18.65, EPSILON=0.993, (W=781,D=1,L=0)
2025-01-16 11:37:09,284 - INFO - Episode 783/100000: Winner=2, Reward=21.30, EPSILON=0.993, (W=782,D=1,L=0)
2025-01-16 11:37:09,503 - INFO - Episode 784/100000: Winner=2, Reward=2.00, EPSILON=0.993, (W=783,D=1,L=0)
2025-01-16 11:37:09,722 - DEBUG - Q-vals = [2.9738940e-02 1.6555582e-03 3.3818927e-04 7.5706506e-01 1.7022231e-01
 2.4762440e-02 1.6217381e-02], best_act=3, best_val=0.757
2025-01-16 11:37:09,722 - DEBUG - Low Q-value (0.757), using MCTS.
2025-01-16 11:37:09,722 - INFO - Running MCTS with 41 simulations using 6 processes.
2025-01-16 11:37:12,315 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:37:12,315 - DEBUG - Chose best action 0
2025-01-16 11:37:12,378 - INFO - Episode 785/100000: Winner=2, Reward=8.15, EPSILON=0.993, (W=784,D=1,L=0)
2025-01-16 11:37:12,518 - INFO - Episode 786/100000: Winner=2, Reward=-4.55, EPSILON=0.993, (W=785,D=1,L=0)
2025-01-16 11:37:12,628 - DEBUG - Q-vals = [0.03785263 0.17311111 0.266611   0.08043277 0.04512236 0.37033388
 0.02653628], best_act=5, best_val=0.370
2025-01-16 11:37:12,628 - DEBUG - Low Q-value (0.370), using MCTS.
2025-01-16 11:37:12,628 - INFO - Running MCTS with 41 simulations using 6 processes.
2025-01-16 11:37:15,252 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:37:15,252 - DEBUG - Chose best action 0
2025-01-16 11:37:15,315 - INFO - Episode 787/100000: Winner=2, Reward=27.30, EPSILON=0.993, (W=786,D=1,L=0)
2025-01-16 11:37:15,409 - INFO - Episode 788/100000: Winner=2, Reward=-3.30, EPSILON=0.993, (W=787,D=1,L=0)
2025-01-16 11:37:15,580 - INFO - Episode 789/100000: Winner=2, Reward=-1.35, EPSILON=0.993, (W=788,D=1,L=0)
2025-01-16 11:37:15,763 - INFO - Episode 790/100000: Winner=2, Reward=8.15, EPSILON=0.993, (W=789,D=1,L=0)
2025-01-16 11:37:15,864 - INFO - Episode 791/100000: Winner=2, Reward=-6.15, EPSILON=0.993, (W=790,D=1,L=0)
2025-01-16 11:37:15,940 - INFO - Episode 792/100000: Winner=2, Reward=-6.05, EPSILON=0.993, (W=791,D=1,L=0)
2025-01-16 11:37:16,149 - DEBUG - Q-vals = [5.4316938e-02 2.8280416e-01 7.5795576e-03 6.4527726e-01 7.2507518e-03
 2.6964112e-03 7.4894306e-05], best_act=3, best_val=0.645
2025-01-16 11:37:16,149 - DEBUG - Low Q-value (0.645), using MCTS.
2025-01-16 11:37:16,151 - INFO - Running MCTS with 41 simulations using 6 processes.
2025-01-16 11:37:18,896 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:37:18,896 - DEBUG - Chose best action 0
2025-01-16 11:37:19,247 - INFO - Episode 793/100000: Winner=2, Reward=-0.65, EPSILON=0.993, (W=792,D=1,L=0)
2025-01-16 11:37:19,487 - INFO - Episode 794/100000: Winner=2, Reward=4.90, EPSILON=0.993, (W=793,D=1,L=0)
2025-01-16 11:37:19,634 - INFO - Episode 795/100000: Winner=2, Reward=0.70, EPSILON=0.993, (W=794,D=1,L=0)
2025-01-16 11:37:19,741 - INFO - Episode 796/100000: Winner=2, Reward=10.95, EPSILON=0.993, (W=795,D=1,L=0)
2025-01-16 11:37:20,037 - INFO - Episode 797/100000: Winner=2, Reward=-12.40, EPSILON=0.993, (W=796,D=1,L=0)
2025-01-16 11:37:20,307 - INFO - Episode 798/100000: Winner=2, Reward=2.60, EPSILON=0.993, (W=797,D=1,L=0)
2025-01-16 11:37:20,432 - INFO - Episode 799/100000: Winner=2, Reward=-3.70, EPSILON=0.993, (W=798,D=1,L=0)
2025-01-16 11:37:20,639 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 800.
2025-01-16 11:37:20,639 - INFO - Models saved at episode 800
2025-01-16 11:37:20,639 - INFO - Target networks updated
2025-01-16 11:37:20,702 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 800.
2025-01-16 11:37:20,702 - INFO - Episode 800/100000: Winner=2, Reward=2.95, EPSILON=0.993, (W=799,D=1,L=0)
2025-01-16 11:37:20,780 - INFO - Episode 801/100000: Winner=2, Reward=1.00, EPSILON=0.993, (W=800,D=1,L=0)
2025-01-16 11:37:21,154 - INFO - Episode 802/100000: Winner=2, Reward=-17.70, EPSILON=0.993, (W=801,D=1,L=0)
2025-01-16 11:37:21,179 - DEBUG - Q-vals = [0.2483148  0.03148565 0.2932425  0.10163322 0.03015122 0.24171996
 0.05345265], best_act=2, best_val=0.293
2025-01-16 11:37:21,179 - DEBUG - Low Q-value (0.293), using MCTS.
2025-01-16 11:37:21,179 - INFO - Running MCTS with 42 simulations using 6 processes.
2025-01-16 11:37:23,935 - DEBUG - Aggregated action counts: {0: 6}
2025-01-16 11:37:23,935 - DEBUG - Chose best action 0
2025-01-16 11:37:24,122 - INFO - Episode 803/100000: Winner=2, Reward=29.30, EPSILON=0.993, (W=802,D=1,L=0)
2025-01-16 11:37:24,185 - INFO - Episode 804/100000: Winner=2, Reward=1.15, EPSILON=0.993, (W=803,D=1,L=0)
2025-01-16 11:37:24,403 - INFO - Episode 805/100000: Winner=2, Reward=27.55, EPSILON=0.993, (W=804,D=1,L=0)
2025-01-16 11:37:24,622 - INFO - Episode 806/100000: Winner=2, Reward=-1.00, EPSILON=0.993, (W=805,D=1,L=0)
2025-01-16 11:37:24,825 - INFO - Episode 807/100000: Winner=2, Reward=13.05, EPSILON=0.993, (W=806,D=1,L=0)
2025-01-16 11:37:24,997 - INFO - Episode 808/100000: Winner=2, Reward=6.10, EPSILON=0.993, (W=807,D=1,L=0)
2025-01-16 11:37:25,169 - INFO - Episode 809/100000: Winner=2, Reward=26.10, EPSILON=0.993, (W=808,D=1,L=0)
2025-01-16 11:37:25,434 - INFO - Episode 810/100000: Winner=2, Reward=12.35, EPSILON=0.993, (W=809,D=1,L=0)
2025-01-16 11:37:25,512 - INFO - Episode 811/100000: Winner=2, Reward=1.10, EPSILON=0.993, (W=810,D=1,L=0)
2025-01-16 11:37:25,809 - INFO - Episode 812/100000: Winner=2, Reward=-7.05, EPSILON=0.993, (W=811,D=1,L=0)
2025-01-16 11:37:26,028 - INFO - Episode 813/100000: Winner=2, Reward=32.00, EPSILON=0.993, (W=812,D=1,L=0)
2025-01-16 11:37:26,231 - INFO - Episode 814/100000: Winner=2, Reward=-4.95, EPSILON=0.993, (W=813,D=1,L=0)
2025-01-16 11:37:26,340 - INFO - Episode 815/100000: Winner=2, Reward=15.80, EPSILON=0.993, (W=814,D=1,L=0)
2025-01-16 11:37:26,512 - INFO - Episode 816/100000: Winner=2, Reward=12.75, EPSILON=0.993, (W=815,D=1,L=0)
2025-01-16 11:37:26,793 - INFO - Episode 817/100000: Winner=2, Reward=4.90, EPSILON=0.993, (W=816,D=1,L=0)
2025-01-16 11:37:27,012 - INFO - Episode 818/100000: Winner=2, Reward=37.35, EPSILON=0.993, (W=817,D=1,L=0)
2025-01-16 11:37:27,246 - INFO - Episode 819/100000: Winner=2, Reward=2.35, EPSILON=0.993, (W=818,D=1,L=0)
2025-01-16 11:37:27,496 - INFO - Episode 820/100000: Winner=2, Reward=8.95, EPSILON=0.993, (W=819,D=1,L=0)
2025-01-16 11:37:27,809 - INFO - Episode 821/100000: Winner=2, Reward=1.60, EPSILON=0.993, (W=820,D=1,L=0)
2025-01-16 11:37:28,074 - INFO - Episode 822/100000: Winner=2, Reward=3.35, EPSILON=0.993, (W=821,D=1,L=0)
2025-01-16 11:37:28,340 - INFO - Episode 823/100000: Winner=2, Reward=22.10, EPSILON=0.993, (W=822,D=1,L=0)
2025-01-16 11:37:28,465 - INFO - Episode 824/100000: Winner=2, Reward=9.20, EPSILON=0.993, (W=823,D=1,L=0)
2025-01-16 11:37:28,730 - INFO - Episode 825/100000: Winner=2, Reward=29.15, EPSILON=0.993, (W=824,D=1,L=0)
2025-01-16 11:37:28,918 - INFO - Episode 826/100000: Winner=2, Reward=-9.45, EPSILON=0.993, (W=825,D=1,L=0)
2025-01-16 11:37:29,090 - INFO - Episode 827/100000: Winner=2, Reward=11.80, EPSILON=0.993, (W=826,D=1,L=0)
2025-01-16 11:37:29,183 - INFO - Episode 828/100000: Winner=2, Reward=-7.45, EPSILON=0.993, (W=827,D=1,L=0)
2025-01-16 11:37:29,387 - INFO - Episode 829/100000: Winner=2, Reward=10.25, EPSILON=0.993, (W=828,D=1,L=0)
2025-01-16 11:37:29,574 - INFO - Episode 830/100000: Winner=2, Reward=-5.55, EPSILON=0.993, (W=829,D=1,L=0)
2025-01-16 11:37:29,730 - INFO - Episode 831/100000: Winner=2, Reward=0.00, EPSILON=0.993, (W=830,D=1,L=0)
2025-01-16 11:37:29,933 - INFO - Episode 832/100000: Winner=2, Reward=13.25, EPSILON=0.993, (W=831,D=1,L=0)
2025-01-16 11:37:30,136 - INFO - Episode 833/100000: Winner=2, Reward=-6.25, EPSILON=0.993, (W=832,D=1,L=0)
2025-01-16 11:37:30,480 - INFO - Episode 834/100000: Winner=2, Reward=-24.70, EPSILON=0.993, (W=833,D=1,L=0)
2025-01-16 11:37:30,527 - DEBUG - Q-vals = [0.12608087 0.06223838 0.2873828  0.40121073 0.01369897 0.07027986
 0.0391082 ], best_act=3, best_val=0.401
2025-01-16 11:37:30,527 - DEBUG - Low Q-value (0.401), using MCTS.
2025-01-16 11:37:30,527 - INFO - Running MCTS with 43 simulations using 6 processes.
2025-01-16 11:37:33,235 - DEBUG - Aggregated action counts: {0: 6, 5: 1}
2025-01-16 11:37:33,235 - DEBUG - Chose best action 0
2025-01-16 11:37:33,511 - INFO - Episode 835/100000: Winner=2, Reward=-34.10, EPSILON=0.993, (W=834,D=1,L=0)
2025-01-16 11:37:33,612 - INFO - Episode 836/100000: Winner=2, Reward=-5.65, EPSILON=0.993, (W=835,D=1,L=0)
2025-01-16 11:37:33,784 - INFO - Episode 837/100000: Winner=2, Reward=4.70, EPSILON=0.992, (W=836,D=1,L=0)
2025-01-16 11:37:34,002 - INFO - Episode 838/100000: Winner=2, Reward=-7.75, EPSILON=0.992, (W=837,D=1,L=0)
2025-01-16 11:37:34,127 - INFO - Episode 839/100000: Winner=2, Reward=7.25, EPSILON=0.992, (W=838,D=1,L=0)
2025-01-16 11:37:34,221 - INFO - Episode 840/100000: Winner=2, Reward=9.35, EPSILON=0.992, (W=839,D=1,L=0)
2025-01-16 11:37:34,408 - INFO - Episode 841/100000: Winner=2, Reward=-8.05, EPSILON=0.992, (W=840,D=1,L=0)
2025-01-16 11:37:34,549 - INFO - Episode 842/100000: Winner=2, Reward=-6.50, EPSILON=0.992, (W=841,D=1,L=0)
2025-01-16 11:37:34,799 - INFO - Episode 843/100000: Winner=2, Reward=1.15, EPSILON=0.992, (W=842,D=1,L=0)
2025-01-16 11:37:35,002 - INFO - Episode 844/100000: Winner=2, Reward=-8.85, EPSILON=0.992, (W=843,D=1,L=0)
2025-01-16 11:37:35,158 - INFO - Episode 845/100000: Winner=2, Reward=-4.95, EPSILON=0.992, (W=844,D=1,L=0)
2025-01-16 11:37:35,314 - INFO - Episode 846/100000: Winner=2, Reward=10.30, EPSILON=0.992, (W=845,D=1,L=0)
2025-01-16 11:37:35,439 - INFO - Episode 847/100000: Winner=2, Reward=7.55, EPSILON=0.992, (W=846,D=1,L=0)
2025-01-16 11:37:35,543 - INFO - Episode 848/100000: Winner=2, Reward=4.45, EPSILON=0.992, (W=847,D=1,L=0)
2025-01-16 11:37:35,722 - INFO - Episode 849/100000: Winner=2, Reward=-3.80, EPSILON=0.992, (W=848,D=1,L=0)
2025-01-16 11:37:35,847 - INFO - Episode 850/100000: Winner=2, Reward=7.35, EPSILON=0.992, (W=849,D=1,L=0)
2025-01-16 11:37:36,094 - INFO - Episode 851/100000: Winner=2, Reward=3.60, EPSILON=0.992, (W=850,D=1,L=0)
2025-01-16 11:37:36,281 - INFO - Episode 852/100000: Winner=2, Reward=10.85, EPSILON=0.992, (W=851,D=1,L=0)
2025-01-16 11:37:36,500 - INFO - Episode 853/100000: Winner=2, Reward=-5.55, EPSILON=0.992, (W=852,D=1,L=0)
2025-01-16 11:37:36,672 - INFO - Episode 854/100000: Winner=2, Reward=1.55, EPSILON=0.992, (W=853,D=1,L=0)
2025-01-16 11:37:36,812 - DEBUG - Q-vals = [0.17051095 0.10141902 0.05716366 0.21187085 0.09279639 0.1430599
 0.2231792 ], best_act=6, best_val=0.223
2025-01-16 11:37:36,812 - DEBUG - Low Q-value (0.223), using MCTS.
2025-01-16 11:37:36,828 - INFO - Episode 855/100000: Winner=2, Reward=-10.75, EPSILON=0.992, (W=854,D=1,L=0)
2025-01-16 11:37:37,047 - INFO - Episode 856/100000: Winner=2, Reward=15.85, EPSILON=0.992, (W=855,D=1,L=0)
2025-01-16 11:37:37,218 - DEBUG - Q-vals = [0.0626752  0.4994766  0.00578699 0.22034863 0.05238308 0.14482217
 0.01450735], best_act=1, best_val=0.499
2025-01-16 11:37:37,234 - DEBUG - Low Q-value (0.499), using MCTS.
2025-01-16 11:37:37,234 - INFO - Running MCTS with 44 simulations using 6 processes.
2025-01-16 11:37:39,954 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:37:39,955 - DEBUG - Chose best action 0
2025-01-16 11:37:39,989 - INFO - Episode 857/100000: Winner=2, Reward=6.80, EPSILON=0.992, (W=856,D=1,L=0)
2025-01-16 11:37:40,193 - INFO - Episode 858/100000: Winner=2, Reward=-11.15, EPSILON=0.992, (W=857,D=1,L=0)
2025-01-16 11:37:40,476 - INFO - Episode 859/100000: Winner=2, Reward=46.45, EPSILON=0.992, (W=858,D=1,L=0)
2025-01-16 11:37:40,627 - INFO - Episode 860/100000: Winner=2, Reward=-0.10, EPSILON=0.992, (W=859,D=1,L=0)
2025-01-16 11:37:40,830 - INFO - Episode 861/100000: Winner=2, Reward=-5.35, EPSILON=0.992, (W=860,D=1,L=0)
2025-01-16 11:37:41,133 - DEBUG - Q-vals = [1.1510176e-02 4.1419603e-02 9.1237910e-03 1.2559817e-03 9.9232560e-04
 3.2985897e-06 9.3569481e-01], best_act=0, best_val=0.012
2025-01-16 11:37:41,133 - DEBUG - Low Q-value (0.012), using MCTS.
2025-01-16 11:37:41,148 - INFO - Running MCTS with 44 simulations using 6 processes.
2025-01-16 11:37:43,726 - DEBUG - Aggregated action counts: {2: 5, 4: 1, 0: 1}
2025-01-16 11:37:43,726 - DEBUG - Chose best action 2
2025-01-16 11:37:43,742 - INFO - Episode 862/100000: Winner=2, Reward=13.05, EPSILON=0.992, (W=861,D=1,L=0)
2025-01-16 11:37:44,007 - INFO - Episode 863/100000: Winner=2, Reward=-10.25, EPSILON=0.992, (W=862,D=1,L=0)
2025-01-16 11:37:44,257 - INFO - Episode 864/100000: Winner=2, Reward=2.50, EPSILON=0.992, (W=863,D=1,L=0)
2025-01-16 11:37:44,413 - INFO - Episode 865/100000: Winner=2, Reward=22.95, EPSILON=0.992, (W=864,D=1,L=0)
2025-01-16 11:37:44,648 - INFO - Episode 866/100000: Winner=2, Reward=12.90, EPSILON=0.992, (W=865,D=1,L=0)
2025-01-16 11:37:44,820 - INFO - Episode 867/100000: Winner=2, Reward=19.25, EPSILON=0.992, (W=866,D=1,L=0)
2025-01-16 11:37:45,148 - INFO - Episode 868/100000: Winner=2, Reward=2.65, EPSILON=0.992, (W=867,D=1,L=0)
2025-01-16 11:37:45,351 - INFO - Episode 869/100000: Winner=2, Reward=10.00, EPSILON=0.992, (W=868,D=1,L=0)
2025-01-16 11:37:45,523 - INFO - Episode 870/100000: Winner=2, Reward=28.10, EPSILON=0.992, (W=869,D=1,L=0)
2025-01-16 11:37:45,648 - DEBUG - Q-vals = [0.01464142 0.00947289 0.01902075 0.00087015 0.18882947 0.01851045
 0.7486549 ], best_act=6, best_val=0.749
2025-01-16 11:37:45,648 - DEBUG - Low Q-value (0.749), using MCTS.
2025-01-16 11:37:45,663 - INFO - Episode 871/100000: Winner=2, Reward=-0.05, EPSILON=0.992, (W=870,D=1,L=0)
2025-01-16 11:37:45,736 - INFO - Episode 872/100000: Winner=2, Reward=-6.65, EPSILON=0.992, (W=871,D=1,L=0)
2025-01-16 11:37:45,984 - INFO - Episode 873/100000: Winner=2, Reward=-2.00, EPSILON=0.992, (W=872,D=1,L=0)
2025-01-16 11:37:46,299 - INFO - Episode 874/100000: Winner=2, Reward=-15.45, EPSILON=0.992, (W=873,D=1,L=0)
2025-01-16 11:37:46,416 - INFO - Episode 875/100000: Winner=2, Reward=-8.95, EPSILON=0.992, (W=874,D=1,L=0)
2025-01-16 11:37:46,646 - INFO - Episode 876/100000: Winner=2, Reward=32.40, EPSILON=0.992, (W=875,D=1,L=0)
2025-01-16 11:37:46,974 - INFO - Episode 877/100000: Winner=2, Reward=-7.05, EPSILON=0.992, (W=876,D=1,L=0)
2025-01-16 11:37:47,273 - INFO - Episode 878/100000: Winner=2, Reward=18.20, EPSILON=0.992, (W=877,D=1,L=0)
2025-01-16 11:37:47,403 - INFO - Episode 879/100000: Winner=2, Reward=-4.95, EPSILON=0.992, (W=878,D=1,L=0)
2025-01-16 11:37:47,562 - INFO - Episode 880/100000: Winner=2, Reward=3.90, EPSILON=0.992, (W=879,D=1,L=0)
2025-01-16 11:37:47,820 - INFO - Episode 881/100000: Winner=2, Reward=21.95, EPSILON=0.992, (W=880,D=1,L=0)
2025-01-16 11:37:48,019 - INFO - Episode 882/100000: Winner=2, Reward=14.85, EPSILON=0.992, (W=881,D=1,L=0)
2025-01-16 11:37:48,212 - INFO - Episode 883/100000: Winner=2, Reward=-7.90, EPSILON=0.992, (W=882,D=1,L=0)
2025-01-16 11:37:48,433 - INFO - Episode 884/100000: Winner=2, Reward=-5.20, EPSILON=0.992, (W=883,D=1,L=0)
2025-01-16 11:37:48,548 - DEBUG - Q-vals = [0.11324759 0.0045712  0.39969015 0.1213052  0.02325038 0.31332213
 0.02461343], best_act=2, best_val=0.400
2025-01-16 11:37:48,548 - DEBUG - Low Q-value (0.400), using MCTS.
2025-01-16 11:37:48,548 - INFO - Running MCTS with 45 simulations using 6 processes.
2025-01-16 11:37:51,326 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:37:51,326 - DEBUG - Chose best action 0
2025-01-16 11:37:51,467 - INFO - Episode 885/100000: Winner=2, Reward=28.70, EPSILON=0.992, (W=884,D=1,L=0)
2025-01-16 11:37:51,576 - DEBUG - Q-vals = [0.33823848 0.04049495 0.03585834 0.22454788 0.26523083 0.02858211
 0.06704742], best_act=0, best_val=0.338
2025-01-16 11:37:51,576 - DEBUG - Low Q-value (0.338), using MCTS.
2025-01-16 11:37:51,576 - INFO - Running MCTS with 45 simulations using 6 processes.
2025-01-16 11:37:54,242 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:37:54,242 - DEBUG - Chose best action 0
2025-01-16 11:37:54,381 - INFO - Episode 886/100000: Winner=2, Reward=31.35, EPSILON=0.992, (W=885,D=1,L=0)
2025-01-16 11:37:54,694 - INFO - Episode 887/100000: Winner=2, Reward=6.55, EPSILON=0.992, (W=886,D=1,L=0)
2025-01-16 11:37:54,756 - INFO - Episode 888/100000: Winner=2, Reward=-6.55, EPSILON=0.992, (W=887,D=1,L=0)
2025-01-16 11:37:54,850 - INFO - Episode 889/100000: Winner=2, Reward=0.80, EPSILON=0.992, (W=888,D=1,L=0)
2025-01-16 11:37:55,068 - INFO - Episode 890/100000: Winner=2, Reward=5.35, EPSILON=0.992, (W=889,D=1,L=0)
2025-01-16 11:37:55,318 - INFO - Episode 891/100000: Winner=2, Reward=33.50, EPSILON=0.992, (W=890,D=1,L=0)
2025-01-16 11:37:55,546 - INFO - Episode 892/100000: Winner=2, Reward=9.40, EPSILON=0.992, (W=891,D=1,L=0)
2025-01-16 11:37:55,829 - INFO - Episode 893/100000: Winner=2, Reward=7.85, EPSILON=0.992, (W=892,D=1,L=0)
2025-01-16 11:37:56,039 - INFO - Episode 894/100000: Winner=2, Reward=44.65, EPSILON=0.992, (W=893,D=1,L=0)
2025-01-16 11:37:56,343 - INFO - Episode 895/100000: Winner=2, Reward=5.60, EPSILON=0.992, (W=894,D=1,L=0)
2025-01-16 11:37:56,585 - DEBUG - Q-vals = [1.9576570e-01 1.3543919e-01 5.8891720e-01 3.6263231e-02 5.2324076e-08
 2.3393992e-03 4.1275159e-02], best_act=0, best_val=0.196
2025-01-16 11:37:56,585 - DEBUG - Low Q-value (0.196), using MCTS.
2025-01-16 11:37:56,585 - INFO - Episode 896/100000: Winner=2, Reward=16.95, EPSILON=0.992, (W=895,D=1,L=0)
2025-01-16 11:37:56,867 - INFO - Episode 897/100000: Winner=2, Reward=2.25, EPSILON=0.992, (W=896,D=1,L=0)
2025-01-16 11:37:56,913 - DEBUG - Q-vals = [0.09520657 0.01546071 0.29203922 0.25626054 0.01622524 0.31095833
 0.01384945], best_act=5, best_val=0.311
2025-01-16 11:37:56,913 - DEBUG - Low Q-value (0.311), using MCTS.
2025-01-16 11:37:56,913 - INFO - Running MCTS with 45 simulations using 6 processes.
2025-01-16 11:37:59,526 - DEBUG - Aggregated action counts: {0: 7}
2025-01-16 11:37:59,526 - DEBUG - Chose best action 0
2025-01-16 11:37:59,753 - INFO - Episode 898/100000: Winner=2, Reward=8.80, EPSILON=0.992, (W=897,D=1,L=0)
2025-01-16 11:38:00,029 - INFO - Episode 899/100000: Winner=2, Reward=16.70, EPSILON=0.992, (W=898,D=1,L=0)
2025-01-16 11:38:00,378 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 900.
2025-01-16 11:38:00,378 - INFO - Models saved at episode 900
2025-01-16 11:38:00,378 - INFO - Target networks updated
2025-01-16 11:38:00,446 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 900.
2025-01-16 11:38:00,446 - INFO - Episode 900/100000: Winner=2, Reward=5.65, EPSILON=0.992, (W=899,D=1,L=0)
2025-01-16 11:38:00,623 - INFO - Episode 901/100000: Winner=2, Reward=7.30, EPSILON=0.992, (W=900,D=1,L=0)
2025-01-16 11:38:00,831 - INFO - Episode 902/100000: Winner=2, Reward=15.80, EPSILON=0.992, (W=901,D=1,L=0)
2025-01-16 11:38:01,006 - DEBUG - Q-vals = [0.23489945 0.02572916 0.43230256 0.00300844 0.00058643 0.10795728
 0.19551669], best_act=0, best_val=0.235
2025-01-16 11:38:01,006 - DEBUG - Low Q-value (0.235), using MCTS.
2025-01-16 11:38:01,012 - INFO - Episode 903/100000: Winner=2, Reward=-3.60, EPSILON=0.992, (W=902,D=1,L=0)
2025-01-16 11:38:01,175 - INFO - Episode 904/100000: Winner=2, Reward=8.05, EPSILON=0.992, (W=903,D=1,L=0)
2025-01-16 11:38:01,395 - INFO - Episode 905/100000: Winner=2, Reward=17.40, EPSILON=0.992, (W=904,D=1,L=0)
2025-01-16 11:38:01,512 - INFO - Episode 906/100000: Winner=2, Reward=10.05, EPSILON=0.992, (W=905,D=1,L=0)
2025-01-16 11:38:01,593 - INFO - Episode 907/100000: Winner=2, Reward=0.10, EPSILON=0.992, (W=906,D=1,L=0)
2025-01-16 11:38:01,728 - INFO - Episode 908/100000: Winner=2, Reward=3.00, EPSILON=0.992, (W=907,D=1,L=0)
2025-01-16 11:38:01,806 - INFO - Episode 909/100000: Winner=2, Reward=0.95, EPSILON=0.992, (W=908,D=1,L=0)
2025-01-16 11:38:01,977 - INFO - Episode 910/100000: Winner=2, Reward=-13.40, EPSILON=0.992, (W=909,D=1,L=0)
2025-01-16 11:38:02,100 - INFO - Episode 911/100000: Winner=2, Reward=2.10, EPSILON=0.992, (W=910,D=1,L=0)
2025-01-16 11:38:02,274 - INFO - Episode 912/100000: Winner=2, Reward=1.65, EPSILON=0.992, (W=911,D=1,L=0)
2025-01-16 11:38:02,337 - INFO - Episode 913/100000: Winner=2, Reward=7.95, EPSILON=0.992, (W=912,D=1,L=0)
2025-01-16 11:38:02,480 - INFO - Episode 914/100000: Winner=2, Reward=4.20, EPSILON=0.992, (W=913,D=1,L=0)
2025-01-16 11:38:02,697 - INFO - Episode 915/100000: Winner=2, Reward=-1.50, EPSILON=0.992, (W=914,D=1,L=0)
2025-01-16 11:38:02,835 - INFO - Episode 916/100000: Winner=2, Reward=1.50, EPSILON=0.992, (W=915,D=1,L=0)
2025-01-16 11:38:03,014 - INFO - Episode 917/100000: Winner=2, Reward=-7.00, EPSILON=0.992, (W=916,D=1,L=0)
2025-01-16 11:38:03,185 - INFO - Episode 918/100000: Winner=2, Reward=10.35, EPSILON=0.992, (W=917,D=1,L=0)
2025-01-16 11:38:03,466 - INFO - Episode 919/100000: Winner=2, Reward=-19.35, EPSILON=0.992, (W=918,D=1,L=0)
2025-01-16 11:38:03,578 - INFO - Episode 920/100000: Winner=2, Reward=-5.60, EPSILON=0.992, (W=919,D=1,L=0)
2025-01-16 11:38:03,741 - INFO - Episode 921/100000: Winner=2, Reward=-6.50, EPSILON=0.992, (W=920,D=1,L=0)
2025-01-16 11:38:03,937 - INFO - Episode 922/100000: Winner=2, Reward=8.70, EPSILON=0.992, (W=921,D=1,L=0)
2025-01-16 11:38:04,079 - INFO - Episode 923/100000: Winner=2, Reward=2.65, EPSILON=0.992, (W=922,D=1,L=0)
2025-01-16 11:38:04,313 - INFO - Episode 924/100000: Winner=2, Reward=7.95, EPSILON=0.992, (W=923,D=1,L=0)
2025-01-16 11:38:04,563 - INFO - Episode 925/100000: Winner=2, Reward=-7.35, EPSILON=0.992, (W=924,D=1,L=0)
2025-01-16 11:38:04,747 - INFO - Episode 926/100000: Winner=2, Reward=-0.35, EPSILON=0.992, (W=925,D=1,L=0)
2025-01-16 11:38:04,950 - INFO - Episode 927/100000: Winner=2, Reward=3.40, EPSILON=0.992, (W=926,D=1,L=0)
2025-01-16 11:38:05,076 - INFO - Episode 928/100000: Winner=2, Reward=10.95, EPSILON=0.992, (W=927,D=1,L=0)
2025-01-16 11:38:05,264 - INFO - Episode 929/100000: Winner=2, Reward=9.15, EPSILON=0.992, (W=928,D=1,L=0)
2025-01-16 11:38:05,413 - INFO - Episode 930/100000: Winner=2, Reward=9.15, EPSILON=0.992, (W=929,D=1,L=0)
2025-01-16 11:38:05,513 - INFO - Episode 931/100000: Winner=2, Reward=9.25, EPSILON=0.992, (W=930,D=1,L=0)
2025-01-16 11:38:05,584 - INFO - Episode 932/100000: Winner=2, Reward=-6.65, EPSILON=0.992, (W=931,D=1,L=0)
2025-01-16 11:38:05,744 - INFO - Episode 933/100000: Winner=2, Reward=43.85, EPSILON=0.992, (W=932,D=1,L=0)
2025-01-16 11:38:05,849 - INFO - Episode 934/100000: Winner=2, Reward=-1.55, EPSILON=0.992, (W=933,D=1,L=0)
2025-01-16 11:38:06,029 - INFO - Episode 935/100000: Winner=2, Reward=21.80, EPSILON=0.992, (W=934,D=1,L=0)
2025-01-16 11:38:06,356 - INFO - Episode 936/100000: Winner=2, Reward=-0.25, EPSILON=0.992, (W=935,D=1,L=0)
2025-01-16 11:38:06,543 - INFO - Episode 937/100000: Winner=2, Reward=-3.20, EPSILON=0.992, (W=936,D=1,L=0)
2025-01-16 11:38:06,699 - INFO - Episode 938/100000: Winner=2, Reward=21.25, EPSILON=0.992, (W=937,D=1,L=0)
2025-01-16 11:38:06,896 - INFO - Episode 939/100000: Winner=2, Reward=-0.50, EPSILON=0.992, (W=938,D=1,L=0)
2025-01-16 11:38:07,201 - INFO - Episode 940/100000: Winner=2, Reward=25.95, EPSILON=0.992, (W=939,D=1,L=0)
2025-01-16 11:38:07,404 - INFO - Episode 941/100000: Winner=2, Reward=6.05, EPSILON=0.992, (W=940,D=1,L=0)
2025-01-16 11:38:07,595 - INFO - Episode 942/100000: Winner=2, Reward=11.50, EPSILON=0.992, (W=941,D=1,L=0)
2025-01-16 11:38:07,714 - INFO - Episode 943/100000: Winner=2, Reward=8.95, EPSILON=0.992, (W=942,D=1,L=0)
2025-01-16 11:38:07,781 - INFO - Episode 944/100000: Winner=2, Reward=0.45, EPSILON=0.992, (W=943,D=1,L=0)
2025-01-16 11:38:07,880 - INFO - Episode 945/100000: Winner=2, Reward=0.15, EPSILON=0.992, (W=944,D=1,L=0)
2025-01-16 11:38:08,083 - INFO - Episode 946/100000: Winner=2, Reward=-6.00, EPSILON=0.992, (W=945,D=1,L=0)
2025-01-16 11:38:08,236 - INFO - Episode 947/100000: Winner=2, Reward=1.70, EPSILON=0.992, (W=946,D=1,L=0)
2025-01-16 11:38:08,402 - INFO - Episode 948/100000: Winner=2, Reward=17.00, EPSILON=0.992, (W=947,D=1,L=0)
2025-01-16 11:38:08,536 - INFO - Episode 949/100000: Winner=2, Reward=-4.45, EPSILON=0.991, (W=948,D=1,L=0)
2025-01-16 11:38:08,752 - INFO - Episode 950/100000: Winner=2, Reward=-19.35, EPSILON=0.991, (W=949,D=1,L=0)
2025-01-16 11:38:09,086 - INFO - Episode 951/100000: Winner=2, Reward=-17.05, EPSILON=0.991, (W=950,D=1,L=0)
2025-01-16 11:38:09,220 - INFO - Episode 952/100000: Winner=2, Reward=-2.25, EPSILON=0.991, (W=951,D=1,L=0)
2025-01-16 11:38:09,484 - INFO - Episode 953/100000: Winner=2, Reward=13.50, EPSILON=0.991, (W=952,D=1,L=0)
2025-01-16 11:38:09,685 - INFO - Episode 954/100000: Winner=2, Reward=28.15, EPSILON=0.991, (W=953,D=1,L=0)
2025-01-16 11:38:09,762 - INFO - Episode 955/100000: Winner=2, Reward=1.20, EPSILON=0.991, (W=954,D=1,L=0)
2025-01-16 11:38:09,967 - INFO - Episode 956/100000: Winner=2, Reward=-2.25, EPSILON=0.991, (W=955,D=1,L=0)
2025-01-16 11:38:10,185 - INFO - Episode 957/100000: Winner=2, Reward=17.20, EPSILON=0.991, (W=956,D=1,L=0)
2025-01-16 11:38:10,386 - INFO - Episode 958/100000: Winner=2, Reward=24.60, EPSILON=0.991, (W=957,D=1,L=0)
2025-01-16 11:38:10,563 - INFO - Episode 959/100000: Winner=2, Reward=8.50, EPSILON=0.991, (W=958,D=1,L=0)
2025-01-16 11:38:10,761 - INFO - Episode 960/100000: Winner=2, Reward=17.75, EPSILON=0.991, (W=959,D=1,L=0)
2025-01-16 11:38:10,884 - INFO - Episode 961/100000: Winner=2, Reward=6.95, EPSILON=0.991, (W=960,D=1,L=0)
2025-01-16 11:38:11,104 - INFO - Episode 962/100000: Winner=2, Reward=24.40, EPSILON=0.991, (W=961,D=1,L=0)
2025-01-16 11:38:11,194 - DEBUG - Q-vals = [0.06005483 0.09139505 0.00937704 0.09011636 0.67689514 0.03009038
 0.04207118], best_act=4, best_val=0.677
2025-01-16 11:38:11,194 - DEBUG - Low Q-value (0.677), using MCTS.
2025-01-16 11:38:11,195 - INFO - Running MCTS with 48 simulations using 6 processes.
2025-01-16 11:38:14,255 - DEBUG - Aggregated action counts: {1: 2, 0: 4}
2025-01-16 11:38:14,255 - DEBUG - Chose best action 0
2025-01-16 11:38:14,462 - INFO - Episode 963/100000: Winner=2, Reward=26.65, EPSILON=0.991, (W=962,D=1,L=0)
2025-01-16 11:38:14,684 - INFO - Episode 964/100000: Winner=2, Reward=16.20, EPSILON=0.991, (W=963,D=1,L=0)
2025-01-16 11:38:14,863 - INFO - Episode 965/100000: Winner=2, Reward=-1.00, EPSILON=0.991, (W=964,D=1,L=0)
2025-01-16 11:38:14,965 - INFO - Episode 966/100000: Winner=2, Reward=2.60, EPSILON=0.991, (W=965,D=1,L=0)
2025-01-16 11:38:15,189 - INFO - Episode 967/100000: Winner=2, Reward=1.55, EPSILON=0.991, (W=966,D=1,L=0)
2025-01-16 11:38:15,379 - INFO - Episode 968/100000: Winner=2, Reward=2.60, EPSILON=0.991, (W=967,D=1,L=0)
2025-01-16 11:38:15,593 - INFO - Episode 969/100000: Winner=2, Reward=32.60, EPSILON=0.991, (W=968,D=1,L=0)
2025-01-16 11:38:15,862 - INFO - Episode 970/100000: Winner=2, Reward=18.50, EPSILON=0.991, (W=969,D=1,L=0)
2025-01-16 11:38:16,031 - INFO - Episode 971/100000: Winner=2, Reward=-10.00, EPSILON=0.991, (W=970,D=1,L=0)
2025-01-16 11:38:16,181 - INFO - Episode 972/100000: Winner=2, Reward=-6.35, EPSILON=0.991, (W=971,D=1,L=0)
2025-01-16 11:38:16,282 - INFO - Episode 973/100000: Winner=2, Reward=3.20, EPSILON=0.991, (W=972,D=1,L=0)
2025-01-16 11:38:16,422 - INFO - Episode 974/100000: Winner=2, Reward=28.55, EPSILON=0.991, (W=973,D=1,L=0)
2025-01-16 11:38:16,537 - INFO - Episode 975/100000: Winner=2, Reward=0.65, EPSILON=0.991, (W=974,D=1,L=0)
2025-01-16 11:38:16,835 - INFO - Episode 976/100000: Winner=2, Reward=-12.25, EPSILON=0.991, (W=975,D=1,L=0)
2025-01-16 11:38:17,040 - INFO - Episode 977/100000: Winner=2, Reward=12.00, EPSILON=0.991, (W=976,D=1,L=0)
2025-01-16 11:38:17,199 - INFO - Episode 978/100000: Winner=2, Reward=16.45, EPSILON=0.991, (W=977,D=1,L=0)
2025-01-16 11:38:17,348 - INFO - Episode 979/100000: Winner=2, Reward=4.75, EPSILON=0.991, (W=978,D=1,L=0)
2025-01-16 11:38:17,613 - INFO - Episode 980/100000: Winner=2, Reward=-17.65, EPSILON=0.991, (W=979,D=1,L=0)
2025-01-16 11:38:17,831 - INFO - Episode 981/100000: Winner=2, Reward=9.95, EPSILON=0.991, (W=980,D=1,L=0)
2025-01-16 11:38:18,036 - INFO - Episode 982/100000: Winner=2, Reward=-7.90, EPSILON=0.991, (W=981,D=1,L=0)
2025-01-16 11:38:18,196 - INFO - Episode 983/100000: Winner=2, Reward=21.25, EPSILON=0.991, (W=982,D=1,L=0)
2025-01-16 11:38:18,382 - INFO - Episode 984/100000: Winner=2, Reward=9.90, EPSILON=0.991, (W=983,D=1,L=0)
2025-01-16 11:38:18,591 - INFO - Episode 985/100000: Winner=2, Reward=-11.75, EPSILON=0.991, (W=984,D=1,L=0)
2025-01-16 11:38:18,767 - INFO - Episode 986/100000: Winner=2, Reward=11.45, EPSILON=0.991, (W=985,D=1,L=0)
2025-01-16 11:38:18,953 - INFO - Episode 987/100000: Winner=2, Reward=-4.10, EPSILON=0.991, (W=986,D=1,L=0)
2025-01-16 11:38:19,105 - INFO - Episode 988/100000: Winner=2, Reward=21.95, EPSILON=0.991, (W=987,D=1,L=0)
2025-01-16 11:38:19,244 - INFO - Episode 989/100000: Winner=2, Reward=0.45, EPSILON=0.991, (W=988,D=1,L=0)
2025-01-16 11:38:19,433 - INFO - Episode 990/100000: Winner=2, Reward=-8.95, EPSILON=0.991, (W=989,D=1,L=0)
2025-01-16 11:38:19,642 - INFO - Episode 991/100000: Winner=2, Reward=-3.20, EPSILON=0.991, (W=990,D=1,L=0)
2025-01-16 11:38:19,989 - INFO - Episode 992/100000: Winner=2, Reward=-4.20, EPSILON=0.991, (W=991,D=1,L=0)
2025-01-16 11:38:20,176 - INFO - Episode 993/100000: Winner=2, Reward=-11.45, EPSILON=0.991, (W=992,D=1,L=0)
2025-01-16 11:38:20,485 - INFO - Episode 994/100000: Winner=2, Reward=-10.05, EPSILON=0.991, (W=993,D=1,L=0)
2025-01-16 11:38:20,721 - INFO - Episode 995/100000: Winner=2, Reward=16.40, EPSILON=0.991, (W=994,D=1,L=0)
2025-01-16 11:38:20,860 - DEBUG - Q-vals = [0.16160887 0.09816921 0.19525827 0.08791702 0.29232347 0.06799742
 0.0967257 ], best_act=4, best_val=0.292
2025-01-16 11:38:20,860 - DEBUG - Low Q-value (0.292), using MCTS.
2025-01-16 11:38:20,871 - INFO - Episode 996/100000: Winner=2, Reward=-7.45, EPSILON=0.991, (W=995,D=1,L=0)
2025-01-16 11:38:21,021 - DEBUG - Q-vals = [0.1228812  0.12004403 0.08734956 0.2046215  0.15033565 0.18182653
 0.13294153], best_act=3, best_val=0.205
2025-01-16 11:38:21,021 - DEBUG - Low Q-value (0.205), using MCTS.
2025-01-16 11:38:21,023 - INFO - Running MCTS with 49 simulations using 6 processes.
2025-01-16 11:38:24,337 - DEBUG - Aggregated action counts: {1: 1, 0: 3, 4: 1, 3: 1, 2: 1}
2025-01-16 11:38:24,337 - DEBUG - Chose best action 0
2025-01-16 11:38:24,408 - INFO - Episode 997/100000: Winner=2, Reward=-0.40, EPSILON=0.991, (W=996,D=1,L=0)
2025-01-16 11:38:24,541 - INFO - Episode 998/100000: Winner=2, Reward=-2.60, EPSILON=0.991, (W=997,D=1,L=0)
2025-01-16 11:38:24,805 - INFO - Episode 999/100000: Winner=2, Reward=-10.45, EPSILON=0.991, (W=998,D=1,L=0)
2025-01-16 11:38:25,097 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1000.
2025-01-16 11:38:25,097 - INFO - Models saved at episode 1000
2025-01-16 11:38:25,098 - INFO - Target networks updated
2025-01-16 11:38:25,159 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1000.
2025-01-16 11:38:25,159 - INFO - Episode 1000/100000: Winner=2, Reward=-9.90, EPSILON=0.991, (W=999,D=1,L=0)
2025-01-16 11:38:25,333 - INFO - Episode 1001/100000: Winner=2, Reward=30.25, EPSILON=0.991, (W=1000,D=1,L=0)
2025-01-16 11:38:25,671 - INFO - Episode 1002/100000: Winner=2, Reward=5.35, EPSILON=0.991, (W=1001,D=1,L=0)
2025-01-16 11:38:26,002 - INFO - Episode 1003/100000: Winner=2, Reward=10.85, EPSILON=0.991, (W=1002,D=1,L=0)
2025-01-16 11:38:26,240 - INFO - Episode 1004/100000: Winner=2, Reward=12.35, EPSILON=0.991, (W=1003,D=1,L=0)
2025-01-16 11:38:26,254 - DEBUG - Q-vals = [0.67324644 0.0511034  0.01104658 0.2289566  0.00935262 0.01985267
 0.00644171], best_act=0, best_val=0.673
2025-01-16 11:38:26,254 - DEBUG - Low Q-value (0.673), using MCTS.
2025-01-16 11:38:26,254 - INFO - Running MCTS with 50 simulations using 6 processes.
2025-01-16 11:38:29,273 - DEBUG - Aggregated action counts: {1: 1, 3: 3, 2: 1, 0: 2}
2025-01-16 11:38:29,273 - DEBUG - Chose best action 3
2025-01-16 11:38:29,387 - INFO - Episode 1005/100000: Winner=2, Reward=13.80, EPSILON=0.991, (W=1004,D=1,L=0)
2025-01-16 11:38:29,653 - INFO - Episode 1006/100000: Winner=2, Reward=25.05, EPSILON=0.991, (W=1005,D=1,L=0)
2025-01-16 11:38:29,793 - INFO - Episode 1007/100000: Winner=2, Reward=-2.90, EPSILON=0.991, (W=1006,D=1,L=0)
2025-01-16 11:38:30,011 - INFO - Episode 1008/100000: Winner=2, Reward=-7.50, EPSILON=0.991, (W=1007,D=1,L=0)
2025-01-16 11:38:30,209 - INFO - Episode 1009/100000: Winner=2, Reward=8.25, EPSILON=0.991, (W=1008,D=1,L=0)
2025-01-16 11:38:30,365 - INFO - Episode 1010/100000: Winner=2, Reward=4.80, EPSILON=0.991, (W=1009,D=1,L=0)
2025-01-16 11:38:30,450 - INFO - Episode 1011/100000: Winner=2, Reward=9.90, EPSILON=0.991, (W=1010,D=1,L=0)
2025-01-16 11:38:30,644 - INFO - Episode 1012/100000: Winner=2, Reward=-4.55, EPSILON=0.991, (W=1011,D=1,L=0)
2025-01-16 11:38:30,937 - INFO - Episode 1013/100000: Winner=2, Reward=-25.75, EPSILON=0.991, (W=1012,D=1,L=0)
2025-01-16 11:38:30,969 - DEBUG - Q-vals = [0.32515785 0.04149013 0.33661717 0.14906017 0.00189841 0.0941189
 0.05165727], best_act=2, best_val=0.337
2025-01-16 11:38:30,969 - DEBUG - Low Q-value (0.337), using MCTS.
2025-01-16 11:38:30,969 - INFO - Running MCTS with 50 simulations using 6 processes.
2025-01-16 11:38:33,952 - DEBUG - Aggregated action counts: {0: 3, 4: 2, 1: 2}
2025-01-16 11:38:33,952 - DEBUG - Chose best action 0
2025-01-16 11:38:34,231 - INFO - Episode 1014/100000: Winner=2, Reward=-15.65, EPSILON=0.991, (W=1013,D=1,L=0)
2025-01-16 11:38:34,446 - INFO - Episode 1015/100000: Winner=2, Reward=-12.45, EPSILON=0.991, (W=1014,D=1,L=0)
2025-01-16 11:38:34,700 - INFO - Episode 1016/100000: Winner=2, Reward=-5.60, EPSILON=0.991, (W=1015,D=1,L=0)
2025-01-16 11:38:34,762 - DEBUG - Q-vals = [0.12393563 0.15295458 0.4013026  0.15949629 0.0308132  0.07728567
 0.05421208], best_act=2, best_val=0.401
2025-01-16 11:38:34,762 - DEBUG - Low Q-value (0.401), using MCTS.
2025-01-16 11:38:34,762 - INFO - Running MCTS with 50 simulations using 6 processes.
2025-01-16 11:38:37,466 - DEBUG - Aggregated action counts: {0: 6, 3: 1}
2025-01-16 11:38:37,466 - DEBUG - Chose best action 0
2025-01-16 11:38:37,481 - INFO - Episode 1017/100000: Winner=2, Reward=8.10, EPSILON=0.991, (W=1016,D=1,L=0)
2025-01-16 11:38:37,622 - INFO - Episode 1018/100000: Winner=2, Reward=-8.15, EPSILON=0.991, (W=1017,D=1,L=0)
2025-01-16 11:38:37,778 - INFO - Episode 1019/100000: Winner=2, Reward=30.80, EPSILON=0.991, (W=1018,D=1,L=0)
2025-01-16 11:38:37,919 - DEBUG - Q-vals = [0.00667041 0.61568743 0.00512734 0.03651379 0.22473869 0.00541468
 0.10584768], best_act=1, best_val=0.616
2025-01-16 11:38:37,919 - DEBUG - Low Q-value (0.616), using MCTS.
2025-01-16 11:38:37,934 - INFO - Episode 1020/100000: Winner=2, Reward=2.70, EPSILON=0.991, (W=1019,D=1,L=0)
2025-01-16 11:38:38,068 - INFO - Episode 1021/100000: Winner=2, Reward=-4.30, EPSILON=0.991, (W=1020,D=1,L=0)
2025-01-16 11:38:38,289 - INFO - Episode 1022/100000: Winner=2, Reward=-7.75, EPSILON=0.991, (W=1021,D=1,L=0)
2025-01-16 11:38:38,512 - INFO - Episode 1023/100000: Winner=2, Reward=22.40, EPSILON=0.991, (W=1022,D=1,L=0)
2025-01-16 11:38:38,620 - INFO - Episode 1024/100000: Winner=2, Reward=8.20, EPSILON=0.991, (W=1023,D=1,L=0)
2025-01-16 11:38:38,853 - INFO - Episode 1025/100000: Winner=2, Reward=3.40, EPSILON=0.991, (W=1024,D=1,L=0)
2025-01-16 11:38:38,970 - INFO - Episode 1026/100000: Winner=2, Reward=-6.10, EPSILON=0.991, (W=1025,D=1,L=0)
2025-01-16 11:38:39,170 - INFO - Episode 1027/100000: Winner=2, Reward=11.35, EPSILON=0.991, (W=1026,D=1,L=0)
2025-01-16 11:38:39,301 - INFO - Episode 1028/100000: Winner=2, Reward=30.60, EPSILON=0.991, (W=1027,D=1,L=0)
2025-01-16 11:38:39,533 - INFO - Episode 1029/100000: Winner=2, Reward=30.70, EPSILON=0.991, (W=1028,D=1,L=0)
2025-01-16 11:38:39,668 - INFO - Episode 1030/100000: Winner=2, Reward=10.05, EPSILON=0.991, (W=1029,D=1,L=0)
2025-01-16 11:38:39,975 - INFO - Episode 1031/100000: Winner=2, Reward=-9.20, EPSILON=0.991, (W=1030,D=1,L=0)
2025-01-16 11:38:40,067 - INFO - Episode 1032/100000: Winner=2, Reward=16.15, EPSILON=0.991, (W=1031,D=1,L=0)
2025-01-16 11:38:40,332 - INFO - Episode 1033/100000: Winner=2, Reward=3.35, EPSILON=0.991, (W=1032,D=1,L=0)
2025-01-16 11:38:40,442 - INFO - Episode 1034/100000: Winner=2, Reward=-4.30, EPSILON=0.991, (W=1033,D=1,L=0)
2025-01-16 11:38:40,582 - INFO - Episode 1035/100000: Winner=2, Reward=0.60, EPSILON=0.991, (W=1034,D=1,L=0)
2025-01-16 11:38:40,729 - INFO - Episode 1036/100000: Winner=2, Reward=-8.10, EPSILON=0.991, (W=1035,D=1,L=0)
2025-01-16 11:38:40,839 - INFO - Episode 1037/100000: Winner=2, Reward=-4.10, EPSILON=0.991, (W=1036,D=1,L=0)
2025-01-16 11:38:41,073 - INFO - Episode 1038/100000: Winner=2, Reward=8.80, EPSILON=0.991, (W=1037,D=1,L=0)
2025-01-16 11:38:41,237 - INFO - Episode 1039/100000: Winner=2, Reward=0.40, EPSILON=0.991, (W=1038,D=1,L=0)
2025-01-16 11:38:41,321 - INFO - Episode 1040/100000: Winner=2, Reward=-5.90, EPSILON=0.991, (W=1039,D=1,L=0)
2025-01-16 11:38:41,634 - INFO - Episode 1041/100000: Winner=2, Reward=-26.70, EPSILON=0.991, (W=1040,D=1,L=0)
2025-01-16 11:38:41,805 - INFO - Episode 1042/100000: Winner=2, Reward=-2.15, EPSILON=0.991, (W=1041,D=1,L=0)
2025-01-16 11:38:42,021 - INFO - Episode 1043/100000: Winner=2, Reward=39.20, EPSILON=0.991, (W=1042,D=1,L=0)
2025-01-16 11:38:42,224 - INFO - Episode 1044/100000: Winner=2, Reward=-0.15, EPSILON=0.991, (W=1043,D=1,L=0)
2025-01-16 11:38:42,505 - INFO - Episode 1045/100000: Winner=2, Reward=23.25, EPSILON=0.991, (W=1044,D=1,L=0)
2025-01-16 11:38:42,721 - INFO - Episode 1046/100000: Winner=2, Reward=4.35, EPSILON=0.991, (W=1045,D=1,L=0)
2025-01-16 11:38:42,926 - INFO - Episode 1047/100000: Winner=2, Reward=1.70, EPSILON=0.991, (W=1046,D=1,L=0)
2025-01-16 11:38:43,183 - INFO - Episode 1048/100000: Winner=2, Reward=10.75, EPSILON=0.991, (W=1047,D=1,L=0)
2025-01-16 11:38:43,270 - INFO - Episode 1049/100000: Winner=2, Reward=1.15, EPSILON=0.991, (W=1048,D=1,L=0)
2025-01-16 11:38:43,403 - INFO - Episode 1050/100000: Winner=2, Reward=3.95, EPSILON=0.991, (W=1049,D=1,L=0)
2025-01-16 11:38:43,686 - INFO - Episode 1051/100000: Winner=2, Reward=-5.70, EPSILON=0.991, (W=1050,D=1,L=0)
2025-01-16 11:38:43,866 - INFO - Episode 1052/100000: Winner=2, Reward=6.70, EPSILON=0.991, (W=1051,D=1,L=0)
2025-01-16 11:38:43,929 - INFO - Episode 1053/100000: Winner=2, Reward=7.95, EPSILON=0.991, (W=1052,D=1,L=0)
2025-01-16 11:38:43,944 - DEBUG - Q-vals = [0.43769684 0.10575852 0.06375071 0.28197968 0.01643513 0.07694925
 0.01742987], best_act=0, best_val=0.438
2025-01-16 11:38:43,944 - DEBUG - Low Q-value (0.438), using MCTS.
2025-01-16 11:38:43,944 - INFO - Running MCTS with 52 simulations using 6 processes.
2025-01-16 11:38:46,631 - DEBUG - Aggregated action counts: {0: 6, 2: 1}
2025-01-16 11:38:46,631 - DEBUG - Chose best action 0
2025-01-16 11:38:46,724 - INFO - Episode 1054/100000: Winner=2, Reward=16.20, EPSILON=0.991, (W=1053,D=1,L=0)
2025-01-16 11:38:46,948 - INFO - Episode 1055/100000: Winner=2, Reward=5.60, EPSILON=0.991, (W=1054,D=1,L=0)
2025-01-16 11:38:47,198 - INFO - Episode 1056/100000: Winner=2, Reward=33.60, EPSILON=0.991, (W=1055,D=1,L=0)
2025-01-16 11:38:47,421 - INFO - Episode 1057/100000: Winner=2, Reward=8.35, EPSILON=0.991, (W=1056,D=1,L=0)
2025-01-16 11:38:47,634 - INFO - Episode 1058/100000: Winner=2, Reward=20.15, EPSILON=0.991, (W=1057,D=1,L=0)
2025-01-16 11:38:47,856 - INFO - Episode 1059/100000: Winner=2, Reward=1.65, EPSILON=0.991, (W=1058,D=1,L=0)
2025-01-16 11:38:47,997 - INFO - Episode 1060/100000: Winner=2, Reward=-8.65, EPSILON=0.991, (W=1059,D=1,L=0)
2025-01-16 11:38:48,236 - INFO - Episode 1061/100000: Winner=2, Reward=9.00, EPSILON=0.990, (W=1060,D=1,L=0)
2025-01-16 11:38:48,346 - INFO - Episode 1062/100000: Winner=2, Reward=1.10, EPSILON=0.990, (W=1061,D=1,L=0)
2025-01-16 11:38:48,423 - INFO - Episode 1063/100000: Winner=2, Reward=15.60, EPSILON=0.990, (W=1062,D=1,L=0)
2025-01-16 11:38:48,634 - INFO - Episode 1064/100000: Winner=2, Reward=16.35, EPSILON=0.990, (W=1063,D=1,L=0)
2025-01-16 11:38:48,881 - INFO - Episode 1065/100000: Winner=2, Reward=15.35, EPSILON=0.990, (W=1064,D=1,L=0)
2025-01-16 11:38:49,162 - INFO - Episode 1066/100000: Winner=2, Reward=24.70, EPSILON=0.990, (W=1065,D=1,L=0)
2025-01-16 11:38:49,241 - INFO - Episode 1067/100000: Winner=2, Reward=2.40, EPSILON=0.990, (W=1066,D=1,L=0)
2025-01-16 11:38:49,439 - DEBUG - Q-vals = [0.0514539  0.6543789  0.06200728 0.00234506 0.00916999 0.00503302
 0.21561188], best_act=1, best_val=0.654
2025-01-16 11:38:49,439 - DEBUG - Low Q-value (0.654), using MCTS.
2025-01-16 11:38:49,439 - INFO - Episode 1068/100000: Winner=2, Reward=-9.70, EPSILON=0.990, (W=1067,D=1,L=0)
2025-01-16 11:38:49,689 - INFO - Episode 1069/100000: Winner=2, Reward=11.90, EPSILON=0.990, (W=1068,D=1,L=0)
2025-01-16 11:38:49,798 - INFO - Episode 1070/100000: Winner=2, Reward=-6.25, EPSILON=0.990, (W=1069,D=1,L=0)
2025-01-16 11:38:50,040 - INFO - Episode 1071/100000: Winner=2, Reward=-14.75, EPSILON=0.990, (W=1070,D=1,L=0)
2025-01-16 11:38:50,165 - INFO - Episode 1072/100000: Winner=2, Reward=-5.70, EPSILON=0.990, (W=1071,D=1,L=0)
2025-01-16 11:38:50,405 - INFO - Episode 1073/100000: Winner=2, Reward=46.35, EPSILON=0.990, (W=1072,D=1,L=0)
2025-01-16 11:38:50,593 - INFO - Episode 1074/100000: Winner=2, Reward=8.40, EPSILON=0.990, (W=1073,D=1,L=0)
2025-01-16 11:38:50,833 - INFO - Episode 1075/100000: Winner=2, Reward=14.00, EPSILON=0.990, (W=1074,D=1,L=0)
2025-01-16 11:38:51,018 - INFO - Episode 1076/100000: Winner=2, Reward=15.85, EPSILON=0.990, (W=1075,D=1,L=0)
2025-01-16 11:38:51,101 - INFO - Episode 1077/100000: Winner=2, Reward=8.00, EPSILON=0.990, (W=1076,D=1,L=0)
2025-01-16 11:38:51,217 - INFO - Episode 1078/100000: Winner=2, Reward=-4.75, EPSILON=0.990, (W=1077,D=1,L=0)
2025-01-16 11:38:51,389 - INFO - Episode 1079/100000: Winner=2, Reward=-5.55, EPSILON=0.990, (W=1078,D=1,L=0)
2025-01-16 11:38:51,527 - INFO - Episode 1080/100000: Winner=2, Reward=-2.65, EPSILON=0.990, (W=1079,D=1,L=0)
2025-01-16 11:38:51,767 - INFO - Episode 1081/100000: Winner=2, Reward=-17.70, EPSILON=0.990, (W=1080,D=1,L=0)
2025-01-16 11:38:51,923 - INFO - Episode 1082/100000: Winner=2, Reward=11.65, EPSILON=0.990, (W=1081,D=1,L=0)
2025-01-16 11:38:52,095 - INFO - Episode 1083/100000: Winner=2, Reward=-7.45, EPSILON=0.990, (W=1082,D=1,L=0)
2025-01-16 11:38:52,304 - INFO - Episode 1084/100000: Winner=2, Reward=9.80, EPSILON=0.990, (W=1083,D=1,L=0)
2025-01-16 11:38:52,554 - INFO - Episode 1085/100000: Winner=2, Reward=-7.15, EPSILON=0.990, (W=1084,D=1,L=0)
2025-01-16 11:38:52,767 - INFO - Episode 1086/100000: Winner=2, Reward=-1.75, EPSILON=0.990, (W=1085,D=1,L=0)
2025-01-16 11:38:52,850 - INFO - Episode 1087/100000: Winner=2, Reward=1.60, EPSILON=0.990, (W=1086,D=1,L=0)
2025-01-16 11:38:52,984 - INFO - Episode 1088/100000: Winner=2, Reward=-7.10, EPSILON=0.990, (W=1087,D=1,L=0)
2025-01-16 11:38:53,177 - INFO - Episode 1089/100000: Winner=2, Reward=-7.85, EPSILON=0.990, (W=1088,D=1,L=0)
2025-01-16 11:38:53,331 - INFO - Episode 1090/100000: Winner=2, Reward=16.15, EPSILON=0.990, (W=1089,D=1,L=0)
2025-01-16 11:38:53,573 - INFO - Episode 1091/100000: Winner=2, Reward=7.45, EPSILON=0.990, (W=1090,D=1,L=0)
2025-01-16 11:38:53,770 - INFO - Episode 1092/100000: Winner=2, Reward=9.40, EPSILON=0.990, (W=1091,D=1,L=0)
2025-01-16 11:38:53,895 - DEBUG - Q-vals = [4.9100187e-02 1.8929763e-03 1.6483655e-02 9.2062199e-01 9.1486861e-04
 3.9363169e-04 1.0592646e-02], best_act=3, best_val=0.921
2025-01-16 11:38:53,895 - DEBUG - Low Q-value (0.921), using MCTS.
2025-01-16 11:38:53,895 - INFO - Running MCTS with 53 simulations using 6 processes.
2025-01-16 11:38:56,794 - DEBUG - Aggregated action counts: {0: 3, 1: 2, 2: 2}
2025-01-16 11:38:56,794 - DEBUG - Chose best action 0
2025-01-16 11:38:56,908 - INFO - Episode 1093/100000: Winner=2, Reward=12.50, EPSILON=0.990, (W=1092,D=1,L=0)
2025-01-16 11:38:57,192 - INFO - Episode 1094/100000: Winner=2, Reward=8.05, EPSILON=0.990, (W=1093,D=1,L=0)
2025-01-16 11:38:57,575 - INFO - Episode 1095/100000: Winner=2, Reward=-17.50, EPSILON=0.990, (W=1094,D=1,L=0)
2025-01-16 11:38:57,756 - INFO - Episode 1096/100000: Winner=2, Reward=13.65, EPSILON=0.990, (W=1095,D=1,L=0)
2025-01-16 11:38:57,924 - DEBUG - Q-vals = [3.7813646e-01 6.0551980e-04 2.2979369e-04 1.4066827e-03 1.3917012e-02
 5.1848137e-01 8.7223142e-02], best_act=5, best_val=0.518
2025-01-16 11:38:57,924 - DEBUG - Low Q-value (0.518), using MCTS.
2025-01-16 11:38:57,924 - INFO - Running MCTS with 53 simulations using 6 processes.
2025-01-16 11:39:00,863 - DEBUG - Aggregated action counts: {0: 4, 2: 1, 6: 1, 5: 1}
2025-01-16 11:39:00,864 - DEBUG - Chose best action 0
2025-01-16 11:39:01,085 - INFO - Episode 1097/100000: Winner=2, Reward=3.05, EPSILON=0.990, (W=1096,D=1,L=0)
2025-01-16 11:39:01,258 - INFO - Episode 1098/100000: Winner=2, Reward=14.65, EPSILON=0.990, (W=1097,D=1,L=0)
2025-01-16 11:39:01,275 - DEBUG - Q-vals = [9.7552466e-01 6.7665149e-03 8.7434864e-03 7.0707048e-03 4.4315137e-04
 1.0684150e-03 3.8295053e-04], best_act=0, best_val=0.976
2025-01-16 11:39:01,275 - DEBUG - Low Q-value (0.976), using MCTS.
2025-01-16 11:39:01,275 - INFO - Running MCTS with 53 simulations using 6 processes.
2025-01-16 11:39:04,192 - DEBUG - Aggregated action counts: {0: 5, 3: 1, 2: 1}
2025-01-16 11:39:04,192 - DEBUG - Chose best action 0
2025-01-16 11:39:04,542 - INFO - Episode 1099/100000: Winner=2, Reward=-30.20, EPSILON=0.990, (W=1098,D=1,L=0)
2025-01-16 11:39:04,792 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1100.
2025-01-16 11:39:04,792 - INFO - Models saved at episode 1100
2025-01-16 11:39:04,792 - INFO - Target networks updated
2025-01-16 11:39:04,858 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1100.
2025-01-16 11:39:04,858 - INFO - Episode 1100/100000: Winner=2, Reward=33.00, EPSILON=0.990, (W=1099,D=1,L=0)
2025-01-16 11:39:05,176 - INFO - Episode 1101/100000: Winner=2, Reward=-4.30, EPSILON=0.990, (W=1100,D=1,L=0)
2025-01-16 11:39:05,475 - INFO - Episode 1102/100000: Winner=2, Reward=-15.25, EPSILON=0.990, (W=1101,D=1,L=0)
2025-01-16 11:39:05,593 - DEBUG - Q-vals = [0.11162663 0.19130722 0.23982581 0.12084895 0.07046644 0.1203039
 0.14562106], best_act=2, best_val=0.240
2025-01-16 11:39:05,593 - DEBUG - Low Q-value (0.240), using MCTS.
2025-01-16 11:39:05,594 - INFO - Running MCTS with 54 simulations using 6 processes.
2025-01-16 11:39:08,462 - DEBUG - Aggregated action counts: {0: 2, 3: 1, 5: 1, 1: 1, 4: 1}
2025-01-16 11:39:08,462 - DEBUG - Chose best action 0
2025-01-16 11:39:08,646 - INFO - Episode 1103/100000: Winner=2, Reward=6.15, EPSILON=0.990, (W=1102,D=1,L=0)
2025-01-16 11:39:08,864 - INFO - Episode 1104/100000: Winner=2, Reward=-11.60, EPSILON=0.990, (W=1103,D=1,L=0)
2025-01-16 11:39:09,023 - INFO - Episode 1105/100000: Winner=2, Reward=-6.60, EPSILON=0.990, (W=1104,D=1,L=0)
2025-01-16 11:39:09,187 - INFO - Episode 1106/100000: Winner=2, Reward=17.10, EPSILON=0.990, (W=1105,D=1,L=0)
2025-01-16 11:39:09,347 - INFO - Episode 1107/100000: Winner=2, Reward=-2.75, EPSILON=0.990, (W=1106,D=1,L=0)
2025-01-16 11:39:09,565 - INFO - Episode 1108/100000: Winner=2, Reward=-4.30, EPSILON=0.990, (W=1107,D=1,L=0)
2025-01-16 11:39:09,848 - INFO - Episode 1109/100000: Winner=2, Reward=42.45, EPSILON=0.990, (W=1108,D=1,L=0)
2025-01-16 11:39:09,977 - DEBUG - Q-vals = [0.08099236 0.06973659 0.03341056 0.08056097 0.62473965 0.02174419
 0.08881573], best_act=4, best_val=0.625
2025-01-16 11:39:09,977 - DEBUG - Low Q-value (0.625), using MCTS.
2025-01-16 11:39:09,978 - INFO - Running MCTS with 54 simulations using 6 processes.
2025-01-16 11:39:13,110 - DEBUG - Aggregated action counts: {3: 1, 0: 5}
2025-01-16 11:39:13,110 - DEBUG - Chose best action 0
2025-01-16 11:39:13,182 - INFO - Episode 1110/100000: Winner=2, Reward=12.15, EPSILON=0.990, (W=1109,D=1,L=0)
2025-01-16 11:39:13,427 - INFO - Episode 1111/100000: Winner=2, Reward=5.15, EPSILON=0.990, (W=1110,D=1,L=0)
2025-01-16 11:39:13,617 - INFO - Episode 1112/100000: Winner=2, Reward=-4.35, EPSILON=0.990, (W=1111,D=1,L=0)
2025-01-16 11:39:13,796 - INFO - Episode 1113/100000: Winner=2, Reward=16.55, EPSILON=0.990, (W=1112,D=1,L=0)
2025-01-16 11:39:13,962 - INFO - Episode 1114/100000: Winner=2, Reward=7.50, EPSILON=0.990, (W=1113,D=1,L=0)
2025-01-16 11:39:14,150 - INFO - Episode 1115/100000: Winner=2, Reward=-0.75, EPSILON=0.990, (W=1114,D=1,L=0)
2025-01-16 11:39:14,280 - INFO - Episode 1116/100000: Winner=2, Reward=-4.70, EPSILON=0.990, (W=1115,D=1,L=0)
2025-01-16 11:39:14,527 - INFO - Episode 1117/100000: Winner=2, Reward=10.45, EPSILON=0.990, (W=1116,D=1,L=0)
2025-01-16 11:39:14,737 - INFO - Episode 1118/100000: Winner=2, Reward=7.30, EPSILON=0.990, (W=1117,D=1,L=0)
2025-01-16 11:39:14,935 - INFO - Episode 1119/100000: Winner=2, Reward=35.45, EPSILON=0.990, (W=1118,D=1,L=0)
2025-01-16 11:39:15,123 - INFO - Episode 1120/100000: Winner=2, Reward=5.80, EPSILON=0.990, (W=1119,D=1,L=0)
2025-01-16 11:39:15,257 - INFO - Episode 1121/100000: Winner=2, Reward=0.85, EPSILON=0.990, (W=1120,D=1,L=0)
2025-01-16 11:39:15,426 - INFO - Episode 1122/100000: Winner=2, Reward=-5.60, EPSILON=0.990, (W=1121,D=1,L=0)
2025-01-16 11:39:15,752 - INFO - Episode 1123/100000: Winner=2, Reward=10.25, EPSILON=0.990, (W=1122,D=1,L=0)
2025-01-16 11:39:15,787 - DEBUG - Q-vals = [0.36532187 0.29266334 0.12562828 0.10279701 0.02435141 0.0392001
 0.05003795], best_act=0, best_val=0.365
2025-01-16 11:39:15,787 - DEBUG - Low Q-value (0.365), using MCTS.
2025-01-16 11:39:15,787 - INFO - Running MCTS with 54 simulations using 6 processes.
2025-01-16 11:39:19,283 - DEBUG - Aggregated action counts: {0: 6}
2025-01-16 11:39:19,283 - DEBUG - Chose best action 0
2025-01-16 11:39:19,492 - INFO - Episode 1124/100000: Winner=2, Reward=16.25, EPSILON=0.990, (W=1123,D=1,L=0)
2025-01-16 11:39:19,630 - INFO - Episode 1125/100000: Winner=2, Reward=0.65, EPSILON=0.990, (W=1124,D=1,L=0)
2025-01-16 11:39:19,882 - INFO - Episode 1126/100000: Winner=2, Reward=-2.45, EPSILON=0.990, (W=1125,D=1,L=0)
2025-01-16 11:39:20,146 - INFO - Episode 1127/100000: Winner=2, Reward=-10.35, EPSILON=0.990, (W=1126,D=1,L=0)
2025-01-16 11:39:20,315 - INFO - Episode 1128/100000: Winner=2, Reward=-4.00, EPSILON=0.990, (W=1127,D=1,L=0)
2025-01-16 11:39:20,492 - INFO - Episode 1129/100000: Winner=2, Reward=17.45, EPSILON=0.990, (W=1128,D=1,L=0)
2025-01-16 11:39:20,844 - INFO - Episode 1130/100000: Winner=2, Reward=5.10, EPSILON=0.990, (W=1129,D=1,L=0)
2025-01-16 11:39:20,984 - INFO - Episode 1131/100000: Winner=2, Reward=0.95, EPSILON=0.990, (W=1130,D=1,L=0)
2025-01-16 11:39:21,089 - INFO - Episode 1132/100000: Winner=2, Reward=8.80, EPSILON=0.990, (W=1131,D=1,L=0)
2025-01-16 11:39:21,277 - INFO - Episode 1133/100000: Winner=2, Reward=-6.10, EPSILON=0.990, (W=1132,D=1,L=0)
2025-01-16 11:39:21,647 - INFO - Episode 1134/100000: Winner=2, Reward=-27.35, EPSILON=0.990, (W=1133,D=1,L=0)
2025-01-16 11:39:21,815 - INFO - Episode 1135/100000: Winner=2, Reward=3.80, EPSILON=0.990, (W=1134,D=1,L=0)
2025-01-16 11:39:22,071 - INFO - Episode 1136/100000: Winner=2, Reward=38.10, EPSILON=0.990, (W=1135,D=1,L=0)
2025-01-16 11:39:22,343 - INFO - Episode 1137/100000: Winner=2, Reward=-8.25, EPSILON=0.990, (W=1136,D=1,L=0)
2025-01-16 11:39:22,532 - INFO - Episode 1138/100000: Winner=2, Reward=-9.05, EPSILON=0.990, (W=1137,D=1,L=0)
2025-01-16 11:39:22,656 - INFO - Episode 1139/100000: Winner=2, Reward=10.75, EPSILON=0.990, (W=1138,D=1,L=0)
2025-01-16 11:39:22,741 - INFO - Episode 1140/100000: Winner=2, Reward=1.40, EPSILON=0.990, (W=1139,D=1,L=0)
2025-01-16 11:39:22,993 - INFO - Episode 1141/100000: Winner=2, Reward=52.85, EPSILON=0.990, (W=1140,D=1,L=0)
2025-01-16 11:39:23,114 - INFO - Episode 1142/100000: Winner=2, Reward=8.20, EPSILON=0.990, (W=1141,D=1,L=0)
2025-01-16 11:39:23,223 - INFO - Episode 1143/100000: Winner=2, Reward=1.10, EPSILON=0.990, (W=1142,D=1,L=0)
2025-01-16 11:39:23,412 - INFO - Episode 1144/100000: Winner=2, Reward=7.00, EPSILON=0.990, (W=1143,D=1,L=0)
2025-01-16 11:39:23,640 - INFO - Episode 1145/100000: Winner=2, Reward=-13.60, EPSILON=0.990, (W=1144,D=1,L=0)
2025-01-16 11:39:23,730 - DEBUG - Q-vals = [5.7607204e-01 4.3317292e-02 1.6986322e-01 7.5869611e-03 7.9774715e-08
 3.0796576e-02 1.7236386e-01], best_act=0, best_val=0.576
2025-01-16 11:39:23,731 - DEBUG - Low Q-value (0.576), using MCTS.
2025-01-16 11:39:23,732 - INFO - Running MCTS with 55 simulations using 6 processes.
2025-01-16 11:39:27,131 - DEBUG - Aggregated action counts: {0: 5, 3: 1, 2: 1}
2025-01-16 11:39:27,131 - DEBUG - Chose best action 0
2025-01-16 11:39:27,241 - INFO - Episode 1146/100000: Winner=2, Reward=23.75, EPSILON=0.990, (W=1145,D=1,L=0)
2025-01-16 11:39:27,374 - INFO - Episode 1147/100000: Winner=2, Reward=-8.65, EPSILON=0.990, (W=1146,D=1,L=0)
2025-01-16 11:39:27,671 - INFO - Episode 1148/100000: Winner=2, Reward=-7.25, EPSILON=0.990, (W=1147,D=1,L=0)
2025-01-16 11:39:27,810 - DEBUG - Q-vals = [0.07554121 0.09288024 0.13896355 0.35685608 0.00946877 0.17567207
 0.1506181 ], best_act=3, best_val=0.357
2025-01-16 11:39:27,810 - DEBUG - Low Q-value (0.357), using MCTS.
2025-01-16 11:39:27,825 - INFO - Episode 1149/100000: Winner=2, Reward=-6.65, EPSILON=0.990, (W=1148,D=1,L=0)
2025-01-16 11:39:28,006 - INFO - Episode 1150/100000: Winner=2, Reward=13.05, EPSILON=0.990, (W=1149,D=1,L=0)
2025-01-16 11:39:28,166 - INFO - Episode 1151/100000: Winner=2, Reward=12.95, EPSILON=0.990, (W=1150,D=1,L=0)
2025-01-16 11:39:28,556 - INFO - Episode 1152/100000: Winner=2, Reward=-12.00, EPSILON=0.990, (W=1151,D=1,L=0)
2025-01-16 11:39:28,700 - INFO - Episode 1153/100000: Winner=2, Reward=18.50, EPSILON=0.990, (W=1152,D=1,L=0)
2025-01-16 11:39:28,892 - INFO - Episode 1154/100000: Winner=2, Reward=4.05, EPSILON=0.990, (W=1153,D=1,L=0)
2025-01-16 11:39:28,945 - INFO - Episode 1155/100000: Winner=2, Reward=15.75, EPSILON=0.990, (W=1154,D=1,L=0)
2025-01-16 11:39:28,986 - DEBUG - Q-vals = [0.09246642 0.10246486 0.02382501 0.13319989 0.22896661 0.36763644
 0.05144078], best_act=5, best_val=0.368
2025-01-16 11:39:28,986 - DEBUG - Low Q-value (0.368), using MCTS.
2025-01-16 11:39:28,986 - INFO - Running MCTS with 56 simulations using 6 processes.
2025-01-16 11:39:32,393 - DEBUG - Aggregated action counts: {4: 1, 1: 1, 0: 3, 2: 1, 6: 1}
2025-01-16 11:39:32,393 - DEBUG - Chose best action 0
2025-01-16 11:39:32,662 - INFO - Episode 1156/100000: Winner=2, Reward=-10.00, EPSILON=0.990, (W=1155,D=1,L=0)
2025-01-16 11:39:32,910 - INFO - Episode 1157/100000: Winner=2, Reward=-6.75, EPSILON=0.990, (W=1156,D=1,L=0)
2025-01-16 11:39:33,112 - INFO - Episode 1158/100000: Winner=2, Reward=-16.15, EPSILON=0.990, (W=1157,D=1,L=0)
2025-01-16 11:39:33,311 - INFO - Episode 1159/100000: Winner=2, Reward=42.90, EPSILON=0.990, (W=1158,D=1,L=0)
2025-01-16 11:39:33,533 - INFO - Episode 1160/100000: Winner=2, Reward=10.00, EPSILON=0.990, (W=1159,D=1,L=0)
2025-01-16 11:39:33,785 - INFO - Episode 1161/100000: Winner=2, Reward=-2.40, EPSILON=0.990, (W=1160,D=1,L=0)
2025-01-16 11:39:33,982 - INFO - Episode 1162/100000: Winner=2, Reward=16.95, EPSILON=0.990, (W=1161,D=1,L=0)
2025-01-16 11:39:34,129 - INFO - Episode 1163/100000: Winner=2, Reward=-5.20, EPSILON=0.990, (W=1162,D=1,L=0)
2025-01-16 11:39:34,384 - INFO - Episode 1164/100000: Winner=2, Reward=-13.65, EPSILON=0.990, (W=1163,D=1,L=0)
2025-01-16 11:39:34,685 - INFO - Episode 1165/100000: Winner=2, Reward=-15.65, EPSILON=0.990, (W=1164,D=1,L=0)
2025-01-16 11:39:34,796 - INFO - Episode 1166/100000: Winner=2, Reward=-7.60, EPSILON=0.990, (W=1165,D=1,L=0)
2025-01-16 11:39:35,113 - INFO - Episode 1167/100000: Winner=2, Reward=16.30, EPSILON=0.990, (W=1166,D=1,L=0)
2025-01-16 11:39:35,309 - INFO - Episode 1168/100000: Winner=2, Reward=14.95, EPSILON=0.990, (W=1167,D=1,L=0)
2025-01-16 11:39:35,529 - INFO - Episode 1169/100000: Winner=2, Reward=22.00, EPSILON=0.990, (W=1168,D=1,L=0)
2025-01-16 11:39:35,872 - INFO - Episode 1170/100000: Winner=2, Reward=11.95, EPSILON=0.990, (W=1169,D=1,L=0)
2025-01-16 11:39:35,887 - DEBUG - Q-vals = [0.34863755 0.04597513 0.16272852 0.2700467  0.03773856 0.04208964
 0.09278379], best_act=0, best_val=0.349
2025-01-16 11:39:35,887 - DEBUG - Low Q-value (0.349), using MCTS.
2025-01-16 11:39:35,887 - INFO - Running MCTS with 56 simulations using 6 processes.
2025-01-16 11:39:39,276 - DEBUG - Aggregated action counts: {1: 1, 0: 5, 5: 1}
2025-01-16 11:39:39,276 - DEBUG - Chose best action 0
2025-01-16 11:39:39,432 - INFO - Episode 1171/100000: Winner=2, Reward=-6.45, EPSILON=0.990, (W=1170,D=1,L=0)
2025-01-16 11:39:39,645 - INFO - Episode 1172/100000: Winner=2, Reward=40.65, EPSILON=0.990, (W=1171,D=1,L=0)
2025-01-16 11:39:39,895 - INFO - Episode 1173/100000: Winner=2, Reward=6.05, EPSILON=0.989, (W=1172,D=1,L=0)
2025-01-16 11:39:40,015 - DEBUG - Q-vals = [0.08031983 0.131563   0.01405066 0.59666693 0.11971821 0.03775365
 0.01992772], best_act=3, best_val=0.597
2025-01-16 11:39:40,015 - DEBUG - Low Q-value (0.597), using MCTS.
2025-01-16 11:39:40,016 - INFO - Running MCTS with 56 simulations using 6 processes.
2025-01-16 11:39:43,537 - DEBUG - Aggregated action counts: {1: 1, 0: 5, 2: 1}
2025-01-16 11:39:43,537 - DEBUG - Chose best action 0
2025-01-16 11:39:43,675 - INFO - Episode 1174/100000: Winner=2, Reward=-4.05, EPSILON=0.989, (W=1173,D=1,L=0)
2025-01-16 11:39:43,900 - INFO - Episode 1175/100000: Winner=2, Reward=3.10, EPSILON=0.989, (W=1174,D=1,L=0)
2025-01-16 11:39:44,221 - INFO - Episode 1176/100000: Winner=2, Reward=18.35, EPSILON=0.989, (W=1175,D=1,L=0)
2025-01-16 11:39:44,325 - INFO - Episode 1177/100000: Winner=2, Reward=23.60, EPSILON=0.989, (W=1176,D=1,L=0)
2025-01-16 11:39:44,643 - INFO - Episode 1178/100000: Winner=2, Reward=5.50, EPSILON=0.989, (W=1177,D=1,L=0)
2025-01-16 11:39:44,838 - INFO - Episode 1179/100000: Winner=2, Reward=15.40, EPSILON=0.989, (W=1178,D=1,L=0)
2025-01-16 11:39:44,995 - INFO - Episode 1180/100000: Winner=2, Reward=37.15, EPSILON=0.989, (W=1179,D=1,L=0)
2025-01-16 11:39:45,156 - INFO - Episode 1181/100000: Winner=2, Reward=15.80, EPSILON=0.989, (W=1180,D=1,L=0)
2025-01-16 11:39:45,349 - INFO - Episode 1182/100000: Winner=2, Reward=6.15, EPSILON=0.989, (W=1181,D=1,L=0)
2025-01-16 11:39:45,610 - INFO - Episode 1183/100000: Winner=2, Reward=-7.05, EPSILON=0.989, (W=1182,D=1,L=0)
2025-01-16 11:39:45,904 - INFO - Episode 1184/100000: Winner=2, Reward=13.20, EPSILON=0.989, (W=1183,D=1,L=0)
2025-01-16 11:39:46,050 - INFO - Episode 1185/100000: Winner=2, Reward=37.20, EPSILON=0.989, (W=1184,D=1,L=0)
2025-01-16 11:39:46,286 - INFO - Episode 1186/100000: Winner=2, Reward=23.75, EPSILON=0.989, (W=1185,D=1,L=0)
2025-01-16 11:39:46,354 - INFO - Episode 1187/100000: Winner=2, Reward=0.60, EPSILON=0.989, (W=1186,D=1,L=0)
2025-01-16 11:39:46,637 - INFO - Episode 1188/100000: Winner=2, Reward=-11.50, EPSILON=0.989, (W=1187,D=1,L=0)
2025-01-16 11:39:46,778 - INFO - Episode 1189/100000: Winner=2, Reward=0.65, EPSILON=0.989, (W=1188,D=1,L=0)
2025-01-16 11:39:46,937 - INFO - Episode 1190/100000: Winner=2, Reward=37.95, EPSILON=0.989, (W=1189,D=1,L=0)
2025-01-16 11:39:47,190 - INFO - Episode 1191/100000: Winner=2, Reward=-10.50, EPSILON=0.989, (W=1190,D=1,L=0)
2025-01-16 11:39:47,279 - INFO - Episode 1192/100000: Winner=2, Reward=9.00, EPSILON=0.989, (W=1191,D=1,L=0)
2025-01-16 11:39:47,552 - INFO - Episode 1193/100000: Winner=2, Reward=18.45, EPSILON=0.989, (W=1192,D=1,L=0)
2025-01-16 11:39:47,706 - INFO - Episode 1194/100000: Winner=2, Reward=-8.25, EPSILON=0.989, (W=1193,D=1,L=0)
2025-01-16 11:39:47,933 - INFO - Episode 1195/100000: Winner=2, Reward=6.25, EPSILON=0.989, (W=1194,D=1,L=0)
2025-01-16 11:39:48,099 - DEBUG - Q-vals = [0.2116027  0.01652013 0.0381143  0.01969575 0.586177   0.00098325
 0.12690684], best_act=4, best_val=0.586
2025-01-16 11:39:48,099 - DEBUG - Low Q-value (0.586), using MCTS.
2025-01-16 11:39:48,101 - INFO - Running MCTS with 57 simulations using 6 processes.
2025-01-16 11:39:51,712 - DEBUG - Aggregated action counts: {3: 2, 0: 4, 4: 1}
2025-01-16 11:39:51,712 - DEBUG - Chose best action 0
2025-01-16 11:39:51,898 - INFO - Episode 1196/100000: Winner=2, Reward=-3.05, EPSILON=0.989, (W=1195,D=1,L=0)
2025-01-16 11:39:51,964 - DEBUG - Q-vals = [0.14694266 0.09247922 0.24463284 0.17027418 0.1744814  0.11465273
 0.05653691], best_act=2, best_val=0.245
2025-01-16 11:39:51,964 - DEBUG - Low Q-value (0.245), using MCTS.
2025-01-16 11:39:51,964 - INFO - Running MCTS with 57 simulations using 6 processes.
2025-01-16 11:39:55,365 - DEBUG - Aggregated action counts: {1: 2, 0: 4, 5: 1}
2025-01-16 11:39:55,365 - DEBUG - Chose best action 0
2025-01-16 11:39:55,496 - INFO - Episode 1197/100000: Winner=2, Reward=-4.45, EPSILON=0.989, (W=1196,D=1,L=0)
2025-01-16 11:39:55,513 - DEBUG - Q-vals = [0.3424135  0.09687717 0.17391472 0.17664203 0.06936202 0.09389532
 0.04689519], best_act=0, best_val=0.342
2025-01-16 11:39:55,513 - DEBUG - Low Q-value (0.342), using MCTS.
2025-01-16 11:39:55,513 - INFO - Running MCTS with 57 simulations using 6 processes.
2025-01-16 11:39:58,469 - DEBUG - Aggregated action counts: {0: 4, 1: 1, 2: 1, 3: 1}
2025-01-16 11:39:58,469 - DEBUG - Chose best action 0
2025-01-16 11:39:58,641 - INFO - Episode 1198/100000: Winner=2, Reward=11.80, EPSILON=0.989, (W=1197,D=1,L=0)
2025-01-16 11:39:58,781 - INFO - Episode 1199/100000: Winner=2, Reward=14.60, EPSILON=0.989, (W=1198,D=1,L=0)
2025-01-16 11:39:59,172 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1200.
2025-01-16 11:39:59,172 - INFO - Models saved at episode 1200
2025-01-16 11:39:59,188 - INFO - Target networks updated
2025-01-16 11:39:59,234 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1200.
2025-01-16 11:39:59,234 - INFO - Episode 1200/100000: Winner=2, Reward=5.80, EPSILON=0.989, (W=1199,D=1,L=0)
2025-01-16 11:39:59,359 - INFO - Episode 1201/100000: Winner=2, Reward=-2.95, EPSILON=0.989, (W=1200,D=1,L=0)
2025-01-16 11:39:59,422 - INFO - Episode 1202/100000: Winner=2, Reward=0.05, EPSILON=0.989, (W=1201,D=1,L=0)
2025-01-16 11:39:59,632 - INFO - Episode 1203/100000: Winner=2, Reward=12.30, EPSILON=0.989, (W=1202,D=1,L=0)
2025-01-16 11:39:59,648 - DEBUG - Q-vals = [0.36252287 0.2646806  0.08405417 0.21036112 0.00767558 0.06415737
 0.00654819], best_act=0, best_val=0.363
2025-01-16 11:39:59,648 - DEBUG - Low Q-value (0.363), using MCTS.
2025-01-16 11:39:59,648 - INFO - Running MCTS with 58 simulations using 6 processes.
2025-01-16 11:40:02,448 - DEBUG - Aggregated action counts: {0: 3, 1: 2, 2: 2}
2025-01-16 11:40:02,448 - DEBUG - Chose best action 0
2025-01-16 11:40:02,787 - INFO - Episode 1204/100000: Winner=2, Reward=-29.65, EPSILON=0.989, (W=1203,D=1,L=0)
2025-01-16 11:40:03,022 - INFO - Episode 1205/100000: Winner=2, Reward=-1.70, EPSILON=0.989, (W=1204,D=1,L=0)
2025-01-16 11:40:03,132 - INFO - Episode 1206/100000: Winner=2, Reward=1.30, EPSILON=0.989, (W=1205,D=1,L=0)
2025-01-16 11:40:03,241 - INFO - Episode 1207/100000: Winner=2, Reward=-6.40, EPSILON=0.989, (W=1206,D=1,L=0)
2025-01-16 11:40:03,413 - INFO - Episode 1208/100000: Winner=2, Reward=11.45, EPSILON=0.989, (W=1207,D=1,L=0)
2025-01-16 11:40:03,606 - INFO - Episode 1209/100000: Winner=2, Reward=-0.75, EPSILON=0.989, (W=1208,D=1,L=0)
2025-01-16 11:40:03,746 - INFO - Episode 1210/100000: Winner=2, Reward=-4.60, EPSILON=0.989, (W=1209,D=1,L=0)
2025-01-16 11:40:03,944 - INFO - Episode 1211/100000: Winner=2, Reward=-4.65, EPSILON=0.989, (W=1210,D=1,L=0)
2025-01-16 11:40:04,082 - INFO - Episode 1212/100000: Winner=2, Reward=5.75, EPSILON=0.989, (W=1211,D=1,L=0)
2025-01-16 11:40:04,256 - INFO - Episode 1213/100000: Winner=2, Reward=0.20, EPSILON=0.989, (W=1212,D=1,L=0)
2025-01-16 11:40:04,329 - INFO - Episode 1214/100000: Winner=2, Reward=-7.20, EPSILON=0.989, (W=1213,D=1,L=0)
2025-01-16 11:40:04,562 - INFO - Episode 1215/100000: Winner=2, Reward=2.35, EPSILON=0.989, (W=1214,D=1,L=0)
2025-01-16 11:40:04,827 - INFO - Episode 1216/100000: Winner=2, Reward=19.95, EPSILON=0.989, (W=1215,D=1,L=0)
2025-01-16 11:40:05,070 - INFO - Episode 1217/100000: Winner=2, Reward=22.90, EPSILON=0.989, (W=1216,D=1,L=0)
2025-01-16 11:40:05,282 - INFO - Episode 1218/100000: Winner=2, Reward=6.30, EPSILON=0.989, (W=1217,D=1,L=0)
2025-01-16 11:40:05,485 - INFO - Episode 1219/100000: Winner=2, Reward=-2.45, EPSILON=0.989, (W=1218,D=1,L=0)
2025-01-16 11:40:05,751 - INFO - Episode 1220/100000: Winner=2, Reward=15.80, EPSILON=0.989, (W=1219,D=1,L=0)
2025-01-16 11:40:05,959 - INFO - Episode 1221/100000: Winner=2, Reward=1.70, EPSILON=0.989, (W=1220,D=1,L=0)
2025-01-16 11:40:06,116 - INFO - Episode 1222/100000: Winner=2, Reward=-11.60, EPSILON=0.989, (W=1221,D=1,L=0)
2025-01-16 11:40:06,398 - INFO - Episode 1223/100000: Winner=2, Reward=-3.75, EPSILON=0.989, (W=1222,D=1,L=0)
2025-01-16 11:40:06,726 - INFO - Episode 1224/100000: Winner=2, Reward=-27.55, EPSILON=0.989, (W=1223,D=1,L=0)
2025-01-16 11:40:07,004 - INFO - Episode 1225/100000: Winner=2, Reward=3.30, EPSILON=0.989, (W=1224,D=1,L=0)
2025-01-16 11:40:07,265 - INFO - Episode 1226/100000: Winner=2, Reward=4.25, EPSILON=0.989, (W=1225,D=1,L=0)
2025-01-16 11:40:07,468 - INFO - Episode 1227/100000: Winner=2, Reward=4.10, EPSILON=0.989, (W=1226,D=1,L=0)
2025-01-16 11:40:07,733 - INFO - Episode 1228/100000: Winner=2, Reward=32.55, EPSILON=0.989, (W=1227,D=1,L=0)
2025-01-16 11:40:07,874 - INFO - Episode 1229/100000: Winner=2, Reward=-5.35, EPSILON=0.989, (W=1228,D=1,L=0)
2025-01-16 11:40:08,108 - INFO - Episode 1230/100000: Winner=2, Reward=9.80, EPSILON=0.989, (W=1229,D=1,L=0)
2025-01-16 11:40:08,249 - INFO - Episode 1231/100000: Winner=2, Reward=17.80, EPSILON=0.989, (W=1230,D=1,L=0)
2025-01-16 11:40:08,483 - INFO - Episode 1232/100000: Winner=2, Reward=22.05, EPSILON=0.989, (W=1231,D=1,L=0)
2025-01-16 11:40:08,561 - INFO - Episode 1233/100000: Winner=2, Reward=0.75, EPSILON=0.989, (W=1232,D=1,L=0)
2025-01-16 11:40:08,765 - INFO - Episode 1234/100000: Winner=2, Reward=-1.50, EPSILON=0.989, (W=1233,D=1,L=0)
2025-01-16 11:40:09,030 - INFO - Episode 1235/100000: Winner=2, Reward=-1.85, EPSILON=0.989, (W=1234,D=1,L=0)
2025-01-16 11:40:09,358 - INFO - Episode 1236/100000: Winner=2, Reward=-1.90, EPSILON=0.989, (W=1235,D=1,L=0)
2025-01-16 11:40:09,452 - INFO - Episode 1237/100000: Winner=2, Reward=3.05, EPSILON=0.989, (W=1236,D=1,L=0)
2025-01-16 11:40:09,733 - INFO - Episode 1238/100000: Winner=2, Reward=-0.65, EPSILON=0.989, (W=1237,D=1,L=0)
2025-01-16 11:40:09,827 - DEBUG - Q-vals = [0.03852099 0.12245167 0.26218337 0.21266139 0.0212596  0.19018137
 0.1527416 ], best_act=2, best_val=0.262
2025-01-16 11:40:09,827 - DEBUG - Low Q-value (0.262), using MCTS.
2025-01-16 11:40:09,827 - INFO - Episode 1239/100000: Winner=2, Reward=-6.35, EPSILON=0.989, (W=1238,D=1,L=0)
2025-01-16 11:40:09,999 - INFO - Episode 1240/100000: Winner=2, Reward=4.90, EPSILON=0.989, (W=1239,D=1,L=0)
2025-01-16 11:40:10,124 - INFO - Episode 1241/100000: Winner=2, Reward=10.75, EPSILON=0.989, (W=1240,D=1,L=0)
2025-01-16 11:40:10,327 - INFO - Episode 1242/100000: Winner=2, Reward=-2.50, EPSILON=0.989, (W=1241,D=1,L=0)
2025-01-16 11:40:10,530 - INFO - Episode 1243/100000: Winner=2, Reward=-4.20, EPSILON=0.989, (W=1242,D=1,L=0)
2025-01-16 11:40:10,655 - INFO - Episode 1244/100000: Winner=2, Reward=-1.10, EPSILON=0.989, (W=1243,D=1,L=0)
2025-01-16 11:40:10,920 - INFO - Episode 1245/100000: Winner=2, Reward=-15.30, EPSILON=0.989, (W=1244,D=1,L=0)
2025-01-16 11:40:11,117 - INFO - Episode 1246/100000: Winner=2, Reward=-6.20, EPSILON=0.989, (W=1245,D=1,L=0)
2025-01-16 11:40:11,403 - INFO - Episode 1247/100000: Winner=2, Reward=-14.80, EPSILON=0.989, (W=1246,D=1,L=0)
2025-01-16 11:40:11,637 - INFO - Episode 1248/100000: Winner=2, Reward=14.75, EPSILON=0.989, (W=1247,D=1,L=0)
2025-01-16 11:40:11,752 - INFO - Episode 1249/100000: Winner=2, Reward=9.25, EPSILON=0.989, (W=1248,D=1,L=0)
2025-01-16 11:40:12,015 - INFO - Episode 1250/100000: Winner=2, Reward=24.50, EPSILON=0.989, (W=1249,D=1,L=0)
2025-01-16 11:40:12,093 - DEBUG - Q-vals = [0.06355543 0.07437812 0.1156793  0.138284   0.41233927 0.11346459
 0.08229925], best_act=4, best_val=0.412
2025-01-16 11:40:12,093 - DEBUG - Low Q-value (0.412), using MCTS.
2025-01-16 11:40:12,093 - INFO - Running MCTS with 60 simulations using 6 processes.
2025-01-16 11:40:14,743 - DEBUG - Aggregated action counts: {0: 4, 2: 1, 1: 1}
2025-01-16 11:40:14,743 - DEBUG - Chose best action 0
2025-01-16 11:40:15,003 - INFO - Episode 1251/100000: Winner=2, Reward=-12.30, EPSILON=0.989, (W=1250,D=1,L=0)
2025-01-16 11:40:15,362 - INFO - Episode 1252/100000: Winner=2, Reward=21.60, EPSILON=0.989, (W=1251,D=1,L=0)
2025-01-16 11:40:15,529 - INFO - Episode 1253/100000: Winner=2, Reward=0.35, EPSILON=0.989, (W=1252,D=1,L=0)
2025-01-16 11:40:15,827 - INFO - Episode 1254/100000: Winner=2, Reward=-35.35, EPSILON=0.989, (W=1253,D=1,L=0)
2025-01-16 11:40:16,139 - INFO - Episode 1255/100000: Winner=2, Reward=-8.65, EPSILON=0.989, (W=1254,D=1,L=0)
2025-01-16 11:40:16,283 - INFO - Episode 1256/100000: Winner=2, Reward=5.50, EPSILON=0.989, (W=1255,D=1,L=0)
2025-01-16 11:40:16,428 - INFO - Episode 1257/100000: Winner=2, Reward=11.30, EPSILON=0.989, (W=1256,D=1,L=0)
2025-01-16 11:40:16,593 - INFO - Episode 1258/100000: Winner=2, Reward=-6.05, EPSILON=0.989, (W=1257,D=1,L=0)
2025-01-16 11:40:16,718 - INFO - Episode 1259/100000: Winner=2, Reward=8.65, EPSILON=0.989, (W=1258,D=1,L=0)
2025-01-16 11:40:16,941 - INFO - Episode 1260/100000: Winner=2, Reward=0.70, EPSILON=0.989, (W=1259,D=1,L=0)
2025-01-16 11:40:17,219 - INFO - Episode 1261/100000: Winner=2, Reward=-18.75, EPSILON=0.989, (W=1260,D=1,L=0)
2025-01-16 11:40:17,365 - INFO - Episode 1262/100000: Winner=2, Reward=0.80, EPSILON=0.989, (W=1261,D=1,L=0)
2025-01-16 11:40:17,458 - INFO - Episode 1263/100000: Winner=2, Reward=-5.35, EPSILON=0.989, (W=1262,D=1,L=0)
2025-01-16 11:40:17,599 - INFO - Episode 1264/100000: Winner=2, Reward=0.30, EPSILON=0.989, (W=1263,D=1,L=0)
2025-01-16 11:40:17,662 - INFO - Episode 1265/100000: Winner=2, Reward=-6.20, EPSILON=0.989, (W=1264,D=1,L=0)
2025-01-16 11:40:17,848 - INFO - Episode 1266/100000: Winner=2, Reward=-8.15, EPSILON=0.989, (W=1265,D=1,L=0)
2025-01-16 11:40:17,944 - DEBUG - Q-vals = [0.06185232 0.16559139 0.16606043 0.28154078 0.22604924 0.06085588
 0.03805004], best_act=3, best_val=0.282
2025-01-16 11:40:17,944 - DEBUG - Low Q-value (0.282), using MCTS.
2025-01-16 11:40:17,945 - INFO - Running MCTS with 60 simulations using 6 processes.
2025-01-16 11:40:20,611 - DEBUG - Aggregated action counts: {0: 4, 2: 1, 1: 1}
2025-01-16 11:40:20,612 - DEBUG - Chose best action 0
2025-01-16 11:40:20,743 - INFO - Episode 1267/100000: Winner=2, Reward=8.50, EPSILON=0.989, (W=1266,D=1,L=0)
2025-01-16 11:40:20,884 - INFO - Episode 1268/100000: Winner=2, Reward=-0.95, EPSILON=0.989, (W=1267,D=1,L=0)
2025-01-16 11:40:21,232 - INFO - Episode 1269/100000: Winner=2, Reward=5.90, EPSILON=0.989, (W=1268,D=1,L=0)
2025-01-16 11:40:21,343 - INFO - Episode 1270/100000: Winner=2, Reward=-2.95, EPSILON=0.989, (W=1269,D=1,L=0)
2025-01-16 11:40:21,515 - INFO - Episode 1271/100000: Winner=2, Reward=-2.80, EPSILON=0.989, (W=1270,D=1,L=0)
2025-01-16 11:40:21,703 - INFO - Episode 1272/100000: Winner=2, Reward=10.25, EPSILON=0.989, (W=1271,D=1,L=0)
2025-01-16 11:40:21,850 - INFO - Episode 1273/100000: Winner=2, Reward=17.75, EPSILON=0.989, (W=1272,D=1,L=0)
2025-01-16 11:40:21,964 - INFO - Episode 1274/100000: Winner=2, Reward=10.60, EPSILON=0.989, (W=1273,D=1,L=0)
2025-01-16 11:40:22,176 - INFO - Episode 1275/100000: Winner=2, Reward=-1.30, EPSILON=0.989, (W=1274,D=1,L=0)
2025-01-16 11:40:22,441 - INFO - Episode 1276/100000: Winner=2, Reward=0.75, EPSILON=0.989, (W=1275,D=1,L=0)
2025-01-16 11:40:22,597 - INFO - Episode 1277/100000: Winner=2, Reward=30.55, EPSILON=0.989, (W=1276,D=1,L=0)
2025-01-16 11:40:22,817 - DEBUG - Q-vals = [4.4762079e-02 2.5029173e-01 3.6212066e-05 5.4186922e-02 7.5353547e-03
 4.9994630e-01 1.4324138e-01], best_act=5, best_val=0.500
2025-01-16 11:40:22,817 - DEBUG - Low Q-value (0.500), using MCTS.
2025-01-16 11:40:22,833 - INFO - Running MCTS with 61 simulations using 6 processes.
2025-01-16 11:40:25,483 - DEBUG - Aggregated action counts: {0: 4, 1: 1, 2: 1, 6: 1}
2025-01-16 11:40:25,483 - DEBUG - Chose best action 0
2025-01-16 11:40:25,530 - INFO - Episode 1278/100000: Winner=2, Reward=-9.70, EPSILON=0.989, (W=1277,D=1,L=0)
2025-01-16 11:40:25,534 - DEBUG - Q-vals = [0.37965122 0.05154265 0.28144434 0.13001716 0.03986305 0.07209885
 0.04538276], best_act=0, best_val=0.380
2025-01-16 11:40:25,534 - DEBUG - Low Q-value (0.380), using MCTS.
2025-01-16 11:40:25,534 - INFO - Running MCTS with 61 simulations using 6 processes.
2025-01-16 11:40:28,300 - DEBUG - Aggregated action counts: {1: 2, 0: 3, 2: 1, 5: 1}
2025-01-16 11:40:28,300 - DEBUG - Chose best action 0
2025-01-16 11:40:28,611 - INFO - Episode 1279/100000: Winner=2, Reward=4.70, EPSILON=0.989, (W=1278,D=1,L=0)
2025-01-16 11:40:28,841 - DEBUG - Q-vals = [7.4565029e-03 2.2800455e-02 8.6469203e-02 1.4345876e-04 2.9234732e-06
 3.6354084e-02 8.4677339e-01], best_act=6, best_val=0.847
2025-01-16 11:40:28,841 - DEBUG - Low Q-value (0.847), using MCTS.
2025-01-16 11:40:28,842 - INFO - Running MCTS with 61 simulations using 6 processes.
2025-01-16 11:40:31,514 - DEBUG - Aggregated action counts: {6: 1, 1: 4, 2: 2}
2025-01-16 11:40:31,514 - DEBUG - Chose best action 1
2025-01-16 11:40:31,576 - INFO - Episode 1280/100000: Winner=2, Reward=-17.55, EPSILON=0.989, (W=1279,D=1,L=0)
2025-01-16 11:40:31,686 - INFO - Episode 1281/100000: Winner=2, Reward=2.00, EPSILON=0.989, (W=1280,D=1,L=0)
2025-01-16 11:40:31,989 - INFO - Episode 1282/100000: Winner=2, Reward=2.40, EPSILON=0.989, (W=1281,D=1,L=0)
2025-01-16 11:40:32,054 - INFO - Episode 1283/100000: Winner=2, Reward=0.45, EPSILON=0.989, (W=1282,D=1,L=0)
2025-01-16 11:40:32,272 - INFO - Episode 1284/100000: Winner=2, Reward=-5.60, EPSILON=0.989, (W=1283,D=1,L=0)
2025-01-16 11:40:32,532 - INFO - Episode 1285/100000: Winner=2, Reward=-2.40, EPSILON=0.989, (W=1284,D=1,L=0)
2025-01-16 11:40:32,721 - INFO - Episode 1286/100000: Winner=2, Reward=15.25, EPSILON=0.988, (W=1285,D=1,L=0)
2025-01-16 11:40:32,893 - INFO - Episode 1287/100000: Winner=2, Reward=15.70, EPSILON=0.988, (W=1286,D=1,L=0)
2025-01-16 11:40:33,038 - INFO - Episode 1288/100000: Winner=2, Reward=0.95, EPSILON=0.988, (W=1287,D=1,L=0)
2025-01-16 11:40:33,137 - INFO - Episode 1289/100000: Winner=2, Reward=1.20, EPSILON=0.988, (W=1288,D=1,L=0)
2025-01-16 11:40:33,410 - INFO - Episode 1290/100000: Winner=2, Reward=3.20, EPSILON=0.988, (W=1289,D=1,L=0)
2025-01-16 11:40:33,479 - DEBUG - Q-vals = [0.03037299 0.10361449 0.5718581  0.00613769 0.24832222 0.01613953
 0.02355506], best_act=2, best_val=0.572
2025-01-16 11:40:33,479 - DEBUG - Low Q-value (0.572), using MCTS.
2025-01-16 11:40:33,479 - INFO - Running MCTS with 61 simulations using 6 processes.
2025-01-16 11:40:36,315 - DEBUG - Aggregated action counts: {0: 4, 1: 3}
2025-01-16 11:40:36,316 - DEBUG - Chose best action 0
2025-01-16 11:40:36,497 - INFO - Episode 1291/100000: Winner=2, Reward=-11.75, EPSILON=0.988, (W=1290,D=1,L=0)
2025-01-16 11:40:36,578 - INFO - Episode 1292/100000: Winner=2, Reward=0.70, EPSILON=0.988, (W=1291,D=1,L=0)
2025-01-16 11:40:36,695 - INFO - Episode 1293/100000: Winner=2, Reward=-5.55, EPSILON=0.988, (W=1292,D=1,L=0)
2025-01-16 11:40:36,868 - INFO - Episode 1294/100000: Winner=2, Reward=-15.10, EPSILON=0.988, (W=1293,D=1,L=0)
2025-01-16 11:40:36,976 - INFO - Episode 1295/100000: Winner=2, Reward=-4.80, EPSILON=0.988, (W=1294,D=1,L=0)
2025-01-16 11:40:37,216 - INFO - Episode 1296/100000: Winner=2, Reward=10.20, EPSILON=0.988, (W=1295,D=1,L=0)
2025-01-16 11:40:37,549 - INFO - Episode 1297/100000: Winner=2, Reward=-3.60, EPSILON=0.988, (W=1296,D=1,L=0)
2025-01-16 11:40:37,637 - INFO - Episode 1298/100000: Winner=2, Reward=8.10, EPSILON=0.988, (W=1297,D=1,L=0)
2025-01-16 11:40:37,736 - DEBUG - Q-vals = [0.14640711 0.1581119  0.15065318 0.1821423  0.171847   0.08924935
 0.10158922], best_act=3, best_val=0.182
2025-01-16 11:40:37,736 - DEBUG - Low Q-value (0.182), using MCTS.
2025-01-16 11:40:37,736 - INFO - Running MCTS with 61 simulations using 6 processes.
2025-01-16 11:40:40,838 - DEBUG - Aggregated action counts: {1: 1, 6: 3, 5: 1, 2: 2}
2025-01-16 11:40:40,838 - DEBUG - Chose best action 6
2025-01-16 11:40:40,994 - INFO - Episode 1299/100000: Winner=2, Reward=16.60, EPSILON=0.988, (W=1298,D=1,L=0)
2025-01-16 11:40:41,229 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1300.
2025-01-16 11:40:41,229 - INFO - Models saved at episode 1300
2025-01-16 11:40:41,229 - INFO - Target networks updated
2025-01-16 11:40:41,275 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1300.
2025-01-16 11:40:41,275 - INFO - Episode 1300/100000: Winner=2, Reward=21.80, EPSILON=0.988, (W=1299,D=1,L=0)
2025-01-16 11:40:41,463 - INFO - Episode 1301/100000: Winner=2, Reward=-7.55, EPSILON=0.988, (W=1300,D=1,L=0)
2025-01-16 11:40:41,479 - DEBUG - Q-vals = [0.33879417 0.05175835 0.1157916  0.20136239 0.05949605 0.1724431
 0.0603543 ], best_act=0, best_val=0.339
2025-01-16 11:40:41,479 - DEBUG - Low Q-value (0.339), using MCTS.
2025-01-16 11:40:41,479 - INFO - Running MCTS with 62 simulations using 6 processes.
2025-01-16 11:40:44,119 - DEBUG - Aggregated action counts: {1: 2, 3: 1, 0: 3, 4: 1}
2025-01-16 11:40:44,119 - DEBUG - Chose best action 0
2025-01-16 11:40:44,281 - INFO - Episode 1302/100000: Winner=2, Reward=29.20, EPSILON=0.988, (W=1301,D=1,L=0)
2025-01-16 11:40:44,519 - INFO - Episode 1303/100000: Winner=2, Reward=1.30, EPSILON=0.988, (W=1302,D=1,L=0)
2025-01-16 11:40:44,744 - INFO - Episode 1304/100000: Winner=2, Reward=10.30, EPSILON=0.988, (W=1303,D=1,L=0)
2025-01-16 11:40:44,978 - INFO - Episode 1305/100000: Winner=2, Reward=23.75, EPSILON=0.988, (W=1304,D=1,L=0)
2025-01-16 11:40:45,214 - INFO - Episode 1306/100000: Winner=2, Reward=6.65, EPSILON=0.988, (W=1305,D=1,L=0)
2025-01-16 11:40:45,477 - INFO - Episode 1307/100000: Winner=2, Reward=-1.20, EPSILON=0.988, (W=1306,D=1,L=0)
2025-01-16 11:40:45,720 - INFO - Episode 1308/100000: Winner=2, Reward=22.55, EPSILON=0.988, (W=1307,D=1,L=0)
2025-01-16 11:40:45,877 - INFO - Episode 1309/100000: Winner=2, Reward=-10.65, EPSILON=0.988, (W=1308,D=1,L=0)
2025-01-16 11:40:45,970 - INFO - Episode 1310/100000: Winner=2, Reward=1.35, EPSILON=0.988, (W=1309,D=1,L=0)
2025-01-16 11:40:46,150 - INFO - Episode 1311/100000: Winner=2, Reward=9.45, EPSILON=0.988, (W=1310,D=1,L=0)
2025-01-16 11:40:46,383 - DEBUG - Q-vals = [0.08643936 0.23620856 0.00529247 0.01052241 0.00646333 0.35086557
 0.30420825], best_act=5, best_val=0.351
2025-01-16 11:40:46,383 - DEBUG - Low Q-value (0.351), using MCTS.
2025-01-16 11:40:46,383 - INFO - Running MCTS with 62 simulations using 6 processes.
2025-01-16 11:40:49,277 - DEBUG - Aggregated action counts: {1: 1, 2: 2, 6: 1, 4: 1, 0: 2}
2025-01-16 11:40:49,277 - DEBUG - Chose best action 2
2025-01-16 11:40:49,335 - INFO - Episode 1312/100000: Winner=2, Reward=12.25, EPSILON=0.988, (W=1311,D=1,L=0)
2025-01-16 11:40:49,596 - INFO - Episode 1313/100000: Winner=2, Reward=-12.20, EPSILON=0.988, (W=1312,D=1,L=0)
2025-01-16 11:40:49,746 - INFO - Episode 1314/100000: Winner=2, Reward=16.30, EPSILON=0.988, (W=1313,D=1,L=0)
2025-01-16 11:40:49,936 - INFO - Episode 1315/100000: Winner=2, Reward=15.70, EPSILON=0.988, (W=1314,D=1,L=0)
2025-01-16 11:40:50,046 - INFO - Episode 1316/100000: Winner=2, Reward=6.75, EPSILON=0.988, (W=1315,D=1,L=0)
2025-01-16 11:40:50,152 - DEBUG - Q-vals = [0.15536886 0.01420237 0.25233242 0.17556305 0.10297381 0.24443232
 0.05512706], best_act=2, best_val=0.252
2025-01-16 11:40:50,152 - DEBUG - Low Q-value (0.252), using MCTS.
2025-01-16 11:40:50,152 - INFO - Running MCTS with 62 simulations using 6 processes.
2025-01-16 11:40:52,956 - DEBUG - Aggregated action counts: {0: 6, 3: 1}
2025-01-16 11:40:52,956 - DEBUG - Chose best action 0
2025-01-16 11:40:53,018 - INFO - Episode 1317/100000: Winner=2, Reward=-9.70, EPSILON=0.988, (W=1316,D=1,L=0)
2025-01-16 11:40:53,265 - INFO - Episode 1318/100000: Winner=2, Reward=5.75, EPSILON=0.988, (W=1317,D=1,L=0)
2025-01-16 11:40:53,520 - INFO - Episode 1319/100000: Winner=2, Reward=-8.25, EPSILON=0.988, (W=1318,D=1,L=0)
2025-01-16 11:40:53,792 - INFO - Episode 1320/100000: Winner=2, Reward=0.20, EPSILON=0.988, (W=1319,D=1,L=0)
2025-01-16 11:40:53,980 - INFO - Episode 1321/100000: Winner=2, Reward=-4.05, EPSILON=0.988, (W=1320,D=1,L=0)
2025-01-16 11:40:54,097 - INFO - Episode 1322/100000: Winner=2, Reward=3.70, EPSILON=0.988, (W=1321,D=1,L=0)
2025-01-16 11:40:54,309 - DEBUG - Q-vals = [0.03314888 0.14475262 0.08954015 0.3180644  0.23786372 0.06504718
 0.11158308], best_act=3, best_val=0.318
2025-01-16 11:40:54,309 - DEBUG - Low Q-value (0.318), using MCTS.
2025-01-16 11:40:54,309 - INFO - Episode 1323/100000: Winner=2, Reward=-7.05, EPSILON=0.988, (W=1322,D=1,L=0)
2025-01-16 11:40:54,419 - DEBUG - Q-vals = [0.07584464 0.06434064 0.20129563 0.26743335 0.06454136 0.00065205
 0.32589233], best_act=6, best_val=0.326
2025-01-16 11:40:54,419 - DEBUG - Low Q-value (0.326), using MCTS.
2025-01-16 11:40:54,419 - INFO - Running MCTS with 62 simulations using 6 processes.
2025-01-16 11:40:57,220 - DEBUG - Aggregated action counts: {4: 2, 6: 1, 0: 4}
2025-01-16 11:40:57,220 - DEBUG - Chose best action 0
2025-01-16 11:40:57,298 - INFO - Episode 1324/100000: Winner=2, Reward=10.90, EPSILON=0.988, (W=1323,D=1,L=0)
2025-01-16 11:40:57,485 - INFO - Episode 1325/100000: Winner=2, Reward=-0.25, EPSILON=0.988, (W=1324,D=1,L=0)
2025-01-16 11:40:57,737 - INFO - Episode 1326/100000: Winner=2, Reward=28.25, EPSILON=0.988, (W=1325,D=1,L=0)
2025-01-16 11:40:57,955 - INFO - Episode 1327/100000: Winner=2, Reward=22.55, EPSILON=0.988, (W=1326,D=1,L=0)
2025-01-16 11:40:58,261 - INFO - Episode 1328/100000: Winner=2, Reward=5.20, EPSILON=0.988, (W=1327,D=1,L=0)
2025-01-16 11:40:58,462 - INFO - Episode 1329/100000: Winner=2, Reward=21.60, EPSILON=0.988, (W=1328,D=1,L=0)
2025-01-16 11:40:58,556 - INFO - Episode 1330/100000: Winner=2, Reward=1.00, EPSILON=0.988, (W=1329,D=1,L=0)
2025-01-16 11:40:58,715 - INFO - Episode 1331/100000: Winner=2, Reward=-3.40, EPSILON=0.988, (W=1330,D=1,L=0)
2025-01-16 11:40:58,872 - INFO - Episode 1332/100000: Winner=2, Reward=-2.50, EPSILON=0.988, (W=1331,D=1,L=0)
2025-01-16 11:40:59,136 - INFO - Episode 1333/100000: Winner=2, Reward=-1.35, EPSILON=0.988, (W=1332,D=1,L=0)
2025-01-16 11:40:59,417 - INFO - Episode 1334/100000: Winner=2, Reward=9.25, EPSILON=0.988, (W=1333,D=1,L=0)
2025-01-16 11:40:59,597 - INFO - Episode 1335/100000: Winner=2, Reward=-9.30, EPSILON=0.988, (W=1334,D=1,L=0)
2025-01-16 11:40:59,730 - INFO - Episode 1336/100000: Winner=2, Reward=-4.30, EPSILON=0.988, (W=1335,D=1,L=0)
2025-01-16 11:40:59,980 - INFO - Episode 1337/100000: Winner=2, Reward=21.35, EPSILON=0.988, (W=1336,D=1,L=0)
2025-01-16 11:41:00,200 - INFO - Episode 1338/100000: Winner=2, Reward=2.10, EPSILON=0.988, (W=1337,D=1,L=0)
2025-01-16 11:41:00,419 - INFO - Episode 1339/100000: Winner=2, Reward=-11.00, EPSILON=0.988, (W=1338,D=1,L=0)
2025-01-16 11:41:00,559 - INFO - Episode 1340/100000: Winner=2, Reward=-5.15, EPSILON=0.988, (W=1339,D=1,L=0)
2025-01-16 11:41:00,768 - INFO - Episode 1341/100000: Winner=2, Reward=23.95, EPSILON=0.988, (W=1340,D=1,L=0)
2025-01-16 11:41:00,924 - INFO - Episode 1342/100000: Winner=2, Reward=-4.40, EPSILON=0.988, (W=1341,D=1,L=0)
2025-01-16 11:41:01,183 - INFO - Episode 1343/100000: Winner=2, Reward=3.10, EPSILON=0.988, (W=1342,D=1,L=0)
2025-01-16 11:41:01,400 - INFO - Episode 1344/100000: Winner=2, Reward=20.70, EPSILON=0.988, (W=1343,D=1,L=0)
2025-01-16 11:41:01,416 - DEBUG - Q-vals = [0.43436536 0.07714002 0.08763395 0.14429338 0.09795742 0.10618807
 0.05242173], best_act=0, best_val=0.434
2025-01-16 11:41:01,416 - DEBUG - Low Q-value (0.434), using MCTS.
2025-01-16 11:41:01,416 - INFO - Running MCTS with 63 simulations using 6 processes.
2025-01-16 11:41:04,338 - DEBUG - Aggregated action counts: {1: 1, 2: 1, 0: 4, 3: 1}
2025-01-16 11:41:04,338 - DEBUG - Chose best action 0
2025-01-16 11:41:04,401 - INFO - Episode 1345/100000: Winner=2, Reward=-6.70, EPSILON=0.988, (W=1344,D=1,L=0)
2025-01-16 11:41:04,557 - INFO - Episode 1346/100000: Winner=2, Reward=10.45, EPSILON=0.988, (W=1345,D=1,L=0)
2025-01-16 11:41:04,826 - INFO - Episode 1347/100000: Winner=2, Reward=26.60, EPSILON=0.988, (W=1346,D=1,L=0)
2025-01-16 11:41:05,048 - INFO - Episode 1348/100000: Winner=2, Reward=-7.80, EPSILON=0.988, (W=1347,D=1,L=0)
2025-01-16 11:41:05,215 - INFO - Episode 1349/100000: Winner=2, Reward=-9.50, EPSILON=0.988, (W=1348,D=1,L=0)
2025-01-16 11:41:05,356 - INFO - Episode 1350/100000: Winner=2, Reward=-8.05, EPSILON=0.988, (W=1349,D=1,L=0)
2025-01-16 11:41:05,498 - DEBUG - Q-vals = [0.20117165 0.43252265 0.06193684 0.04842867 0.10179862 0.07144268
 0.0826989 ], best_act=1, best_val=0.433
2025-01-16 11:41:05,499 - DEBUG - Low Q-value (0.433), using MCTS.
2025-01-16 11:41:05,499 - INFO - Running MCTS with 64 simulations using 6 processes.
2025-01-16 11:41:08,346 - DEBUG - Aggregated action counts: {0: 2, 1: 2, 2: 3}
2025-01-16 11:41:08,346 - DEBUG - Chose best action 2
2025-01-16 11:41:08,495 - INFO - Episode 1351/100000: Winner=2, Reward=-1.10, EPSILON=0.988, (W=1350,D=1,L=0)
2025-01-16 11:41:08,747 - INFO - Episode 1352/100000: Winner=2, Reward=-1.50, EPSILON=0.988, (W=1351,D=1,L=0)
2025-01-16 11:41:09,099 - INFO - Episode 1353/100000: Winner=2, Reward=-11.70, EPSILON=0.988, (W=1352,D=1,L=0)
2025-01-16 11:41:09,295 - INFO - Episode 1354/100000: Winner=2, Reward=-10.95, EPSILON=0.988, (W=1353,D=1,L=0)
2025-01-16 11:41:09,404 - DEBUG - Q-vals = [0.15609196 0.0064924  0.38276738 0.20209472 0.00707748 0.23428065
 0.01119543], best_act=2, best_val=0.383
2025-01-16 11:41:09,404 - DEBUG - Low Q-value (0.383), using MCTS.
2025-01-16 11:41:09,404 - INFO - Episode 1355/100000: Winner=2, Reward=-8.50, EPSILON=0.988, (W=1354,D=1,L=0)
2025-01-16 11:41:09,560 - INFO - Episode 1356/100000: Winner=2, Reward=1.40, EPSILON=0.988, (W=1355,D=1,L=0)
2025-01-16 11:41:09,785 - INFO - Episode 1357/100000: Winner=2, Reward=15.65, EPSILON=0.988, (W=1356,D=1,L=0)
2025-01-16 11:41:10,066 - INFO - Episode 1358/100000: Winner=2, Reward=-0.20, EPSILON=0.988, (W=1357,D=1,L=0)
2025-01-16 11:41:10,278 - INFO - Episode 1359/100000: Winner=2, Reward=5.20, EPSILON=0.988, (W=1358,D=1,L=0)
2025-01-16 11:41:10,416 - INFO - Episode 1360/100000: Winner=2, Reward=-0.35, EPSILON=0.988, (W=1359,D=1,L=0)
2025-01-16 11:41:10,479 - INFO - Episode 1361/100000: Winner=2, Reward=8.40, EPSILON=0.988, (W=1360,D=1,L=0)
2025-01-16 11:41:10,654 - INFO - Episode 1362/100000: Winner=2, Reward=10.55, EPSILON=0.988, (W=1361,D=1,L=0)
2025-01-16 11:41:10,873 - INFO - Episode 1363/100000: Winner=2, Reward=14.45, EPSILON=0.988, (W=1362,D=1,L=0)
2025-01-16 11:41:11,001 - INFO - Episode 1364/100000: Winner=2, Reward=3.25, EPSILON=0.988, (W=1363,D=1,L=0)
2025-01-16 11:41:11,200 - INFO - Episode 1365/100000: Winner=2, Reward=-9.55, EPSILON=0.988, (W=1364,D=1,L=0)
2025-01-16 11:41:11,294 - DEBUG - Q-vals = [0.13427755 0.1886087  0.05412054 0.24245244 0.14120375 0.12357989
 0.11575714], best_act=3, best_val=0.242
2025-01-16 11:41:11,294 - DEBUG - Low Q-value (0.242), using MCTS.
2025-01-16 11:41:11,294 - INFO - Running MCTS with 64 simulations using 6 processes.
2025-01-16 11:41:14,106 - DEBUG - Aggregated action counts: {1: 2, 3: 2, 0: 2, 2: 1}
2025-01-16 11:41:14,106 - DEBUG - Chose best action 1
2025-01-16 11:41:14,188 - DEBUG - Q-vals = [0.13633648 0.25009674 0.18971981 0.18431675 0.02287067 0.19120578
 0.02545371], best_act=1, best_val=0.250
2025-01-16 11:41:14,203 - DEBUG - Low Q-value (0.250), using MCTS.
2025-01-16 11:41:14,203 - INFO - Running MCTS with 64 simulations using 6 processes.
2025-01-16 11:41:17,019 - DEBUG - Aggregated action counts: {4: 2, 2: 1, 0: 3, 3: 1}
2025-01-16 11:41:17,019 - DEBUG - Chose best action 0
2025-01-16 11:41:17,157 - INFO - Episode 1366/100000: Winner=2, Reward=5.10, EPSILON=0.988, (W=1365,D=1,L=0)
2025-01-16 11:41:17,454 - INFO - Episode 1367/100000: Winner=2, Reward=-5.05, EPSILON=0.988, (W=1366,D=1,L=0)
2025-01-16 11:41:17,686 - INFO - Episode 1368/100000: Winner=2, Reward=-7.50, EPSILON=0.988, (W=1367,D=1,L=0)
2025-01-16 11:41:17,889 - INFO - Episode 1369/100000: Winner=2, Reward=10.75, EPSILON=0.988, (W=1368,D=1,L=0)
2025-01-16 11:41:18,084 - INFO - Episode 1370/100000: Winner=2, Reward=14.15, EPSILON=0.988, (W=1369,D=1,L=0)
2025-01-16 11:41:18,202 - DEBUG - Q-vals = [9.7503595e-02 7.3176748e-01 1.4139254e-01 5.2550782e-05 1.4426604e-04
 1.5783792e-06 2.9138014e-02], best_act=1, best_val=0.732
2025-01-16 11:41:18,202 - DEBUG - Low Q-value (0.732), using MCTS.
2025-01-16 11:41:18,202 - INFO - Running MCTS with 64 simulations using 6 processes.
2025-01-16 11:41:20,982 - DEBUG - Aggregated action counts: {6: 1, 3: 2, 0: 2, 5: 1, 2: 1}
2025-01-16 11:41:20,982 - DEBUG - Chose best action 3
2025-01-16 11:41:21,076 - INFO - Episode 1371/100000: Winner=2, Reward=13.25, EPSILON=0.988, (W=1370,D=1,L=0)
2025-01-16 11:41:21,263 - INFO - Episode 1372/100000: Winner=2, Reward=6.35, EPSILON=0.988, (W=1371,D=1,L=0)
2025-01-16 11:41:21,497 - INFO - Episode 1373/100000: Winner=2, Reward=-12.45, EPSILON=0.988, (W=1372,D=1,L=0)
2025-01-16 11:41:21,770 - INFO - Episode 1374/100000: Winner=2, Reward=-1.95, EPSILON=0.988, (W=1373,D=1,L=0)
2025-01-16 11:41:21,848 - INFO - Episode 1375/100000: Winner=2, Reward=8.55, EPSILON=0.988, (W=1374,D=1,L=0)
2025-01-16 11:41:22,083 - INFO - Episode 1376/100000: Winner=2, Reward=-3.10, EPSILON=0.988, (W=1375,D=1,L=0)
2025-01-16 11:41:22,312 - INFO - Episode 1377/100000: Winner=2, Reward=4.80, EPSILON=0.988, (W=1376,D=1,L=0)
2025-01-16 11:41:22,496 - INFO - Episode 1378/100000: Winner=2, Reward=-12.35, EPSILON=0.988, (W=1377,D=1,L=0)
2025-01-16 11:41:22,893 - INFO - Episode 1379/100000: Winner=2, Reward=3.65, EPSILON=0.988, (W=1378,D=1,L=0)
2025-01-16 11:41:23,139 - INFO - Episode 1380/100000: Winner=2, Reward=-6.20, EPSILON=0.988, (W=1379,D=1,L=0)
2025-01-16 11:41:23,389 - INFO - Episode 1381/100000: Winner=2, Reward=4.10, EPSILON=0.988, (W=1380,D=1,L=0)
2025-01-16 11:41:23,554 - DEBUG - Q-vals = [0.10692057 0.16711247 0.05886082 0.04346968 0.15682034 0.33527094
 0.13154514], best_act=5, best_val=0.335
2025-01-16 11:41:23,554 - DEBUG - Low Q-value (0.335), using MCTS.
2025-01-16 11:41:23,554 - INFO - Episode 1382/100000: Winner=2, Reward=3.35, EPSILON=0.988, (W=1381,D=1,L=0)
2025-01-16 11:41:23,748 - INFO - Episode 1383/100000: Winner=2, Reward=-9.10, EPSILON=0.988, (W=1382,D=1,L=0)
2025-01-16 11:41:23,826 - INFO - Episode 1384/100000: Winner=2, Reward=8.40, EPSILON=0.988, (W=1383,D=1,L=0)
2025-01-16 11:41:24,045 - INFO - Episode 1385/100000: Winner=2, Reward=11.60, EPSILON=0.988, (W=1384,D=1,L=0)
2025-01-16 11:41:24,202 - INFO - Episode 1386/100000: Winner=2, Reward=5.20, EPSILON=0.988, (W=1385,D=1,L=0)
2025-01-16 11:41:24,421 - INFO - Episode 1387/100000: Winner=2, Reward=5.95, EPSILON=0.988, (W=1386,D=1,L=0)
2025-01-16 11:41:24,515 - INFO - Episode 1388/100000: Winner=2, Reward=1.40, EPSILON=0.988, (W=1387,D=1,L=0)
2025-01-16 11:41:24,639 - INFO - Episode 1389/100000: Winner=2, Reward=-6.95, EPSILON=0.988, (W=1388,D=1,L=0)
2025-01-16 11:41:24,942 - INFO - Episode 1390/100000: Winner=2, Reward=2.00, EPSILON=0.988, (W=1389,D=1,L=0)
2025-01-16 11:41:25,067 - DEBUG - Q-vals = [0.11322193 0.03496611 0.11422491 0.18744741 0.4063707  0.12202113
 0.02174775], best_act=4, best_val=0.406
2025-01-16 11:41:25,067 - DEBUG - Low Q-value (0.406), using MCTS.
2025-01-16 11:41:25,067 - INFO - Episode 1391/100000: Winner=2, Reward=-3.40, EPSILON=0.988, (W=1390,D=1,L=0)
2025-01-16 11:41:25,308 - INFO - Episode 1392/100000: Winner=2, Reward=13.05, EPSILON=0.988, (W=1391,D=1,L=0)
2025-01-16 11:41:25,495 - INFO - Episode 1393/100000: Winner=2, Reward=36.80, EPSILON=0.988, (W=1392,D=1,L=0)
2025-01-16 11:41:25,671 - DEBUG - Q-vals = [0.18676558 0.06691889 0.09054592 0.00358293 0.04562393 0.33949944
 0.26706335], best_act=5, best_val=0.339
2025-01-16 11:41:25,671 - DEBUG - Low Q-value (0.339), using MCTS.
2025-01-16 11:41:25,671 - INFO - Running MCTS with 65 simulations using 6 processes.
2025-01-16 11:41:28,813 - DEBUG - Aggregated action counts: {5: 1, 3: 1, 0: 3, 6: 1, 1: 1}
2025-01-16 11:41:28,813 - DEBUG - Chose best action 0
2025-01-16 11:41:29,033 - INFO - Episode 1394/100000: Winner=2, Reward=2.15, EPSILON=0.988, (W=1393,D=1,L=0)
2025-01-16 11:41:29,247 - INFO - Episode 1395/100000: Winner=2, Reward=-11.15, EPSILON=0.988, (W=1394,D=1,L=0)
2025-01-16 11:41:29,598 - INFO - Episode 1396/100000: Winner=2, Reward=-13.95, EPSILON=0.988, (W=1395,D=1,L=0)
2025-01-16 11:41:29,781 - DEBUG - Q-vals = [4.8975334e-02 2.1686584e-02 5.0257195e-02 1.4608153e-08 8.6805391e-01
 2.5250725e-05 1.1001720e-02], best_act=4, best_val=0.868
2025-01-16 11:41:29,781 - DEBUG - Low Q-value (0.868), using MCTS.
2025-01-16 11:41:29,781 - INFO - Running MCTS with 65 simulations using 6 processes.
2025-01-16 11:41:32,688 - DEBUG - Aggregated action counts: {0: 5, 1: 2}
2025-01-16 11:41:32,688 - DEBUG - Chose best action 0
2025-01-16 11:41:32,751 - INFO - Episode 1397/100000: Winner=2, Reward=4.20, EPSILON=0.988, (W=1396,D=1,L=0)
2025-01-16 11:41:32,923 - INFO - Episode 1398/100000: Winner=2, Reward=8.85, EPSILON=0.987, (W=1397,D=1,L=0)
2025-01-16 11:41:33,101 - INFO - Episode 1399/100000: Winner=2, Reward=28.45, EPSILON=0.987, (W=1398,D=1,L=0)
2025-01-16 11:41:33,282 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1400.
2025-01-16 11:41:33,282 - INFO - Models saved at episode 1400
2025-01-16 11:41:33,282 - INFO - Target networks updated
2025-01-16 11:41:33,329 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1400.
2025-01-16 11:41:33,329 - INFO - Episode 1400/100000: Winner=2, Reward=8.20, EPSILON=0.987, (W=1399,D=1,L=0)
2025-01-16 11:41:33,516 - INFO - Episode 1401/100000: Winner=2, Reward=-16.10, EPSILON=0.987, (W=1400,D=1,L=0)
2025-01-16 11:41:33,772 - INFO - Episode 1402/100000: Winner=2, Reward=3.25, EPSILON=0.987, (W=1401,D=1,L=0)
2025-01-16 11:41:33,897 - INFO - Episode 1403/100000: Winner=2, Reward=2.95, EPSILON=0.987, (W=1402,D=1,L=0)
2025-01-16 11:41:34,124 - INFO - Episode 1404/100000: Winner=2, Reward=22.10, EPSILON=0.987, (W=1403,D=1,L=0)
2025-01-16 11:41:34,310 - INFO - Episode 1405/100000: Winner=2, Reward=-8.95, EPSILON=0.987, (W=1404,D=1,L=0)
2025-01-16 11:41:34,434 - INFO - Episode 1406/100000: Winner=2, Reward=-8.55, EPSILON=0.987, (W=1405,D=1,L=0)
2025-01-16 11:41:34,591 - INFO - Episode 1407/100000: Winner=2, Reward=-8.35, EPSILON=0.987, (W=1406,D=1,L=0)
2025-01-16 11:41:34,806 - INFO - Episode 1408/100000: Winner=2, Reward=4.60, EPSILON=0.987, (W=1407,D=1,L=0)
2025-01-16 11:41:35,019 - INFO - Episode 1409/100000: Winner=2, Reward=-2.40, EPSILON=0.987, (W=1408,D=1,L=0)
2025-01-16 11:41:35,237 - INFO - Episode 1410/100000: Winner=2, Reward=32.15, EPSILON=0.987, (W=1409,D=1,L=0)
2025-01-16 11:41:35,377 - DEBUG - Q-vals = [0.06957214 0.01240673 0.00852569 0.14587711 0.2955219  0.46196616
 0.00613023], best_act=5, best_val=0.462
2025-01-16 11:41:35,377 - DEBUG - Low Q-value (0.462), using MCTS.
2025-01-16 11:41:35,377 - INFO - Episode 1411/100000: Winner=2, Reward=-5.10, EPSILON=0.987, (W=1410,D=1,L=0)
2025-01-16 11:41:35,408 - DEBUG - Q-vals = [0.08774417 0.22898747 0.12129511 0.12972398 0.13886514 0.18673734
 0.10664679], best_act=1, best_val=0.229
2025-01-16 11:41:35,408 - DEBUG - Low Q-value (0.229), using MCTS.
2025-01-16 11:41:35,408 - INFO - Running MCTS with 66 simulations using 6 processes.
2025-01-16 11:41:38,081 - DEBUG - Aggregated action counts: {0: 2, 1: 2, 2: 1, 3: 1}
2025-01-16 11:41:38,081 - DEBUG - Chose best action 0
2025-01-16 11:41:38,300 - INFO - Episode 1412/100000: Winner=2, Reward=4.10, EPSILON=0.987, (W=1411,D=1,L=0)
2025-01-16 11:41:38,394 - DEBUG - Q-vals = [0.08943659 0.16387461 0.21569937 0.18636985 0.09528051 0.19014104
 0.05919814], best_act=2, best_val=0.216
2025-01-16 11:41:38,394 - DEBUG - Low Q-value (0.216), using MCTS.
2025-01-16 11:41:38,394 - INFO - Running MCTS with 66 simulations using 6 processes.
2025-01-16 11:41:41,035 - DEBUG - Aggregated action counts: {2: 3, 3: 1, 5: 1, 0: 1}
2025-01-16 11:41:41,035 - DEBUG - Chose best action 2
2025-01-16 11:41:41,144 - INFO - Episode 1413/100000: Winner=2, Reward=-1.80, EPSILON=0.987, (W=1412,D=1,L=0)
2025-01-16 11:41:41,331 - DEBUG - Q-vals = [0.08656932 0.02395887 0.18241319 0.038549   0.28617108 0.03633493
 0.34600362], best_act=6, best_val=0.346
2025-01-16 11:41:41,331 - DEBUG - Low Q-value (0.346), using MCTS.
2025-01-16 11:41:41,331 - INFO - Running MCTS with 66 simulations using 6 processes.
2025-01-16 11:41:44,003 - DEBUG - Aggregated action counts: {5: 1, 2: 2, 1: 3}
2025-01-16 11:41:44,003 - DEBUG - Chose best action 1
2025-01-16 11:41:44,112 - INFO - Episode 1414/100000: Winner=2, Reward=-12.25, EPSILON=0.987, (W=1413,D=1,L=0)
2025-01-16 11:41:44,315 - INFO - Episode 1415/100000: Winner=2, Reward=8.30, EPSILON=0.987, (W=1414,D=1,L=0)
2025-01-16 11:41:44,534 - INFO - Episode 1416/100000: Winner=2, Reward=3.55, EPSILON=0.987, (W=1415,D=1,L=0)
2025-01-16 11:41:44,737 - INFO - Episode 1417/100000: Winner=2, Reward=-13.35, EPSILON=0.987, (W=1416,D=1,L=0)
2025-01-16 11:41:44,940 - INFO - Episode 1418/100000: Winner=2, Reward=2.10, EPSILON=0.987, (W=1417,D=1,L=0)
2025-01-16 11:41:45,050 - INFO - Episode 1419/100000: Winner=2, Reward=3.40, EPSILON=0.987, (W=1418,D=1,L=0)
2025-01-16 11:41:45,300 - INFO - Episode 1420/100000: Winner=2, Reward=12.55, EPSILON=0.987, (W=1419,D=1,L=0)
2025-01-16 11:41:45,549 - INFO - Episode 1421/100000: Winner=2, Reward=17.15, EPSILON=0.987, (W=1420,D=1,L=0)
2025-01-16 11:41:45,753 - INFO - Episode 1422/100000: Winner=2, Reward=-8.45, EPSILON=0.987, (W=1421,D=1,L=0)
2025-01-16 11:41:45,940 - INFO - Episode 1423/100000: Winner=2, Reward=15.85, EPSILON=0.987, (W=1422,D=1,L=0)
2025-01-16 11:41:46,065 - INFO - Episode 1424/100000: Winner=2, Reward=9.15, EPSILON=0.987, (W=1423,D=1,L=0)
2025-01-16 11:41:46,268 - INFO - Episode 1425/100000: Winner=2, Reward=-9.35, EPSILON=0.987, (W=1424,D=1,L=0)
2025-01-16 11:41:46,331 - DEBUG - Q-vals = [0.20701255 0.1267075  0.14653847 0.07612284 0.2390028  0.12250125
 0.0821146 ], best_act=4, best_val=0.239
2025-01-16 11:41:46,331 - DEBUG - Low Q-value (0.239), using MCTS.
2025-01-16 11:41:46,331 - INFO - Running MCTS with 67 simulations using 6 processes.
2025-01-16 11:41:49,018 - DEBUG - Aggregated action counts: {6: 1, 2: 2, 0: 2, 1: 2}
2025-01-16 11:41:49,018 - DEBUG - Chose best action 2
2025-01-16 11:41:49,128 - INFO - Episode 1426/100000: Winner=2, Reward=3.95, EPSILON=0.987, (W=1425,D=1,L=0)
2025-01-16 11:41:49,211 - INFO - Episode 1427/100000: Winner=2, Reward=7.65, EPSILON=0.987, (W=1426,D=1,L=0)
2025-01-16 11:41:49,299 - INFO - Episode 1428/100000: Winner=2, Reward=8.10, EPSILON=0.987, (W=1427,D=1,L=0)
2025-01-16 11:41:49,393 - INFO - Episode 1429/100000: Winner=2, Reward=1.30, EPSILON=0.987, (W=1428,D=1,L=0)
2025-01-16 11:41:49,565 - DEBUG - Q-vals = [1.7938095e-01 7.8856889e-03 1.9765708e-05 5.7099319e-01 1.7446415e-02
 1.6620494e-01 5.8068983e-02], best_act=3, best_val=0.571
2025-01-16 11:41:49,565 - DEBUG - Low Q-value (0.571), using MCTS.
2025-01-16 11:41:49,581 - INFO - Running MCTS with 67 simulations using 6 processes.
2025-01-16 11:41:52,471 - DEBUG - Aggregated action counts: {0: 3, 2: 1, 1: 3}
2025-01-16 11:41:52,471 - DEBUG - Chose best action 0
2025-01-16 11:41:52,549 - INFO - Episode 1430/100000: Winner=2, Reward=-2.65, EPSILON=0.987, (W=1429,D=1,L=0)
2025-01-16 11:41:52,737 - INFO - Episode 1431/100000: Winner=2, Reward=10.60, EPSILON=0.987, (W=1430,D=1,L=0)
2025-01-16 11:41:52,908 - DEBUG - Q-vals = [0.07581633 0.00818171 0.00135769 0.00792294 0.67423016 0.22996038
 0.0025308 ], best_act=5, best_val=0.230
2025-01-16 11:41:52,908 - DEBUG - Low Q-value (0.230), using MCTS.
2025-01-16 11:41:52,924 - INFO - Episode 1432/100000: Winner=2, Reward=-10.70, EPSILON=0.987, (W=1431,D=1,L=0)
2025-01-16 11:41:53,174 - INFO - Episode 1433/100000: Winner=2, Reward=12.85, EPSILON=0.987, (W=1432,D=1,L=0)
2025-01-16 11:41:53,330 - INFO - Episode 1434/100000: Winner=2, Reward=-8.75, EPSILON=0.987, (W=1433,D=1,L=0)
2025-01-16 11:41:53,502 - INFO - Episode 1435/100000: Winner=2, Reward=-1.15, EPSILON=0.987, (W=1434,D=1,L=0)
2025-01-16 11:41:53,565 - INFO - Episode 1436/100000: Winner=2, Reward=0.60, EPSILON=0.987, (W=1435,D=1,L=0)
2025-01-16 11:41:53,877 - INFO - Episode 1437/100000: Winner=2, Reward=-15.40, EPSILON=0.987, (W=1436,D=1,L=0)
2025-01-16 11:41:54,033 - INFO - Episode 1438/100000: Winner=2, Reward=-7.15, EPSILON=0.987, (W=1437,D=1,L=0)
2025-01-16 11:41:54,096 - DEBUG - Q-vals = [5.7669003e-03 9.5573670e-01 2.1014368e-02 1.6034849e-04 2.6926724e-03
 6.7922826e-07 1.4628370e-02], best_act=1, best_val=0.956
2025-01-16 11:41:54,096 - DEBUG - Low Q-value (0.956), using MCTS.
2025-01-16 11:41:54,096 - INFO - Running MCTS with 67 simulations using 6 processes.
2025-01-16 11:41:56,752 - DEBUG - Aggregated action counts: {0: 2, 2: 1, 1: 1, 3: 1, 4: 2}
2025-01-16 11:41:56,752 - DEBUG - Chose best action 0
2025-01-16 11:41:56,783 - INFO - Episode 1439/100000: Winner=2, Reward=8.10, EPSILON=0.987, (W=1438,D=1,L=0)
2025-01-16 11:41:56,908 - INFO - Episode 1440/100000: Winner=2, Reward=-9.05, EPSILON=0.987, (W=1439,D=1,L=0)
2025-01-16 11:41:57,064 - INFO - Episode 1441/100000: Winner=2, Reward=-8.60, EPSILON=0.987, (W=1440,D=1,L=0)
2025-01-16 11:41:57,158 - INFO - Episode 1442/100000: Winner=2, Reward=7.45, EPSILON=0.987, (W=1441,D=1,L=0)
2025-01-16 11:41:57,377 - INFO - Episode 1443/100000: Winner=2, Reward=9.75, EPSILON=0.987, (W=1442,D=1,L=0)
2025-01-16 11:41:57,580 - INFO - Episode 1444/100000: Winner=2, Reward=2.55, EPSILON=0.987, (W=1443,D=1,L=0)
2025-01-16 11:41:57,720 - INFO - Episode 1445/100000: Winner=2, Reward=-6.65, EPSILON=0.987, (W=1444,D=1,L=0)
2025-01-16 11:41:57,986 - INFO - Episode 1446/100000: Winner=2, Reward=7.65, EPSILON=0.987, (W=1445,D=1,L=0)
2025-01-16 11:41:58,111 - DEBUG - Q-vals = [0.07805928 0.04621288 0.3982434  0.43000874 0.01389554 0.03063493
 0.0029452 ], best_act=3, best_val=0.430
2025-01-16 11:41:58,111 - DEBUG - Low Q-value (0.430), using MCTS.
2025-01-16 11:41:58,111 - INFO - Running MCTS with 67 simulations using 6 processes.
2025-01-16 11:42:01,330 - DEBUG - Aggregated action counts: {2: 3, 0: 4}
2025-01-16 11:42:01,330 - DEBUG - Chose best action 0
2025-01-16 11:42:01,376 - DEBUG - Q-vals = [0.15908842 0.01938953 0.00317351 0.3951613  0.00463691 0.32920688
 0.08934338], best_act=3, best_val=0.395
2025-01-16 11:42:01,376 - DEBUG - Low Q-value (0.395), using MCTS.
2025-01-16 11:42:01,376 - INFO - Running MCTS with 67 simulations using 6 processes.
2025-01-16 11:42:04,220 - DEBUG - Aggregated action counts: {0: 1, 2: 3, 6: 2, 1: 1}
2025-01-16 11:42:04,220 - DEBUG - Chose best action 2
2025-01-16 11:42:04,251 - INFO - Episode 1447/100000: Winner=2, Reward=-0.40, EPSILON=0.987, (W=1446,D=1,L=0)
2025-01-16 11:42:04,345 - INFO - Episode 1448/100000: Winner=2, Reward=9.15, EPSILON=0.987, (W=1447,D=1,L=0)
2025-01-16 11:42:04,532 - INFO - Episode 1449/100000: Winner=2, Reward=-8.40, EPSILON=0.987, (W=1448,D=1,L=0)
2025-01-16 11:42:04,688 - INFO - Episode 1450/100000: Winner=2, Reward=8.60, EPSILON=0.987, (W=1449,D=1,L=0)
2025-01-16 11:42:04,766 - INFO - Episode 1451/100000: Winner=2, Reward=0.80, EPSILON=0.987, (W=1450,D=1,L=0)
2025-01-16 11:42:04,985 - INFO - Episode 1452/100000: Winner=2, Reward=18.45, EPSILON=0.987, (W=1451,D=1,L=0)
2025-01-16 11:42:05,282 - INFO - Episode 1453/100000: Winner=2, Reward=-3.90, EPSILON=0.987, (W=1452,D=1,L=0)
2025-01-16 11:42:05,532 - INFO - Episode 1454/100000: Winner=2, Reward=19.90, EPSILON=0.987, (W=1453,D=1,L=0)
2025-01-16 11:42:05,719 - INFO - Episode 1455/100000: Winner=2, Reward=13.15, EPSILON=0.987, (W=1454,D=1,L=0)
2025-01-16 11:42:05,954 - INFO - Episode 1456/100000: Winner=2, Reward=16.75, EPSILON=0.987, (W=1455,D=1,L=0)
2025-01-16 11:42:06,094 - INFO - Episode 1457/100000: Winner=2, Reward=-0.45, EPSILON=0.987, (W=1456,D=1,L=0)
2025-01-16 11:42:06,235 - INFO - Episode 1458/100000: Winner=2, Reward=-0.95, EPSILON=0.987, (W=1457,D=1,L=0)
2025-01-16 11:42:06,344 - INFO - Episode 1459/100000: Winner=2, Reward=-7.25, EPSILON=0.987, (W=1458,D=1,L=0)
2025-01-16 11:42:06,360 - DEBUG - Q-vals = [0.05331414 0.12899643 0.30694452 0.10742323 0.04107824 0.24938998
 0.11285334], best_act=2, best_val=0.307
2025-01-16 11:42:06,360 - DEBUG - Low Q-value (0.307), using MCTS.
2025-01-16 11:42:06,360 - INFO - Running MCTS with 68 simulations using 6 processes.
2025-01-16 11:42:09,094 - DEBUG - Aggregated action counts: {2: 4, 0: 2, 4: 1}
2025-01-16 11:42:09,094 - DEBUG - Chose best action 2
2025-01-16 11:42:09,360 - INFO - Episode 1460/100000: Winner=2, Reward=-18.10, EPSILON=0.987, (W=1459,D=1,L=0)
2025-01-16 11:42:09,547 - INFO - Episode 1461/100000: Winner=2, Reward=-4.80, EPSILON=0.987, (W=1460,D=1,L=0)
2025-01-16 11:42:09,782 - INFO - Episode 1462/100000: Winner=2, Reward=25.35, EPSILON=0.987, (W=1461,D=1,L=0)
2025-01-16 11:42:09,969 - INFO - Episode 1463/100000: Winner=2, Reward=3.65, EPSILON=0.987, (W=1462,D=1,L=0)
2025-01-16 11:42:10,141 - INFO - Episode 1464/100000: Winner=2, Reward=24.80, EPSILON=0.987, (W=1463,D=1,L=0)
2025-01-16 11:42:10,406 - INFO - Episode 1465/100000: Winner=2, Reward=-2.45, EPSILON=0.987, (W=1464,D=1,L=0)
2025-01-16 11:42:10,688 - INFO - Episode 1466/100000: Winner=2, Reward=-7.80, EPSILON=0.987, (W=1465,D=1,L=0)
2025-01-16 11:42:10,781 - INFO - Episode 1467/100000: Winner=2, Reward=-6.85, EPSILON=0.987, (W=1466,D=1,L=0)
2025-01-16 11:42:10,953 - DEBUG - Q-vals = [0.1321578  0.09296636 0.09083237 0.26151654 0.0272729  0.2896486
 0.10560541], best_act=5, best_val=0.290
2025-01-16 11:42:10,953 - DEBUG - Low Q-value (0.290), using MCTS.
2025-01-16 11:42:10,953 - INFO - Running MCTS with 68 simulations using 6 processes.
2025-01-16 11:42:13,687 - DEBUG - Aggregated action counts: {0: 3, 1: 1, 4: 1, 2: 2}
2025-01-16 11:42:13,687 - DEBUG - Chose best action 0
2025-01-16 11:42:13,734 - INFO - Episode 1468/100000: Winner=2, Reward=13.15, EPSILON=0.987, (W=1467,D=1,L=0)
2025-01-16 11:42:14,093 - INFO - Episode 1469/100000: Winner=2, Reward=41.55, EPSILON=0.987, (W=1468,D=1,L=0)
2025-01-16 11:42:14,202 - INFO - Episode 1470/100000: Winner=2, Reward=9.40, EPSILON=0.987, (W=1469,D=1,L=0)
2025-01-16 11:42:14,281 - INFO - Episode 1471/100000: Winner=2, Reward=-2.55, EPSILON=0.987, (W=1470,D=1,L=0)
2025-01-16 11:42:14,359 - INFO - Episode 1472/100000: Winner=2, Reward=8.55, EPSILON=0.987, (W=1471,D=1,L=0)
2025-01-16 11:42:14,484 - INFO - Episode 1473/100000: Winner=2, Reward=2.90, EPSILON=0.987, (W=1472,D=1,L=0)
2025-01-16 11:42:14,655 - INFO - Episode 1474/100000: Winner=2, Reward=-9.15, EPSILON=0.987, (W=1473,D=1,L=0)
2025-01-16 11:42:14,859 - INFO - Episode 1475/100000: Winner=2, Reward=-5.35, EPSILON=0.987, (W=1474,D=1,L=0)
2025-01-16 11:42:14,952 - INFO - Episode 1476/100000: Winner=2, Reward=2.95, EPSILON=0.987, (W=1475,D=1,L=0)
2025-01-16 11:42:15,124 - INFO - Episode 1477/100000: Winner=2, Reward=-8.20, EPSILON=0.987, (W=1476,D=1,L=0)
2025-01-16 11:42:15,328 - INFO - Episode 1478/100000: Winner=2, Reward=-8.65, EPSILON=0.987, (W=1477,D=1,L=0)
2025-01-16 11:42:15,468 - INFO - Episode 1479/100000: Winner=2, Reward=24.85, EPSILON=0.987, (W=1478,D=1,L=0)
2025-01-16 11:42:15,749 - INFO - Episode 1480/100000: Winner=2, Reward=3.50, EPSILON=0.987, (W=1479,D=1,L=0)
2025-01-16 11:42:15,921 - DEBUG - Q-vals = [0.03623618 0.01375386 0.1483561  0.0093628  0.3686663  0.35908496
 0.06453973], best_act=4, best_val=0.369
2025-01-16 11:42:15,921 - DEBUG - Low Q-value (0.369), using MCTS.
2025-01-16 11:42:15,921 - INFO - Running MCTS with 69 simulations using 6 processes.
2025-01-16 11:42:18,640 - DEBUG - Aggregated action counts: {0: 5, 1: 2}
2025-01-16 11:42:18,640 - DEBUG - Chose best action 0
2025-01-16 11:42:18,686 - INFO - Episode 1481/100000: Winner=2, Reward=2.85, EPSILON=0.987, (W=1480,D=1,L=0)
2025-01-16 11:42:18,905 - INFO - Episode 1482/100000: Winner=2, Reward=19.50, EPSILON=0.987, (W=1481,D=1,L=0)
2025-01-16 11:42:19,077 - INFO - Episode 1483/100000: Winner=2, Reward=14.80, EPSILON=0.987, (W=1482,D=1,L=0)
2025-01-16 11:42:19,155 - INFO - Episode 1484/100000: Winner=2, Reward=0.80, EPSILON=0.987, (W=1483,D=1,L=0)
2025-01-16 11:42:19,358 - INFO - Episode 1485/100000: Winner=2, Reward=15.65, EPSILON=0.987, (W=1484,D=1,L=0)
2025-01-16 11:42:19,593 - INFO - Episode 1486/100000: Winner=2, Reward=-12.10, EPSILON=0.987, (W=1485,D=1,L=0)
2025-01-16 11:42:19,686 - INFO - Episode 1487/100000: Winner=2, Reward=-6.25, EPSILON=0.987, (W=1486,D=1,L=0)
2025-01-16 11:42:19,921 - INFO - Episode 1488/100000: Winner=2, Reward=25.10, EPSILON=0.987, (W=1487,D=1,L=0)
2025-01-16 11:42:20,046 - INFO - Episode 1489/100000: Winner=2, Reward=7.65, EPSILON=0.987, (W=1488,D=1,L=0)
2025-01-16 11:42:20,296 - INFO - Episode 1490/100000: Winner=2, Reward=-12.90, EPSILON=0.987, (W=1489,D=1,L=0)
2025-01-16 11:42:20,530 - INFO - Episode 1491/100000: Winner=2, Reward=-3.10, EPSILON=0.987, (W=1490,D=1,L=0)
2025-01-16 11:42:20,639 - INFO - Episode 1492/100000: Winner=2, Reward=10.00, EPSILON=0.987, (W=1491,D=1,L=0)
2025-01-16 11:42:20,764 - INFO - Episode 1493/100000: Winner=2, Reward=8.25, EPSILON=0.987, (W=1492,D=1,L=0)
2025-01-16 11:42:21,061 - INFO - Episode 1494/100000: Winner=2, Reward=3.35, EPSILON=0.987, (W=1493,D=1,L=0)
2025-01-16 11:42:21,311 - INFO - Episode 1495/100000: Winner=2, Reward=1.80, EPSILON=0.987, (W=1494,D=1,L=0)
2025-01-16 11:42:21,374 - INFO - Episode 1496/100000: Winner=2, Reward=1.00, EPSILON=0.987, (W=1495,D=1,L=0)
2025-01-16 11:42:21,561 - INFO - Episode 1497/100000: Winner=2, Reward=9.45, EPSILON=0.987, (W=1496,D=1,L=0)
2025-01-16 11:42:21,671 - DEBUG - Q-vals = [0.07727285 0.37023574 0.19036412 0.12061914 0.10170856 0.11213665
 0.02766296], best_act=1, best_val=0.370
2025-01-16 11:42:21,671 - DEBUG - Low Q-value (0.370), using MCTS.
2025-01-16 11:42:21,671 - INFO - Running MCTS with 69 simulations using 6 processes.
2025-01-16 11:42:24,717 - DEBUG - Aggregated action counts: {0: 2, 1: 2, 3: 2, 5: 1}
2025-01-16 11:42:24,717 - DEBUG - Chose best action 0
2025-01-16 11:42:24,952 - INFO - Episode 1498/100000: Winner=2, Reward=-22.25, EPSILON=0.987, (W=1497,D=1,L=0)
2025-01-16 11:42:25,077 - INFO - Episode 1499/100000: Winner=2, Reward=2.95, EPSILON=0.987, (W=1498,D=1,L=0)
2025-01-16 11:42:25,295 - ERROR - Failed to save model checkpoint to Connect4_Agent_Model.pth: File Connect4_Agent_Model.pth cannot be opened..
2025-01-16 11:42:25,295 - INFO - Models saved at episode 1500
2025-01-16 11:42:25,295 - INFO - Target networks updated
2025-01-16 11:42:25,295 - ERROR - Failed to save model checkpoint to Connect4_Agent_Model.pth: File Connect4_Agent_Model.pth cannot be opened..
2025-01-16 11:42:25,295 - INFO - Episode 1500/100000: Winner=2, Reward=-9.70, EPSILON=0.987, (W=1499,D=1,L=0)
2025-01-16 11:42:25,499 - INFO - Episode 1501/100000: Winner=2, Reward=-9.70, EPSILON=0.987, (W=1500,D=1,L=0)
2025-01-16 11:42:25,624 - INFO - Episode 1502/100000: Winner=2, Reward=-7.35, EPSILON=0.987, (W=1501,D=1,L=0)
2025-01-16 11:42:25,796 - INFO - Episode 1503/100000: Winner=2, Reward=1.30, EPSILON=0.987, (W=1502,D=1,L=0)
2025-01-16 11:42:26,014 - INFO - Episode 1504/100000: Winner=2, Reward=17.15, EPSILON=0.987, (W=1503,D=1,L=0)
2025-01-16 11:42:26,170 - INFO - Episode 1505/100000: Winner=2, Reward=19.75, EPSILON=0.987, (W=1504,D=1,L=0)
2025-01-16 11:42:26,389 - INFO - Episode 1506/100000: Winner=2, Reward=-2.10, EPSILON=0.987, (W=1505,D=1,L=0)
2025-01-16 11:42:26,592 - INFO - Episode 1507/100000: Winner=2, Reward=-4.90, EPSILON=0.987, (W=1506,D=1,L=0)
2025-01-16 11:42:26,702 - INFO - Episode 1508/100000: Winner=2, Reward=-0.20, EPSILON=0.987, (W=1507,D=1,L=0)
2025-01-16 11:42:26,874 - DEBUG - Q-vals = [1.02407672e-01 2.26377741e-01 1.29973926e-02 2.36596170e-04
 5.33958077e-01 5.38244005e-03 1.18640095e-01], best_act=4, best_val=0.534
2025-01-16 11:42:26,874 - DEBUG - Low Q-value (0.534), using MCTS.
2025-01-16 11:42:26,889 - INFO - Running MCTS with 70 simulations using 6 processes.
2025-01-16 11:42:29,937 - DEBUG - Aggregated action counts: {0: 5, 5: 1, 1: 1}
2025-01-16 11:42:29,937 - DEBUG - Chose best action 0
2025-01-16 11:42:29,984 - DEBUG - Q-vals = [2.6214823e-01 2.4096623e-01 2.8781893e-02 1.6624892e-04 9.5405206e-03
 3.8121688e-01 7.7180073e-02], best_act=5, best_val=0.381
2025-01-16 11:42:29,984 - DEBUG - Low Q-value (0.381), using MCTS.
2025-01-16 11:42:29,999 - INFO - Episode 1509/100000: Winner=2, Reward=-9.30, EPSILON=0.987, (W=1508,D=1,L=0)
2025-01-16 11:42:30,093 - INFO - Episode 1510/100000: Winner=2, Reward=-5.35, EPSILON=0.987, (W=1509,D=1,L=0)
2025-01-16 11:42:30,187 - DEBUG - Q-vals = [0.06963286 0.07066509 0.0466651  0.1046071  0.6307857  0.03876554
 0.03887854], best_act=4, best_val=0.631
2025-01-16 11:42:30,187 - DEBUG - Low Q-value (0.631), using MCTS.
2025-01-16 11:42:30,187 - INFO - Running MCTS with 70 simulations using 6 processes.
2025-01-16 11:42:32,999 - DEBUG - Aggregated action counts: {1: 2, 2: 2, 4: 1, 5: 1, 0: 1}
2025-01-16 11:42:32,999 - DEBUG - Chose best action 1
2025-01-16 11:42:33,031 - INFO - Episode 1511/100000: Winner=2, Reward=-3.65, EPSILON=0.986, (W=1510,D=1,L=0)
2025-01-16 11:42:33,234 - INFO - Episode 1512/100000: Winner=2, Reward=4.00, EPSILON=0.986, (W=1511,D=1,L=0)
2025-01-16 11:42:33,437 - INFO - Episode 1513/100000: Winner=2, Reward=-5.10, EPSILON=0.986, (W=1512,D=1,L=0)
2025-01-16 11:42:33,624 - INFO - Episode 1514/100000: Winner=2, Reward=6.30, EPSILON=0.986, (W=1513,D=1,L=0)
2025-01-16 11:42:33,749 - DEBUG - Q-vals = [6.4366736e-02 8.5037899e-01 1.2126321e-03 8.2481463e-05 3.7441976e-06
 1.4669547e-03 8.2488358e-02], best_act=1, best_val=0.850
2025-01-16 11:42:33,749 - DEBUG - Low Q-value (0.850), using MCTS.
2025-01-16 11:42:33,765 - INFO - Running MCTS with 70 simulations using 6 processes.
2025-01-16 11:42:36,421 - DEBUG - Aggregated action counts: {1: 3, 2: 2, 5: 1, 0: 1}
2025-01-16 11:42:36,421 - DEBUG - Chose best action 1
2025-01-16 11:42:36,515 - INFO - Episode 1515/100000: Winner=2, Reward=-7.20, EPSILON=0.986, (W=1514,D=1,L=0)
2025-01-16 11:42:36,593 - INFO - Episode 1516/100000: Winner=2, Reward=7.90, EPSILON=0.986, (W=1515,D=1,L=0)
2025-01-16 11:42:36,671 - INFO - Episode 1517/100000: Winner=2, Reward=3.25, EPSILON=0.986, (W=1516,D=1,L=0)
2025-01-16 11:42:36,859 - INFO - Episode 1518/100000: Winner=2, Reward=1.50, EPSILON=0.986, (W=1517,D=1,L=0)
2025-01-16 11:42:37,046 - INFO - Episode 1519/100000: Winner=2, Reward=-10.50, EPSILON=0.986, (W=1518,D=1,L=0)
2025-01-16 11:42:37,187 - INFO - Episode 1520/100000: Winner=2, Reward=-8.00, EPSILON=0.986, (W=1519,D=1,L=0)
2025-01-16 11:42:37,343 - INFO - Episode 1521/100000: Winner=2, Reward=-3.20, EPSILON=0.986, (W=1520,D=1,L=0)
2025-01-16 11:42:37,437 - INFO - Episode 1522/100000: Winner=2, Reward=15.65, EPSILON=0.986, (W=1521,D=1,L=0)
2025-01-16 11:42:37,640 - INFO - Episode 1523/100000: Winner=2, Reward=-11.65, EPSILON=0.986, (W=1522,D=1,L=0)
2025-01-16 11:42:37,812 - DEBUG - Q-vals = [1.84734017e-01 2.74052709e-01 1.39204515e-02 2.50670314e-01
 7.85071097e-05 1.91601917e-01 8.49421099e-02], best_act=1, best_val=0.274
2025-01-16 11:42:37,812 - DEBUG - Low Q-value (0.274), using MCTS.
2025-01-16 11:42:37,827 - INFO - Episode 1524/100000: Winner=2, Reward=-6.05, EPSILON=0.986, (W=1523,D=1,L=0)
2025-01-16 11:42:38,030 - INFO - Episode 1525/100000: Winner=2, Reward=31.45, EPSILON=0.986, (W=1524,D=1,L=0)
2025-01-16 11:42:38,202 - INFO - Episode 1526/100000: Winner=2, Reward=-1.55, EPSILON=0.986, (W=1525,D=1,L=0)
2025-01-16 11:42:38,436 - INFO - Episode 1527/100000: Winner=2, Reward=0.15, EPSILON=0.986, (W=1526,D=1,L=0)
2025-01-16 11:42:38,702 - INFO - Episode 1528/100000: Winner=2, Reward=25.20, EPSILON=0.986, (W=1527,D=1,L=0)
2025-01-16 11:42:38,874 - INFO - Episode 1529/100000: Winner=2, Reward=8.25, EPSILON=0.986, (W=1528,D=1,L=0)
2025-01-16 11:42:38,936 - DEBUG - Q-vals = [0.16431312 0.3831304  0.07490703 0.17084493 0.01427018 0.11799103
 0.0745433 ], best_act=1, best_val=0.383
2025-01-16 11:42:38,936 - DEBUG - Low Q-value (0.383), using MCTS.
2025-01-16 11:42:38,936 - INFO - Running MCTS with 71 simulations using 6 processes.
2025-01-16 11:42:41,717 - DEBUG - Aggregated action counts: {2: 2, 5: 1, 6: 1, 0: 2, 1: 1}
2025-01-16 11:42:41,717 - DEBUG - Chose best action 2
2025-01-16 11:42:41,873 - INFO - Episode 1530/100000: Winner=2, Reward=1.70, EPSILON=0.986, (W=1529,D=1,L=0)
2025-01-16 11:42:41,998 - INFO - Episode 1531/100000: Winner=2, Reward=-4.90, EPSILON=0.986, (W=1530,D=1,L=0)
2025-01-16 11:42:42,201 - INFO - Episode 1532/100000: Winner=2, Reward=-7.30, EPSILON=0.986, (W=1531,D=1,L=0)
2025-01-16 11:42:42,451 - INFO - Episode 1533/100000: Winner=2, Reward=-20.10, EPSILON=0.986, (W=1532,D=1,L=0)
2025-01-16 11:42:42,623 - INFO - Episode 1534/100000: Winner=2, Reward=36.15, EPSILON=0.986, (W=1533,D=1,L=0)
2025-01-16 11:42:42,748 - INFO - Episode 1535/100000: Winner=2, Reward=7.85, EPSILON=0.986, (W=1534,D=1,L=0)
2025-01-16 11:42:42,889 - INFO - Episode 1536/100000: Winner=2, Reward=7.95, EPSILON=0.986, (W=1535,D=1,L=0)
2025-01-16 11:42:43,029 - INFO - Episode 1537/100000: Winner=2, Reward=15.05, EPSILON=0.986, (W=1536,D=1,L=0)
2025-01-16 11:42:43,139 - INFO - Episode 1538/100000: Winner=2, Reward=16.45, EPSILON=0.986, (W=1537,D=1,L=0)
2025-01-16 11:42:43,357 - INFO - Episode 1539/100000: Winner=2, Reward=29.85, EPSILON=0.986, (W=1538,D=1,L=0)
2025-01-16 11:42:43,467 - DEBUG - Q-vals = [0.03557831 0.087254   0.06919165 0.0437685  0.6351748  0.07375844
 0.05527425], best_act=4, best_val=0.635
2025-01-16 11:42:43,467 - DEBUG - Low Q-value (0.635), using MCTS.
2025-01-16 11:42:43,467 - INFO - Running MCTS with 71 simulations using 6 processes.
2025-01-16 11:42:46,108 - DEBUG - Aggregated action counts: {6: 1, 0: 3, 4: 1, 2: 2}
2025-01-16 11:42:46,108 - DEBUG - Chose best action 0
2025-01-16 11:42:46,264 - INFO - Episode 1540/100000: Winner=2, Reward=28.70, EPSILON=0.986, (W=1539,D=1,L=0)
2025-01-16 11:42:46,358 - INFO - Episode 1541/100000: Winner=2, Reward=-7.30, EPSILON=0.986, (W=1540,D=1,L=0)
2025-01-16 11:42:46,420 - DEBUG - Q-vals = [0.08786274 0.06263692 0.082615   0.09880728 0.5002653  0.07488698
 0.09292571], best_act=4, best_val=0.500
2025-01-16 11:42:46,420 - DEBUG - Low Q-value (0.500), using MCTS.
2025-01-16 11:42:46,420 - INFO - Running MCTS with 71 simulations using 6 processes.
2025-01-16 11:42:49,233 - DEBUG - Aggregated action counts: {3: 1, 0: 6}
2025-01-16 11:42:49,233 - DEBUG - Chose best action 0
2025-01-16 11:42:49,436 - INFO - Episode 1542/100000: Winner=2, Reward=-19.85, EPSILON=0.986, (W=1541,D=1,L=0)
2025-01-16 11:42:49,514 - INFO - Episode 1543/100000: Winner=2, Reward=-6.45, EPSILON=0.986, (W=1542,D=1,L=0)
2025-01-16 11:42:49,654 - INFO - Episode 1544/100000: Winner=2, Reward=18.45, EPSILON=0.986, (W=1543,D=1,L=0)
2025-01-16 11:42:49,951 - INFO - Episode 1545/100000: Winner=2, Reward=24.10, EPSILON=0.986, (W=1544,D=1,L=0)
2025-01-16 11:42:50,154 - INFO - Episode 1546/100000: Winner=2, Reward=-11.10, EPSILON=0.986, (W=1545,D=1,L=0)
2025-01-16 11:42:50,467 - INFO - Episode 1547/100000: Winner=2, Reward=19.20, EPSILON=0.986, (W=1546,D=1,L=0)
2025-01-16 11:42:50,748 - INFO - Episode 1548/100000: Winner=2, Reward=-2.00, EPSILON=0.986, (W=1547,D=1,L=0)
2025-01-16 11:42:50,764 - DEBUG - Q-vals = [0.11815632 0.0643862  0.09419651 0.37663978 0.16541432 0.11629874
 0.06490815], best_act=3, best_val=0.377
2025-01-16 11:42:50,764 - DEBUG - Low Q-value (0.377), using MCTS.
2025-01-16 11:42:50,764 - INFO - Running MCTS with 71 simulations using 6 processes.
2025-01-16 11:42:53,623 - DEBUG - Aggregated action counts: {1: 2, 0: 4, 4: 1}
2025-01-16 11:42:53,623 - DEBUG - Chose best action 0
2025-01-16 11:42:53,857 - INFO - Episode 1549/100000: Winner=2, Reward=23.50, EPSILON=0.986, (W=1548,D=1,L=0)
2025-01-16 11:42:54,045 - INFO - Episode 1550/100000: Winner=2, Reward=-5.00, EPSILON=0.986, (W=1549,D=1,L=0)
2025-01-16 11:42:54,232 - INFO - Episode 1551/100000: Winner=2, Reward=-7.10, EPSILON=0.986, (W=1550,D=1,L=0)
2025-01-16 11:42:54,420 - INFO - Episode 1552/100000: Winner=2, Reward=18.65, EPSILON=0.986, (W=1551,D=1,L=0)
2025-01-16 11:42:54,623 - INFO - Episode 1553/100000: Winner=2, Reward=7.25, EPSILON=0.986, (W=1552,D=1,L=0)
2025-01-16 11:42:54,920 - INFO - Episode 1554/100000: Winner=2, Reward=14.80, EPSILON=0.986, (W=1553,D=1,L=0)
2025-01-16 11:42:55,060 - INFO - Episode 1555/100000: Winner=2, Reward=11.25, EPSILON=0.986, (W=1554,D=1,L=0)
2025-01-16 11:42:55,310 - INFO - Episode 1556/100000: Winner=2, Reward=16.50, EPSILON=0.986, (W=1555,D=1,L=0)
2025-01-16 11:42:55,419 - INFO - Episode 1557/100000: Winner=2, Reward=0.00, EPSILON=0.986, (W=1556,D=1,L=0)
2025-01-16 11:42:55,544 - INFO - Episode 1558/100000: Winner=2, Reward=3.25, EPSILON=0.986, (W=1557,D=1,L=0)
2025-01-16 11:42:55,779 - INFO - Episode 1559/100000: Winner=2, Reward=-0.85, EPSILON=0.986, (W=1558,D=1,L=0)
2025-01-16 11:42:55,982 - INFO - Episode 1560/100000: Winner=2, Reward=-6.00, EPSILON=0.986, (W=1559,D=1,L=0)
2025-01-16 11:42:56,247 - INFO - Episode 1561/100000: Winner=2, Reward=15.60, EPSILON=0.986, (W=1560,D=1,L=0)
2025-01-16 11:42:56,482 - INFO - Episode 1562/100000: Winner=2, Reward=11.10, EPSILON=0.986, (W=1561,D=1,L=0)
2025-01-16 11:42:56,575 - INFO - Episode 1563/100000: Winner=2, Reward=-6.75, EPSILON=0.986, (W=1562,D=1,L=0)
2025-01-16 11:42:56,747 - INFO - Episode 1564/100000: Winner=2, Reward=7.45, EPSILON=0.986, (W=1563,D=1,L=0)
2025-01-16 11:42:56,935 - INFO - Episode 1565/100000: Winner=2, Reward=13.10, EPSILON=0.986, (W=1564,D=1,L=0)
2025-01-16 11:42:57,107 - DEBUG - Q-vals = [0.03008088 0.03799577 0.1411235  0.04003925 0.5820304  0.13051343
 0.03821672], best_act=4, best_val=0.582
2025-01-16 11:42:57,107 - DEBUG - Low Q-value (0.582), using MCTS.
2025-01-16 11:42:57,107 - INFO - Running MCTS with 72 simulations using 6 processes.
2025-01-16 11:43:00,043 - DEBUG - Aggregated action counts: {5: 1, 1: 1, 4: 1, 0: 1, 3: 1, 6: 1}
2025-01-16 11:43:00,043 - DEBUG - Chose best action 5
2025-01-16 11:43:00,090 - DEBUG - Q-vals = [0.03886456 0.01848874 0.07206247 0.00307278 0.26258245 0.5924547
 0.01247437], best_act=5, best_val=0.592
2025-01-16 11:43:00,090 - DEBUG - Low Q-value (0.592), using MCTS.
2025-01-16 11:43:00,090 - INFO - Episode 1566/100000: Winner=2, Reward=-5.10, EPSILON=0.986, (W=1565,D=1,L=0)
2025-01-16 11:43:00,309 - INFO - Episode 1567/100000: Winner=2, Reward=2.60, EPSILON=0.986, (W=1566,D=1,L=0)
2025-01-16 11:43:00,543 - INFO - Episode 1568/100000: Winner=2, Reward=13.95, EPSILON=0.986, (W=1567,D=1,L=0)
2025-01-16 11:43:00,809 - INFO - Episode 1569/100000: Winner=2, Reward=37.70, EPSILON=0.986, (W=1568,D=1,L=0)
2025-01-16 11:43:00,981 - INFO - Episode 1570/100000: Winner=2, Reward=11.55, EPSILON=0.986, (W=1569,D=1,L=0)
2025-01-16 11:43:01,184 - INFO - Episode 1571/100000: Winner=2, Reward=-7.20, EPSILON=0.986, (W=1570,D=1,L=0)
2025-01-16 11:43:01,527 - INFO - Episode 1572/100000: Winner=2, Reward=1.95, EPSILON=0.986, (W=1571,D=1,L=0)
2025-01-16 11:43:01,652 - DEBUG - Q-vals = [0.12187237 0.13323496 0.1111478  0.37278825 0.04331153 0.14119494
 0.07645016], best_act=3, best_val=0.373
2025-01-16 11:43:01,652 - DEBUG - Low Q-value (0.373), using MCTS.
2025-01-16 11:43:01,652 - INFO - Running MCTS with 72 simulations using 6 processes.
2025-01-16 11:43:04,434 - DEBUG - Aggregated action counts: {5: 1, 0: 4, 1: 1}
2025-01-16 11:43:04,434 - DEBUG - Chose best action 0
2025-01-16 11:43:04,528 - INFO - Episode 1573/100000: Winner=2, Reward=-7.50, EPSILON=0.986, (W=1572,D=1,L=0)
2025-01-16 11:43:04,809 - INFO - Episode 1574/100000: Winner=2, Reward=2.15, EPSILON=0.986, (W=1573,D=1,L=0)
2025-01-16 11:43:05,028 - INFO - Episode 1575/100000: Winner=2, Reward=19.25, EPSILON=0.986, (W=1574,D=1,L=0)
2025-01-16 11:43:05,231 - INFO - Episode 1576/100000: Winner=2, Reward=3.50, EPSILON=0.986, (W=1575,D=1,L=0)
2025-01-16 11:43:05,450 - INFO - Episode 1577/100000: Winner=2, Reward=11.75, EPSILON=0.986, (W=1576,D=1,L=0)
2025-01-16 11:43:05,606 - INFO - Episode 1578/100000: Winner=2, Reward=1.25, EPSILON=0.986, (W=1577,D=1,L=0)
2025-01-16 11:43:05,778 - DEBUG - Q-vals = [0.12895426 0.06867729 0.17295    0.26066723 0.16251612 0.14604546
 0.06018966], best_act=3, best_val=0.261
2025-01-16 11:43:05,778 - DEBUG - Low Q-value (0.261), using MCTS.
2025-01-16 11:43:05,778 - INFO - Episode 1579/100000: Winner=2, Reward=-3.70, EPSILON=0.986, (W=1578,D=1,L=0)
2025-01-16 11:43:06,028 - INFO - Episode 1580/100000: Winner=2, Reward=-8.35, EPSILON=0.986, (W=1579,D=1,L=0)
2025-01-16 11:43:06,153 - DEBUG - Q-vals = [0.21099734 0.02925599 0.32722571 0.15407774 0.02601128 0.02028034
 0.23215154], best_act=2, best_val=0.327
2025-01-16 11:43:06,153 - DEBUG - Low Q-value (0.327), using MCTS.
2025-01-16 11:43:06,168 - INFO - Episode 1581/100000: Winner=2, Reward=-9.45, EPSILON=0.986, (W=1580,D=1,L=0)
2025-01-16 11:43:06,402 - INFO - Episode 1582/100000: Winner=2, Reward=9.30, EPSILON=0.986, (W=1581,D=1,L=0)
2025-01-16 11:43:06,481 - INFO - Episode 1583/100000: Winner=2, Reward=1.65, EPSILON=0.986, (W=1582,D=1,L=0)
2025-01-16 11:43:06,574 - INFO - Episode 1584/100000: Winner=2, Reward=-3.55, EPSILON=0.986, (W=1583,D=1,L=0)
2025-01-16 11:43:06,590 - DEBUG - Q-vals = [0.16096517 0.05484771 0.06422517 0.269002   0.08972126 0.1996576
 0.16158101], best_act=3, best_val=0.269
2025-01-16 11:43:06,590 - DEBUG - Low Q-value (0.269), using MCTS.
2025-01-16 11:43:06,590 - INFO - Running MCTS with 73 simulations using 6 processes.
2025-01-16 11:43:09,667 - DEBUG - Aggregated action counts: {6: 1, 3: 2, 1: 1, 0: 1, 4: 1, 5: 1}
2025-01-16 11:43:09,667 - DEBUG - Chose best action 3
2025-01-16 11:43:09,808 - INFO - Episode 1585/100000: Winner=2, Reward=-7.00, EPSILON=0.986, (W=1584,D=1,L=0)
2025-01-16 11:43:10,042 - INFO - Episode 1586/100000: Winner=2, Reward=-4.00, EPSILON=0.986, (W=1585,D=1,L=0)
2025-01-16 11:43:10,152 - INFO - Episode 1587/100000: Winner=2, Reward=-6.35, EPSILON=0.986, (W=1586,D=1,L=0)
2025-01-16 11:43:10,370 - INFO - Episode 1588/100000: Winner=2, Reward=9.10, EPSILON=0.986, (W=1587,D=1,L=0)
2025-01-16 11:43:10,573 - INFO - Episode 1589/100000: Winner=2, Reward=-7.20, EPSILON=0.986, (W=1588,D=1,L=0)
2025-01-16 11:43:10,776 - INFO - Episode 1590/100000: Winner=2, Reward=19.85, EPSILON=0.986, (W=1589,D=1,L=0)
2025-01-16 11:43:10,933 - INFO - Episode 1591/100000: Winner=2, Reward=10.70, EPSILON=0.986, (W=1590,D=1,L=0)
2025-01-16 11:43:11,073 - INFO - Episode 1592/100000: Winner=2, Reward=2.30, EPSILON=0.986, (W=1591,D=1,L=0)
2025-01-16 11:43:11,209 - INFO - Episode 1593/100000: Winner=2, Reward=-6.20, EPSILON=0.986, (W=1592,D=1,L=0)
2025-01-16 11:43:11,308 - INFO - Episode 1594/100000: Winner=2, Reward=8.50, EPSILON=0.986, (W=1593,D=1,L=0)
2025-01-16 11:43:11,558 - INFO - Episode 1595/100000: Winner=2, Reward=-2.85, EPSILON=0.986, (W=1594,D=1,L=0)
2025-01-16 11:43:11,667 - INFO - Episode 1596/100000: Winner=2, Reward=-6.95, EPSILON=0.986, (W=1595,D=1,L=0)
2025-01-16 11:43:11,808 - INFO - Episode 1597/100000: Winner=2, Reward=-0.35, EPSILON=0.986, (W=1596,D=1,L=0)
2025-01-16 11:43:11,917 - INFO - Episode 1598/100000: Winner=2, Reward=8.00, EPSILON=0.986, (W=1597,D=1,L=0)
2025-01-16 11:43:12,136 - INFO - Episode 1599/100000: Winner=2, Reward=9.15, EPSILON=0.986, (W=1598,D=1,L=0)
2025-01-16 11:43:12,453 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1600.
2025-01-16 11:43:12,453 - INFO - Models saved at episode 1600
2025-01-16 11:43:12,454 - INFO - Target networks updated
2025-01-16 11:43:12,512 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1600.
2025-01-16 11:43:12,512 - INFO - Episode 1600/100000: Winner=2, Reward=-18.20, EPSILON=0.986, (W=1599,D=1,L=0)
2025-01-16 11:43:12,602 - INFO - Episode 1601/100000: Winner=2, Reward=-2.35, EPSILON=0.986, (W=1600,D=1,L=0)
2025-01-16 11:43:12,684 - INFO - Episode 1602/100000: Winner=2, Reward=1.90, EPSILON=0.986, (W=1601,D=1,L=0)
2025-01-16 11:43:12,877 - INFO - Episode 1603/100000: Winner=2, Reward=11.85, EPSILON=0.986, (W=1602,D=1,L=0)
2025-01-16 11:43:13,012 - INFO - Episode 1604/100000: Winner=2, Reward=-4.25, EPSILON=0.986, (W=1603,D=1,L=0)
2025-01-16 11:43:13,224 - INFO - Episode 1605/100000: Winner=2, Reward=27.15, EPSILON=0.986, (W=1604,D=1,L=0)
2025-01-16 11:43:13,461 - INFO - Episode 1606/100000: Winner=2, Reward=19.35, EPSILON=0.986, (W=1605,D=1,L=0)
2025-01-16 11:43:13,754 - INFO - Episode 1607/100000: Winner=2, Reward=19.80, EPSILON=0.986, (W=1606,D=1,L=0)
2025-01-16 11:43:13,910 - INFO - Episode 1608/100000: Winner=2, Reward=10.90, EPSILON=0.986, (W=1607,D=1,L=0)
2025-01-16 11:43:13,946 - DEBUG - Q-vals = [0.18327859 0.08274543 0.1361694  0.16213815 0.17922087 0.16047032
 0.09597723], best_act=0, best_val=0.183
2025-01-16 11:43:13,947 - DEBUG - Low Q-value (0.183), using MCTS.
2025-01-16 11:43:13,947 - INFO - Running MCTS with 74 simulations using 6 processes.
2025-01-16 11:43:16,874 - DEBUG - Aggregated action counts: {6: 1, 5: 1, 1: 2, 2: 1, 3: 1, 0: 1}
2025-01-16 11:43:16,874 - DEBUG - Chose best action 1
2025-01-16 11:43:16,921 - INFO - Episode 1609/100000: Winner=2, Reward=15.50, EPSILON=0.986, (W=1608,D=1,L=0)
2025-01-16 11:43:17,046 - INFO - Episode 1610/100000: Winner=2, Reward=-5.65, EPSILON=0.986, (W=1609,D=1,L=0)
2025-01-16 11:43:17,187 - INFO - Episode 1611/100000: Winner=2, Reward=0.15, EPSILON=0.986, (W=1610,D=1,L=0)
2025-01-16 11:43:17,421 - INFO - Episode 1612/100000: Winner=2, Reward=18.15, EPSILON=0.986, (W=1611,D=1,L=0)
2025-01-16 11:43:17,589 - INFO - Episode 1613/100000: Winner=2, Reward=2.75, EPSILON=0.986, (W=1612,D=1,L=0)
2025-01-16 11:43:17,857 - INFO - Episode 1614/100000: Winner=2, Reward=12.50, EPSILON=0.986, (W=1613,D=1,L=0)
2025-01-16 11:43:18,019 - INFO - Episode 1615/100000: Winner=2, Reward=-0.80, EPSILON=0.986, (W=1614,D=1,L=0)
2025-01-16 11:43:18,201 - INFO - Episode 1616/100000: Winner=2, Reward=2.00, EPSILON=0.986, (W=1615,D=1,L=0)
2025-01-16 11:43:18,287 - INFO - Episode 1617/100000: Winner=2, Reward=1.15, EPSILON=0.986, (W=1616,D=1,L=0)
2025-01-16 11:43:18,628 - INFO - Episode 1618/100000: Winner=2, Reward=-17.10, EPSILON=0.986, (W=1617,D=1,L=0)
2025-01-16 11:43:18,828 - INFO - Episode 1619/100000: Winner=2, Reward=7.75, EPSILON=0.986, (W=1618,D=1,L=0)
2025-01-16 11:43:18,969 - INFO - Episode 1620/100000: Winner=2, Reward=-6.70, EPSILON=0.986, (W=1619,D=1,L=0)
2025-01-16 11:43:19,063 - INFO - Episode 1621/100000: Winner=2, Reward=1.25, EPSILON=0.986, (W=1620,D=1,L=0)
2025-01-16 11:43:19,313 - INFO - Episode 1622/100000: Winner=2, Reward=29.05, EPSILON=0.986, (W=1621,D=1,L=0)
2025-01-16 11:43:19,422 - DEBUG - Q-vals = [0.19179134 0.55951566 0.11871856 0.09190147 0.00266205 0.01579975
 0.01961119], best_act=1, best_val=0.560
2025-01-16 11:43:19,422 - DEBUG - Low Q-value (0.560), using MCTS.
2025-01-16 11:43:19,422 - INFO - Episode 1623/100000: Winner=2, Reward=-8.90, EPSILON=0.985, (W=1622,D=1,L=0)
2025-01-16 11:43:19,563 - INFO - Episode 1624/100000: Winner=2, Reward=-2.70, EPSILON=0.985, (W=1623,D=1,L=0)
2025-01-16 11:43:19,813 - INFO - Episode 1625/100000: Winner=2, Reward=9.75, EPSILON=0.985, (W=1624,D=1,L=0)
2025-01-16 11:43:19,985 - INFO - Episode 1626/100000: Winner=2, Reward=-6.60, EPSILON=0.985, (W=1625,D=1,L=0)
2025-01-16 11:43:20,141 - INFO - Episode 1627/100000: Winner=2, Reward=11.10, EPSILON=0.985, (W=1626,D=1,L=0)
2025-01-16 11:43:20,360 - INFO - Episode 1628/100000: Winner=2, Reward=15.50, EPSILON=0.985, (W=1627,D=1,L=0)
2025-01-16 11:43:20,578 - DEBUG - Q-vals = [0.07985882 0.38099387 0.1371213  0.00618325 0.00413153 0.13621753
 0.25549364], best_act=1, best_val=0.381
2025-01-16 11:43:20,578 - DEBUG - Low Q-value (0.381), using MCTS.
2025-01-16 11:43:20,578 - INFO - Episode 1629/100000: Winner=2, Reward=-11.35, EPSILON=0.985, (W=1628,D=1,L=0)
2025-01-16 11:43:20,719 - INFO - Episode 1630/100000: Winner=2, Reward=17.75, EPSILON=0.985, (W=1629,D=1,L=0)
2025-01-16 11:43:20,891 - INFO - Episode 1631/100000: Winner=2, Reward=-3.90, EPSILON=0.985, (W=1630,D=1,L=0)
2025-01-16 11:43:21,203 - INFO - Episode 1632/100000: Winner=2, Reward=2.50, EPSILON=0.985, (W=1631,D=1,L=0)
2025-01-16 11:43:21,328 - INFO - Episode 1633/100000: Winner=2, Reward=-6.90, EPSILON=0.985, (W=1632,D=1,L=0)
2025-01-16 11:43:21,516 - INFO - Episode 1634/100000: Winner=2, Reward=9.35, EPSILON=0.985, (W=1633,D=1,L=0)
2025-01-16 11:43:21,625 - INFO - Episode 1635/100000: Winner=2, Reward=-4.55, EPSILON=0.985, (W=1634,D=1,L=0)
2025-01-16 11:43:21,922 - INFO - Episode 1636/100000: Winner=2, Reward=-17.65, EPSILON=0.985, (W=1635,D=1,L=0)
2025-01-16 11:43:22,141 - INFO - Episode 1637/100000: Winner=2, Reward=-3.00, EPSILON=0.985, (W=1636,D=1,L=0)
2025-01-16 11:43:22,266 - INFO - Episode 1638/100000: Winner=2, Reward=14.35, EPSILON=0.985, (W=1637,D=1,L=0)
2025-01-16 11:43:22,453 - INFO - Episode 1639/100000: Winner=2, Reward=0.20, EPSILON=0.985, (W=1638,D=1,L=0)
2025-01-16 11:43:22,609 - INFO - Episode 1640/100000: Winner=2, Reward=5.45, EPSILON=0.985, (W=1639,D=1,L=0)
2025-01-16 11:43:22,890 - INFO - Episode 1641/100000: Winner=2, Reward=-3.80, EPSILON=0.985, (W=1640,D=1,L=0)
2025-01-16 11:43:23,062 - INFO - Episode 1642/100000: Winner=2, Reward=23.95, EPSILON=0.985, (W=1641,D=1,L=0)
2025-01-16 11:43:23,359 - INFO - Episode 1643/100000: Winner=2, Reward=20.30, EPSILON=0.985, (W=1642,D=1,L=0)
2025-01-16 11:43:23,547 - INFO - Episode 1644/100000: Winner=2, Reward=-6.70, EPSILON=0.985, (W=1643,D=1,L=0)
2025-01-16 11:43:23,703 - INFO - Episode 1645/100000: Winner=2, Reward=-5.80, EPSILON=0.985, (W=1644,D=1,L=0)
2025-01-16 11:43:23,875 - INFO - Episode 1646/100000: Winner=2, Reward=0.85, EPSILON=0.985, (W=1645,D=1,L=0)
2025-01-16 11:43:24,062 - INFO - Episode 1647/100000: Winner=2, Reward=-7.30, EPSILON=0.985, (W=1646,D=1,L=0)
2025-01-16 11:43:24,421 - INFO - Episode 1648/100000: Winner=2, Reward=-11.30, EPSILON=0.985, (W=1647,D=1,L=0)
2025-01-16 11:43:24,609 - INFO - Episode 1649/100000: Winner=2, Reward=-8.45, EPSILON=0.985, (W=1648,D=1,L=0)
2025-01-16 11:43:24,718 - INFO - Episode 1650/100000: Winner=2, Reward=15.35, EPSILON=0.985, (W=1649,D=1,L=0)
2025-01-16 11:43:25,036 - INFO - Episode 1651/100000: Winner=2, Reward=-11.50, EPSILON=0.985, (W=1650,D=1,L=0)
2025-01-16 11:43:25,129 - INFO - Episode 1652/100000: Winner=2, Reward=16.10, EPSILON=0.985, (W=1651,D=1,L=0)
2025-01-16 11:43:25,317 - INFO - Episode 1653/100000: Winner=2, Reward=-0.90, EPSILON=0.985, (W=1652,D=1,L=0)
2025-01-16 11:43:25,520 - INFO - Episode 1654/100000: Winner=2, Reward=1.90, EPSILON=0.985, (W=1653,D=1,L=0)
2025-01-16 11:43:25,598 - INFO - Episode 1655/100000: Winner=2, Reward=8.90, EPSILON=0.985, (W=1654,D=1,L=0)
2025-01-16 11:43:25,848 - INFO - Episode 1656/100000: Winner=2, Reward=-15.85, EPSILON=0.985, (W=1655,D=1,L=0)
2025-01-16 11:43:25,957 - INFO - Episode 1657/100000: Winner=2, Reward=1.10, EPSILON=0.985, (W=1656,D=1,L=0)
2025-01-16 11:43:26,129 - INFO - Episode 1658/100000: Winner=2, Reward=10.90, EPSILON=0.985, (W=1657,D=1,L=0)
2025-01-16 11:43:26,363 - INFO - Episode 1659/100000: Winner=2, Reward=1.35, EPSILON=0.985, (W=1658,D=1,L=0)
2025-01-16 11:43:26,598 - INFO - Episode 1660/100000: Winner=2, Reward=6.00, EPSILON=0.985, (W=1659,D=1,L=0)
2025-01-16 11:43:26,738 - DEBUG - Q-vals = [0.15341447 0.06533341 0.00785808 0.04310112 0.00384417 0.5108527
 0.21559606], best_act=5, best_val=0.511
2025-01-16 11:43:26,738 - DEBUG - Low Q-value (0.511), using MCTS.
2025-01-16 11:43:26,738 - INFO - Episode 1661/100000: Winner=2, Reward=4.85, EPSILON=0.985, (W=1660,D=1,L=0)
2025-01-16 11:43:26,879 - DEBUG - Q-vals = [0.14869702 0.0859644  0.20990768 0.15039529 0.004442   0.3587183
 0.04187533], best_act=5, best_val=0.359
2025-01-16 11:43:26,879 - DEBUG - Low Q-value (0.359), using MCTS.
2025-01-16 11:43:26,879 - INFO - Running MCTS with 76 simulations using 6 processes.
2025-01-16 11:43:29,535 - DEBUG - Aggregated action counts: {4: 2, 5: 1, 0: 2, 1: 1, 3: 1}
2025-01-16 11:43:29,535 - DEBUG - Chose best action 4
2025-01-16 11:43:29,598 - INFO - Episode 1662/100000: Winner=2, Reward=16.10, EPSILON=0.985, (W=1661,D=1,L=0)
2025-01-16 11:43:29,832 - INFO - Episode 1663/100000: Winner=2, Reward=0.40, EPSILON=0.985, (W=1662,D=1,L=0)
2025-01-16 11:43:29,942 - DEBUG - Q-vals = [1.9320072e-01 1.9537486e-01 7.0083247e-06 2.7713761e-01 1.3520244e-01
 7.0468083e-02 1.2860936e-01], best_act=3, best_val=0.277
2025-01-16 11:43:29,942 - DEBUG - Low Q-value (0.277), using MCTS.
2025-01-16 11:43:29,942 - INFO - Episode 1664/100000: Winner=2, Reward=-5.25, EPSILON=0.985, (W=1663,D=1,L=0)
2025-01-16 11:43:30,113 - INFO - Episode 1665/100000: Winner=2, Reward=-5.30, EPSILON=0.985, (W=1664,D=1,L=0)
2025-01-16 11:43:30,332 - INFO - Episode 1666/100000: Winner=2, Reward=-0.60, EPSILON=0.985, (W=1665,D=1,L=0)
2025-01-16 11:43:30,520 - DEBUG - Q-vals = [9.1834040e-03 3.6693998e-03 6.0479087e-01 1.6864782e-03 1.1912878e-01
 9.7378484e-07 2.6154014e-01], best_act=2, best_val=0.605
2025-01-16 11:43:30,520 - DEBUG - Low Q-value (0.605), using MCTS.
2025-01-16 11:43:30,520 - INFO - Running MCTS with 76 simulations using 6 processes.
2025-01-16 11:43:33,284 - DEBUG - Aggregated action counts: {2: 1, 4: 1, 5: 1, 0: 2, 3: 1, 1: 1}
2025-01-16 11:43:33,284 - DEBUG - Chose best action 0
2025-01-16 11:43:33,300 - INFO - Episode 1667/100000: Winner=2, Reward=12.70, EPSILON=0.985, (W=1666,D=1,L=0)
2025-01-16 11:43:33,488 - INFO - Episode 1668/100000: Winner=2, Reward=-4.65, EPSILON=0.985, (W=1667,D=1,L=0)
2025-01-16 11:43:33,675 - INFO - Episode 1669/100000: Winner=2, Reward=-7.30, EPSILON=0.985, (W=1668,D=1,L=0)
2025-01-16 11:43:33,972 - INFO - Episode 1670/100000: Winner=2, Reward=-14.70, EPSILON=0.985, (W=1669,D=1,L=0)
2025-01-16 11:43:34,144 - DEBUG - Q-vals = [5.7254478e-02 1.8164071e-03 5.7913053e-01 7.1805046e-04 1.1877714e-10
 3.6039782e-01 6.8269524e-04], best_act=2, best_val=0.579
2025-01-16 11:43:34,144 - DEBUG - Low Q-value (0.579), using MCTS.
2025-01-16 11:43:34,144 - INFO - Running MCTS with 76 simulations using 6 processes.
2025-01-16 11:43:37,019 - DEBUG - Aggregated action counts: {2: 2, 1: 2, 0: 3}
2025-01-16 11:43:37,019 - DEBUG - Chose best action 0
2025-01-16 11:43:37,050 - INFO - Episode 1671/100000: Winner=2, Reward=-6.35, EPSILON=0.985, (W=1670,D=1,L=0)
2025-01-16 11:43:37,112 - INFO - Episode 1672/100000: Winner=2, Reward=8.10, EPSILON=0.985, (W=1671,D=1,L=0)
2025-01-16 11:43:37,253 - INFO - Episode 1673/100000: Winner=2, Reward=15.20, EPSILON=0.985, (W=1672,D=1,L=0)
2025-01-16 11:43:37,378 - INFO - Episode 1674/100000: Winner=2, Reward=5.95, EPSILON=0.985, (W=1673,D=1,L=0)
2025-01-16 11:43:37,628 - INFO - Episode 1675/100000: Winner=2, Reward=8.70, EPSILON=0.985, (W=1674,D=1,L=0)
2025-01-16 11:43:37,785 - INFO - Episode 1676/100000: Winner=2, Reward=2.90, EPSILON=0.985, (W=1675,D=1,L=0)
2025-01-16 11:43:37,988 - INFO - Episode 1677/100000: Winner=2, Reward=12.30, EPSILON=0.985, (W=1676,D=1,L=0)
2025-01-16 11:43:38,113 - DEBUG - Q-vals = [0.07687005 0.17004769 0.2198789  0.23003325 0.1818755  0.04836247
 0.0729321 ], best_act=3, best_val=0.230
2025-01-16 11:43:38,113 - DEBUG - Low Q-value (0.230), using MCTS.
2025-01-16 11:43:38,113 - INFO - Running MCTS with 77 simulations using 6 processes.
2025-01-16 11:43:40,941 - DEBUG - Aggregated action counts: {0: 4, 4: 1, 6: 1, 1: 1}
2025-01-16 11:43:40,941 - DEBUG - Chose best action 0
2025-01-16 11:43:41,066 - INFO - Episode 1678/100000: Winner=2, Reward=-13.25, EPSILON=0.985, (W=1677,D=1,L=0)
2025-01-16 11:43:41,206 - INFO - Episode 1679/100000: Winner=2, Reward=17.55, EPSILON=0.985, (W=1678,D=1,L=0)
2025-01-16 11:43:41,285 - DEBUG - Q-vals = [0.11331469 0.08812022 0.12258901 0.2533588  0.15343207 0.11210053
 0.15708469], best_act=3, best_val=0.253
2025-01-16 11:43:41,285 - DEBUG - Low Q-value (0.253), using MCTS.
2025-01-16 11:43:41,285 - INFO - Running MCTS with 77 simulations using 6 processes.
2025-01-16 11:43:44,331 - DEBUG - Aggregated action counts: {4: 2, 0: 2, 3: 1, 2: 1, 1: 1}
2025-01-16 11:43:44,331 - DEBUG - Chose best action 4
2025-01-16 11:43:44,362 - DEBUG - Q-vals = [4.90651652e-02 2.87710340e-04 6.92048848e-01 3.64029258e-02
 8.32689852e-02 1.00955345e-01 3.79710682e-02], best_act=2, best_val=0.692
2025-01-16 11:43:44,362 - DEBUG - Low Q-value (0.692), using MCTS.
2025-01-16 11:43:44,362 - INFO - Running MCTS with 77 simulations using 6 processes.
2025-01-16 11:43:47,628 - DEBUG - Aggregated action counts: {0: 4, 4: 1, 1: 1, 2: 1}
2025-01-16 11:43:47,628 - DEBUG - Chose best action 0
2025-01-16 11:43:47,675 - INFO - Episode 1680/100000: Winner=2, Reward=2.60, EPSILON=0.985, (W=1679,D=1,L=0)
2025-01-16 11:43:48,096 - INFO - Episode 1681/100000: Winner=2, Reward=12.00, EPSILON=0.985, (W=1680,D=1,L=0)
2025-01-16 11:43:48,284 - INFO - Episode 1682/100000: Winner=2, Reward=-0.65, EPSILON=0.985, (W=1681,D=1,L=0)
2025-01-16 11:43:48,471 - INFO - Episode 1683/100000: Winner=2, Reward=-6.30, EPSILON=0.985, (W=1682,D=1,L=0)
2025-01-16 11:43:48,643 - INFO - Episode 1684/100000: Winner=2, Reward=-15.55, EPSILON=0.985, (W=1683,D=1,L=0)
2025-01-16 11:43:48,815 - INFO - Episode 1685/100000: Winner=2, Reward=-9.40, EPSILON=0.985, (W=1684,D=1,L=0)
2025-01-16 11:43:48,909 - INFO - Episode 1686/100000: Winner=2, Reward=1.30, EPSILON=0.985, (W=1685,D=1,L=0)
2025-01-16 11:43:49,174 - INFO - Episode 1687/100000: Winner=2, Reward=0.15, EPSILON=0.985, (W=1686,D=1,L=0)
2025-01-16 11:43:49,346 - INFO - Episode 1688/100000: Winner=2, Reward=21.95, EPSILON=0.985, (W=1687,D=1,L=0)
2025-01-16 11:43:49,471 - INFO - Episode 1689/100000: Winner=2, Reward=1.90, EPSILON=0.985, (W=1688,D=1,L=0)
2025-01-16 11:43:49,752 - INFO - Episode 1690/100000: Winner=2, Reward=0.95, EPSILON=0.985, (W=1689,D=1,L=0)
2025-01-16 11:43:49,971 - INFO - Episode 1691/100000: Winner=2, Reward=-7.30, EPSILON=0.985, (W=1690,D=1,L=0)
2025-01-16 11:43:50,143 - INFO - Episode 1692/100000: Winner=2, Reward=-0.45, EPSILON=0.985, (W=1691,D=1,L=0)
2025-01-16 11:43:50,221 - DEBUG - Q-vals = [0.13830024 0.09401676 0.14575967 0.3269088  0.1658878  0.06707909
 0.0620476 ], best_act=3, best_val=0.327
2025-01-16 11:43:50,221 - DEBUG - Low Q-value (0.327), using MCTS.
2025-01-16 11:43:50,221 - INFO - Running MCTS with 77 simulations using 6 processes.
2025-01-16 11:43:53,533 - DEBUG - Aggregated action counts: {5: 1, 2: 1, 0: 3, 1: 1, 4: 1}
2025-01-16 11:43:53,533 - DEBUG - Chose best action 0
2025-01-16 11:43:53,767 - INFO - Episode 1693/100000: Winner=2, Reward=-5.25, EPSILON=0.985, (W=1692,D=1,L=0)
2025-01-16 11:43:54,001 - INFO - Episode 1694/100000: Winner=2, Reward=-10.85, EPSILON=0.985, (W=1693,D=1,L=0)
2025-01-16 11:43:54,204 - INFO - Episode 1695/100000: Winner=2, Reward=31.70, EPSILON=0.985, (W=1694,D=1,L=0)
2025-01-16 11:43:54,392 - DEBUG - Q-vals = [0.11501162 0.23941055 0.3239033  0.00060584 0.16045512 0.02846037
 0.13215329], best_act=2, best_val=0.324
2025-01-16 11:43:54,392 - DEBUG - Low Q-value (0.324), using MCTS.
2025-01-16 11:43:54,392 - INFO - Running MCTS with 77 simulations using 6 processes.
2025-01-16 11:43:57,547 - DEBUG - Aggregated action counts: {2: 1, 0: 6}
2025-01-16 11:43:57,547 - DEBUG - Chose best action 0
2025-01-16 11:43:57,719 - INFO - Episode 1696/100000: Winner=2, Reward=-31.35, EPSILON=0.985, (W=1695,D=1,L=0)
2025-01-16 11:43:57,969 - INFO - Episode 1697/100000: Winner=2, Reward=9.15, EPSILON=0.985, (W=1696,D=1,L=0)
2025-01-16 11:43:58,297 - INFO - Episode 1698/100000: Winner=2, Reward=-3.70, EPSILON=0.985, (W=1697,D=1,L=0)
2025-01-16 11:43:58,516 - INFO - Episode 1699/100000: Winner=2, Reward=13.90, EPSILON=0.985, (W=1698,D=1,L=0)
2025-01-16 11:43:58,734 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1700.
2025-01-16 11:43:58,734 - INFO - Models saved at episode 1700
2025-01-16 11:43:58,750 - INFO - Target networks updated
2025-01-16 11:43:58,797 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1700.
2025-01-16 11:43:58,797 - INFO - Episode 1700/100000: Winner=2, Reward=-1.50, EPSILON=0.985, (W=1699,D=1,L=0)
2025-01-16 11:43:59,063 - INFO - Episode 1701/100000: Winner=2, Reward=-10.85, EPSILON=0.985, (W=1700,D=1,L=0)
2025-01-16 11:43:59,203 - INFO - Episode 1702/100000: Winner=2, Reward=9.40, EPSILON=0.985, (W=1701,D=1,L=0)
2025-01-16 11:43:59,344 - DEBUG - Q-vals = [0.11820544 0.225098   0.3772106  0.0440217  0.00398361 0.20753461
 0.0239461 ], best_act=2, best_val=0.377
2025-01-16 11:43:59,344 - DEBUG - Low Q-value (0.377), using MCTS.
2025-01-16 11:43:59,344 - INFO - Running MCTS with 78 simulations using 6 processes.
2025-01-16 11:44:02,343 - DEBUG - Aggregated action counts: {6: 1, 0: 2, 1: 2, 3: 1}
2025-01-16 11:44:02,343 - DEBUG - Chose best action 0
2025-01-16 11:44:02,437 - INFO - Episode 1703/100000: Winner=2, Reward=-8.40, EPSILON=0.985, (W=1702,D=1,L=0)
2025-01-16 11:44:02,609 - INFO - Episode 1704/100000: Winner=2, Reward=23.40, EPSILON=0.985, (W=1703,D=1,L=0)
2025-01-16 11:44:02,703 - INFO - Episode 1705/100000: Winner=2, Reward=2.50, EPSILON=0.985, (W=1704,D=1,L=0)
2025-01-16 11:44:02,718 - DEBUG - Q-vals = [0.20774516 0.05219175 0.12021166 0.26002666 0.11944121 0.18014887
 0.06023468], best_act=3, best_val=0.260
2025-01-16 11:44:02,718 - DEBUG - Low Q-value (0.260), using MCTS.
2025-01-16 11:44:02,718 - INFO - Running MCTS with 78 simulations using 6 processes.
2025-01-16 11:44:05,733 - DEBUG - Aggregated action counts: {0: 3, 2: 1, 3: 1, 4: 1}
2025-01-16 11:44:05,733 - DEBUG - Chose best action 0
2025-01-16 11:44:06,046 - INFO - Episode 1706/100000: Winner=2, Reward=-19.20, EPSILON=0.985, (W=1705,D=1,L=0)
2025-01-16 11:44:06,217 - INFO - Episode 1707/100000: Winner=2, Reward=1.45, EPSILON=0.985, (W=1706,D=1,L=0)
2025-01-16 11:44:06,389 - INFO - Episode 1708/100000: Winner=2, Reward=2.90, EPSILON=0.985, (W=1707,D=1,L=0)
2025-01-16 11:44:06,624 - INFO - Episode 1709/100000: Winner=2, Reward=27.40, EPSILON=0.985, (W=1708,D=1,L=0)
2025-01-16 11:44:06,733 - INFO - Episode 1710/100000: Winner=2, Reward=15.70, EPSILON=0.985, (W=1709,D=1,L=0)
2025-01-16 11:44:06,920 - INFO - Episode 1711/100000: Winner=2, Reward=14.70, EPSILON=0.985, (W=1710,D=1,L=0)
2025-01-16 11:44:06,983 - DEBUG - Q-vals = [0.15216173 0.04494514 0.13785318 0.32227573 0.16965902 0.11084484
 0.06226033], best_act=3, best_val=0.322
2025-01-16 11:44:06,983 - DEBUG - Low Q-value (0.322), using MCTS.
2025-01-16 11:44:06,983 - INFO - Running MCTS with 78 simulations using 6 processes.
2025-01-16 11:44:09,733 - DEBUG - Aggregated action counts: {4: 2, 0: 3, 5: 1}
2025-01-16 11:44:09,733 - DEBUG - Chose best action 0
2025-01-16 11:44:09,780 - INFO - Episode 1712/100000: Winner=2, Reward=2.45, EPSILON=0.985, (W=1711,D=1,L=0)
2025-01-16 11:44:10,108 - INFO - Episode 1713/100000: Winner=2, Reward=-3.45, EPSILON=0.985, (W=1712,D=1,L=0)
2025-01-16 11:44:10,295 - INFO - Episode 1714/100000: Winner=2, Reward=7.95, EPSILON=0.985, (W=1713,D=1,L=0)
2025-01-16 11:44:10,529 - INFO - Episode 1715/100000: Winner=2, Reward=29.80, EPSILON=0.985, (W=1714,D=1,L=0)
2025-01-16 11:44:10,717 - DEBUG - Q-vals = [0.17840606 0.06276634 0.18018363 0.09763063 0.2091842  0.23194538
 0.03988377], best_act=5, best_val=0.232
2025-01-16 11:44:10,717 - DEBUG - Low Q-value (0.232), using MCTS.
2025-01-16 11:44:10,717 - INFO - Episode 1716/100000: Winner=2, Reward=-7.15, EPSILON=0.985, (W=1715,D=1,L=0)
2025-01-16 11:44:10,889 - INFO - Episode 1717/100000: Winner=2, Reward=1.30, EPSILON=0.985, (W=1716,D=1,L=0)
2025-01-16 11:44:11,029 - INFO - Episode 1718/100000: Winner=2, Reward=1.60, EPSILON=0.985, (W=1717,D=1,L=0)
2025-01-16 11:44:11,248 - INFO - Episode 1719/100000: Winner=2, Reward=22.80, EPSILON=0.985, (W=1718,D=1,L=0)
2025-01-16 11:44:11,420 - INFO - Episode 1720/100000: Winner=2, Reward=5.85, EPSILON=0.985, (W=1719,D=1,L=0)
2025-01-16 11:44:11,654 - INFO - Episode 1721/100000: Winner=2, Reward=-10.80, EPSILON=0.985, (W=1720,D=1,L=0)
2025-01-16 11:44:11,857 - INFO - Episode 1722/100000: Winner=2, Reward=10.85, EPSILON=0.985, (W=1721,D=1,L=0)
2025-01-16 11:44:11,904 - DEBUG - Q-vals = [0.14124265 0.15383916 0.07333361 0.23366128 0.22305302 0.11725854
 0.05761172], best_act=3, best_val=0.234
2025-01-16 11:44:11,904 - DEBUG - Low Q-value (0.234), using MCTS.
2025-01-16 11:44:11,904 - INFO - Running MCTS with 78 simulations using 6 processes.
2025-01-16 11:44:14,528 - DEBUG - Aggregated action counts: {0: 1, 6: 1, 1: 2, 2: 1, 5: 1}
2025-01-16 11:44:14,528 - DEBUG - Chose best action 1
2025-01-16 11:44:14,685 - INFO - Episode 1723/100000: Winner=2, Reward=-2.70, EPSILON=0.985, (W=1722,D=1,L=0)
2025-01-16 11:44:15,013 - INFO - Episode 1724/100000: Winner=2, Reward=-8.95, EPSILON=0.985, (W=1723,D=1,L=0)
2025-01-16 11:44:15,263 - INFO - Episode 1725/100000: Winner=2, Reward=26.25, EPSILON=0.985, (W=1724,D=1,L=0)
2025-01-16 11:44:15,606 - INFO - Episode 1726/100000: Winner=2, Reward=-11.55, EPSILON=0.985, (W=1725,D=1,L=0)
2025-01-16 11:44:15,684 - INFO - Episode 1727/100000: Winner=2, Reward=0.35, EPSILON=0.985, (W=1726,D=1,L=0)
2025-01-16 11:44:15,919 - INFO - Episode 1728/100000: Winner=2, Reward=1.80, EPSILON=0.985, (W=1727,D=1,L=0)
2025-01-16 11:44:16,184 - INFO - Episode 1729/100000: Winner=2, Reward=-6.75, EPSILON=0.985, (W=1728,D=1,L=0)
2025-01-16 11:44:16,387 - INFO - Episode 1730/100000: Winner=2, Reward=-2.95, EPSILON=0.985, (W=1729,D=1,L=0)
2025-01-16 11:44:16,528 - INFO - Episode 1731/100000: Winner=2, Reward=21.85, EPSILON=0.985, (W=1730,D=1,L=0)
2025-01-16 11:44:16,700 - INFO - Episode 1732/100000: Winner=2, Reward=-12.70, EPSILON=0.985, (W=1731,D=1,L=0)
2025-01-16 11:44:16,872 - DEBUG - Q-vals = [1.02522686e-01 1.97199974e-02 1.92416203e-03 3.01140273e-04
 5.18015027e-02 4.66341823e-02 7.77096331e-01], best_act=6, best_val=0.777
2025-01-16 11:44:16,872 - DEBUG - Low Q-value (0.777), using MCTS.
2025-01-16 11:44:16,872 - INFO - Episode 1733/100000: Winner=2, Reward=3.05, EPSILON=0.985, (W=1732,D=1,L=0)
2025-01-16 11:44:17,043 - INFO - Episode 1734/100000: Winner=2, Reward=1.90, EPSILON=0.985, (W=1733,D=1,L=0)
2025-01-16 11:44:17,215 - INFO - Episode 1735/100000: Winner=2, Reward=3.85, EPSILON=0.985, (W=1734,D=1,L=0)
2025-01-16 11:44:17,309 - DEBUG - Q-vals = [0.15609807 0.06351235 0.12344652 0.1385648  0.18762912 0.32759726
 0.00315184], best_act=5, best_val=0.328
2025-01-16 11:44:17,309 - DEBUG - Low Q-value (0.328), using MCTS.
2025-01-16 11:44:17,309 - INFO - Running MCTS with 79 simulations using 6 processes.
2025-01-16 11:44:19,949 - DEBUG - Aggregated action counts: {4: 2, 3: 2, 1: 1, 2: 1, 5: 1}
2025-01-16 11:44:19,949 - DEBUG - Chose best action 4
2025-01-16 11:44:19,996 - INFO - Episode 1736/100000: Winner=2, Reward=2.45, EPSILON=0.984, (W=1735,D=1,L=0)
2025-01-16 11:44:20,136 - INFO - Episode 1737/100000: Winner=2, Reward=-1.90, EPSILON=0.984, (W=1736,D=1,L=0)
2025-01-16 11:44:20,340 - INFO - Episode 1738/100000: Winner=2, Reward=-7.20, EPSILON=0.984, (W=1737,D=1,L=0)
2025-01-16 11:44:20,558 - INFO - Episode 1739/100000: Winner=2, Reward=-5.50, EPSILON=0.984, (W=1738,D=1,L=0)
2025-01-16 11:44:20,683 - DEBUG - Q-vals = [3.5547352e-01 4.5162216e-01 3.3556893e-02 1.3921126e-05 6.7393966e-02
 9.8185800e-03 8.2120940e-02], best_act=1, best_val=0.452
2025-01-16 11:44:20,683 - DEBUG - Low Q-value (0.452), using MCTS.
2025-01-16 11:44:20,683 - INFO - Running MCTS with 79 simulations using 6 processes.
2025-01-16 11:44:23,698 - DEBUG - Aggregated action counts: {0: 1, 2: 1, 6: 2, 3: 2, 4: 1}
2025-01-16 11:44:23,698 - DEBUG - Chose best action 6
2025-01-16 11:44:23,761 - INFO - Episode 1740/100000: Winner=2, Reward=4.95, EPSILON=0.984, (W=1739,D=1,L=0)
2025-01-16 11:44:23,948 - INFO - Episode 1741/100000: Winner=2, Reward=7.80, EPSILON=0.984, (W=1740,D=1,L=0)
2025-01-16 11:44:24,136 - INFO - Episode 1742/100000: Winner=2, Reward=6.25, EPSILON=0.984, (W=1741,D=1,L=0)
2025-01-16 11:44:24,245 - INFO - Episode 1743/100000: Winner=2, Reward=16.15, EPSILON=0.984, (W=1742,D=1,L=0)
2025-01-16 11:44:24,542 - INFO - Episode 1744/100000: Winner=2, Reward=-2.95, EPSILON=0.984, (W=1743,D=1,L=0)
2025-01-16 11:44:24,885 - INFO - Episode 1745/100000: Winner=2, Reward=-19.30, EPSILON=0.984, (W=1744,D=1,L=0)
2025-01-16 11:44:25,073 - INFO - Episode 1746/100000: Winner=2, Reward=26.80, EPSILON=0.984, (W=1745,D=1,L=0)
2025-01-16 11:44:25,104 - DEBUG - Q-vals = [0.10915498 0.05242131 0.10617303 0.39052194 0.22183044 0.0805081
 0.03939023], best_act=3, best_val=0.391
2025-01-16 11:44:25,104 - DEBUG - Low Q-value (0.391), using MCTS.
2025-01-16 11:44:25,104 - INFO - Running MCTS with 79 simulations using 6 processes.
2025-01-16 11:44:29,662 - DEBUG - Aggregated action counts: {5: 2, 3: 4, 2: 1}
2025-01-16 11:44:29,662 - DEBUG - Chose best action 3
2025-01-16 11:44:29,724 - INFO - Episode 1747/100000: Winner=2, Reward=-6.15, EPSILON=0.984, (W=1746,D=1,L=0)
2025-01-16 11:44:29,974 - INFO - Episode 1748/100000: Winner=2, Reward=-13.85, EPSILON=0.984, (W=1747,D=1,L=0)
2025-01-16 11:44:30,074 - INFO - Episode 1749/100000: Winner=2, Reward=1.20, EPSILON=0.984, (W=1748,D=1,L=0)
2025-01-16 11:44:30,224 - INFO - Episode 1750/100000: Winner=2, Reward=-0.80, EPSILON=0.984, (W=1749,D=1,L=0)
2025-01-16 11:44:30,364 - INFO - Episode 1751/100000: Winner=2, Reward=2.45, EPSILON=0.984, (W=1750,D=1,L=0)
2025-01-16 11:44:30,641 - INFO - Episode 1752/100000: Winner=2, Reward=-3.75, EPSILON=0.984, (W=1751,D=1,L=0)
2025-01-16 11:44:30,734 - INFO - Episode 1753/100000: Winner=2, Reward=4.00, EPSILON=0.984, (W=1752,D=1,L=0)
2025-01-16 11:44:30,901 - INFO - Episode 1754/100000: Winner=2, Reward=3.65, EPSILON=0.984, (W=1753,D=1,L=0)
2025-01-16 11:44:31,064 - INFO - Episode 1755/100000: Winner=2, Reward=-0.20, EPSILON=0.984, (W=1754,D=1,L=0)
2025-01-16 11:44:31,259 - INFO - Episode 1756/100000: Winner=2, Reward=24.00, EPSILON=0.984, (W=1755,D=1,L=0)
2025-01-16 11:44:31,506 - INFO - Episode 1757/100000: Winner=2, Reward=2.20, EPSILON=0.984, (W=1756,D=1,L=0)
2025-01-16 11:44:31,589 - INFO - Episode 1758/100000: Winner=2, Reward=0.90, EPSILON=0.984, (W=1757,D=1,L=0)
2025-01-16 11:44:31,783 - INFO - Episode 1759/100000: Winner=2, Reward=4.00, EPSILON=0.984, (W=1758,D=1,L=0)
2025-01-16 11:44:32,070 - INFO - Episode 1760/100000: Winner=2, Reward=13.10, EPSILON=0.984, (W=1759,D=1,L=0)
2025-01-16 11:44:32,513 - INFO - Episode 1761/100000: Winner=2, Reward=-29.65, EPSILON=0.984, (W=1760,D=1,L=0)
2025-01-16 11:44:32,605 - DEBUG - Q-vals = [0.08798615 0.0975273  0.24654685 0.27369794 0.20868519 0.04628936
 0.03926722], best_act=3, best_val=0.274
2025-01-16 11:44:32,605 - DEBUG - Low Q-value (0.274), using MCTS.
2025-01-16 11:44:32,605 - INFO - Running MCTS with 80 simulations using 6 processes.
2025-01-16 11:44:36,089 - DEBUG - Aggregated action counts: {1: 4, 0: 2, 3: 1}
2025-01-16 11:44:36,090 - DEBUG - Chose best action 1
2025-01-16 11:44:36,396 - INFO - Episode 1762/100000: Winner=2, Reward=-17.40, EPSILON=0.984, (W=1761,D=1,L=0)
2025-01-16 11:44:36,510 - INFO - Episode 1763/100000: Winner=2, Reward=7.85, EPSILON=0.984, (W=1762,D=1,L=0)
2025-01-16 11:44:36,681 - INFO - Episode 1764/100000: Winner=2, Reward=2.95, EPSILON=0.984, (W=1763,D=1,L=0)
2025-01-16 11:44:36,989 - INFO - Episode 1765/100000: Winner=2, Reward=-14.30, EPSILON=0.984, (W=1764,D=1,L=0)
2025-01-16 11:44:37,214 - INFO - Episode 1766/100000: Winner=2, Reward=13.95, EPSILON=0.984, (W=1765,D=1,L=0)
2025-01-16 11:44:37,295 - DEBUG - Q-vals = [0.13468814 0.19430232 0.22939166 0.05587704 0.12455904 0.18654212
 0.07463966], best_act=2, best_val=0.229
2025-01-16 11:44:37,295 - DEBUG - Low Q-value (0.229), using MCTS.
2025-01-16 11:44:37,295 - INFO - Running MCTS with 80 simulations using 6 processes.
2025-01-16 11:44:40,951 - DEBUG - Aggregated action counts: {0: 2, 1: 1, 3: 2, 2: 1, 5: 1}
2025-01-16 11:44:40,951 - DEBUG - Chose best action 0
2025-01-16 11:44:41,006 - INFO - Episode 1767/100000: Winner=2, Reward=2.85, EPSILON=0.984, (W=1766,D=1,L=0)
2025-01-16 11:44:41,092 - INFO - Episode 1768/100000: Winner=2, Reward=24.05, EPSILON=0.984, (W=1767,D=1,L=0)
2025-01-16 11:44:41,251 - INFO - Episode 1769/100000: Winner=2, Reward=24.60, EPSILON=0.984, (W=1768,D=1,L=0)
2025-01-16 11:44:41,342 - INFO - Episode 1770/100000: Winner=2, Reward=-7.60, EPSILON=0.984, (W=1769,D=1,L=0)
2025-01-16 11:44:41,492 - INFO - Episode 1771/100000: Winner=2, Reward=-1.30, EPSILON=0.984, (W=1770,D=1,L=0)
2025-01-16 11:44:41,638 - INFO - Episode 1772/100000: Winner=2, Reward=-6.80, EPSILON=0.984, (W=1771,D=1,L=0)
2025-01-16 11:44:41,741 - INFO - Episode 1773/100000: Winner=2, Reward=1.10, EPSILON=0.984, (W=1772,D=1,L=0)
2025-01-16 11:44:41,880 - INFO - Episode 1774/100000: Winner=2, Reward=8.05, EPSILON=0.984, (W=1773,D=1,L=0)
2025-01-16 11:44:42,050 - INFO - Episode 1775/100000: Winner=2, Reward=-5.15, EPSILON=0.984, (W=1774,D=1,L=0)
2025-01-16 11:44:42,302 - INFO - Episode 1776/100000: Winner=2, Reward=40.30, EPSILON=0.984, (W=1775,D=1,L=0)
2025-01-16 11:44:42,450 - INFO - Episode 1777/100000: Winner=2, Reward=-5.65, EPSILON=0.984, (W=1776,D=1,L=0)
2025-01-16 11:44:42,716 - INFO - Episode 1778/100000: Winner=2, Reward=16.05, EPSILON=0.984, (W=1777,D=1,L=0)
2025-01-16 11:44:42,829 - INFO - Episode 1779/100000: Winner=2, Reward=-5.80, EPSILON=0.984, (W=1778,D=1,L=0)
2025-01-16 11:44:43,001 - INFO - Episode 1780/100000: Winner=2, Reward=-3.85, EPSILON=0.984, (W=1779,D=1,L=0)
2025-01-16 11:44:43,222 - INFO - Episode 1781/100000: Winner=2, Reward=9.00, EPSILON=0.984, (W=1780,D=1,L=0)
2025-01-16 11:44:43,413 - INFO - Episode 1782/100000: Winner=2, Reward=-2.10, EPSILON=0.984, (W=1781,D=1,L=0)
2025-01-16 11:44:43,700 - INFO - Episode 1783/100000: Winner=2, Reward=5.45, EPSILON=0.984, (W=1782,D=1,L=0)
2025-01-16 11:44:43,789 - DEBUG - Q-vals = [2.20662773e-01 7.98022300e-02 8.59784335e-02 4.70625579e-01
 2.02873386e-02 3.70054244e-04 1.22273654e-01], best_act=3, best_val=0.471
2025-01-16 11:44:43,790 - DEBUG - Low Q-value (0.471), using MCTS.
2025-01-16 11:44:43,790 - INFO - Running MCTS with 81 simulations using 6 processes.
2025-01-16 11:44:47,121 - DEBUG - Aggregated action counts: {0: 2, 3: 2, 2: 3}
2025-01-16 11:44:47,121 - DEBUG - Chose best action 2
2025-01-16 11:44:47,288 - INFO - Episode 1784/100000: Winner=2, Reward=9.80, EPSILON=0.984, (W=1783,D=1,L=0)
2025-01-16 11:44:47,589 - INFO - Episode 1785/100000: Winner=2, Reward=1.25, EPSILON=0.984, (W=1784,D=1,L=0)
2025-01-16 11:44:47,879 - INFO - Episode 1786/100000: Winner=2, Reward=-6.85, EPSILON=0.984, (W=1785,D=1,L=0)
2025-01-16 11:44:48,096 - INFO - Episode 1787/100000: Winner=2, Reward=1.45, EPSILON=0.984, (W=1786,D=1,L=0)
2025-01-16 11:44:48,227 - INFO - Episode 1788/100000: Winner=2, Reward=0.20, EPSILON=0.984, (W=1787,D=1,L=0)
2025-01-16 11:44:48,333 - DEBUG - Q-vals = [0.05475536 0.00536417 0.00121715 0.20807153 0.6094579  0.00164066
 0.11949318], best_act=4, best_val=0.609
2025-01-16 11:44:48,333 - DEBUG - Low Q-value (0.609), using MCTS.
2025-01-16 11:44:48,339 - INFO - Episode 1789/100000: Winner=2, Reward=-7.30, EPSILON=0.984, (W=1788,D=1,L=0)
2025-01-16 11:44:48,594 - INFO - Episode 1790/100000: Winner=2, Reward=-9.25, EPSILON=0.984, (W=1789,D=1,L=0)
2025-01-16 11:44:48,691 - INFO - Episode 1791/100000: Winner=2, Reward=14.85, EPSILON=0.984, (W=1790,D=1,L=0)
2025-01-16 11:44:48,978 - INFO - Episode 1792/100000: Winner=2, Reward=-0.35, EPSILON=0.984, (W=1791,D=1,L=0)
2025-01-16 11:44:49,086 - INFO - Episode 1793/100000: Winner=2, Reward=8.35, EPSILON=0.984, (W=1792,D=1,L=0)
2025-01-16 11:44:49,329 - INFO - Episode 1794/100000: Winner=2, Reward=29.10, EPSILON=0.984, (W=1793,D=1,L=0)
2025-01-16 11:44:49,460 - INFO - Episode 1795/100000: Winner=2, Reward=-9.10, EPSILON=0.984, (W=1794,D=1,L=0)
2025-01-16 11:44:49,545 - INFO - Episode 1796/100000: Winner=2, Reward=0.90, EPSILON=0.984, (W=1795,D=1,L=0)
2025-01-16 11:44:49,856 - INFO - Episode 1797/100000: Winner=2, Reward=7.50, EPSILON=0.984, (W=1796,D=1,L=0)
2025-01-16 11:44:50,061 - DEBUG - Q-vals = [5.0133176e-02 7.5663216e-03 6.1538580e-05 2.6264023e-03 9.3070996e-01
 8.2118800e-03 6.9068151e-04], best_act=4, best_val=0.931
2025-01-16 11:44:50,061 - DEBUG - Low Q-value (0.931), using MCTS.
2025-01-16 11:44:50,061 - INFO - Running MCTS with 81 simulations using 6 processes.
2025-01-16 11:44:52,801 - DEBUG - Aggregated action counts: {0: 5, 3: 1, 2: 1}
2025-01-16 11:44:52,801 - DEBUG - Chose best action 0
2025-01-16 11:44:52,833 - INFO - Episode 1798/100000: Winner=2, Reward=-10.85, EPSILON=0.984, (W=1797,D=1,L=0)
2025-01-16 11:44:53,005 - INFO - Episode 1799/100000: Winner=2, Reward=-2.30, EPSILON=0.984, (W=1798,D=1,L=0)
2025-01-16 11:44:53,286 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1800.
2025-01-16 11:44:53,286 - INFO - Models saved at episode 1800
2025-01-16 11:44:53,286 - INFO - Target networks updated
2025-01-16 11:44:53,348 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1800.
2025-01-16 11:44:53,348 - INFO - Episode 1800/100000: Winner=2, Reward=-2.45, EPSILON=0.984, (W=1799,D=1,L=0)
2025-01-16 11:44:53,520 - INFO - Episode 1801/100000: Winner=2, Reward=23.65, EPSILON=0.984, (W=1800,D=1,L=0)
2025-01-16 11:44:53,629 - INFO - Episode 1802/100000: Winner=2, Reward=-7.05, EPSILON=0.984, (W=1801,D=1,L=0)
2025-01-16 11:44:53,879 - INFO - Episode 1803/100000: Winner=2, Reward=-15.00, EPSILON=0.984, (W=1802,D=1,L=0)
2025-01-16 11:44:54,114 - INFO - Episode 1804/100000: Winner=2, Reward=8.95, EPSILON=0.984, (W=1803,D=1,L=0)
2025-01-16 11:44:54,286 - INFO - Episode 1805/100000: Winner=2, Reward=-4.10, EPSILON=0.984, (W=1804,D=1,L=0)
2025-01-16 11:44:54,551 - INFO - Episode 1806/100000: Winner=2, Reward=-16.15, EPSILON=0.984, (W=1805,D=1,L=0)
2025-01-16 11:44:54,723 - INFO - Episode 1807/100000: Winner=2, Reward=6.45, EPSILON=0.984, (W=1806,D=1,L=0)
2025-01-16 11:44:55,004 - INFO - Episode 1808/100000: Winner=2, Reward=2.05, EPSILON=0.984, (W=1807,D=1,L=0)
2025-01-16 11:44:55,238 - INFO - Episode 1809/100000: Winner=2, Reward=9.90, EPSILON=0.984, (W=1808,D=1,L=0)
2025-01-16 11:44:55,332 - INFO - Episode 1810/100000: Winner=2, Reward=-8.05, EPSILON=0.984, (W=1809,D=1,L=0)
2025-01-16 11:44:55,535 - INFO - Episode 1811/100000: Winner=2, Reward=-4.50, EPSILON=0.984, (W=1810,D=1,L=0)
2025-01-16 11:44:55,738 - INFO - Episode 1812/100000: Winner=2, Reward=7.55, EPSILON=0.984, (W=1811,D=1,L=0)
2025-01-16 11:44:55,879 - INFO - Episode 1813/100000: Winner=2, Reward=8.45, EPSILON=0.984, (W=1812,D=1,L=0)
2025-01-16 11:44:56,144 - INFO - Episode 1814/100000: Winner=2, Reward=21.95, EPSILON=0.984, (W=1813,D=1,L=0)
2025-01-16 11:44:56,394 - INFO - Episode 1815/100000: Winner=2, Reward=-1.15, EPSILON=0.984, (W=1814,D=1,L=0)
2025-01-16 11:44:56,551 - INFO - Episode 1816/100000: Winner=2, Reward=14.40, EPSILON=0.984, (W=1815,D=1,L=0)
2025-01-16 11:44:56,722 - INFO - Episode 1817/100000: Winner=2, Reward=5.15, EPSILON=0.984, (W=1816,D=1,L=0)
2025-01-16 11:44:56,847 - INFO - Episode 1818/100000: Winner=2, Reward=2.85, EPSILON=0.984, (W=1817,D=1,L=0)
2025-01-16 11:44:57,160 - INFO - Episode 1819/100000: Winner=2, Reward=-37.00, EPSILON=0.984, (W=1818,D=1,L=0)
2025-01-16 11:44:57,410 - INFO - Episode 1820/100000: Winner=2, Reward=12.75, EPSILON=0.984, (W=1819,D=1,L=0)
2025-01-16 11:44:57,675 - INFO - Episode 1821/100000: Winner=2, Reward=20.40, EPSILON=0.984, (W=1820,D=1,L=0)
2025-01-16 11:44:58,019 - INFO - Episode 1822/100000: Winner=2, Reward=-10.40, EPSILON=0.984, (W=1821,D=1,L=0)
2025-01-16 11:44:58,128 - INFO - Episode 1823/100000: Winner=2, Reward=-8.70, EPSILON=0.984, (W=1822,D=1,L=0)
2025-01-16 11:44:58,394 - INFO - Episode 1824/100000: Winner=2, Reward=5.50, EPSILON=0.984, (W=1823,D=1,L=0)
2025-01-16 11:44:58,534 - INFO - Episode 1825/100000: Winner=2, Reward=8.60, EPSILON=0.984, (W=1824,D=1,L=0)
2025-01-16 11:44:58,566 - DEBUG - Q-vals = [8.4859264e-01 3.0678201e-03 9.8156761e-03 1.1117093e-04 1.6407826e-04
 1.3477641e-01 3.4722404e-03], best_act=0, best_val=0.849
2025-01-16 11:44:58,566 - DEBUG - Low Q-value (0.849), using MCTS.
2025-01-16 11:44:58,566 - INFO - Running MCTS with 83 simulations using 6 processes.
2025-01-16 11:45:01,440 - DEBUG - Aggregated action counts: {6: 2, 2: 1, 3: 1, 1: 2, 0: 1}
2025-01-16 11:45:01,440 - DEBUG - Chose best action 6
2025-01-16 11:45:01,456 - DEBUG - Q-vals = [0.30782604 0.03494624 0.12441069 0.13774554 0.10737541 0.21775904
 0.06993704], best_act=0, best_val=0.308
2025-01-16 11:45:01,456 - DEBUG - Low Q-value (0.308), using MCTS.
2025-01-16 11:45:01,456 - INFO - Running MCTS with 83 simulations using 6 processes.
2025-01-16 11:45:04,441 - DEBUG - Aggregated action counts: {4: 3, 2: 1, 0: 2, 5: 1}
2025-01-16 11:45:04,441 - DEBUG - Chose best action 4
2025-01-16 11:45:04,550 - INFO - Episode 1826/100000: Winner=2, Reward=-3.80, EPSILON=0.984, (W=1825,D=1,L=0)
2025-01-16 11:45:04,769 - INFO - Episode 1827/100000: Winner=2, Reward=3.00, EPSILON=0.984, (W=1826,D=1,L=0)
2025-01-16 11:45:04,862 - INFO - Episode 1828/100000: Winner=2, Reward=0.30, EPSILON=0.984, (W=1827,D=1,L=0)
2025-01-16 11:45:04,988 - INFO - Episode 1829/100000: Winner=2, Reward=0.30, EPSILON=0.984, (W=1828,D=1,L=0)
2025-01-16 11:45:05,128 - INFO - Episode 1830/100000: Winner=2, Reward=-4.20, EPSILON=0.984, (W=1829,D=1,L=0)
2025-01-16 11:45:05,206 - DEBUG - Q-vals = [7.2712819e-03 5.3884649e-01 3.2758049e-03 1.6315322e-06 7.4507180e-03
 2.5486583e-01 1.8828829e-01], best_act=1, best_val=0.539
2025-01-16 11:45:05,206 - DEBUG - Low Q-value (0.539), using MCTS.
2025-01-16 11:45:05,222 - INFO - Running MCTS with 83 simulations using 6 processes.
2025-01-16 11:45:08,066 - DEBUG - Aggregated action counts: {3: 1, 4: 3, 5: 1, 0: 2}
2025-01-16 11:45:08,066 - DEBUG - Chose best action 4
2025-01-16 11:45:08,300 - INFO - Episode 1831/100000: Winner=2, Reward=-15.65, EPSILON=0.984, (W=1830,D=1,L=0)
2025-01-16 11:45:08,581 - INFO - Episode 1832/100000: Winner=2, Reward=30.90, EPSILON=0.984, (W=1831,D=1,L=0)
2025-01-16 11:45:08,628 - DEBUG - Q-vals = [0.10898348 0.10970341 0.15053453 0.16955197 0.13436145 0.27723205
 0.04963316], best_act=5, best_val=0.277
2025-01-16 11:45:08,628 - DEBUG - Low Q-value (0.277), using MCTS.
2025-01-16 11:45:08,628 - INFO - Running MCTS with 83 simulations using 6 processes.
2025-01-16 11:45:11,379 - DEBUG - Aggregated action counts: {3: 1, 4: 2, 5: 1, 0: 3}
2025-01-16 11:45:11,379 - DEBUG - Chose best action 0
2025-01-16 11:45:11,535 - INFO - Episode 1833/100000: Winner=2, Reward=27.10, EPSILON=0.984, (W=1832,D=1,L=0)
2025-01-16 11:45:11,738 - INFO - Episode 1834/100000: Winner=2, Reward=9.40, EPSILON=0.984, (W=1833,D=1,L=0)
2025-01-16 11:45:12,019 - INFO - Episode 1835/100000: Winner=2, Reward=-20.75, EPSILON=0.984, (W=1834,D=1,L=0)
2025-01-16 11:45:12,191 - INFO - Episode 1836/100000: Winner=2, Reward=6.80, EPSILON=0.984, (W=1835,D=1,L=0)
2025-01-16 11:45:12,347 - INFO - Episode 1837/100000: Winner=2, Reward=5.00, EPSILON=0.984, (W=1836,D=1,L=0)
2025-01-16 11:45:12,550 - INFO - Episode 1838/100000: Winner=2, Reward=1.65, EPSILON=0.984, (W=1837,D=1,L=0)
2025-01-16 11:45:12,863 - DEBUG - Q-vals = [9.0803625e-04 4.8558367e-04 6.5440858e-05 6.7213075e-09 5.6238939e-08
 5.0991653e-03 9.9344170e-01], best_act=6, best_val=0.993
2025-01-16 11:45:12,863 - DEBUG - Low Q-value (0.993), using MCTS.
2025-01-16 11:45:12,879 - INFO - Episode 1839/100000: Winner=2, Reward=-10.40, EPSILON=0.984, (W=1838,D=1,L=0)
2025-01-16 11:45:13,003 - INFO - Episode 1840/100000: Winner=2, Reward=-1.90, EPSILON=0.984, (W=1839,D=1,L=0)
2025-01-16 11:45:13,160 - INFO - Episode 1841/100000: Winner=2, Reward=-5.70, EPSILON=0.984, (W=1840,D=1,L=0)
2025-01-16 11:45:13,316 - INFO - Episode 1842/100000: Winner=2, Reward=3.70, EPSILON=0.984, (W=1841,D=1,L=0)
2025-01-16 11:45:13,597 - INFO - Episode 1843/100000: Winner=2, Reward=-1.00, EPSILON=0.984, (W=1842,D=1,L=0)
2025-01-16 11:45:13,847 - INFO - Episode 1844/100000: Winner=2, Reward=9.45, EPSILON=0.984, (W=1843,D=1,L=0)
2025-01-16 11:45:14,066 - INFO - Episode 1845/100000: Winner=2, Reward=20.10, EPSILON=0.984, (W=1844,D=1,L=0)
2025-01-16 11:45:14,284 - DEBUG - Q-vals = [4.1734722e-02 1.7171015e-01 6.1719432e-03 9.4416400e-06 6.7419922e-01
 5.8022331e-02 4.8152138e-02], best_act=4, best_val=0.674
2025-01-16 11:45:14,284 - DEBUG - Low Q-value (0.674), using MCTS.
2025-01-16 11:45:14,284 - INFO - Running MCTS with 83 simulations using 6 processes.
2025-01-16 11:45:17,206 - DEBUG - Aggregated action counts: {0: 3, 4: 1, 1: 2, 5: 1}
2025-01-16 11:45:17,206 - DEBUG - Chose best action 0
2025-01-16 11:45:17,269 - INFO - Episode 1846/100000: Winner=2, Reward=9.90, EPSILON=0.984, (W=1845,D=1,L=0)
2025-01-16 11:45:17,378 - INFO - Episode 1847/100000: Winner=2, Reward=-5.40, EPSILON=0.984, (W=1846,D=1,L=0)
2025-01-16 11:45:17,628 - DEBUG - Q-vals = [0.5877959  0.02489358 0.00850367 0.00153978 0.22836152 0.09196683
 0.05693873], best_act=0, best_val=0.588
2025-01-16 11:45:17,628 - DEBUG - Low Q-value (0.588), using MCTS.
2025-01-16 11:45:17,644 - INFO - Episode 1848/100000: Winner=2, Reward=-2.15, EPSILON=0.984, (W=1847,D=1,L=0)
2025-01-16 11:45:17,925 - INFO - Episode 1849/100000: Winner=2, Reward=-0.05, EPSILON=0.983, (W=1848,D=1,L=0)
2025-01-16 11:45:18,191 - INFO - Episode 1850/100000: Winner=2, Reward=2.15, EPSILON=0.983, (W=1849,D=1,L=0)
2025-01-16 11:45:18,378 - INFO - Episode 1851/100000: Winner=2, Reward=-7.80, EPSILON=0.983, (W=1850,D=1,L=0)
2025-01-16 11:45:18,409 - DEBUG - Q-vals = [0.09757066 0.07432319 0.09482612 0.42599073 0.18794473 0.08498472
 0.03436   ], best_act=3, best_val=0.426
2025-01-16 11:45:18,409 - DEBUG - Low Q-value (0.426), using MCTS.
2025-01-16 11:45:18,409 - INFO - Running MCTS with 84 simulations using 6 processes.
2025-01-16 11:45:21,331 - DEBUG - Aggregated action counts: {1: 1, 2: 2, 5: 2, 4: 1}
2025-01-16 11:45:21,331 - DEBUG - Chose best action 2
2025-01-16 11:45:21,800 - INFO - Episode 1852/100000: Winner=2, Reward=3.55, EPSILON=0.983, (W=1851,D=1,L=0)
2025-01-16 11:45:21,987 - INFO - Episode 1853/100000: Winner=2, Reward=-1.85, EPSILON=0.983, (W=1852,D=1,L=0)
2025-01-16 11:45:22,034 - DEBUG - Q-vals = [0.2302     0.1550728  0.13517462 0.3168231  0.05836498 0.02369118
 0.08067335], best_act=3, best_val=0.317
2025-01-16 11:45:22,034 - DEBUG - Low Q-value (0.317), using MCTS.
2025-01-16 11:45:22,034 - INFO - Running MCTS with 84 simulations using 6 processes.
2025-01-16 11:45:24,862 - DEBUG - Aggregated action counts: {3: 1, 5: 1, 0: 1, 2: 1, 1: 2}
2025-01-16 11:45:24,862 - DEBUG - Chose best action 1
2025-01-16 11:45:24,909 - INFO - Episode 1854/100000: Winner=2, Reward=0.60, EPSILON=0.983, (W=1853,D=1,L=0)
2025-01-16 11:45:24,987 - DEBUG - Q-vals = [0.09309535 0.1852457  0.09217148 0.25258297 0.22286119 0.06239668
 0.09164663], best_act=3, best_val=0.253
2025-01-16 11:45:24,987 - DEBUG - Low Q-value (0.253), using MCTS.
2025-01-16 11:45:24,987 - INFO - Running MCTS with 84 simulations using 6 processes.
2025-01-16 11:45:27,737 - DEBUG - Aggregated action counts: {6: 2, 0: 4}
2025-01-16 11:45:27,737 - DEBUG - Chose best action 0
2025-01-16 11:45:27,909 - INFO - Episode 1855/100000: Winner=2, Reward=-7.55, EPSILON=0.983, (W=1854,D=1,L=0)
2025-01-16 11:45:28,159 - INFO - Episode 1856/100000: Winner=2, Reward=8.45, EPSILON=0.983, (W=1855,D=1,L=0)
2025-01-16 11:45:28,502 - INFO - Episode 1857/100000: Winner=2, Reward=-20.70, EPSILON=0.983, (W=1856,D=1,L=0)
2025-01-16 11:45:28,721 - INFO - Episode 1858/100000: Winner=2, Reward=-0.05, EPSILON=0.983, (W=1857,D=1,L=0)
2025-01-16 11:45:28,940 - INFO - Episode 1859/100000: Winner=2, Reward=-2.70, EPSILON=0.983, (W=1858,D=1,L=0)
2025-01-16 11:45:29,158 - INFO - Episode 1860/100000: Winner=2, Reward=-13.35, EPSILON=0.983, (W=1859,D=1,L=0)
2025-01-16 11:45:29,221 - DEBUG - Q-vals = [0.07136551 0.21346807 0.15046565 0.243037   0.11604065 0.14179008
 0.06383292], best_act=3, best_val=0.243
2025-01-16 11:45:29,221 - DEBUG - Low Q-value (0.243), using MCTS.
2025-01-16 11:45:29,221 - INFO - Running MCTS with 84 simulations using 6 processes.
2025-01-16 11:45:32,424 - DEBUG - Aggregated action counts: {1: 2, 2: 2, 5: 1, 0: 1}
2025-01-16 11:45:32,424 - DEBUG - Chose best action 1
2025-01-16 11:45:32,627 - INFO - Episode 1861/100000: Winner=2, Reward=29.95, EPSILON=0.983, (W=1860,D=1,L=0)
2025-01-16 11:45:32,877 - INFO - Episode 1862/100000: Winner=2, Reward=2.35, EPSILON=0.983, (W=1861,D=1,L=0)
2025-01-16 11:45:33,064 - INFO - Episode 1863/100000: Winner=2, Reward=10.65, EPSILON=0.983, (W=1862,D=1,L=0)
2025-01-16 11:45:33,267 - INFO - Episode 1864/100000: Winner=2, Reward=-0.10, EPSILON=0.983, (W=1863,D=1,L=0)
2025-01-16 11:45:33,439 - DEBUG - Q-vals = [0.20063989 0.01011939 0.04202073 0.3802251  0.0232971  0.23801322
 0.10568462], best_act=3, best_val=0.380
2025-01-16 11:45:33,439 - DEBUG - Low Q-value (0.380), using MCTS.
2025-01-16 11:45:33,439 - INFO - Running MCTS with 84 simulations using 6 processes.
2025-01-16 11:45:36,455 - DEBUG - Aggregated action counts: {0: 1, 4: 1, 1: 4}
2025-01-16 11:45:36,455 - DEBUG - Chose best action 1
2025-01-16 11:45:36,517 - INFO - Episode 1865/100000: Winner=2, Reward=-12.05, EPSILON=0.983, (W=1864,D=1,L=0)
2025-01-16 11:45:36,721 - INFO - Episode 1866/100000: Winner=2, Reward=8.10, EPSILON=0.983, (W=1865,D=1,L=0)
2025-01-16 11:45:36,939 - INFO - Episode 1867/100000: Winner=2, Reward=18.75, EPSILON=0.983, (W=1866,D=1,L=0)
2025-01-16 11:45:37,049 - INFO - Episode 1868/100000: Winner=2, Reward=3.25, EPSILON=0.983, (W=1867,D=1,L=0)
2025-01-16 11:45:37,142 - DEBUG - Q-vals = [0.05845941 0.15574759 0.06306013 0.26213434 0.32208222 0.05651466
 0.08200171], best_act=4, best_val=0.322
2025-01-16 11:45:37,142 - DEBUG - Low Q-value (0.322), using MCTS.
2025-01-16 11:45:37,142 - INFO - Running MCTS with 84 simulations using 6 processes.
2025-01-16 11:45:40,002 - DEBUG - Aggregated action counts: {6: 1, 0: 3, 4: 1, 5: 1}
2025-01-16 11:45:40,002 - DEBUG - Chose best action 0
2025-01-16 11:45:40,127 - INFO - Episode 1869/100000: Winner=2, Reward=6.05, EPSILON=0.983, (W=1868,D=1,L=0)
2025-01-16 11:45:40,314 - DEBUG - Q-vals = [0.09009424 0.10824926 0.07400553 0.529443   0.04234116 0.10429449
 0.05157233], best_act=3, best_val=0.529
2025-01-16 11:45:40,314 - DEBUG - Low Q-value (0.529), using MCTS.
2025-01-16 11:45:40,314 - INFO - Running MCTS with 84 simulations using 6 processes.
2025-01-16 11:45:43,064 - DEBUG - Aggregated action counts: {5: 1, 0: 2, 2: 1, 1: 2}
2025-01-16 11:45:43,064 - DEBUG - Chose best action 0
2025-01-16 11:45:43,080 - INFO - Episode 1870/100000: Winner=2, Reward=10.65, EPSILON=0.983, (W=1869,D=1,L=0)
2025-01-16 11:45:43,377 - INFO - Episode 1871/100000: Winner=2, Reward=-10.90, EPSILON=0.983, (W=1870,D=1,L=0)
2025-01-16 11:45:43,580 - INFO - Episode 1872/100000: Winner=2, Reward=15.55, EPSILON=0.983, (W=1871,D=1,L=0)
2025-01-16 11:45:43,877 - INFO - Episode 1873/100000: Winner=2, Reward=11.00, EPSILON=0.983, (W=1872,D=1,L=0)
2025-01-16 11:45:43,955 - INFO - Episode 1874/100000: Winner=2, Reward=0.70, EPSILON=0.983, (W=1873,D=1,L=0)
2025-01-16 11:45:44,174 - INFO - Episode 1875/100000: Winner=2, Reward=-6.30, EPSILON=0.983, (W=1874,D=1,L=0)
2025-01-16 11:45:44,361 - INFO - Episode 1876/100000: Winner=2, Reward=18.75, EPSILON=0.983, (W=1875,D=1,L=0)
2025-01-16 11:45:44,595 - INFO - Episode 1877/100000: Winner=2, Reward=-10.40, EPSILON=0.983, (W=1876,D=1,L=0)
2025-01-16 11:45:44,689 - INFO - Episode 1878/100000: Winner=2, Reward=8.65, EPSILON=0.983, (W=1877,D=1,L=0)
2025-01-16 11:45:44,986 - INFO - Episode 1879/100000: Winner=2, Reward=37.05, EPSILON=0.983, (W=1878,D=1,L=0)
2025-01-16 11:45:45,236 - INFO - Episode 1880/100000: Winner=2, Reward=22.20, EPSILON=0.983, (W=1879,D=1,L=0)
2025-01-16 11:45:45,423 - INFO - Episode 1881/100000: Winner=2, Reward=-3.70, EPSILON=0.983, (W=1880,D=1,L=0)
2025-01-16 11:45:45,611 - INFO - Episode 1882/100000: Winner=2, Reward=-8.95, EPSILON=0.983, (W=1881,D=1,L=0)
2025-01-16 11:45:45,767 - INFO - Episode 1883/100000: Winner=2, Reward=5.85, EPSILON=0.983, (W=1882,D=1,L=0)
2025-01-16 11:45:45,845 - INFO - Episode 1884/100000: Winner=2, Reward=0.75, EPSILON=0.983, (W=1883,D=1,L=0)
2025-01-16 11:45:46,095 - INFO - Episode 1885/100000: Winner=2, Reward=-20.75, EPSILON=0.983, (W=1884,D=1,L=0)
2025-01-16 11:45:46,314 - INFO - Episode 1886/100000: Winner=2, Reward=0.65, EPSILON=0.983, (W=1885,D=1,L=0)
2025-01-16 11:45:46,423 - INFO - Episode 1887/100000: Winner=2, Reward=3.60, EPSILON=0.983, (W=1886,D=1,L=0)
2025-01-16 11:45:46,720 - INFO - Episode 1888/100000: Winner=2, Reward=-2.00, EPSILON=0.983, (W=1887,D=1,L=0)
2025-01-16 11:45:46,892 - INFO - Episode 1889/100000: Winner=2, Reward=4.80, EPSILON=0.983, (W=1888,D=1,L=0)
2025-01-16 11:45:47,048 - INFO - Episode 1890/100000: Winner=2, Reward=3.95, EPSILON=0.983, (W=1889,D=1,L=0)
2025-01-16 11:45:47,204 - INFO - Episode 1891/100000: Winner=2, Reward=-8.75, EPSILON=0.983, (W=1890,D=1,L=0)
2025-01-16 11:45:47,407 - INFO - Episode 1892/100000: Winner=2, Reward=14.95, EPSILON=0.983, (W=1891,D=1,L=0)
2025-01-16 11:45:47,673 - INFO - Episode 1893/100000: Winner=2, Reward=12.60, EPSILON=0.983, (W=1892,D=1,L=0)
2025-01-16 11:45:47,751 - INFO - Episode 1894/100000: Winner=2, Reward=8.30, EPSILON=0.983, (W=1893,D=1,L=0)
2025-01-16 11:45:47,969 - INFO - Episode 1895/100000: Winner=2, Reward=2.15, EPSILON=0.983, (W=1894,D=1,L=0)
2025-01-16 11:45:48,016 - DEBUG - Q-vals = [0.06219004 0.09342742 0.1178785  0.13666427 0.3222811  0.18332647
 0.08423223], best_act=4, best_val=0.322
2025-01-16 11:45:48,016 - DEBUG - Low Q-value (0.322), using MCTS.
2025-01-16 11:45:48,016 - INFO - Running MCTS with 85 simulations using 6 processes.
2025-01-16 11:45:50,907 - DEBUG - Aggregated action counts: {0: 1, 6: 1, 1: 1, 3: 3, 5: 1}
2025-01-16 11:45:50,907 - DEBUG - Chose best action 3
2025-01-16 11:45:51,173 - INFO - Episode 1896/100000: Winner=2, Reward=35.70, EPSILON=0.983, (W=1895,D=1,L=0)
2025-01-16 11:45:51,344 - INFO - Episode 1897/100000: Winner=2, Reward=0.05, EPSILON=0.983, (W=1896,D=1,L=0)
2025-01-16 11:45:51,501 - INFO - Episode 1898/100000: Winner=2, Reward=-3.85, EPSILON=0.983, (W=1897,D=1,L=0)
2025-01-16 11:45:51,672 - INFO - Episode 1899/100000: Winner=2, Reward=5.70, EPSILON=0.983, (W=1898,D=1,L=0)
2025-01-16 11:45:51,907 - DEBUG - Q-vals = [1.9714119e-02 2.1356142e-01 5.8181893e-02 4.2257039e-04 7.7075362e-03
 1.9009766e-01 5.1031476e-01], best_act=6, best_val=0.510
2025-01-16 11:45:51,907 - DEBUG - Low Q-value (0.510), using MCTS.
2025-01-16 11:45:51,907 - INFO - Running MCTS with 86 simulations using 6 processes.
2025-01-16 11:45:54,798 - DEBUG - Aggregated action counts: {4: 2, 0: 5}
2025-01-16 11:45:54,798 - DEBUG - Chose best action 0
2025-01-16 11:45:54,923 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1900.
2025-01-16 11:45:54,923 - INFO - Models saved at episode 1900
2025-01-16 11:45:54,923 - INFO - Target networks updated
2025-01-16 11:45:54,970 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 1900.
2025-01-16 11:45:54,970 - INFO - Episode 1900/100000: Winner=2, Reward=-13.90, EPSILON=0.983, (W=1899,D=1,L=0)
2025-01-16 11:45:55,017 - DEBUG - Q-vals = [0.07991539 0.14943379 0.10484622 0.2878056  0.18458208 0.113747
 0.07966991], best_act=3, best_val=0.288
2025-01-16 11:45:55,017 - DEBUG - Low Q-value (0.288), using MCTS.
2025-01-16 11:45:55,017 - INFO - Running MCTS with 86 simulations using 6 processes.
2025-01-16 11:45:57,719 - DEBUG - Aggregated action counts: {1: 1, 2: 2, 3: 2, 0: 2}
2025-01-16 11:45:57,719 - DEBUG - Chose best action 2
2025-01-16 11:45:58,001 - INFO - Episode 1901/100000: Winner=2, Reward=-7.35, EPSILON=0.983, (W=1900,D=1,L=0)
2025-01-16 11:45:58,141 - INFO - Episode 1902/100000: Winner=2, Reward=2.60, EPSILON=0.983, (W=1901,D=1,L=0)
2025-01-16 11:45:58,329 - INFO - Episode 1903/100000: Winner=2, Reward=2.90, EPSILON=0.983, (W=1902,D=1,L=0)
2025-01-16 11:45:58,407 - DEBUG - Q-vals = [0.04976561 0.04223924 0.2771455  0.3708999  0.04076676 0.15597421
 0.06320876], best_act=3, best_val=0.371
2025-01-16 11:45:58,407 - DEBUG - Low Q-value (0.371), using MCTS.
2025-01-16 11:45:58,407 - INFO - Running MCTS with 86 simulations using 6 processes.
2025-01-16 11:46:01,094 - DEBUG - Aggregated action counts: {1: 2, 2: 2, 0: 2, 3: 1}
2025-01-16 11:46:01,094 - DEBUG - Chose best action 1
2025-01-16 11:46:01,172 - INFO - Episode 1904/100000: Winner=2, Reward=15.95, EPSILON=0.983, (W=1903,D=1,L=0)
2025-01-16 11:46:01,469 - INFO - Episode 1905/100000: Winner=2, Reward=12.15, EPSILON=0.983, (W=1904,D=1,L=0)
2025-01-16 11:46:01,672 - INFO - Episode 1906/100000: Winner=2, Reward=24.10, EPSILON=0.983, (W=1905,D=1,L=0)
2025-01-16 11:46:01,688 - DEBUG - Q-vals = [0.08870169 0.017667   0.05645411 0.06629702 0.26365262 0.4050386
 0.10218892], best_act=5, best_val=0.405
2025-01-16 11:46:01,688 - DEBUG - Low Q-value (0.405), using MCTS.
2025-01-16 11:46:01,688 - INFO - Running MCTS with 86 simulations using 6 processes.
2025-01-16 11:46:04,547 - DEBUG - Aggregated action counts: {6: 2, 3: 1, 1: 2, 0: 2}
2025-01-16 11:46:04,547 - DEBUG - Chose best action 6
2025-01-16 11:46:04,687 - INFO - Episode 1907/100000: Winner=2, Reward=18.65, EPSILON=0.983, (W=1906,D=1,L=0)
2025-01-16 11:46:05,031 - INFO - Episode 1908/100000: Winner=2, Reward=-13.35, EPSILON=0.983, (W=1907,D=1,L=0)
2025-01-16 11:46:05,219 - INFO - Episode 1909/100000: Winner=2, Reward=16.30, EPSILON=0.983, (W=1908,D=1,L=0)
2025-01-16 11:46:05,453 - INFO - Episode 1910/100000: Winner=2, Reward=20.70, EPSILON=0.983, (W=1909,D=1,L=0)
2025-01-16 11:46:05,547 - DEBUG - Q-vals = [0.08743667 0.05971175 0.07512194 0.08967575 0.6066333  0.01697399
 0.06444655], best_act=4, best_val=0.607
2025-01-16 11:46:05,547 - DEBUG - Low Q-value (0.607), using MCTS.
2025-01-16 11:46:05,547 - INFO - Running MCTS with 86 simulations using 6 processes.
2025-01-16 11:46:08,296 - DEBUG - Aggregated action counts: {0: 4, 4: 1, 5: 1, 2: 1}
2025-01-16 11:46:08,296 - DEBUG - Chose best action 0
2025-01-16 11:46:08,562 - DEBUG - Q-vals = [0.08949943 0.28542638 0.1264197  0.19312105 0.18166558 0.0277296
 0.09613816], best_act=1, best_val=0.285
2025-01-16 11:46:08,562 - DEBUG - Low Q-value (0.285), using MCTS.
2025-01-16 11:46:08,562 - INFO - Running MCTS with 86 simulations using 6 processes.
2025-01-16 11:46:11,234 - DEBUG - Aggregated action counts: {5: 1, 1: 3, 0: 3}
2025-01-16 11:46:11,234 - DEBUG - Chose best action 1
2025-01-16 11:46:11,312 - INFO - Episode 1911/100000: Winner=2, Reward=10.25, EPSILON=0.983, (W=1910,D=1,L=0)
2025-01-16 11:46:11,500 - INFO - Episode 1912/100000: Winner=2, Reward=-10.30, EPSILON=0.983, (W=1911,D=1,L=0)
2025-01-16 11:46:11,593 - INFO - Episode 1913/100000: Winner=2, Reward=-7.45, EPSILON=0.983, (W=1912,D=1,L=0)
2025-01-16 11:46:11,718 - INFO - Episode 1914/100000: Winner=2, Reward=-5.85, EPSILON=0.983, (W=1913,D=1,L=0)
2025-01-16 11:46:11,781 - DEBUG - Q-vals = [0.07363749 0.11812775 0.16164237 0.11099382 0.08378972 0.22433946
 0.22746931], best_act=6, best_val=0.227
2025-01-16 11:46:11,781 - DEBUG - Low Q-value (0.227), using MCTS.
2025-01-16 11:46:11,781 - INFO - Running MCTS with 86 simulations using 6 processes.
2025-01-16 11:46:14,593 - DEBUG - Aggregated action counts: {1: 2, 0: 3, 4: 1, 2: 1}
2025-01-16 11:46:14,593 - DEBUG - Chose best action 0
2025-01-16 11:46:14,687 - INFO - Episode 1915/100000: Winner=2, Reward=5.40, EPSILON=0.983, (W=1914,D=1,L=0)
2025-01-16 11:46:14,828 - INFO - Episode 1916/100000: Winner=2, Reward=0.60, EPSILON=0.983, (W=1915,D=1,L=0)
2025-01-16 11:46:14,984 - INFO - Episode 1917/100000: Winner=2, Reward=-7.05, EPSILON=0.983, (W=1916,D=1,L=0)
2025-01-16 11:46:15,140 - INFO - Episode 1918/100000: Winner=2, Reward=-5.55, EPSILON=0.983, (W=1917,D=1,L=0)
2025-01-16 11:46:15,343 - INFO - Episode 1919/100000: Winner=2, Reward=-12.45, EPSILON=0.983, (W=1918,D=1,L=0)
2025-01-16 11:46:15,499 - INFO - Episode 1920/100000: Winner=2, Reward=16.50, EPSILON=0.983, (W=1919,D=1,L=0)
2025-01-16 11:46:15,609 - INFO - Episode 1921/100000: Winner=2, Reward=-2.40, EPSILON=0.983, (W=1920,D=1,L=0)
2025-01-16 11:46:15,640 - DEBUG - Q-vals = [0.4068565  0.11082137 0.02332118 0.11939757 0.05287423 0.27285215
 0.01387701], best_act=0, best_val=0.407
2025-01-16 11:46:15,640 - DEBUG - Low Q-value (0.407), using MCTS.
2025-01-16 11:46:15,640 - INFO - Running MCTS with 86 simulations using 6 processes.
2025-01-16 11:46:18,421 - DEBUG - Aggregated action counts: {0: 4, 1: 2, 3: 1}
2025-01-16 11:46:18,421 - DEBUG - Chose best action 0
2025-01-16 11:46:18,578 - INFO - Episode 1922/100000: Winner=2, Reward=25.30, EPSILON=0.983, (W=1921,D=1,L=0)
2025-01-16 11:46:18,827 - INFO - Episode 1923/100000: Winner=2, Reward=19.25, EPSILON=0.983, (W=1922,D=1,L=0)
2025-01-16 11:46:19,077 - INFO - Episode 1924/100000: Winner=2, Reward=-5.05, EPSILON=0.983, (W=1923,D=1,L=0)
2025-01-16 11:46:19,343 - INFO - Episode 1925/100000: Winner=2, Reward=-0.85, EPSILON=0.983, (W=1924,D=1,L=0)
2025-01-16 11:46:19,359 - DEBUG - Q-vals = [0.7156226  0.03726661 0.0301579  0.06994637 0.08627509 0.04638851
 0.01434308], best_act=0, best_val=0.716
2025-01-16 11:46:19,359 - DEBUG - Low Q-value (0.716), using MCTS.
2025-01-16 11:46:19,359 - INFO - Running MCTS with 87 simulations using 6 processes.
2025-01-16 11:46:22,375 - DEBUG - Aggregated action counts: {4: 1, 1: 1, 0: 3, 6: 1, 3: 1}
2025-01-16 11:46:22,375 - DEBUG - Chose best action 0
2025-01-16 11:46:22,484 - INFO - Episode 1926/100000: Winner=2, Reward=-5.05, EPSILON=0.983, (W=1925,D=1,L=0)
2025-01-16 11:46:22,859 - INFO - Episode 1927/100000: Winner=2, Reward=1.00, EPSILON=0.983, (W=1926,D=1,L=0)
2025-01-16 11:46:23,141 - INFO - Episode 1928/100000: Winner=2, Reward=1.65, EPSILON=0.983, (W=1927,D=1,L=0)
2025-01-16 11:46:23,375 - INFO - Episode 1929/100000: Winner=2, Reward=32.05, EPSILON=0.983, (W=1928,D=1,L=0)
2025-01-16 11:46:23,469 - INFO - Episode 1930/100000: Winner=2, Reward=8.90, EPSILON=0.983, (W=1929,D=1,L=0)
2025-01-16 11:46:23,812 - DEBUG - Q-vals = [6.3268709e-01 6.3225273e-03 3.3473468e-03 1.4712807e-02 2.4789453e-01
 2.6860875e-05 9.5008969e-02], best_act=6, best_val=0.095
2025-01-16 11:46:23,812 - DEBUG - Low Q-value (0.095), using MCTS.
2025-01-16 11:46:23,812 - INFO - Running MCTS with 87 simulations using 6 processes.
2025-01-16 11:46:27,186 - DEBUG - Aggregated action counts: {5: 4, 2: 3}
2025-01-16 11:46:27,186 - DEBUG - Chose best action 5
2025-01-16 11:46:27,218 - INFO - Episode 1931/100000: Winner=2, Reward=-18.75, EPSILON=0.983, (W=1930,D=1,L=0)
2025-01-16 11:46:27,546 - INFO - Episode 1932/100000: Winner=2, Reward=-23.75, EPSILON=0.983, (W=1931,D=1,L=0)
2025-01-16 11:46:27,671 - DEBUG - Q-vals = [0.07375028 0.12501514 0.23195018 0.15065244 0.1726096  0.13871396
 0.10730848], best_act=2, best_val=0.232
2025-01-16 11:46:27,671 - DEBUG - Low Q-value (0.232), using MCTS.
2025-01-16 11:46:27,671 - INFO - Running MCTS with 87 simulations using 6 processes.
2025-01-16 11:46:30,765 - DEBUG - Aggregated action counts: {3: 2, 1: 3, 2: 1, 0: 1}
2025-01-16 11:46:30,765 - DEBUG - Chose best action 1
2025-01-16 11:46:30,843 - INFO - Episode 1933/100000: Winner=2, Reward=21.40, EPSILON=0.983, (W=1932,D=1,L=0)
2025-01-16 11:46:31,186 - INFO - Episode 1934/100000: Winner=2, Reward=-23.00, EPSILON=0.983, (W=1933,D=1,L=0)
2025-01-16 11:46:31,327 - INFO - Episode 1935/100000: Winner=2, Reward=14.25, EPSILON=0.983, (W=1934,D=1,L=0)
2025-01-16 11:46:31,514 - INFO - Episode 1936/100000: Winner=2, Reward=12.40, EPSILON=0.983, (W=1935,D=1,L=0)
2025-01-16 11:46:31,655 - INFO - Episode 1937/100000: Winner=2, Reward=-5.60, EPSILON=0.983, (W=1936,D=1,L=0)
2025-01-16 11:46:31,874 - INFO - Episode 1938/100000: Winner=2, Reward=2.45, EPSILON=0.983, (W=1937,D=1,L=0)
2025-01-16 11:46:32,108 - INFO - Episode 1939/100000: Winner=2, Reward=16.50, EPSILON=0.983, (W=1938,D=1,L=0)
2025-01-16 11:46:32,233 - INFO - Episode 1940/100000: Winner=2, Reward=14.90, EPSILON=0.983, (W=1939,D=1,L=0)
2025-01-16 11:46:32,249 - DEBUG - Q-vals = [9.9902821e-01 1.6252705e-04 3.6547492e-06 4.3466463e-04 4.3880271e-05
 3.1925208e-04 7.7752575e-06], best_act=0, best_val=0.999
2025-01-16 11:46:32,249 - DEBUG - Low Q-value (0.999), using MCTS.
2025-01-16 11:46:32,249 - INFO - Running MCTS with 87 simulations using 6 processes.
2025-01-16 11:46:35,171 - DEBUG - Aggregated action counts: {1: 3, 2: 1, 3: 1, 4: 1, 0: 1}
2025-01-16 11:46:35,171 - DEBUG - Chose best action 1
2025-01-16 11:46:35,233 - INFO - Episode 1941/100000: Winner=2, Reward=17.60, EPSILON=0.983, (W=1940,D=1,L=0)
2025-01-16 11:46:35,436 - INFO - Episode 1942/100000: Winner=2, Reward=0.85, EPSILON=0.983, (W=1941,D=1,L=0)
2025-01-16 11:46:35,624 - INFO - Episode 1943/100000: Winner=2, Reward=-14.80, EPSILON=0.983, (W=1942,D=1,L=0)
2025-01-16 11:46:35,749 - INFO - Episode 1944/100000: Winner=2, Reward=-5.90, EPSILON=0.983, (W=1943,D=1,L=0)
2025-01-16 11:46:35,811 - INFO - Episode 1945/100000: Winner=2, Reward=0.25, EPSILON=0.983, (W=1944,D=1,L=0)
2025-01-16 11:46:36,046 - INFO - Episode 1946/100000: Winner=2, Reward=-4.90, EPSILON=0.983, (W=1945,D=1,L=0)
2025-01-16 11:46:36,265 - INFO - Episode 1947/100000: Winner=2, Reward=16.60, EPSILON=0.983, (W=1946,D=1,L=0)
2025-01-16 11:46:36,406 - INFO - Episode 1948/100000: Winner=2, Reward=-9.30, EPSILON=0.983, (W=1947,D=1,L=0)
2025-01-16 11:46:36,640 - INFO - Episode 1949/100000: Winner=2, Reward=-2.40, EPSILON=0.983, (W=1948,D=1,L=0)
2025-01-16 11:46:36,796 - INFO - Episode 1950/100000: Winner=2, Reward=11.00, EPSILON=0.983, (W=1949,D=1,L=0)
2025-01-16 11:46:36,921 - INFO - Episode 1951/100000: Winner=2, Reward=-4.55, EPSILON=0.983, (W=1950,D=1,L=0)
2025-01-16 11:46:37,124 - INFO - Episode 1952/100000: Winner=2, Reward=-12.50, EPSILON=0.983, (W=1951,D=1,L=0)
2025-01-16 11:46:37,187 - INFO - Episode 1953/100000: Winner=2, Reward=0.70, EPSILON=0.983, (W=1952,D=1,L=0)
2025-01-16 11:46:37,265 - INFO - Episode 1954/100000: Winner=2, Reward=0.70, EPSILON=0.983, (W=1953,D=1,L=0)
2025-01-16 11:46:37,437 - INFO - Episode 1955/100000: Winner=2, Reward=-3.70, EPSILON=0.983, (W=1954,D=1,L=0)
2025-01-16 11:46:37,640 - INFO - Episode 1956/100000: Winner=2, Reward=-7.40, EPSILON=0.983, (W=1955,D=1,L=0)
2025-01-16 11:46:37,890 - INFO - Episode 1957/100000: Winner=2, Reward=-7.10, EPSILON=0.983, (W=1956,D=1,L=0)
2025-01-16 11:46:38,108 - INFO - Episode 1958/100000: Winner=2, Reward=-3.20, EPSILON=0.983, (W=1957,D=1,L=0)
2025-01-16 11:46:38,280 - INFO - Episode 1959/100000: Winner=2, Reward=4.70, EPSILON=0.983, (W=1958,D=1,L=0)
2025-01-16 11:46:38,530 - INFO - Episode 1960/100000: Winner=2, Reward=0.75, EPSILON=0.983, (W=1959,D=1,L=0)
2025-01-16 11:46:38,655 - INFO - Episode 1961/100000: Winner=2, Reward=16.20, EPSILON=0.983, (W=1960,D=1,L=0)
2025-01-16 11:46:38,858 - INFO - Episode 1962/100000: Winner=2, Reward=4.25, EPSILON=0.982, (W=1961,D=1,L=0)
2025-01-16 11:46:39,061 - INFO - Episode 1963/100000: Winner=2, Reward=28.25, EPSILON=0.982, (W=1962,D=1,L=0)
2025-01-16 11:46:39,186 - INFO - Episode 1964/100000: Winner=2, Reward=2.00, EPSILON=0.982, (W=1963,D=1,L=0)
2025-01-16 11:46:39,311 - INFO - Episode 1965/100000: Winner=2, Reward=10.75, EPSILON=0.982, (W=1964,D=1,L=0)
2025-01-16 11:46:39,421 - INFO - Episode 1966/100000: Winner=2, Reward=9.95, EPSILON=0.982, (W=1965,D=1,L=0)
2025-01-16 11:46:39,530 - DEBUG - Q-vals = [0.02790836 0.08296296 0.08441148 0.66933    0.06997504 0.03127931
 0.03413291], best_act=3, best_val=0.669
2025-01-16 11:46:39,530 - DEBUG - Low Q-value (0.669), using MCTS.
2025-01-16 11:46:39,530 - INFO - Running MCTS with 88 simulations using 6 processes.
2025-01-16 11:46:42,457 - DEBUG - Aggregated action counts: {5: 1, 1: 1, 2: 1, 3: 1, 6: 1, 4: 1, 0: 1}
2025-01-16 11:46:42,457 - DEBUG - Chose best action 5
2025-01-16 11:46:42,582 - INFO - Episode 1967/100000: Winner=2, Reward=-1.00, EPSILON=0.982, (W=1966,D=1,L=0)
2025-01-16 11:46:42,786 - INFO - Episode 1968/100000: Winner=2, Reward=13.65, EPSILON=0.982, (W=1967,D=1,L=0)
2025-01-16 11:46:42,979 - INFO - Episode 1969/100000: Winner=2, Reward=17.65, EPSILON=0.982, (W=1968,D=1,L=0)
2025-01-16 11:46:43,290 - INFO - Episode 1970/100000: Winner=2, Reward=-19.90, EPSILON=0.982, (W=1969,D=1,L=0)
2025-01-16 11:46:43,516 - INFO - Episode 1971/100000: Winner=2, Reward=5.90, EPSILON=0.982, (W=1970,D=1,L=0)
2025-01-16 11:46:43,739 - INFO - Episode 1972/100000: Winner=2, Reward=5.00, EPSILON=0.982, (W=1971,D=1,L=0)
2025-01-16 11:46:43,895 - DEBUG - Q-vals = [0.05570775 0.00649415 0.06154231 0.2512307  0.11768771 0.46692398
 0.04041343], best_act=5, best_val=0.467
2025-01-16 11:46:43,895 - DEBUG - Low Q-value (0.467), using MCTS.
2025-01-16 11:46:43,895 - INFO - Running MCTS with 88 simulations using 6 processes.
2025-01-16 11:46:46,645 - DEBUG - Aggregated action counts: {1: 4, 0: 3}
2025-01-16 11:46:46,645 - DEBUG - Chose best action 1
2025-01-16 11:46:46,741 - INFO - Episode 1973/100000: Winner=2, Reward=-15.40, EPSILON=0.982, (W=1972,D=1,L=0)
2025-01-16 11:46:46,864 - DEBUG - Q-vals = [0.08275138 0.08404651 0.1759153  0.12137837 0.29459593 0.1699967
 0.07131574], best_act=4, best_val=0.295
2025-01-16 11:46:46,864 - DEBUG - Low Q-value (0.295), using MCTS.
2025-01-16 11:46:46,864 - INFO - Running MCTS with 88 simulations using 6 processes.
2025-01-16 11:46:49,676 - DEBUG - Aggregated action counts: {1: 3, 6: 1, 2: 1, 0: 2}
2025-01-16 11:46:49,676 - DEBUG - Chose best action 1
2025-01-16 11:46:49,723 - INFO - Episode 1974/100000: Winner=2, Reward=-1.00, EPSILON=0.982, (W=1973,D=1,L=0)
2025-01-16 11:46:49,864 - INFO - Episode 1975/100000: Winner=2, Reward=-2.80, EPSILON=0.982, (W=1974,D=1,L=0)
2025-01-16 11:46:50,067 - INFO - Episode 1976/100000: Winner=2, Reward=5.05, EPSILON=0.982, (W=1975,D=1,L=0)
2025-01-16 11:46:50,223 - INFO - Episode 1977/100000: Winner=2, Reward=12.40, EPSILON=0.982, (W=1976,D=1,L=0)
2025-01-16 11:46:50,426 - INFO - Episode 1978/100000: Winner=2, Reward=-9.65, EPSILON=0.982, (W=1977,D=1,L=0)
2025-01-16 11:46:50,629 - INFO - Episode 1979/100000: Winner=2, Reward=-1.60, EPSILON=0.982, (W=1978,D=1,L=0)
2025-01-16 11:46:50,723 - INFO - Episode 1980/100000: Winner=2, Reward=0.55, EPSILON=0.982, (W=1979,D=1,L=0)
2025-01-16 11:46:50,895 - INFO - Episode 1981/100000: Winner=2, Reward=2.30, EPSILON=0.982, (W=1980,D=1,L=0)
2025-01-16 11:46:51,098 - INFO - Episode 1982/100000: Winner=2, Reward=11.50, EPSILON=0.982, (W=1981,D=1,L=0)
2025-01-16 11:46:51,192 - DEBUG - Q-vals = [5.8254278e-01 3.3560093e-02 1.8373888e-05 3.8817983e-02 1.7648678e-01
 1.5321569e-01 1.5358368e-02], best_act=0, best_val=0.583
2025-01-16 11:46:51,192 - DEBUG - Low Q-value (0.583), using MCTS.
2025-01-16 11:46:51,192 - INFO - Running MCTS with 89 simulations using 6 processes.
2025-01-16 11:46:54,348 - DEBUG - Aggregated action counts: {0: 2, 5: 3, 4: 1, 2: 1}
2025-01-16 11:46:54,348 - DEBUG - Chose best action 5
2025-01-16 11:46:54,410 - INFO - Episode 1983/100000: Winner=2, Reward=-3.30, EPSILON=0.982, (W=1982,D=1,L=0)
2025-01-16 11:46:54,660 - INFO - Episode 1984/100000: Winner=2, Reward=-14.00, EPSILON=0.982, (W=1983,D=1,L=0)
2025-01-16 11:46:54,785 - INFO - Episode 1985/100000: Winner=2, Reward=3.00, EPSILON=0.982, (W=1984,D=1,L=0)
2025-01-16 11:46:54,973 - INFO - Episode 1986/100000: Winner=2, Reward=-5.30, EPSILON=0.982, (W=1985,D=1,L=0)
2025-01-16 11:46:55,098 - INFO - Episode 1987/100000: Winner=2, Reward=9.90, EPSILON=0.982, (W=1986,D=1,L=0)
2025-01-16 11:46:55,113 - DEBUG - Q-vals = [0.91915303 0.00380517 0.00390814 0.00670044 0.05077379 0.01083948
 0.00481993], best_act=0, best_val=0.919
2025-01-16 11:46:55,113 - DEBUG - Low Q-value (0.919), using MCTS.
2025-01-16 11:46:55,113 - INFO - Running MCTS with 89 simulations using 6 processes.
2025-01-16 11:46:58,425 - DEBUG - Aggregated action counts: {0: 2, 2: 2, 1: 1, 3: 2}
2025-01-16 11:46:58,425 - DEBUG - Chose best action 0
2025-01-16 11:46:58,738 - INFO - Episode 1988/100000: Winner=2, Reward=18.95, EPSILON=0.982, (W=1987,D=1,L=0)
2025-01-16 11:46:58,988 - INFO - Episode 1989/100000: Winner=2, Reward=-18.45, EPSILON=0.982, (W=1988,D=1,L=0)
2025-01-16 11:46:59,081 - DEBUG - Q-vals = [0.05209615 0.06694742 0.15937546 0.04688835 0.3942106  0.13700347
 0.14347848], best_act=4, best_val=0.394
2025-01-16 11:46:59,081 - DEBUG - Low Q-value (0.394), using MCTS.
2025-01-16 11:46:59,081 - INFO - Running MCTS with 89 simulations using 6 processes.
2025-01-16 11:47:02,378 - DEBUG - Aggregated action counts: {0: 3, 3: 1, 6: 1, 1: 1, 4: 1}
2025-01-16 11:47:02,378 - DEBUG - Chose best action 0
2025-01-16 11:47:02,488 - INFO - Episode 1990/100000: Winner=2, Reward=12.95, EPSILON=0.982, (W=1989,D=1,L=0)
2025-01-16 11:47:02,675 - INFO - Episode 1991/100000: Winner=2, Reward=12.55, EPSILON=0.982, (W=1990,D=1,L=0)
2025-01-16 11:47:02,878 - INFO - Episode 1992/100000: Winner=2, Reward=23.25, EPSILON=0.982, (W=1991,D=1,L=0)
2025-01-16 11:47:03,003 - INFO - Episode 1993/100000: Winner=2, Reward=9.85, EPSILON=0.982, (W=1992,D=1,L=0)
2025-01-16 11:47:03,206 - INFO - Episode 1994/100000: Winner=2, Reward=12.55, EPSILON=0.982, (W=1993,D=1,L=0)
2025-01-16 11:47:03,347 - INFO - Episode 1995/100000: Winner=2, Reward=3.15, EPSILON=0.982, (W=1994,D=1,L=0)
2025-01-16 11:47:03,503 - INFO - Episode 1996/100000: Winner=2, Reward=2.35, EPSILON=0.982, (W=1995,D=1,L=0)
2025-01-16 11:47:03,675 - INFO - Episode 1997/100000: Winner=2, Reward=14.80, EPSILON=0.982, (W=1996,D=1,L=0)
2025-01-16 11:47:03,769 - INFO - Episode 1998/100000: Winner=2, Reward=-5.45, EPSILON=0.982, (W=1997,D=1,L=0)
2025-01-16 11:47:03,878 - INFO - Episode 1999/100000: Winner=2, Reward=1.30, EPSILON=0.982, (W=1998,D=1,L=0)
2025-01-16 11:47:04,143 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2000.
2025-01-16 11:47:04,143 - INFO - Models saved at episode 2000
2025-01-16 11:47:04,143 - INFO - Target networks updated
2025-01-16 11:47:04,206 - INFO - Saved model checkpoint to Connect4_Agent_Model.pth at episode 2000.
2025-01-16 11:47:04,206 - INFO - Episode 2000/100000: Winner=2, Reward=7.75, EPSILON=0.982, (W=1999,D=1,L=0)
2025-01-16 11:47:04,347 - INFO - Episode 2001/100000: Winner=2, Reward=24.80, EPSILON=0.982, (W=2000,D=1,L=0)
2025-01-16 11:47:04,675 - INFO - Episode 2002/100000: Winner=2, Reward=-10.20, EPSILON=0.982, (W=2001,D=1,L=0)
2025-01-16 11:47:04,846 - INFO - Episode 2003/100000: Winner=2, Reward=17.95, EPSILON=0.982, (W=2002,D=1,L=0)
2025-01-16 11:47:05,034 - INFO - Episode 2004/100000: Winner=2, Reward=11.10, EPSILON=0.982, (W=2003,D=1,L=0)
2025-01-16 11:47:05,206 - INFO - Episode 2005/100000: Winner=2, Reward=-7.10, EPSILON=0.982, (W=2004,D=1,L=0)
2025-01-16 11:47:05,299 - INFO - Episode 2006/100000: Winner=2, Reward=-6.50, EPSILON=0.982, (W=2005,D=1,L=0)
2025-01-16 11:47:05,409 - INFO - Episode 2007/100000: Winner=2, Reward=2.25, EPSILON=0.982, (W=2006,D=1,L=0)
2025-01-16 11:47:05,518 - INFO - Episode 2008/100000: Winner=2, Reward=-4.85, EPSILON=0.982, (W=2007,D=1,L=0)
2025-01-16 11:47:05,784 - INFO - Episode 2009/100000: Winner=2, Reward=-7.40, EPSILON=0.982, (W=2008,D=1,L=0)
2025-01-16 11:47:05,893 - INFO - Episode 2010/100000: Winner=2, Reward=-6.80, EPSILON=0.982, (W=2009,D=1,L=0)
2025-01-16 11:47:06,065 - INFO - Episode 2011/100000: Winner=2, Reward=-6.70, EPSILON=0.982, (W=2010,D=1,L=0)
2025-01-16 11:47:06,315 - INFO - Episode 2012/100000: Winner=2, Reward=13.45, EPSILON=0.982, (W=2011,D=1,L=0)
2025-01-16 11:47:06,643 - INFO - Episode 2013/100000: Winner=2, Reward=1.35, EPSILON=0.982, (W=2012,D=1,L=0)
2025-01-16 11:47:06,737 - INFO - Episode 2014/100000: Winner=2, Reward=8.80, EPSILON=0.982, (W=2013,D=1,L=0)
2025-01-16 11:47:07,002 - INFO - Episode 2015/100000: Winner=2, Reward=21.60, EPSILON=0.982, (W=2014,D=1,L=0)
2025-01-16 11:47:07,330 - INFO - Episode 2016/100000: Winner=2, Reward=32.10, EPSILON=0.982, (W=2015,D=1,L=0)
2025-01-16 11:47:07,471 - DEBUG - Q-vals = [0.23069656 0.14683668 0.2337911  0.0038019  0.27182335 0.04768062
 0.06536976], best_act=4, best_val=0.272
2025-01-16 11:47:07,471 - DEBUG - Low Q-value (0.272), using MCTS.
2025-01-16 11:47:07,471 - INFO - Episode 2017/100000: Winner=2, Reward=-5.05, EPSILON=0.982, (W=2016,D=1,L=0)
2025-01-16 11:47:07,596 - INFO - Episode 2018/100000: Winner=2, Reward=1.45, EPSILON=0.982, (W=2017,D=1,L=0)
2025-01-16 11:47:07,830 - INFO - Episode 2019/100000: Winner=2, Reward=-9.25, EPSILON=0.982, (W=2018,D=1,L=0)
2025-01-16 11:47:08,127 - INFO - Episode 2020/100000: Winner=2, Reward=4.05, EPSILON=0.982, (W=2019,D=1,L=0)
2025-01-16 11:47:08,314 - INFO - Episode 2021/100000: Winner=2, Reward=-12.10, EPSILON=0.982, (W=2020,D=1,L=0)
2025-01-16 11:47:08,408 - INFO - Episode 2022/100000: Winner=2, Reward=0.60, EPSILON=0.982, (W=2021,D=1,L=0)
2025-01-16 11:47:08,564 - DEBUG - Q-vals = [0.13362794 0.17945355 0.12315761 0.03710226 0.35746983 0.11742079
 0.05176806], best_act=4, best_val=0.357
2025-01-16 11:47:08,564 - DEBUG - Low Q-value (0.357), using MCTS.
2025-01-16 11:47:08,564 - INFO - Running MCTS with 90 simulations using 6 processes.
2025-01-16 11:47:11,924 - DEBUG - Aggregated action counts: {3: 1, 2: 1, 0: 3, 5: 1}
2025-01-16 11:47:11,924 - DEBUG - Chose best action 0
2025-01-16 11:47:12,095 - INFO - Episode 2023/100000: Winner=2, Reward=-26.85, EPSILON=0.982, (W=2022,D=1,L=0)
2025-01-16 11:47:12,315 - INFO - Episode 2024/100000: Winner=2, Reward=-3.35, EPSILON=0.982, (W=2023,D=1,L=0)
2025-01-16 11:47:12,408 - INFO - Episode 2025/100000: Winner=2, Reward=-7.25, EPSILON=0.982, (W=2024,D=1,L=0)
2025-01-16 11:47:12,580 - INFO - Episode 2026/100000: Winner=2, Reward=25.30, EPSILON=0.982, (W=2025,D=1,L=0)
2025-01-16 11:47:12,768 - INFO - Episode 2027/100000: Winner=2, Reward=15.70, EPSILON=0.982, (W=2026,D=1,L=0)
2025-01-16 11:47:12,877 - DEBUG - Q-vals = [7.9046522e-04 2.6671600e-04 7.8513217e-01 2.2475036e-04 3.6422987e-02
 1.7709221e-01 7.0754977e-05], best_act=2, best_val=0.785
2025-01-16 11:47:12,877 - DEBUG - Low Q-value (0.785), using MCTS.
2025-01-16 11:47:12,877 - INFO - Running MCTS with 91 simulations using 6 processes.
2025-01-16 11:47:16,095 - DEBUG - Aggregated action counts: {0: 4, 1: 1, 3: 2}
2025-01-16 11:47:16,095 - DEBUG - Chose best action 0
2025-01-16 11:47:16,236 - INFO - Episode 2028/100000: Winner=2, Reward=15.20, EPSILON=0.982, (W=2027,D=1,L=0)
2025-01-16 11:47:16,408 - INFO - Episode 2029/100000: Winner=2, Reward=-0.65, EPSILON=0.982, (W=2028,D=1,L=0)
2025-01-16 11:47:16,689 - INFO - Episode 2030/100000: Winner=2, Reward=-6.15, EPSILON=0.982, (W=2029,D=1,L=0)
2025-01-16 11:47:16,846 - INFO - Episode 2031/100000: Winner=2, Reward=12.25, EPSILON=0.982, (W=2030,D=1,L=0)
2025-01-16 11:47:16,955 - DEBUG - Q-vals = [0.17879161 0.04967866 0.00358049 0.00313882 0.51455975 0.11505516
 0.1351955 ], best_act=4, best_val=0.515
2025-01-16 11:47:16,955 - DEBUG - Low Q-value (0.515), using MCTS.
2025-01-16 11:47:16,971 - INFO - Episode 2032/100000: Winner=2, Reward=-6.30, EPSILON=0.982, (W=2031,D=1,L=0)
2025-01-16 11:47:17,189 - INFO - Episode 2033/100000: Winner=2, Reward=-8.95, EPSILON=0.982, (W=2032,D=1,L=0)
2025-01-16 11:47:17,377 - INFO - Episode 2034/100000: Winner=2, Reward=9.20, EPSILON=0.982, (W=2033,D=1,L=0)
2025-01-16 11:47:17,689 - INFO - Episode 2035/100000: Winner=2, Reward=-0.75, EPSILON=0.982, (W=2034,D=1,L=0)
2025-01-16 11:47:17,861 - INFO - Episode 2036/100000: Winner=2, Reward=-2.50, EPSILON=0.982, (W=2035,D=1,L=0)
2025-01-16 11:47:17,955 - INFO - Episode 2037/100000: Winner=2, Reward=9.25, EPSILON=0.982, (W=2036,D=1,L=0)
2025-01-16 11:47:18,111 - INFO - Episode 2038/100000: Winner=2, Reward=4.80, EPSILON=0.982, (W=2037,D=1,L=0)
2025-01-16 11:47:18,173 - INFO - Episode 2039/100000: Winner=2, Reward=0.60, EPSILON=0.982, (W=2038,D=1,L=0)
2025-01-16 11:47:18,376 - INFO - Episode 2040/100000: Winner=2, Reward=8.60, EPSILON=0.982, (W=2039,D=1,L=0)
2025-01-16 11:47:18,705 - INFO - Episode 2041/100000: Winner=2, Reward=28.95, EPSILON=0.982, (W=2040,D=1,L=0)
2025-01-16 11:47:18,861 - INFO - Episode 2042/100000: Winner=2, Reward=24.00, EPSILON=0.982, (W=2041,D=1,L=0)
2025-01-16 11:47:19,111 - INFO - Episode 2043/100000: Winner=2, Reward=6.15, EPSILON=0.982, (W=2042,D=1,L=0)
2025-01-16 11:47:19,220 - DEBUG - Q-vals = [9.8143309e-02 1.5673380e-02 2.1225031e-01 9.8211467e-02 3.1765759e-01
 2.5775236e-01 3.1157784e-04], best_act=4, best_val=0.318
2025-01-16 11:47:19,220 - DEBUG - Low Q-value (0.318), using MCTS.
2025-01-16 11:47:19,220 - INFO - Running MCTS with 91 simulations using 6 processes.
2025-01-16 11:47:22,126 - DEBUG - Aggregated action counts: {5: 2, 4: 1, 3: 2, 6: 1, 0: 1}
2025-01-16 11:47:22,126 - DEBUG - Chose best action 5
2025-01-16 11:47:22,251 - INFO - Episode 2044/100000: Winner=2, Reward=4.30, EPSILON=0.982, (W=2043,D=1,L=0)
2025-01-16 11:47:22,283 - DEBUG - Q-vals = [0.30683178 0.3510591  0.04854108 0.03392548 0.02361641 0.21931623
 0.01670982], best_act=1, best_val=0.351
2025-01-16 11:47:22,283 - DEBUG - Low Q-value (0.351), using MCTS.
2025-01-16 11:47:22,283 - INFO - Running MCTS with 91 simulations using 6 processes.
2025-01-16 11:47:25,189 - DEBUG - Aggregated action counts: {0: 4, 4: 1, 1: 1, 2: 1}
2025-01-16 11:47:25,189 - DEBUG - Chose best action 0
2025-01-16 11:47:25,220 - INFO - Episode 2045/100000: Winner=2, Reward=8.55, EPSILON=0.982, (W=2044,D=1,L=0)
2025-01-16 11:47:25,424 - DEBUG - Q-vals = [2.8934570e-02 2.6770684e-01 4.9257204e-02 1.6356664e-03 8.9137787e-03
 3.7310172e-05 6.4351463e-01], best_act=6, best_val=0.644
2025-01-16 11:47:25,424 - DEBUG - Low Q-value (0.644), using MCTS.
2025-01-16 11:47:25,439 - INFO - Episode 2046/100000: Winner=2, Reward=-3.35, EPSILON=0.982, (W=2045,D=1,L=0)
2025-01-16 11:47:25,720 - DEBUG - Q-vals = [2.42732372e-02 1.08520456e-01 1.09278737e-02 3.90223340e-06
 8.74242323e-05 4.09610057e-03 8.52091074e-01], best_act=1, best_val=0.109
2025-01-16 11:47:25,720 - DEBUG - Low Q-value (0.109), using MCTS.
2025-01-16 11:47:25,736 - INFO - Episode 2047/100000: Winner=2, Reward=0.40, EPSILON=0.982, (W=2046,D=1,L=0)
2025-01-16 11:47:25,861 - INFO - Episode 2048/100000: Winner=2, Reward=18.05, EPSILON=0.982, (W=2047,D=1,L=0)
2025-01-16 11:47:26,189 - INFO - Episode 2049/100000: Winner=2, Reward=-13.80, EPSILON=0.982, (W=2048,D=1,L=0)
2025-01-16 11:47:26,314 - INFO - Episode 2050/100000: Winner=2, Reward=-6.60, EPSILON=0.982, (W=2049,D=1,L=0)
2025-01-16 11:47:26,502 - INFO - Episode 2051/100000: Winner=2, Reward=-13.20, EPSILON=0.982, (W=2050,D=1,L=0)
2025-01-16 11:47:26,689 - INFO - Episode 2052/100000: Winner=2, Reward=6.85, EPSILON=0.982, (W=2051,D=1,L=0)
2025-01-16 11:47:26,845 - INFO - Episode 2053/100000: Winner=2, Reward=-9.75, EPSILON=0.982, (W=2052,D=1,L=0)
2025-01-16 11:47:26,861 - DEBUG - Q-vals = [0.05286843 0.05277181 0.03855982 0.04741419 0.06031135 0.6492372
 0.09883719], best_act=5, best_val=0.649
2025-01-16 11:47:26,861 - DEBUG - Low Q-value (0.649), using MCTS.
2025-01-16 11:47:26,861 - INFO - Running MCTS with 92 simulations using 6 processes.
2025-01-16 11:47:29,735 - DEBUG - Aggregated action counts: {3: 1, 5: 1, 2: 2, 6: 1, 1: 1, 0: 1}
2025-01-16 11:47:29,735 - DEBUG - Chose best action 2
2025-01-16 11:47:29,969 - INFO - Episode 2054/100000: Winner=2, Reward=-12.80, EPSILON=0.982, (W=2053,D=1,L=0)
2025-01-16 11:47:30,157 - INFO - Episode 2055/100000: Winner=2, Reward=-4.50, EPSILON=0.982, (W=2054,D=1,L=0)
2025-01-16 11:47:30,469 - INFO - Episode 2056/100000: Winner=2, Reward=10.05, EPSILON=0.982, (W=2055,D=1,L=0)
2025-01-16 11:47:30,704 - INFO - Episode 2057/100000: Winner=2, Reward=14.65, EPSILON=0.982, (W=2056,D=1,L=0)
2025-01-16 11:47:30,954 - INFO - Episode 2058/100000: Winner=2, Reward=-7.55, EPSILON=0.982, (W=2057,D=1,L=0)
2025-01-16 11:47:31,094 - INFO - Episode 2059/100000: Winner=2, Reward=5.45, EPSILON=0.982, (W=2058,D=1,L=0)
2025-01-16 11:47:31,266 - INFO - Episode 2060/100000: Winner=2, Reward=-10.50, EPSILON=0.982, (W=2059,D=1,L=0)
2025-01-16 11:47:31,485 - DEBUG - Q-vals = [0.01456884 0.04700729 0.5121882  0.3042427  0.09860862 0.0178158
 0.00556849], best_act=2, best_val=0.512
2025-01-16 11:47:31,485 - DEBUG - Low Q-value (0.512), using MCTS.
2025-01-16 11:47:31,485 - INFO - Episode 2061/100000: Winner=2, Reward=-9.25, EPSILON=0.982, (W=2060,D=1,L=0)
2025-01-16 11:47:31,641 - INFO - Episode 2062/100000: Winner=2, Reward=2.15, EPSILON=0.982, (W=2061,D=1,L=0)
2025-01-16 11:47:31,782 - INFO - Episode 2063/100000: Winner=2, Reward=-7.50, EPSILON=0.982, (W=2062,D=1,L=0)
2025-01-16 11:47:31,844 - DEBUG - Q-vals = [0.12552267 0.08821202 0.11672694 0.16234395 0.37239656 0.0938473
 0.04095056], best_act=4, best_val=0.372
2025-01-16 11:47:31,844 - DEBUG - Low Q-value (0.372), using MCTS.
2025-01-16 11:47:31,844 - INFO - Running MCTS with 92 simulations using 6 processes.
