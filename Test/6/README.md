#Change from 5
#Trainer use logic-based and MCTS
#Trainer Skip training and not using DQN
#Model use Q-Learning and Random
#More model(agent2) wins means better performance
#Archived the double 3 in row since it is not working
#Less MCTS computation More weight on Q-Values